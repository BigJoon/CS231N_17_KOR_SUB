1
00:00:08,691 --> 00:00:15,430
안녕하세요. 진행하도록 하겠습니다.
CS231N 11강입니다.

2
00:00:15,430 --> 00:00:23,259
오늘은 Detection과 Segmentation등 아주 재미있는
Compuver Vision task들을 소개해 드리겠습니다.

3
00:00:23,259 --> 00:00:25,590
수업에 앞서 공지사항을 전달해 드리겠습니다.

4
00:00:25,590 --> 00:00:31,358
지난 시간에는 수업 대신 중간고사가 있었습니다.

5
00:00:31,358 --> 00:00:42,270
하지만 아직은 시험에 관한 이야기들은
삼가해 주시기 바랍니다.

6
00:00:42,270 --> 00:00:48,518
아직 시험을 치루지 않은 학생들이 있습니다.

7
00:00:48,518 --> 00:00:53,668
중간고사 문제와 관련된 이야기들은 
되도록이면 삼가해 주시기 바랍니다.

8
00:00:56,329 --> 00:01:02,062
월요일까지만 참아주세요. [웃음] 
좋습니다.

9
00:01:02,921 --> 00:01:07,761
현재 중간고사 채점을 진행 중입니다. 
최대한 빨리 결과를 알려드리도록 하겠습니다.

10
00:01:07,761 --> 00:01:14,079
그리고 과제 2도 채점 중입니다. 이번 주에 거의 완료된 
상태입니다. TA들이 아주 바쁩니다.

11
00:01:14,079 --> 00:01:18,479
그리고 모두들 프로젝트를 열심히 진행해 주시고 있습니다.

12
00:01:18,479 --> 00:01:26,970
그리고 대부분 중간고사를 마쳤으므로 화요일까지는
프로젝트 마일스톤을 제출해 주시기 바랍니다.

13
00:01:26,970 --> 00:01:31,650
일부 인원들이 프로젝트 계획서 제출 이후에 프로젝트를 
변경하거나, 팀원이 변경된 경우가 있었습니다.

14
00:01:31,650 --> 00:01:39,677
이번에 제출하는 마일스톤에 남은 학기동안
진행할 사항들을 반드시 반영시켜 주시기 바랍니다.

15
00:01:39,677 --> 00:01:43,900
그리고 Piazza에 많은 분들이 과제2에 대한 문의를 남겨주셨습니다.

16
00:01:43,900 --> 00:01:50,189
과제3은 작년과 내용이 조금 변경되어
현재 열심히 작업 중에 있습니다.

17
00:01:50,189 --> 00:01:53,951
과제3은 아마도 오늘, 내일쯤 확인하실 수 있을 것입니다.

18
00:01:53,951 --> 00:02:01,551
과제 제출기한은 출제일로부터 2주이므로 
너무 걱적하지 않으셔도 됩니다.

19
00:02:01,551 --> 00:02:09,079
과제3에는 아주 흥미 진진한 내용들이 담겨 있으니
기대해 주시기 바랍니다.

20
00:02:09,079 --> 00:02:13,340
그리고 지난 강의에 "Train Game" 에 대해
말씀드린 적이 있습니다.

21
00:02:13,340 --> 00:02:17,780
Train Game은 우리가 현재 Side Project로 진행중입니다.

22
00:02:17,780 --> 00:02:27,340
Train Game은 실제 문제를 가지고 하이퍼파라미터를 조정하면서
학습시켜 볼 수 있는 반응형 도구입니다.

23
00:02:27,340 --> 00:02:37,963
Train Game을 하는 것이 필수는 아니지만 참여자에 한해서
소량의 extra credit을 지급할 예정입니다.

24
00:02:37,963 --> 00:02:42,224
자세한 사항은 오후 중으로 Piazza에 다시 공지하겠습니다.

25
00:02:42,224 --> 00:02:51,752
Train Game이 무엇인지 간략한 Demo를 보여드리겠습니다. 
실제 이름은 HyperQuest 입니다.

26
00:02:51,752 --> 00:02:54,464
모델에 가장 적합한 하이퍼파라미터를 
찾는 게임이라서 붙혀진 이름입니다.

27
00:02:54,464 --> 00:03:01,254
HyperQuest은 브라우저 환경에서 하이퍼파라미터를
조절해가며 모델을 학습시킬 수 있는 아주 멋있는 툴입니다.

28
00:03:01,254 --> 00:03:04,871
우선 Student ID와 Name으로 로그인합니다.

29
00:03:04,871 --> 00:03:08,830
그리고 여러분의 딥러닝 지식에 관한
몇 가지 설문조사를 수행합니다.

30
00:03:08,830 --> 00:03:16,152
그리고 몇 가지 지시사항이 있습니다.
여러분은 매 시도마다 임의의 데이터를 부여받습니다.

31
00:03:16,152 --> 00:03:21,494
데이터셋은 이미지이거나 벡터일 수도 있습니다. 
HyperQuest에서 여러분이 해야 할 일은

32
00:03:21,494 --> 00:03:28,077
적절한 하이퍼파라미터를 선택해서 모델을 학습시키고 
Tran/Validation Set의 성능을 높히는 것입니다.

33
00:03:28,077 --> 00:03:33,423
Leaderboard도 제공됩니다.

34
00:03:33,423 --> 00:03:38,723
게임을 시작하면 여러분께 데이터셋에 관련된
간단한 통계들을 알려드립니다.

35
00:03:38,723 --> 00:03:42,397
가령 이 예제에서는 클래스 10개를 분류해야하는
Classification 문제입니다.

36
00:03:43,424 --> 00:03:47,774
아래 임의의 데이터셋에 대한 통계가 있습니다.
클래스는 10가지 이고

37
00:03:47,774 --> 00:03:52,987
그리고 입력 데이터는 3 x 32 x 32 이미지 데이터입니다.

38
00:03:52,987 --> 00:03:58,832
그리고 Train Set 8500개 
Validation Set 1500 개가 있습니다.

39
00:03:58,832 --> 00:04:01,518
이들은 모두 임의로 결정되며 
매번 조금씩 바뀝니다.

40
00:04:01,518 --> 00:04:08,931
이 통계정보를 바탕으로 Init Learning rate, 네트워크 사이즈, 
Init Dropout rate를 결정하시면 됩니다.

41
00:04:08,931 --> 00:04:13,811
설정이 끝나면 이 화면을 보실 수 있습니다. 
모델은 선택된 하이퍼파라미터로 1 epoch 학습이 진행됩니다.

42
00:04:13,811 --> 00:04:21,040
그리고 오른쪽 아래에 두 개의 그래프가 있습니다. 
하나는 1 epoch 이후의 Train/Validation Loss 입니다.

43
00:04:21,040 --> 00:04:23,409
그리고 다른 하나는 Train/Validation Accuracy 입니다.

44
00:04:23,409 --> 00:04:26,280
그 첫 번째 신기원과 당신이 본 격차에 근거하여

45
00:04:26,280 --> 00:04:32,290
이 그래프를 보시고 다음 Epoch의 하이퍼 파라미터를
적절하게 조절하시면 되겠습니다.

46
00:04:32,290 --> 00:04:37,803
분석이 끝나면 기존의 또는 변경된 하이퍼파라미터로
학습을 계속 진행시키거나

47
00:04:37,803 --> 00:04:43,872
학습을 끝내거나, 혹은 뭔가 잘못 되었을 시에 
기존의 체크포인트로 돌아갈 수도 있습니다.

48
00:04:43,872 --> 00:04:54,971
학습을 계속한다면, 이런 식으로 다음 Epoch을 위해서 
하이퍼파라미터를 새롭게 조정할 수 있습니다.

49
00:04:54,971 --> 00:05:01,899
그리고 흥미롭게도 학습 도중에도 
네트워크의 크기를 조절할 수 있습니다.

50
00:05:01,899 --> 00:05:07,562
여기에는 최근 발표된 논문들의 기법들이 적용되었습니다.

51
00:05:07,562 --> 00:05:15,762
학습 도중에 네트워크의 기존 레이어들은 유지시키고 
레이어를 넓히거나 새로운 레이어를 추가할 수 있습니다.

52
00:05:15,762 --> 00:05:20,131
이 방법을 이용해서 여러분도 학습 도중에
네트워크의 크기를 변경할 수 있습니다.

53
00:05:20,131 --> 00:05:33,072
학습이 끝나면 최종 Validation accuracy가 leaderboard
에 기록되며, baseline models과 비교해 보실 수 있습니다.

54
00:05:33,072 --> 00:05:39,774
HyperQuest에 참여하여 Leaderboard에 좋은 성능을 기록하시면
소량의 Extra credit을 드릴 예정입니다.

55
00:05:39,774 --> 00:05:42,322
다시한번 말씀드리지만 선택사항입니다.

56
00:05:42,322 --> 00:05:49,243
하지만 여러분에게는 하이퍼파라미터가 학습과정에 어떤 영향을
미치는지 알아볼 수 있는 아주 좋은 경험이 될 것입니다.

57
00:05:49,243 --> 00:05:54,872
이는 저희에게도 도움이 됩니다. 
여러분이 실험이 참여하므로써 얻는 것들이 있습니다.

58
00:05:54,872 --> 00:06:04,422
저희는 사람들이 Neural Network를 학습시킬 때의 행동양상에
대한 관심이 많습니다. 여러분들의 결정이 도움이 될 것입니다.

59
00:06:04,422 --> 00:06:08,462
하지만 선택사항입니다.

60
00:06:08,462 --> 00:06:10,295
질문 있으십니까?
[학생이 질문]

61
00:06:15,080 --> 00:06:20,272
질문은 "이 실험이 논문으로 쓰여지는지" 입니다.

62
00:06:20,272 --> 00:06:29,510
희망사항입니다. 하지만 아직 실험의 초기단계라서
장담할 수는 없습니다. 그렇게 됐으면 좋겠군요

63
00:06:33,240 --> 00:06:35,000
[웃음]

64
00:06:35,000 --> 00:06:37,971
질문은 "학습 도중에 어떻게 레이어를 추가하는지"
입니다.

65
00:06:37,971 --> 00:06:45,291
지금 깊이있는 설명은 해드릴 수 없지만, 해당 논문은 
Ian Goodfello가 저자로 들어간 Net2Net 이라는 논문입니다.

66
00:06:45,291 --> 00:06:48,240
또 하나는 Microsoft의 Network Morphism 
이라는 논문입니다.

67
00:06:48,240 --> 00:06:52,407
이 두 논문을 보시면 어떻게 동작하는지
살펴보실 수 있을 것입니다.

68
00:06:53,680 --> 00:06:59,792
좋습니다. 이제 수업을 진행하겠습니다. 지난 시간에
Recurrent Neural Networks를 소개했습니다.

69
00:06:59,792 --> 00:07:03,032
RNN을 이용해서 다양한 문제를 시도해 볼 수 있었습니다.

70
00:07:03,032 --> 00:07:07,192
"one to one", "one to many", "many to one",
그리고 "many to many" 가 있었죠

71
00:07:07,192 --> 00:07:10,679
RNN은 Language modeling에 적용해 보았습니다.

72
00:07:10,679 --> 00:07:15,460
RNN으로 다양한 Character level Language model을
구축해서 다양한 시도를 해보았습니다.

73
00:07:15,460 --> 00:07:20,571
그리고 수학 수식, 셰익스피어, C 소스코드
등을 샘플링해 보았습니다.

74
00:07:20,571 --> 00:07:31,011
그리고 CNN feature extracter와 RNN Language 
model 을 결합한 Image caption 문제도 살펴보았습니다.

75
00:07:31,011 --> 00:07:36,040
그리고 다양한 종류의 RNN을 살펴보았습니다. 
Vanilla RNN이 있었죠

76
00:07:36,040 --> 00:07:42,331
Vanilla RNN은 문헌에 따라 Simple RNN 혹은
Elman RNN이라고도 합니다.

77
00:07:42,331 --> 00:07:44,997
그리고 LSTM도 배웠습니다. 
Long Short Term Memory 입니다.

78
00:07:44,997 --> 00:07:59,443
수식은 복잡했지만, 이로인해 backprop 시 그레디언트를 더 잘 
전달할 수 있었고 더 긴 시퀀스도 잘 학습할 수 있었습니다.

79
00:07:59,443 --> 00:08:03,982
오늘은 주제를 조금 바꿔보고자 합니다. 
다양한 재미있는 Tasks를 소개해 드리고자합니다.

80
00:08:03,982 --> 00:08:08,992
지금까지는 image classification 문제를 위주로 다뤘습니다.

81
00:08:08,992 --> 00:08:13,262
오늘은 다양한 Computer Vision Tasks를 다뤄볼 예정입니다.

82
00:08:13,262 --> 00:08:21,942
Segmentation, Localization, Detection 등 다양한
Computer Vision Tasks와

83
00:08:21,942 --> 00:08:25,494
이 문제들을 CNN으로 어떻게 접근해 볼 수
있을지에 대해서 다룰 예정입니다.

84
00:08:25,494 --> 00:08:32,163
잠시 주제를 환기시켜 보겠습니다. 이 수업에서는 주로 
Image Classification 문제를 다룹니다.

85
00:08:32,163 --> 00:08:36,583
입력 이미지가 들어오면 Deep Conv Net을 통과합니다.

86
00:08:36,583 --> 00:08:42,991
네트워크를 통과하면 Feature Vector가 나옵니다. 
가령 AlexNet이나 VGG의 경우 4096 차원이었죠

87
00:08:42,991 --> 00:08:50,568
그리고 최종 Fully Connected Layer는 
1000개의 클래스 스코어를 나타냅니다.

88
00:08:50,568 --> 00:08:55,660
이 예제에서는 1000개의 클래스는
ImageNet의 클래스를 의미하죠

89
00:08:55,660 --> 00:09:05,083
다시 말해, 입력 이미지가 들어오면
"전체 이미지"가 속하는 카테고리가 출력입니다.

90
00:09:05,083 --> 00:09:14,314
Image Classification은 아주 기본적인 Task입니다. 
Deep Learning으로 더 흥미로운 것들이 가능할지 모릅니다.

91
00:09:14,314 --> 00:09:21,515
오늘은 그 흥미로운 것들 중 몇 가지를 다룰 것입니다. 
이들이 Deep Learning으로 어떻게 동작하는지 살펴보겠습니다.

92
00:09:21,515 --> 00:09:28,852
더 자세히 들어가기 전에 
요약 슬라이드를 먼저 살펴보겠습니다.

93
00:09:28,852 --> 00:09:31,480
우선 Semantic Segmentation에 대해 배울 것입니다.

94
00:09:31,480 --> 00:09:35,153
그리고 Classification + Localization 과
Object Detection에 대해서도 알아보겠습니다.

95
00:09:35,153 --> 00:09:39,086
그리고 Instance Segmentation도 간단하게 알아보겠습니다.

96
00:09:39,967 --> 00:09:44,035
우선 Sementic Segmentation 입니다.

97
00:09:44,035 --> 00:09:52,567
Sementic Segmentation 문제에서는 입력은 이미지이고
출력으로 이미지의 모든 픽셀에 카테고리를 정합니다.

98
00:09:52,567 --> 00:09:58,327
가령 이 예제의 경우는 입력이 고양이입니다.
아주 귀엽네요

99
00:09:58,327 --> 00:10:07,701
출력은 모든 픽셀에 대해서 그 픽셀이 
"고양이, 잔디, 하늘, 나무, 배경"인지를 결정하는 것이죠

100
00:10:07,701 --> 00:10:09,490
그래서 우리는 몇 가지 카테고리를 가질 것입니다.

101
00:10:09,490 --> 00:10:11,922
이미지 분류의 경우처럼

102
00:10:11,922 --> 00:10:13,829
하지만 지금은 하나의 카테고리를 할당하는 것보다

103
00:10:13,829 --> 00:10:15,820
전체 이미지에 레이블이 지정되면

104
00:10:15,820 --> 00:10:19,569
입력 이미지의 각 픽셀에 대한 범주 레이블

105
00:10:19,569 --> 00:10:22,674
그리고이를 의미 론적 세분화 (semantic segmentation)라고합니다.

106
00:10:22,674 --> 00:10:25,086
의미 론적 세분화에 대한 흥미로운 점이 하나 있습니다.

107
00:10:25,086 --> 00:10:27,340
인스턴스를 구별하지 않는다는 것입니다.

108
00:10:27,340 --> 00:10:29,769
오른쪽의이 예에서는이 이미지가 있습니다.

109
00:10:29,769 --> 00:10:31,523
그들이 바로 옆에 서있는 두 마리의 젖소들과

110
00:10:31,523 --> 00:10:34,031
우리는 서로 의미 론적으로 이야기 할 때

111
00:10:34,031 --> 00:10:36,859
세분화 우리는 단지 모든 픽셀에 라벨을 붙이고 있습니다.

112
00:10:36,859 --> 00:10:39,741
해당 픽셀의 범주가 무엇인지에 대해 독립적으로 결정됩니다.

113
00:10:39,741 --> 00:10:41,747
그래서 우리가 두 마리의 암소를 가지고있는 이런 경우에.

114
00:10:41,747 --> 00:10:44,510
바로 옆에 출력물이 만들어지지 않습니다.

115
00:10:44,510 --> 00:10:46,840
구별하는 것, 구별하지 않는 것

116
00:10:46,840 --> 00:10:48,309
이 두 마리의 암소 사이.

117
00:10:48,309 --> 00:10:50,098
대신에 우리는 전체 픽셀 덩어리를 얻습니다.

118
00:10:50,098 --> 00:10:51,782
모두 암소로 표시되어 있습니다.

119
00:10:51,782 --> 00:10:54,868
이것은 의미 론적 세분화의 단점입니다.

120
00:10:54,868 --> 00:10:56,625
나중에이 문제를 해결할 수있는 방법을 알아 보겠습니다.

121
00:10:56,625 --> 00:10:58,910
인스턴스 분할로 이동할 때

122
00:10:58,910 --> 00:11:00,549
하지만 적어도 지금은 우리가

123
00:11:00,549 --> 00:11:02,882
의미 론적 세분화.

124
00:11:04,437 --> 00:11:07,595
그래서 당신은 아마도 수업을 사용한다고 상상할 수 있습니다.

125
00:11:07,595 --> 00:11:09,340
그래서 공격을위한 하나의 잠재적 접근법

126
00:11:09,340 --> 00:11:12,544
의미 론적 세분화는 분류를 통한 것일 수 있습니다.

127
00:11:12,544 --> 00:11:14,553
그래서이 아이디어를 사용할 수 있습니다.

128
00:11:14,553 --> 00:11:17,755
의미 분할 (semantic segmentation)에
대한 슬라이딩 윈도우 (sliding window) 접근법

129
00:11:17,755 --> 00:11:21,076
따라서 여러분은 우리가 입력 이미지를
가지고 있다고 상상할 수 있습니다.

130
00:11:21,076 --> 00:11:24,315
우리는 그것을 많은 작은 작고 작은 지방 작물로 나눕니다.

131
00:11:24,315 --> 00:11:27,763
이 예제에서 우리는 찍은 이미지의

132
00:11:27,763 --> 00:11:31,310
이 소의 머리 주위에서 아마 3 곡물

133
00:11:31,310 --> 00:11:33,705
그리고 그 작물 각각을 먹는다고 상상해보십시오.

134
00:11:33,705 --> 00:11:36,564
지금 이것을 분류 문제로 취급합니다.

135
00:11:36,564 --> 00:11:39,086
이 작물에 대해 말하면, 카테고리는 무엇입니까

136
00:11:39,086 --> 00:11:41,246
작물 중앙 픽셀의?

137
00:11:41,246 --> 00:11:43,828
그리고 같은 기계를 모두 사용할 수 있습니다.

138
00:11:43,828 --> 00:11:46,752
우리가 전체 이미지를 분류하기 위해 개발 한

139
00:11:46,752 --> 00:11:48,760
하지만 지금은 농작물에 적용하기보다는

140
00:11:48,760 --> 00:11:51,083
전체 이미지에.

141
00:11:51,083 --> 00:11:54,412
그리고 이것은 아마도 어느 정도는 작동 할 것입니다.

142
00:11:54,412 --> 00:11:56,601
그러나 그것은 아마도 좋은 생각이 아닙니다.

143
00:11:56,601 --> 00:11:58,422
그래서 이것은 슈퍼 슈퍼가 될 것입니다.

144
00:11:58,422 --> 00:12:02,498
우리가 라벨을 붙이려고하기 때문에 계산 비용이 많이 든다.

145
00:12:02,498 --> 00:12:04,701
이미지의 모든 픽셀, 우리는 별도의

146
00:12:04,701 --> 00:12:07,319
해당 이미지의 모든 픽셀에 대해 자르기를 수행하면됩니다.

147
00:12:07,319 --> 00:12:09,407
슈퍼 슈퍼 비싼 앞뒤로 실행하는

148
00:12:09,407 --> 00:12:10,910
통과한다.

149
00:12:10,910 --> 00:12:14,437
게다가, 우리는 실제로, 만약
당신이 이것에 대해 생각한다면

150
00:12:14,437 --> 00:12:17,085
우리는 실제로 서로 다른 계산을 공유 할 수 있습니다.

151
00:12:17,085 --> 00:12:20,476
두 개의 패치를 분류하려고한다면 패치를하십시오.

152
00:12:20,476 --> 00:12:22,950
서로 바로 옆에 있고 실제로 중첩되는

153
00:12:22,950 --> 00:12:25,509
그 패치의 콘볼 루션 특징

154
00:12:25,509 --> 00:12:28,242
같은 콘볼 루션 레이어를 통과하게된다.

155
00:12:28,242 --> 00:12:30,611
우리는 실제로 많은 계산을 공유 할 수 있습니다.

156
00:12:30,611 --> 00:12:32,644
패스를 분리하여 적용 할 때

157
00:12:32,644 --> 00:12:34,742
또는 이러한 유형의 접근법을 적용 할 때

158
00:12:34,742 --> 00:12:37,194
이미지의 패치를 분리합니다.

159
00:12:37,194 --> 00:12:39,801
그래서 이것은 실제로 끔찍한 생각이며
아무도 이것을하지 않습니다.

160
00:12:39,801 --> 00:12:41,896
당신은 아마 이것을하지 말아야합니다.

161
00:12:41,896 --> 00:12:44,913
그러나 적어도 당신이 생각할 수있는 첫 번째 것입니다.

162
00:12:44,913 --> 00:12:48,683
의미 론적 세분화에 대해 생각하고 있다면

163
00:12:48,683 --> 00:12:50,598
그런 다음 조금 더 잘 작동하는 다음 아이디어

164
00:12:50,598 --> 00:12:53,372
완전 컨볼 루션 네트워크 권리에 대한이 아이디어입니다.

165
00:12:53,372 --> 00:12:56,080
따라서 이미지에서 개별 패치를 추출하는 것보다

166
00:12:56,080 --> 00:12:58,305
및 상기 패치들을 독립적으로 분류하는 단계로서,

167
00:12:58,305 --> 00:13:00,959
우리는 우리의 네트워크가 전체
거인이되는 것을 상상할 수 있습니다.

168
00:13:00,959 --> 00:13:03,604
완전히 연결되지 않은 길쌈 레이어 스택

169
00:13:03,604 --> 00:13:06,501
레이어 또는 아무것도 그래서이
경우에는 우리는 무리를 가지고

170
00:13:06,501 --> 00:13:10,631
모든 3 ~ 3 개의 길쌈 레이어의

171
00:13:10,631 --> 00:13:12,633
제로 패딩 또는 그와 비슷한 것으로

172
00:13:12,633 --> 00:13:15,422
각 콘볼 루션 층은 공간 크기를 보존한다

173
00:13:15,422 --> 00:13:17,843
우리가 이미지를 전달한다면

174
00:13:17,843 --> 00:13:20,605
이러한 컨볼 루션 층들의 전체 스택을 통해,

175
00:13:20,605 --> 00:13:23,090
마지막 콘볼 루션 계층은 출력 할 수있다.

176
00:13:23,090 --> 00:13:27,184
C에 의해 H에 의해 W에 의해 무언가의 텐서

177
00:13:27,184 --> 00:13:29,622
여기서 C는 우리가 신경 쓰는 범주의 수입니다.

178
00:13:29,622 --> 00:13:32,491
그리고 당신은이 텐서가 단지주는 것으로 볼 수 있습니다.

179
00:13:32,491 --> 00:13:34,734
모든 픽셀에 대한 우리의 분류 점수

180
00:13:34,734 --> 00:13:38,127
입력 이미지의 모든 위치에서 입력 이미지에.

181
00:13:38,127 --> 00:13:40,144
그리고 우리는 이것을 한꺼번에 계산할 수 있습니다.

182
00:13:40,144 --> 00:13:43,014
거대한 컨볼 루션 레이어 스택이 있습니다.

183
00:13:43,014 --> 00:13:44,571
그리고 나서 이걸 훈련시키는 걸 상상할 수 있어요.

184
00:13:44,571 --> 00:13:47,216
모든 픽셀에 분류 손실을 가함

185
00:13:47,216 --> 00:13:50,558
이 출력의 평균값을 취합니다.

186
00:13:50,558 --> 00:13:52,718
우주에서, 그리고 이런 종류의 네트워크를 훈련하는 것

187
00:13:52,718 --> 00:13:55,137
정상적이고 규칙적인 등 전파를 통해

188
00:13:55,137 --> 00:13:55,970
문제?

189
00:13:58,430 --> 00:13:59,728
오, 문제는 어떻게 개발 하느냐입니다.

190
00:13:59,728 --> 00:14:01,179
이것을위한 훈련 자료?

191
00:14:01,179 --> 00:14:02,687
그것은 매우 비싸다.

192
00:14:02,687 --> 00:14:04,366
그래서 이것을위한 훈련 데이터는

193
00:14:04,366 --> 00:14:06,899
우리는 입력 이미지의 모든 픽셀에 라벨을 붙일 필요가있다.

194
00:14:06,899 --> 00:14:09,654
사람들이 온라인에 가끔 가지고있는 도구가 있습니다.

195
00:14:09,654 --> 00:14:11,831
당신이 들어가서 일종의 무승부 윤곽을 가질 수있는 곳

196
00:14:11,831 --> 00:14:14,613
물체를 둘러싼 다음 지역을 채우십시오.

197
00:14:14,613 --> 00:14:16,104
그러나 일반적으로 이러한 종류의 훈련 데이터를 얻는 경우

198
00:14:16,104 --> 00:14:17,604
매우 비싸다.

199
00:14:29,243 --> 00:14:31,357
네, 문제는 손실 함수입니다.

200
00:14:31,357 --> 00:14:34,328
그래서 우리는 분류 결정을 내리고 있습니다.

201
00:14:34,328 --> 00:14:37,009
픽셀 당 교차 엔트로피 손실

202
00:14:37,009 --> 00:14:39,025
출력의 모든 픽셀에 대해

203
00:14:39,025 --> 00:14:40,739
그래서 우리는 지상 진실 카테고리 레이블을 가지고 있습니다.

204
00:14:40,739 --> 00:14:42,212
출력의 모든 픽셀에 대해,

205
00:14:42,212 --> 00:14:44,363
그런 다음 우리는 엔트로피 손실

206
00:14:44,363 --> 00:14:45,793
출력의 모든 픽셀 사이

207
00:14:45,793 --> 00:14:48,143
지상 진실 픽셀 그리고 나서

208
00:14:48,143 --> 00:14:50,437
공간의 합이나 평균을 취한다.

209
00:14:50,437 --> 00:14:52,739
그런 다음 미니 배치를 합하거나 평균을 계산합니다.

210
00:14:52,739 --> 00:14:53,572
문제?

211
00:15:18,548 --> 00:15:19,465
그래, 그래.

212
00:15:24,804 --> 00:15:26,505
그래, 문제는 우리가 가정하는 것이다.

213
00:15:26,505 --> 00:15:28,008
우리는 카테고리를 알고 있습니까?

214
00:15:28,008 --> 00:15:31,258
그래서 네, 우리는 앞에서 카테고리를
알고 있다고 가정합니다.

215
00:15:31,258 --> 00:15:33,716
그래서 이것은 이미지 분류의 경우와 같습니다.

216
00:15:33,716 --> 00:15:36,785
따라서 교육 시작시 알 수있는 이미지 분류

217
00:15:36,785 --> 00:15:39,466
우리의 데이터 세트를 기반으로 아마 10 또는 20

218
00:15:39,466 --> 00:15:41,357
또는 우리가 신경 쓰는 100 또는 1000 클래스

219
00:15:41,357 --> 00:15:45,024
이 데이터 세트는 여기에서 우리는 고정되어있다.

220
00:15:45,910 --> 00:15:50,077
데이터 세트에 대해 고정 된 클래스 세트에 적용됩니다.

221
00:15:51,012 --> 00:15:53,927
따라서이 모델은 비교적 간단합니다.

222
00:15:53,927 --> 00:15:56,206
당신은 합리적으로 잘 작동하는 것을 상상할 수 있습니다.

223
00:15:56,206 --> 00:15:58,853
모든 하이퍼 매개 변수를 올바르게 조정했다고 가정합니다.

224
00:15:58,853 --> 00:16:00,562
그러나 그것은 문제의 종류입니다.

225
00:16:00,562 --> 00:16:02,346
이 설정에서, 우리는 묶음을 적용하기 때문에

226
00:16:02,346 --> 00:16:05,120
모두 같은 것을 유지하는 회선의

227
00:16:05,120 --> 00:16:07,479
입력 영상의 공간 크기,

228
00:16:07,479 --> 00:16:09,574
이것은 슈퍼 슈퍼 비싼 권리 것입니다.

229
00:16:09,574 --> 00:16:12,500
아마 당신이 가지고있는 회선을 원한다면

230
00:16:12,500 --> 00:16:16,435
64 또는 128 또는 256 채널의 컨볼 루션 필터

231
00:16:16,435 --> 00:16:18,982
이것은 많은 네트워크에서 꽤 일반적입니다.

232
00:16:18,982 --> 00:16:21,394
이 고해상도에서 이러한 콘볼 루션을 실행하십시오.

233
00:16:21,394 --> 00:16:24,111
일련의 레이어에 걸친 입력 이미지는

234
00:16:24,111 --> 00:16:25,849
매우 계산적으로 비싼

235
00:16:25,849 --> 00:16:27,361
그리고 1 톤의 기억을 취할 것입니다.

236
00:16:27,361 --> 00:16:29,252
따라서 실제로는 일반적으로 네트워크를 보지 못합니다.

237
00:16:29,252 --> 00:16:31,304
이 아키텍처와.

238
00:16:31,304 --> 00:16:33,526
대신 뭔가 보이는 네트워크를 보는 경향이 있습니다.

239
00:16:33,526 --> 00:16:37,512
우리가 다운 샘플링을하는 곳

240
00:16:37,512 --> 00:16:39,277
그리고 나서 feature map의 일부 업 샘플링

241
00:16:39,277 --> 00:16:40,592
이미지 내부.

242
00:16:40,592 --> 00:16:42,490
그래서 모든 회선을하기보다는

243
00:16:42,490 --> 00:16:44,614
이미지의 전체 공간 해상도 중,

244
00:16:44,614 --> 00:16:46,304
우리는 아마 작은 수를 통과 할 것이다.

245
00:16:46,304 --> 00:16:48,997
원본 해상도에서 길쌈 레이어의

246
00:16:48,997 --> 00:16:50,858
그런 다음 무언가를 사용하여 해당
기능 맵을 다운 샘플링하십시오.

247
00:16:50,858 --> 00:16:53,991
최대 풀링 또는 스트라이드 컨볼 루션과 같은

248
00:16:53,991 --> 00:16:55,719
다운 샘플의 종류, 다운 샘플,

249
00:16:55,719 --> 00:16:57,656
그래서 우리는 다운 샘플링에서의 컨볼 루션을 가지고있다.

250
00:16:57,656 --> 00:16:59,338
다운 샘플링에서의 컨볼 루션

251
00:16:59,338 --> 00:17:02,199
많은 분류 네트워크와 비슷하게 보입니다.

252
00:17:02,199 --> 00:17:04,640
당신이 보았지만 지금은 차이점이 있습니다.

253
00:17:04,640 --> 00:17:06,800
완전히 연결된 레이어로 전환하는 것이 아니라

254
00:17:06,800 --> 00:17:09,346
이미지 분류 설정에서 할 수있는 것처럼,

255
00:17:09,346 --> 00:17:12,071
대신 우리는 공간 해상도를 높이고 싶다.

256
00:17:12,071 --> 00:17:15,213
네트워크 후반부의 예측

257
00:17:15,214 --> 00:17:17,598
우리의 출력 이미지는 이제 같은 크기가 될 수 있습니다.

258
00:17:17,598 --> 00:17:20,614
우리의 입력 이미지와 이것이 끝나는 것처럼

259
00:17:20,614 --> 00:17:22,136
훨씬 더 계산 상 효율적이다.

260
00:17:22,136 --> 00:17:24,176
네트워크를 매우 깊게 만들 수 있기 때문에

261
00:17:24,176 --> 00:17:26,417
낮은 공간 해상도로 작업 할 수 있습니다.

262
00:17:26,417 --> 00:17:29,749
네트워크 내부의 여러 계층에 대해

263
00:17:29,749 --> 00:17:33,205
따라서 우리는 이미 다운 샘플링의 예를 보았습니다.

264
00:17:33,205 --> 00:17:36,418
길쌈 네트워크에 올 때.

265
00:17:36,418 --> 00:17:38,343
우리는 당신이 번민 한 회선을 할
수 있다는 것을 보았습니다.

266
00:17:38,343 --> 00:17:41,180
또는 공간 크기를 줄이기위한 다양한 유형의 풀링

267
00:17:41,180 --> 00:17:44,050
네트워크 내부의 이미지를

268
00:17:44,050 --> 00:17:46,040
upsampling과 질문에 관해 정말로 말했어.

269
00:17:46,040 --> 00:17:49,107
이러한 업 샘플링이 무엇인지 궁금해 할 것입니다.

270
00:17:49,107 --> 00:17:51,476
레이어는 실제로 네트워크 내부처럼 보입니까?

271
00:17:51,476 --> 00:17:53,833
크기를 늘리기위한 우리의 전략은 무엇입니까?

272
00:17:53,833 --> 00:17:55,875
네트워크 내부의 기능 맵?

273
00:17:55,875 --> 00:17:59,208
미안, 뒷문에 질문이 있니?

274
00:18:07,316 --> 00:18:09,061
예, 질문은 어떻게 업 샘플링합니까?

275
00:18:09,061 --> 00:18:10,330
그리고 그 대답은 주제입니다.

276
00:18:10,330 --> 00:18:11,758
다음 커플의 슬라이드.

277
00:18:11,758 --> 00:18:13,263
[웃음]

278
00:18:13,263 --> 00:18:17,197
업 샘플링을위한 한 가지 전략은

279
00:18:17,197 --> 00:18:21,075
우리가 풀링의 개념을 가지고 있으므로 풀리기

280
00:18:21,075 --> 00:18:23,379
다운 샘플링하기 위해 평균 풀링에 대해 이야기했습니다.

281
00:18:23,379 --> 00:18:26,187
또는 우리가 평균 풀링에 대해 말했을 때 최대 풀링

282
00:18:26,187 --> 00:18:27,754
우리는 일종의 공간 평균을 취하고 있습니다.

283
00:18:27,754 --> 00:18:30,389
각 풀링 영역의 수용 필드 내에서.

284
00:18:30,389 --> 00:18:32,765
업 샘플링을위한 아날로그의 한 종류는이 아이디어입니다

285
00:18:32,765 --> 00:18:34,853
가장 가까운 이웃 풀링 중.

286
00:18:34,853 --> 00:18:36,761
여기 왼쪽에는이 예제가 있습니다.

287
00:18:36,761 --> 00:18:39,090
가장 가까운 이웃 풀리지 않음

288
00:18:39,090 --> 00:18:41,379
어쩌면 두 개의 그리드로 된 두 개의 출력이고 우리의 출력

289
00:18:41,379 --> 00:18:43,853
4x4 격자이며 지금은 우리의 산출물입니다.

290
00:18:43,853 --> 00:18:47,698
우리는 두 개의 이웃을 두 발을 내디뎠다.

291
00:18:47,698 --> 00:18:50,461
우리가 방금 복사 한 곳에서 풀링 또는 업 샘플링

292
00:18:50,461 --> 00:18:53,177
우리 요소에있는 모든 점에 대한 그 원소

293
00:18:53,177 --> 00:18:56,149
unpooling 지역의 수용 필드.

294
00:18:56,149 --> 00:18:59,605
네가 볼 수있는 또 다른 일은 풀을 풀지 않는이 침대이다.

295
00:18:59,605 --> 00:19:03,472
또는 당신이 걸릴 곳을 upsampling 손톱의 침대,

296
00:19:03,472 --> 00:19:05,741
다시 우리는 2 x 2 수용 필드

297
00:19:05,741 --> 00:19:09,116
우리 unpooling 지역에 대한 그리고 당신은,

298
00:19:09,116 --> 00:19:13,465
이 경우 하나의 요소를 제외하고 모두 0으로 만듭니다.

299
00:19:13,465 --> 00:19:17,487
unpooling 지역의이 경우 우리는

300
00:19:17,487 --> 00:19:19,376
우리의 모든 입력은 항상 상단에 놓습니다.

301
00:19:19,376 --> 00:19:21,852
이 unpooling 영역의 왼쪽 구석

302
00:19:21,852 --> 00:19:23,463
그 외 모든 것은 0입니다.

303
00:19:23,463 --> 00:19:24,867
그리고 이것은 일종의 못의 침대 같아요.

304
00:19:24,867 --> 00:19:27,341
0은 매우 평평하기 때문에,

305
00:19:27,341 --> 00:19:30,133
그때 너는이 물건을 파고있어.

306
00:19:30,133 --> 00:19:33,560
이러한 다양한 0이 아닌 지역의 값은

307
00:19:33,560 --> 00:19:35,899
당신이 때때로 암시하는 또 다른 사항은

308
00:19:35,899 --> 00:19:39,591
분 전에는 최대 풀링에 대한 아이디어가 있습니다.

309
00:19:39,591 --> 00:19:42,848
그래서 많은 이들 네트워크에서 그들은 대칭적인 경향이있다.

310
00:19:42,848 --> 00:19:46,340
우리는 네트워크의 다운 샘플링 부분을 가지고있다.

311
00:19:46,340 --> 00:19:48,266
네트워크의 업 샘플링 부분

312
00:19:48,266 --> 00:19:52,047
네트워크의 두 부분 사이에 대칭이 있습니다.

313
00:19:52,047 --> 00:19:55,628
그래서 가끔씩 당신이 보게 될 것은
맥스 풀링에 대한 아이디어입니다.

314
00:19:55,628 --> 00:20:00,553
각각의 풀링에 대해, 각각의 업 샘플링 계층에 대해,

315
00:20:00,553 --> 00:20:03,325
풀링 레이어 중 하나와 연결됩니다.

316
00:20:03,325 --> 00:20:06,140
네트워크의 전반부에서 그리고 지금 상반기에,

317
00:20:06,140 --> 00:20:09,380
우리가 최대 풀링을 할 때 다운 샘플링에서

318
00:20:09,380 --> 00:20:12,577
우리는 실제로 수용 영역의 어떤 요소를 기억할 것입니다.

319
00:20:12,577 --> 00:20:16,465
최대 풀링을하는 동안 최대 풀링을 수행하는 동안

320
00:20:16,465 --> 00:20:18,481
이제 나머지 네트워크를 통과 할 때

321
00:20:18,481 --> 00:20:20,821
그러면 우리는이 못 침대처럼 보이는 것을 할 것입니다.

322
00:20:20,821 --> 00:20:23,969
업 샘플링 (항상 요소를 넣기보다는)

323
00:20:23,969 --> 00:20:26,391
같은 위치에, 대신에 우리는 그것을 집어 넣을거야.

324
00:20:26,391 --> 00:20:29,775
해당 위치에서 사용 된 위치로

325
00:20:29,775 --> 00:20:33,697
최대 풀링 단계.

326
00:20:33,697 --> 00:20:35,154
그 설명이 명확한 지 모르겠다.

327
00:20:35,154 --> 00:20:38,321
그러나 희망을 갖고 그림은 의미가있다.

328
00:20:39,248 --> 00:20:42,388
네, 그래서 나머지는 0으로 채우게 될 것입니다.

329
00:20:42,388 --> 00:20:43,751
그럼 나머지는 0으로 채 웁니다.

330
00:20:43,751 --> 00:20:45,871
그리고 나서 저해상도에서 요소들을 집어 넣습니다.

331
00:20:45,871 --> 00:20:48,256
고해상도 패치로 패치

332
00:20:48,256 --> 00:20:51,714
최대 풀링이 발생한 지점에서

333
00:20:51,714 --> 00:20:54,964
거기에서 대응하는 최대 풀링에서.

334
00:20:56,871 --> 00:21:00,723
좋습니다, 그래서 그것은 재미있는 생각입니다.

335
00:21:00,723 --> 00:21:02,056
미안 해요, 질문?

336
00:21:08,696 --> 00:21:10,559
오 그래, 질문은 왜 이것이 좋은 생각일까요?

337
00:21:10,559 --> 00:21:11,801
왜이 일이 중요할까요?

338
00:21:11,801 --> 00:21:14,502
아이디어는 우리가 의미 론적 세분화를 할 때

339
00:21:14,502 --> 00:21:16,806
우리는 우리의 예측이 픽셀 완전하게되기를 원합니다.

340
00:21:16,806 --> 00:21:19,667
우리는 그 날카로운 경계를 얻고 싶습니다.

341
00:21:19,667 --> 00:21:23,708
우리의 예측 세분화에있는 작은 세부 사항들

342
00:21:23,708 --> 00:21:27,001
그래서 지금 당신이이 최대 풀링을하고 있다면,

343
00:21:27,001 --> 00:21:29,279
이런 종류의 이질성이 일어나고 있습니다.

344
00:21:29,279 --> 00:21:31,782
최대 풀링으로 인해 피쳐 맵 내부에

345
00:21:31,782 --> 00:21:35,949
당신이 모르는 저해상도 이미지에서,

346
00:21:36,839 --> 00:21:39,395
당신은 어떤 의미에서 공간 정보를 잃는 것과 같습니다.

347
00:21:39,395 --> 00:21:42,390
당신은 그 특징 벡터가 어디서 왔는지 모릅니다.

348
00:21:42,390 --> 00:21:45,253
최대 수용 후 수용 지역에서

349
00:21:45,253 --> 00:21:48,673
따라서 벡터를 넣음으로써 실제로 풀을 풀면

350
00:21:48,673 --> 00:21:51,394
같은 슬롯에서 당신은 그것이 우리에게
도움이 될 것이라고 생각할지도 모릅니다.

351
00:21:51,394 --> 00:21:53,759
이 세세한 것들을 조금 더 잘 다뤄야한다.

352
00:21:53,759 --> 00:21:55,866
공간 정보의 일부를 보존하는 데 도움이됩니다.

353
00:21:55,866 --> 00:21:59,051
최대 풀링 중에 손실되었습니다.

354
00:21:59,051 --> 00:21:59,884
문제?

355
00:22:10,883 --> 00:22:13,809
문제는 이것이 등 받침대를 더 쉽게
만들 수 있는가하는 것입니다.

356
00:22:13,809 --> 00:22:17,275
그래, 내 생각 엔 뒤의 받침대가 바뀌지 않았을거야.

357
00:22:17,275 --> 00:22:19,389
이러한 지수를 저장하기 때문에 역학이 너무

358
00:22:19,389 --> 00:22:21,009
거대한 계산 오버 헤드가 아닙니다.

359
00:22:21,009 --> 00:22:24,851
그들은 다른 모든 것에 비해 꽤 작습니다.

360
00:22:24,851 --> 00:22:26,606
그래서 당신이 때때로 볼 수있는 또 다른 것

361
00:22:26,606 --> 00:22:29,566
트랜스 포즈 컨볼 루션 (transpose convolution)에 대한 아이디어입니다.

362
00:22:29,566 --> 00:22:33,259
따라서 컨볼 루션을 조 변경하면 이러한 다양한 유형의

363
00:22:33,259 --> 00:22:34,724
우리가 방금 말했던

364
00:22:34,724 --> 00:22:36,561
이 못 침대,이 가장 가까운 이웃,

365
00:22:36,561 --> 00:22:38,945
이 최대 unpooling,이 모든 종류의

366
00:22:38,945 --> 00:22:41,347
고정 함수, 그들은 실제로 정확하게 학습하지 않습니다.

367
00:22:41,347 --> 00:22:44,964
업 샘플링을하는 방법 그래서 뭔가 생각하면

368
00:22:44,964 --> 00:22:47,404
strided convolution,
strided convolution과 같이

369
00:22:47,404 --> 00:22:50,212
방법을 배울 수있는 배우기 쉬운 계층과 비슷합니다.

370
00:22:50,212 --> 00:22:53,010
네트워크가 다운 샘플링을 수행하기를 원함

371
00:22:53,010 --> 00:22:54,423
그 레이어에서.

372
00:22:54,423 --> 00:22:57,890
그리고 이와 유사한 방식으로이 유형의 레이어가 있습니다.

373
00:22:57,890 --> 00:23:00,317
우리가 할 수있는 트랜스 포스 컨볼 루션
(transpose convolution)

374
00:23:00,317 --> 00:23:02,534
학습 가능한 업 샘플링의 종류.

375
00:23:02,534 --> 00:23:04,233
그래서 그것은 특징지도를 업 샘플링 할 것입니다.

376
00:23:04,233 --> 00:23:05,954
원하는 방식에 대해 약간의 무게를 배웁니다.

377
00:23:05,954 --> 00:23:08,068
그 업 샘플링을 할 수 있습니다.

378
00:23:08,068 --> 00:23:10,363
그리고 이것은 정말로 또 다른 유형의 회선입니다.

379
00:23:10,363 --> 00:23:13,262
그래서 어떻게 작동하는지보고 정상적인

380
00:23:13,262 --> 00:23:16,663
한 3 개의 보폭을 세 번 겹쳐
쓰면 하나의 대 회가 작동합니다.

381
00:23:16,663 --> 00:23:18,524
이런 종류의 정상 회선

382
00:23:18,524 --> 00:23:20,488
우리는 지금이 수업에서 여러 번 보았습니다.

383
00:23:20,488 --> 00:23:22,207
우리의 의견은 4 씩 4 씩,

384
00:23:22,207 --> 00:23:24,316
우리의 산출량은 4x4가 될 수 있습니다.

385
00:23:24,316 --> 00:23:26,119
이제 우리는 3x3 커널을 가질 것입니다.

386
00:23:26,119 --> 00:23:27,698
우리는 내부 제품을 가져갈 것입니다.

387
00:23:27,698 --> 00:23:29,721
우리는 이미지의 구석에 그 커널을 내려 놓을 것이고,

388
00:23:29,721 --> 00:23:31,639
내부 제품을 가지고, 그 내부 제품

389
00:23:31,639 --> 00:23:33,249
우리에게 가치와 활성화를 줄 것입니다.

390
00:23:33,249 --> 00:23:35,409
우리 출력의 왼쪽 상단 모서리에.

391
00:23:35,409 --> 00:23:37,749
그리고 우리는 모든 수용적인
영역에서 이것을 반복 할 것입니다.

392
00:23:37,749 --> 00:23:39,388
이미지에서.

393
00:23:39,388 --> 00:23:42,177
이제 우리가 strided convolution에 대해 이야기한다면

394
00:23:42,177 --> 00:23:44,688
strided convolution은
매우 유사하게 보입니다.

395
00:23:44,688 --> 00:23:47,714
그러나 우리의 입력은 4x4 영역 일 수 있습니다.

396
00:23:47,714 --> 00:23:49,648
우리의 산출물은 두 지역에 의해 2 개입니다.

397
00:23:49,648 --> 00:23:51,573
그러나 우리는 여전히이 생각을 가지고 있습니다.

398
00:23:51,573 --> 00:23:54,633
3 ~ 3 개의 필터 또는 커널이 있음

399
00:23:54,633 --> 00:23:56,523
우리가 그 이미지의 구석에 앉아서

400
00:23:56,523 --> 00:23:58,318
내부 제품을 가져 와서 계산에 사용하십시오.

401
00:23:58,318 --> 00:24:00,808
활성화 값과 출력 값.

402
00:24:00,808 --> 00:24:02,865
그러나 이제는 번뜩이는 회선과 함께 아이디어는

403
00:24:02,865 --> 00:24:06,676
우리는 그 필터를 튀어 나오기보다는
그것을 움직이고 있습니다.

404
00:24:06,676 --> 00:24:08,879
입력의 모든 가능한 포인트에서,

405
00:24:08,879 --> 00:24:11,057
대신 필터를 두 픽셀 씩 이동하려고합니다.

406
00:24:11,057 --> 00:24:14,191
우리가 필터를 한 픽셀 씩 이동할 때마다 입력에서,

407
00:24:14,191 --> 00:24:16,961
우리가 출력에서 한 픽셀 씩 이동할 때마다.

408
00:24:16,961 --> 00:24:19,293
맞아요.이 두 보폭은 우리에게 비율을줍니다.

409
00:24:19,293 --> 00:24:21,363
우리가 입력에서 얼마나 많이 움직이는 지

410
00:24:21,363 --> 00:24:23,361
우리가 산출물에서 얼마나 많이 움직이는 지 비교하는 것입니다.

411
00:24:23,361 --> 00:24:25,907
그래서 두 배의 스트라이드 컨볼 루션을 할 때

412
00:24:25,907 --> 00:24:28,653
이것은 이미지 또는 피쳐 맵을
다운 샘플링하는 것을 끝낸다.

413
00:24:28,653 --> 00:24:32,495
학습 방법의 종류로 2 배 정도.

414
00:24:32,495 --> 00:24:35,187
그리고 이제 전치 컨볼 루션은 그 반대입니다

415
00:24:35,187 --> 00:24:39,955
여기에서 우리의 입력은 두 지역의 두 지역이 될 것입니다.

416
00:24:39,955 --> 00:24:42,638
우리의 산출물은 4x4 지역이 될 것입니다.

417
00:24:42,638 --> 00:24:44,375
하지만 지금 우리가 수행하는 작업

418
00:24:44,375 --> 00:24:46,904
전치 컨볼 루션은 조금 다릅니다.

419
00:24:46,904 --> 00:24:50,675
이제 내적 제품을 복용하는 것보다

420
00:24:50,675 --> 00:24:53,368
대신에 우리가 할 일은

421
00:24:53,368 --> 00:24:56,074
우리의 입력 특징지도의 가치를 가져라.

422
00:24:56,074 --> 00:24:58,379
그 왼쪽 상단 모서리에

423
00:24:58,379 --> 00:25:00,856
좌상 구석의 스칼라 값

424
00:25:00,856 --> 00:25:04,211
우리는 스칼라 값으로 필터를 곱하려고합니다.

425
00:25:04,211 --> 00:25:06,767
그 값을이 3에 3을 복사합니다.

426
00:25:06,767 --> 00:25:11,620
지역을 산출물로 가져가는 것이
아니라 내적 산출물을 취하는 것

427
00:25:11,620 --> 00:25:14,428
우리의 필터와 입력, 대신에 우리의 입력

428
00:25:14,428 --> 00:25:17,299
필터를 가중치로 사용할 가중치를 제공합니다.

429
00:25:17,299 --> 00:25:21,547
우리 출력은 필터의 가중치 복사본이됩니다.

430
00:25:21,547 --> 00:25:24,911
입력 값에 의해 가중치가 적용됩니다.

431
00:25:24,911 --> 00:25:28,243
그리고 이제 우리는 같은 비율의 속임수를 쓸 수 있습니다.

432
00:25:28,243 --> 00:25:31,168
한 픽셀을 이동할 때 지금 업 샘플링하기 위해

433
00:25:31,168 --> 00:25:33,947
입력에서 우리는 필터를 아래로 내릴 수 있습니다.

434
00:25:33,947 --> 00:25:36,703
출력에서 2 픽셀 떨어져 있고 같은 트릭입니다.

435
00:25:36,703 --> 00:25:39,743
이제 입력의 파란색 픽셀은 스칼라 값입니다.

436
00:25:39,743 --> 00:25:41,254
우리는 그 스칼라 값을 취할 것이고,

437
00:25:41,254 --> 00:25:43,713
그것을 필터의 값으로 곱하고,

438
00:25:43,713 --> 00:25:46,269
이러한 가중 필터 값을 복사합니다.

439
00:25:46,269 --> 00:25:49,048
출력에서이 새로운 영역으로

440
00:25:49,048 --> 00:25:51,678
까다로운 부분은 때때로 이러한 수용성 장

441
00:25:51,678 --> 00:25:54,765
출력물에서 지금 겹칠 수 있습니다.

442
00:25:54,765 --> 00:25:57,419
출력의 수용 필드가 중첩 됨

443
00:25:57,419 --> 00:26:00,143
우리는 출력 결과를 합산합니다.

444
00:26:00,143 --> 00:26:02,299
그럼 어디서나 반복해서 상상할 수 있습니다.

445
00:26:02,299 --> 00:26:04,720
그리고이 프로세스를 어디에서나 반복합니다.

446
00:26:04,720 --> 00:26:07,931
그리고 이것은 학습 가능한 업
샘플링의 일종을 수행하게된다.

447
00:26:07,931 --> 00:26:10,299
우리는 이러한 학습 된 길쌈
(convolutional) 필터 가중치를 사용한다.

448
00:26:10,299 --> 00:26:14,466
이미지를 업 샘플링하고 공간 크기를 증가시킵니다.

449
00:26:15,609 --> 00:26:17,768
그건 그렇고,이 작업이 진행되는 것을 보게 될 것입니다.

450
00:26:17,768 --> 00:26:19,975
문학에서 많은 다른 이름으로.

451
00:26:19,975 --> 00:26:24,153
때로는 이것은 디콘 볼 루션과 같은 것으로 불립니다.

452
00:26:24,153 --> 00:26:27,024
나는 나쁜 이름의 종류라고 생각합니다.
그러나 당신은 그것을 볼 것입니다.

453
00:26:27,024 --> 00:26:31,269
신호 처리의 관점에서 보면

454
00:26:31,269 --> 00:26:34,066
deconvolution은 컨볼
루션에 대한 역 연산을 의미합니다.

455
00:26:34,066 --> 00:26:37,343
그러나 이것은 당신이 자주 이것을 볼 것입니다.

456
00:26:37,343 --> 00:26:39,945
디콘 볼 루션 층 (deconvolution layer)이라고 불리는 층 유형

457
00:26:39,945 --> 00:26:42,239
일부 깊은 학습 논문에서 그렇게 알고 있어야합니다.

458
00:26:42,239 --> 00:26:44,121
그 용어에 조심하십시오.

459
00:26:44,121 --> 00:26:46,615
당신은 때때로 이것을 보았습니다 upconvolution

460
00:26:46,615 --> 00:26:48,280
그것은 귀여운 종류의 종류 다.

461
00:26:48,280 --> 00:26:51,490
때때로 그것은 부분적으로 strided
convolution이라고 불리게된다.

462
00:26:51,490 --> 00:26:54,435
왜냐하면 우리가 보폭을 단계의 비율로 생각한다면

463
00:26:54,435 --> 00:26:57,791
입력과 출력 사이에 지금 이것은 무언가이다.

464
00:26:57,791 --> 00:27:01,437
이 비율 때문에 한 걸음 반의 길들처럼

465
00:27:01,437 --> 00:27:03,247
입력 단계에서 1 ~ 2 단계

466
00:27:03,247 --> 00:27:04,869
출력의 단계들.

467
00:27:04,869 --> 00:27:07,180
이것은 때로는 뒷걸음질을받습니다.

468
00:27:07,180 --> 00:27:09,311
만약 당신이 그것에 대해 생각한다면

469
00:27:09,311 --> 00:27:13,039
그리고 수학을 통해 일하는 것은
이것이 끝나는 것을 끝내고,

470
00:27:13,039 --> 00:27:15,287
전치 회선의 순방향 패스

471
00:27:15,287 --> 00:27:17,611
수학적 연산이 끝난다.

472
00:27:17,611 --> 00:27:20,030
후방이 정상 회선을 통과 할 때

473
00:27:20,030 --> 00:27:21,859
그래서 당신은 내 말을 가져야 할 수도 있습니다.

474
00:27:21,859 --> 00:27:24,172
처음에 이걸 보았을 때 분명하지 않을 수도 있습니다.

475
00:27:24,172 --> 00:27:26,420
하지만 그것은 일종의 깔끔한 사실이므로 때때로

476
00:27:26,420 --> 00:27:28,698
그 이름도 보아라.

477
00:27:28,698 --> 00:27:30,929
그리고 좀 더 구체적인 예가 될 수 있습니다.

478
00:27:30,929 --> 00:27:33,035
이게 어쩌면 좀 더 쉬울 것 같아.

479
00:27:33,035 --> 00:27:36,923
우리가 상상한다면, 한 차원에서 볼 수 있습니다.

480
00:27:36,923 --> 00:27:40,084
여기에서 우리는 3 x 3 중첩 컨볼 루션을하고 있습니다.

481
00:27:40,084 --> 00:27:41,272
한 차원으로

482
00:27:41,272 --> 00:27:43,612
죄송합니다, 3 명이 아니라 3 명이 하나씩

483
00:27:43,612 --> 00:27:46,091
하나의 차원에서 컨볼 루션을 바꾸십시오.

484
00:27:46,091 --> 00:27:48,117
여기 필터는 세 개의 숫자입니다.

485
00:27:48,117 --> 00:27:50,211
우리의 의견은 두 개의 숫자이며,
이제 당신은 볼 수 있습니다.

486
00:27:50,211 --> 00:27:53,318
우리 출력에서 우리는 입력 값을 가져 왔고,

487
00:27:53,318 --> 00:27:55,396
그것들을 사용하여 필터 값에 가중치를 매겼다.

488
00:27:55,396 --> 00:27:58,060
그 가중치를 적용한 필터를 결과물에 표시했습니다.

489
00:27:58,060 --> 00:28:00,501
2의 보폭과 더불어 지금,이 수용하는 들판

490
00:28:00,501 --> 00:28:03,597
출력에서 중첩되면 합계됩니다.

491
00:28:03,597 --> 00:28:06,297
그래서 당신은 궁금해 할 것 같은데,
이것은 일종의 재미있는 이름입니다.

492
00:28:06,297 --> 00:28:08,698
이름 전치 컨볼 루션은 어디에서 왔는가?

493
00:28:08,698 --> 00:28:10,725
왜 실제로 그게 내 선호하는 이름 이니?

494
00:28:10,725 --> 00:28:12,253
이 수술을 위해서?

495
00:28:12,253 --> 00:28:13,621
그래서 이런 종류의

496
00:28:13,621 --> 00:28:15,530
회선의 깔끔한 해석.

497
00:28:15,530 --> 00:28:18,131
그래서 당신이 회선을 할 때마다

498
00:28:18,131 --> 00:28:21,902
언제나 곱셈을 행렬 곱셈으로 쓸 수 있습니다.

499
00:28:21,902 --> 00:28:23,711
다시 한번 말하지만,보기가 더 쉽습니다.

500
00:28:23,711 --> 00:28:25,737
1 차원 예제

501
00:28:25,737 --> 00:28:28,320
그러나 여기에 우리는 약간의 무게를 가지고있다.

502
00:28:29,347 --> 00:28:31,266
그래서 우리는 1 차원 컨볼 루션을하고 있습니다.

503
00:28:31,266 --> 00:28:34,497
3 개의 요소를 갖는 가중치 벡터 x의,

504
00:28:34,497 --> 00:28:37,259
입력 벡터는 4 개의 요소를 갖는 벡터이며,

505
00:28:37,259 --> 00:28:38,706
A, B, C, D

506
00:28:38,706 --> 00:28:41,532
그래서 여기에서 우리는 3 대 1 회선을하고 있습니다.

507
00:28:41,532 --> 00:28:44,944
큰 걸음으로 우리는 프레임 수
있다는 것을 알 수 있습니다.

508
00:28:44,944 --> 00:28:47,869
행렬 곱셈으로서의이 전체 연산

509
00:28:47,869 --> 00:28:51,944
여기서 컨볼 루션 커널 x를 취한다.

510
00:28:51,944 --> 00:28:54,781
그것을 어떤 행렬의 수도 X로 바꾼다.

511
00:28:54,781 --> 00:28:57,498
해당 컨벌루션 커널의 복사본이 들어 있습니다.

512
00:28:57,498 --> 00:28:59,360
다른 지역에 의해 상쇄됩니다.

513
00:28:59,360 --> 00:29:01,710
그리고 이제 우리는이 거대한 무게
행렬 X를 취할 수 있습니다.

514
00:29:01,710 --> 00:29:03,726
x와 행렬 벡터 곱셈을합니다.

515
00:29:03,726 --> 00:29:06,907
그리고 우리의 입력 a와 같은 결과가 나온다.

516
00:29:06,907 --> 00:29:08,157
회선으로.

517
00:29:09,274 --> 00:29:11,155
그리고 이제는 트랜스 포즈 컨볼 루션 수단을 사용합니다.

518
00:29:11,155 --> 00:29:13,505
우리는이 동일한 무게 매트릭스를 취할 것입니다.

519
00:29:13,505 --> 00:29:15,989
그러나 이제 우리는 전치

520
00:29:15,989 --> 00:29:17,770
그 같은 무게 매트릭스의.

521
00:29:17,770 --> 00:29:21,019
그래서 여기 당신은이 보폭에 대한
동일한 예를 볼 수 있습니다.

522
00:29:21,019 --> 00:29:24,106
왼쪽의 컨볼 루션과 그에 상응하는 스트라이드

523
00:29:24,106 --> 00:29:26,491
오른쪽에 컨볼 루션을 옮겨 놓으십시오.

524
00:29:26,491 --> 00:29:28,165
세부 사항을 확인해 보면

525
00:29:28,165 --> 00:29:31,018
한 걸음 걸 으면,

526
00:29:31,018 --> 00:29:34,313
한 걸음 걸음 걸레질 전환은 또한 끝나기도합니다.

527
00:29:34,313 --> 00:29:37,570
하나의 정상적인 회선을 넘기 때문에 조금있다.

528
00:29:37,570 --> 00:29:39,533
보더와 패딩의 세부 사항

529
00:29:39,533 --> 00:29:42,334
기본적으로 동일한 작업입니다.

530
00:29:42,334 --> 00:29:43,971
하지만 상황이 다르게 보입니다.

531
00:29:43,971 --> 00:29:45,879
네가 두 발자국을 말할 때.

532
00:29:45,879 --> 00:29:49,514
다시 왼쪽에서 우리는 두 걸음 걸릴 수 있습니다.

533
00:29:49,514 --> 00:29:51,828
컨볼 루션 (convolution)은 두 번의 회선

534
00:29:51,828 --> 00:29:54,240
행렬 곱셈으로.

535
00:29:54,240 --> 00:29:57,310
그리고 이제는 해당 조옮김 컨볼 루션

536
00:29:57,310 --> 00:29:59,837
더 이상 회선이 아니므로

537
00:29:59,837 --> 00:30:01,953
이 무게 매트릭스를 통해 생각해보십시오.

538
00:30:01,953 --> 00:30:04,985
이런 컨버전스가 어떻게 대두 되느냐

539
00:30:04,985 --> 00:30:08,496
이제이 두 배의 스트라이드에 대한이 전치 행렬

540
00:30:08,496 --> 00:30:10,926
회선은 근본적으로 다른 것입니다.

541
00:30:10,926 --> 00:30:13,913
원래 정상 컨벌루션 연산에서

542
00:30:13,913 --> 00:30:16,208
그래서 그 이름 뒤에 추론의 종류입니다

543
00:30:16,208 --> 00:30:18,675
그게 내가 생각하기에 그것이 가장 좋은 이름 인 것 같아.

544
00:30:18,675 --> 00:30:20,647
에 의해이 작업을 호출합니다.

545
00:30:20,647 --> 00:30:22,980
미안, 질문 있니?

546
00:30:27,991 --> 00:30:29,646
죄송합니다?

547
00:30:29,646 --> 00:30:31,617
슬라이드에 오타가있을 가능성이 매우 높습니다.

548
00:30:31,617 --> 00:30:33,824
그래서 피아자를 지적하고 고칠 것입니다.

549
00:30:33,824 --> 00:30:36,523
그러나 그 아이디어가 분명하기를 바란다.

550
00:30:36,523 --> 00:30:38,026
또 다른 질문이 있습니까?

551
00:30:38,026 --> 00:30:40,167
좋아요, 고마워요. [웃음].

552
00:30:40,167 --> 00:30:43,000
네, 그렇습니다. 오 질문은별로 없습니다.

553
00:30:53,576 --> 00:30:56,360
그래, 문제는 왜 우리가 합계하고
평균이 아닌가하는 것입니다.

554
00:30:56,360 --> 00:31:00,373
그래서 우리가 합친 이유는이 전치 컨볼 루션 때문입니다.

555
00:31:00,373 --> 00:31:03,404
수식 영역 그래서 우리가 합계하는 이유입니다

556
00:31:03,404 --> 00:31:04,846
하지만 당신 말이 맞아요. 사실,

557
00:31:04,846 --> 00:31:06,646
이것은 큰 문제가되는 종류의 문제입니다.

558
00:31:06,646 --> 00:31:08,337
출력에 따라 실제로 달라질 것입니다.

559
00:31:08,337 --> 00:31:11,325
산출물에 얼마나 많은 수용 필드가 있었는지에 대한 정보.

560
00:31:11,325 --> 00:31:13,152
그래서 실제로 이것은 실제로 사람들이

561
00:31:13,152 --> 00:31:15,322
아주 최근과 다소 지적하기 시작했다.

562
00:31:15,322 --> 00:31:19,561
이 보폭에서 바뀌었고, 그래서 3을 3으로 사용했다.

563
00:31:19,561 --> 00:31:22,064
두 개의 트랜스 포즈 컨볼 루션 업 샘플링을 걸음

564
00:31:22,064 --> 00:31:24,250
때로는 체커 보드 아티팩트가 생길 수 있습니다.

565
00:31:24,250 --> 00:31:26,250
정확히 그 문제로 인해 출력에.

566
00:31:26,250 --> 00:31:28,611
그래서 제가 최근 몇 몇 논문에서 보았던 것

567
00:31:28,611 --> 00:31:31,117
어쩌면 4 ~ 4 네 걸음 걸음을 사용하는 것일 수 있습니다.

568
00:31:31,117 --> 00:31:33,414
또는 2 x 2 x 2 x 2 x x 2

569
00:31:33,414 --> 00:31:34,960
업 샘플링을 위해

570
00:31:34,960 --> 00:31:37,127
그 문제는 조금.

571
00:31:46,834 --> 00:31:50,499
네, 그렇다면 질문은 반 걸음
걸음이 무엇인가하는 것입니다.

572
00:31:50,499 --> 00:31:52,515
그 용어는 어디에서 왔습니까?

573
00:31:52,515 --> 00:31:53,864
내 논문에서 나온 것 같아.

574
00:31:53,864 --> 00:31:56,790
그래서 그것은 실제로, 그렇습니다. 분명히 이것이었습니다.

575
00:31:56,790 --> 00:31:58,707
그래서 당시 저는 그 논문을 쓰고있었습니다.

576
00:31:58,707 --> 00:32:01,181
나는 이름에 부분적으로 걸린 회선

577
00:32:01,181 --> 00:32:02,971
하지만 그것에 대해 생각한 후에는 조금 더 생각합니다.

578
00:32:02,971 --> 00:32:07,282
트랜스 포스 컨볼 루션은 아마도 올바른 이름 일 것입니다.

579
00:32:07,282 --> 00:32:11,350
그럼 의미 론적 세분화에 대한이 아이디어

580
00:32:11,350 --> 00:32:13,746
실제로 꽤 자연 스럽습니다.

581
00:32:13,746 --> 00:32:15,850
너는이 거대한 길쌈 네트워크를 가지고있다.

582
00:32:15,850 --> 00:32:19,540
네트워크 내부의 다운 샘플링 및 업 샘플링

583
00:32:19,540 --> 00:32:22,053
이제 우리의 다운 샘플링은 strided
convolution으로 이루어질 것입니다.

584
00:32:22,053 --> 00:32:25,246
또는 풀링하면, 우리의 업 샘플링은
트랜스 포즈 컨볼 루션에 의한 것입니다

585
00:32:25,246 --> 00:32:28,035
또는 다양한 유형의 풀링 또는 업 샘플링

586
00:32:28,035 --> 00:32:29,773
우리는이 모든 것을 끝까지 훈련시킬 수 있습니다.

587
00:32:29,773 --> 00:32:31,994
이 교차 엔트로피 손실을 이용한 역 전파

588
00:32:31,994 --> 00:32:33,634
모든 픽셀에 걸쳐

589
00:32:33,634 --> 00:32:36,793
그래서 이것은 실제로 우리가 취할 수있는 매우 차갑습니다.

590
00:32:36,793 --> 00:32:38,794
우리가 이미 배웠던 많은 기계들

591
00:32:38,794 --> 00:32:41,514
이미지 분류를 위해 이제 그것을 적용하기 만하면됩니다.

592
00:32:41,514 --> 00:32:43,664
새로운 유형의 문제까지 매우 쉽게 확장

593
00:32:43,664 --> 00:32:45,414
너무 멋집니다.

594
00:32:46,333 --> 00:32:49,362
그래서 제가 이야기하고 싶은 다음 과제는이 아이디어입니다.

595
00:32:49,362 --> 00:32:52,024
분류 플러스 현지화.

596
00:32:52,024 --> 00:32:54,953
그래서 이미지 분류에 대해 많이 이야기했습니다.

597
00:32:54,953 --> 00:32:56,712
카테고리 레이블을 지정하려는 경우

598
00:32:56,712 --> 00:32:59,474
입력 이미지에 가깝지만 때로는 알고 싶을 수도 있습니다.

599
00:32:59,474 --> 00:33:01,234
이미지에 대해 조금 더.

600
00:33:01,234 --> 00:33:04,093
카테고리가 무엇인지 예측하는 것 외에도,

601
00:33:04,093 --> 00:33:06,762
이 경우에는 고양이, 당신도 알고 싶어 할 수도 있습니다

602
00:33:06,762 --> 00:33:09,077
이미지의 그 대상은 어디입니까?

603
00:33:09,077 --> 00:33:12,352
따라서 범주 레이블 cat을 예측하는 것 외에도,

604
00:33:12,352 --> 00:33:14,408
경계 상자를 그릴 수도 있습니다.

605
00:33:14,408 --> 00:33:17,874
그 이미지의 고양이 주변.

606
00:33:17,874 --> 00:33:20,122
분류 플러스 현지화,

607
00:33:20,122 --> 00:33:22,713
이것과 객체 검출 사이의 구별

608
00:33:22,713 --> 00:33:25,203
현지화 시나리오에서 가정합니다.

609
00:33:25,203 --> 00:33:28,482
사전에 정확히 하나의 객체가 있다는 것을 알기 전에

610
00:33:28,482 --> 00:33:31,242
찾고있는 이미지 또는 어쩌면 하나 이상

611
00:33:31,242 --> 00:33:34,001
그러나 우리는 우리가

612
00:33:34,001 --> 00:33:36,202
이 이미지에 대한 어떤 분류 결정

613
00:33:36,202 --> 00:33:38,434
정확히 하나의 경계 상자를 생성하려고합니다.

614
00:33:38,434 --> 00:33:41,001
그 물건이 어디에 있는지 말해 줄거야.

615
00:33:41,001 --> 00:33:44,053
이미지에서 우리는 때로는 그 일을 부릅니다

616
00:33:44,053 --> 00:33:47,584
분류 플러스 현지화.

617
00:33:47,584 --> 00:33:49,904
그리고 다시, 우리는 같은 기계를
많이 재사용 할 수 있습니다.

618
00:33:49,904 --> 00:33:51,968
이미지 분류에서 이미 배웠던

619
00:33:51,968 --> 00:33:53,680
이 문제를 해결하기 위해

620
00:33:53,680 --> 00:33:56,789
이 문제에 대한 일종의 기본 아키텍처

621
00:33:56,789 --> 00:33:58,220
이런 식으로 보입니다.

622
00:33:58,220 --> 00:33:59,949
다시 한번 우리는 입력 이미지를 가지고 있습니다.

623
00:33:59,949 --> 00:34:01,570
일부 거인을 통해 입력 이미지를 공급합니다.

624
00:34:01,570 --> 00:34:03,560
컨볼 루션 네트워크, 이쪽은 Alex입니다.

625
00:34:03,560 --> 00:34:05,610
예를 들어 AlexNet입니다.

626
00:34:05,610 --> 00:34:09,301
이미지의 내용을 요약하는 최종 벡터.

627
00:34:09,301 --> 00:34:12,379
그런 다음 전에 완전히 연결된 레이어가있을 것입니다.

628
00:34:12,379 --> 00:34:15,730
그 최종 벡터에서 우리의 수업 점수로갑니다.

629
00:34:15,730 --> 00:34:18,341
하지만 이제는 완전히 연결된 또 다른 레이어가 생깁니다.

630
00:34:18,341 --> 00:34:21,109
그 벡터에서 네 개의 숫자로 이동합니다.

631
00:34:21,109 --> 00:34:23,339
네 개의 숫자가 같은 곳에

632
00:34:23,339 --> 00:34:26,309
높이, 너비 및 x 및 y 위치

633
00:34:26,309 --> 00:34:28,478
그 테두리 상자의.

634
00:34:28,478 --> 00:34:31,449
이제 우리 네트워크는이 두 가지 다른

635
00:34:31,449 --> 00:34:34,228
출력, 하나는이 클래스 점수 집합,

636
00:34:34,228 --> 00:34:36,340
다른 하나는 좌표를 제공하는이 4 개의 숫자입니다.

637
00:34:36,341 --> 00:34:39,094
입력 이미지에서 경계 상자의

638
00:34:39,094 --> 00:34:41,180
이제 교육 시간에이 네트워크를 훈련 할 때

639
00:34:41,181 --> 00:34:44,489
이 시나리오에서는 실제로 두 가지 손실이 발생합니다.

640
00:34:44,489 --> 00:34:47,210
우리는 완전히 감독 된 환경을 가정합니다.

641
00:34:47,210 --> 00:34:49,159
그래서 우리는 각각의 트레이닝 이미지

642
00:34:49,159 --> 00:34:52,119
카테고리 라벨과 함께 주석이 달려 있습니다.

643
00:34:52,120 --> 00:34:55,331
이미지의 해당 카테고리에 대한 경계 진리 경계 상자.

644
00:34:55,331 --> 00:34:57,118
이제 두 가지 손실 함수가 생깁니다.

645
00:34:57,118 --> 00:34:59,864
우리가 가장 좋아하는 softmax 손실이 있습니다.

646
00:34:59,864 --> 00:35:01,640
지상 진실 카테고리 레이블 사용

647
00:35:01,640 --> 00:35:03,360
예측 된 클래스 점수,

648
00:35:03,360 --> 00:35:06,461
우리에게도 어떤 손실이 있습니다.

649
00:35:06,461 --> 00:35:09,920
우리가 예측 한 것 사이의 비 유사성의 일부 척도

650
00:35:09,920 --> 00:35:11,348
경계 상자의 좌표

651
00:35:11,348 --> 00:35:13,669
경계 상자에 대한 실제 좌표입니다.

652
00:35:13,669 --> 00:35:16,448
그래서 아주 간단한 것은 L2 손실을 취하는 것입니다.

653
00:35:16,448 --> 00:35:18,610
그 두 사람 사이에 그것은 가장 단순한 것입니다

654
00:35:18,610 --> 00:35:20,509
때로는 실제로 볼 수 있습니다.

655
00:35:20,509 --> 00:35:22,570
사람들은 이것으로 놀고 L1을 사용할 수도 있습니다.

656
00:35:22,570 --> 00:35:25,181
또는 L1을 부드럽게하거나 테두리
상자를 매개 변수화합니다.

657
00:35:25,181 --> 00:35:27,728
다르게 다르게 그러나 아이디어는 항상 동일 하,

658
00:35:27,728 --> 00:35:30,277
당신은 약간의 회귀 손실이 있다고

659
00:35:30,277 --> 00:35:32,709
예상 경계 상자 좌표 간

660
00:35:32,709 --> 00:35:35,509
그리고 지상 진리 경계 상자 좌표.

661
00:35:35,509 --> 00:35:36,342
문제?

662
00:35:38,177 --> 00:35:39,510
미안 해요.

663
00:35:49,410 --> 00:35:50,966
그래서 질문은 좋은 생각인가?

664
00:35:50,966 --> 00:35:52,193
동시에 모든 것을 할 수 있습니까?

665
00:35:52,193 --> 00:35:53,633
당신이 잘못 분류하면 어떻게되는지,

666
00:35:53,633 --> 00:35:55,600
상자 좌표를보아야합니까?

667
00:35:55,600 --> 00:35:57,401
그래서 때로는 사람들이 그걸 가지고 놀란다.

668
00:35:57,401 --> 00:35:59,901
그래서 일반적으로 괜찮습니다.

669
00:35:59,901 --> 00:36:01,993
큰 문제는 아니며 실제로 네트워크를 훈련시킬 수 있습니다.

670
00:36:01,993 --> 00:36:03,652
동시에이 두 가지를 모두 수행한다.

671
00:36:03,652 --> 00:36:06,753
그리고 그것을 알아낼 것입니다 그러나
때로는 일들이 까다로울 수 있습니다.

672
00:36:06,753 --> 00:36:09,592
잘못된 분류의 관점에서 때때로 볼 수있는 것

673
00:36:09,592 --> 00:36:12,741
예를 들어 하나의 상자를 예측하는 것이 아니라

674
00:36:12,741 --> 00:36:15,102
별도의 예측과 같은 예측을 할 수 있습니다.

675
00:36:15,102 --> 00:36:19,232
각 카테고리에 대해 상자의 다음 손실 만 적용

676
00:36:19,232 --> 00:36:22,651
예측 된 상자에 해당

677
00:36:22,651 --> 00:36:24,091
지상 진실 카테고리로

678
00:36:24,091 --> 00:36:26,011
그래서 사람들은 이런 것들을 조금 좋아하게됩니다.

679
00:36:26,011 --> 00:36:28,318
때로는 약간의 연습에 도움이됩니다.

680
00:36:28,318 --> 00:36:30,552
그러나 최소한이 기본 설정은 완벽하지 않을 수 있습니다.

681
00:36:30,552 --> 00:36:32,232
또는 그것은 최적이 아니지만 작동 할 수 있습니다.

682
00:36:32,232 --> 00:36:34,611
그리고 그것은 뭔가를 할 것입니다.

683
00:36:34,611 --> 00:36:37,361
뒷쪽에 질문이 있었습니까?

684
00:36:41,226 --> 00:36:43,447
그래, 그 질문은 이러한 손실을하는 것입니다.

685
00:36:43,447 --> 00:36:46,746
서로 다른 단위를 가지고 있습니다,
그들은 그라디언트를 지배합니까?

686
00:36:46,746 --> 00:36:49,306
이것이 우리가 다중 작업 손실이라고 부르는 것입니다.

687
00:36:49,306 --> 00:36:51,415
그래서 우리가 파생 상품을 복용 할 때마다 항상 우리는

688
00:36:51,415 --> 00:36:54,325
존경심을 갖고 스칼라의 유래 물을 가져 가고 싶다.

689
00:36:54,325 --> 00:36:56,725
우리의 네트워크 매개 변수에

690
00:36:56,725 --> 00:36:58,554
그라데이션 단계를 수행합니다.

691
00:36:58,554 --> 00:37:01,331
하지만 이제 우리는 두 개의
스칼라를 모두 최소화하고자합니다.

692
00:37:01,331 --> 00:37:03,662
그래서 당신이 실제로하는 경향이있는 것은

693
00:37:03,662 --> 00:37:05,742
가중치를주는 하이퍼 매개 변수

694
00:37:05,742 --> 00:37:08,243
이 두 손실 사이에 가중치가 적용됩니다.

695
00:37:08,243 --> 00:37:09,843
이 두 가지 손실 함수 중

696
00:37:09,843 --> 00:37:11,833
최종 스칼라 손실을 줄 수 있습니다.

697
00:37:11,833 --> 00:37:13,422
그리고 존경심을 가지고 당신의 그라디언트를 취할 것입니다.

698
00:37:13,422 --> 00:37:15,642
이 두 손실의 가중 합계.

699
00:37:15,642 --> 00:37:18,513
그리고 이것은 결국 정말로 까다로워집니다.

700
00:37:18,513 --> 00:37:21,022
이 가중치 매개 변수가 하이퍼 매개 변수이기 때문에

701
00:37:21,022 --> 00:37:23,691
당신이 설정해야하지만 그것은 일종의 종류입니다

702
00:37:23,691 --> 00:37:25,422
다른 하이퍼 매개 변수 중 일부에서

703
00:37:25,422 --> 00:37:27,851
과거에 우리가 지금까지 보았던

704
00:37:27,851 --> 00:37:29,923
이 가중치 하이퍼 파라미터

705
00:37:29,923 --> 00:37:32,390
실제로 손실 함수의 값을 변경합니다.

706
00:37:32,390 --> 00:37:34,872
그래서 당신이 자주 볼 수있는 한가지

707
00:37:34,872 --> 00:37:36,531
하이퍼 파라미터를 설정하려고 할 때

708
00:37:36,531 --> 00:37:38,701
당신은 다른 hyperparameter 선택을 할 것입니다

709
00:37:38,701 --> 00:37:40,502
손실에 어떤 일이 일어나는 지보십시오.

710
00:37:40,502 --> 00:37:43,091
하이퍼 파라미터의 다른 선택하에

711
00:37:43,091 --> 00:37:45,570
그러나이 경우 실제로 손실이 있기 때문에,

712
00:37:45,570 --> 00:37:47,851
하이퍼 매개 변수가 절대 값에 영향을주기 때문에

713
00:37:47,851 --> 00:37:51,089
그 비교를 만드는 손실의 일종의 까다로운된다.

714
00:37:51,089 --> 00:37:54,473
그래서 하이퍼 매개 변수를 설정하는 것은 다소 어렵습니다.

715
00:37:54,473 --> 00:37:56,121
그리고 실제로, 당신은 그것을 취할 필요가 있습니다.

716
00:37:56,121 --> 00:37:58,153
정확히 문제를 해결하기 위해 사례별로

717
00:37:58,153 --> 00:38:00,393
당신이 해결하고 있지만 내 일반적인 전략이

718
00:38:00,393 --> 00:38:04,342
성능에 대한 다른 척도가 있어야합니다.

719
00:38:04,342 --> 00:38:08,163
당신이 실제 손실 값이 아닌 다른 것을 신경 쓰는 것

720
00:38:08,163 --> 00:38:11,182
그러면 최종 실적 통계를 실제로 사용하게됩니다.

721
00:38:11,182 --> 00:38:13,502
찾고있는 것보다 교차 검증 옵션을 만드는 것

722
00:38:13,502 --> 00:38:17,763
그 선택의 손실에 대한 가치.

723
00:38:17,763 --> 00:38:18,596
문제?

724
00:38:27,529 --> 00:38:30,432
문제는 왜 우리가이 모든 것을 한꺼번에하는 것입니까?

725
00:38:30,432 --> 00:38:32,682
이 작업을 별도로하지 않는 이유는 무엇입니까?

726
00:38:38,131 --> 00:38:40,099
네, 그렇다면 왜 우리는 큰
네트워크를 수정하지 않는 것입니까?

727
00:38:40,099 --> 00:38:43,923
그런 다음 완전히 연결된 별도의 레이어 만 배우십시오.

728
00:38:43,923 --> 00:38:45,413
이 두 가지 일에 대해서?

729
00:38:45,413 --> 00:38:47,833
사람들은 가끔 그런 일을하고 실제로는 아마 그렇게합니다.

730
00:38:47,833 --> 00:38:49,523
직면하면 먼저 시도해야합니다.

731
00:38:49,523 --> 00:38:52,702
이런 상황이 일반적이지만

732
00:38:52,702 --> 00:38:53,894
당신이 전학 학습을 할 때마다

733
00:38:53,894 --> 00:38:55,742
당신이 미세 조정하면 항상 더 나은 성능을 얻습니다.

734
00:38:55,742 --> 00:38:57,734
아마도 시스템 전체가 공동으로

735
00:38:57,734 --> 00:39:00,574
기능 간의 일부 불일치,

736
00:39:00,574 --> 00:39:02,961
ImageNet에서 교육을하고 그 네트워크를 사용한다면

737
00:39:02,961 --> 00:39:05,451
데이터 세트에 대해 더 나은 성능을 얻으려고합니다.

738
00:39:05,451 --> 00:39:09,280
또한 네트워크를 변경할 수있는 경우 데이터 세트에서

739
00:39:09,280 --> 00:39:11,521
하지만 때로는 실제로 볼 수있는 트릭 하나

740
00:39:11,521 --> 00:39:13,641
그 네트워크를 동결시킬 수도 있다는 것입니다.

741
00:39:13,641 --> 00:39:16,870
그런 다음 두 가지를 수렴 할 때까지 따로 훈련하십시오.

742
00:39:16,870 --> 00:39:18,459
그리고 나서 그들이 수렴 한 후에 당신은 돌아갑니다.

743
00:39:18,459 --> 00:39:20,398
전체 시스템을 공동으로 조정할 수 있습니다.

744
00:39:20,398 --> 00:39:21,958
그래서 그것은 때때로 사람들이하는 속임수입니다.

745
00:39:21,958 --> 00:39:24,558
그 상황에서 실제로.

746
00:39:24,558 --> 00:39:26,310
그리고이 큰 네트워크에 대해 일종의 언급이 있습니다.

747
00:39:26,310 --> 00:39:28,811
종종 미리 훈련받은 네트워크입니다.

748
00:39:28,811 --> 00:39:30,978
ImageNet에서 예를 들면.

749
00:39:31,979 --> 00:39:34,729
그래서 약간은 제쳐두고, 예측하는이 아이디어는

750
00:39:34,729 --> 00:39:37,339
이미지의 일부 고정 위치

751
00:39:37,339 --> 00:39:38,921
다양한 문제에 적용될 수있다.

752
00:39:38,921 --> 00:39:41,881
분류 및 지역화 이상.

753
00:39:41,881 --> 00:39:44,710
멋진 예제 중 하나는 인간의 포즈 추정입니다.

754
00:39:44,710 --> 00:39:47,379
여기서 우리는 입력 이미지를 얻고 자합니다.

755
00:39:47,379 --> 00:39:49,440
사람의 사진입니다.

756
00:39:49,440 --> 00:39:51,569
우리는 관절의 위치를 출력하고 싶습니다.

757
00:39:51,569 --> 00:39:54,542
그 사람에 대한 그리고 이것은 실제로 네트워크를 허용

758
00:39:54,542 --> 00:39:56,462
인간의 포즈가 무엇인지 예측합니다.

759
00:39:56,462 --> 00:39:59,030
그의 팔은 어디에 있는가, 그의
다리는 어디에 있는가, 그런 것들,

760
00:39:59,030 --> 00:40:02,702
일반적으로 대부분의 사람들은 같은
수의 관절을 가지고 있습니다.

761
00:40:02,702 --> 00:40:04,060
이것은 약간 단순화 된 가정입니다.

762
00:40:04,060 --> 00:40:06,862
항상 사실 일 수는 없지만 네트워크에서 작동합니다.

763
00:40:06,862 --> 00:40:10,251
예를 들어 볼 수있는 하나의 매개 변수화

764
00:40:10,251 --> 00:40:13,451
일부 데이터 세트에서는 사람의 포즈를 정의합니다.

765
00:40:13,451 --> 00:40:15,430
14 개의 공동 위치.

766
00:40:15,430 --> 00:40:16,932
발과 무릎과 엉덩이

767
00:40:16,932 --> 00:40:19,652
그리고 그런 것과 지금 우리가 네트워크를 훈련 할 때

768
00:40:19,652 --> 00:40:23,150
우리는이 사람의 이미지를 입력하려고합니다.

769
00:40:23,150 --> 00:40:27,132
이제는이 경우 14 개의 숫자를 출력 할 것입니다.

770
00:40:27,132 --> 00:40:30,521
14 개의 각 관절에 대해 x와 y 좌표를 제공합니다.

771
00:40:30,521 --> 00:40:33,120
그리고 나서 어떤 종류의 회귀 손실을 적용합니다.

772
00:40:33,120 --> 00:40:35,961
14 개의 서로 다른 예측 포인트

773
00:40:35,961 --> 00:40:40,619
역 전파로이 네트워크를 다시 훈련하십시오.

774
00:40:40,619 --> 00:40:43,579
네, L2 손실은 있지만 사람들은 놀아 볼 수 있습니다.

775
00:40:43,579 --> 00:40:46,571
다른 회귀 손실도 여기에 있습니다.

776
00:40:46,571 --> 00:40:47,404
문제?

777
00:40:50,934 --> 00:40:52,432
그래서 질문은 무엇을 의미합니까?

778
00:40:52,432 --> 00:40:53,992
회귀 손실이라고 할 때?

779
00:40:53,992 --> 00:40:56,099
그래서 저는 크로스 엔트로피가 아닌 다른 것을 의미합니다.

780
00:40:56,099 --> 00:40:57,294
또는 softmax 권리.

781
00:40:57,294 --> 00:40:59,094
내가 회귀선 상실을 말할 때 나는 보통 의미한다.

782
00:40:59,094 --> 00:41:02,382
L2 유클리드 손실 또는 L1 손실과 같은

783
00:41:02,382 --> 00:41:04,494
또는 때로는 부드러운 L1 손실.

784
00:41:04,494 --> 00:41:07,512
그러나 일반적으로 분류 대 회귀 분석

785
00:41:07,512 --> 00:41:10,502
귀하의 산출물이 범주 형 또는 연속 형인지 여부입니다.

786
00:41:10,502 --> 00:41:12,643
그래서 만약 당신이 범주 적 산출물을 기대한다면

787
00:41:12,643 --> 00:41:15,272
당신이 궁극적으로 분류 결정을 내리고 싶어하는 것처럼

788
00:41:15,272 --> 00:41:17,243
고정 된 수의 카테고리

789
00:41:17,243 --> 00:41:19,942
그러면 교차 엔트로피 손실에 대해 생각할 것입니다.

790
00:41:19,942 --> 00:41:23,094
softmax 손실 또는 이러한 SVM 마진 유형 손실

791
00:41:23,094 --> 00:41:25,022
우리가 이미 수업에서 말했던 것.

792
00:41:25,022 --> 00:41:28,272
그러나 예상되는 결과가 일정한 가치를 지니고 있다면,

793
00:41:28,272 --> 00:41:30,222
이 경우이 점의 위치,

794
00:41:30,222 --> 00:41:32,174
출력이 연속적이어서 사용하는 경향이 있습니다.

795
00:41:32,174 --> 00:41:34,734
그 상황에서 손실의 다른 유형.

796
00:41:34,734 --> 00:41:37,883
일반적으로 L2, L1, 다른 종류의 것들이 있습니다.

797
00:41:37,883 --> 00:41:41,482
더 일찍 그것을 명확히하지 않기 때문에 유감스럽게 생각합니다.

798
00:41:41,482 --> 00:41:44,471
그러나 여기서 더 큰 요점은 언제든지

799
00:41:44,471 --> 00:41:46,832
고정 된 번호를 만들고 싶다는 것을 알고 있습니다.

800
00:41:46,832 --> 00:41:51,003
예를 들어 알고 있다면 네트워크 출력을

801
00:41:51,003 --> 00:41:54,344
어쩌면 당신은 당신이 원한다는 것을 알았을 것입니다,

802
00:41:54,344 --> 00:41:56,395
당신은 항상 당신이 그림을 가질 것이라는 것을 알았습니다.

803
00:41:56,395 --> 00:41:58,763
개와 고양이 둘 다 예측하고 싶다.

804
00:41:58,763 --> 00:42:01,392
고양이의 테두리 상자와 개 테두리 상자

805
00:42:01,392 --> 00:42:03,062
이 경우 당신은 당신이 고정 된 숫자를
가지고 있음을 알게 될 것입니다.

806
00:42:03,062 --> 00:42:05,304
당신이 상상할 수 있도록 각 입력에 대한 출력

807
00:42:05,304 --> 00:42:07,093
이런 종류의 회귀

808
00:42:07,093 --> 00:42:09,264
분류 플러스 현지화 프레임 워크

809
00:42:09,264 --> 00:42:10,743
그 문제에 대해서도.

810
00:42:10,743 --> 00:42:13,094
고정 된 수의 회귀 출력에 대한이 아이디어

811
00:42:13,094 --> 00:42:14,872
다양한 문제에 적용될 수있다.

812
00:42:14,872 --> 00:42:17,039
포즈 추정 포함.

813
00:42:19,062 --> 00:42:23,531
그래서 제가 이야기하고 싶은 다음 과제는 물체 감지입니다.

814
00:42:23,531 --> 00:42:25,342
그리고 이것은 정말 육감적 인 주제입니다.

815
00:42:25,342 --> 00:42:27,422
이것은 컴퓨터 비전의 핵심 문제입니다.

816
00:42:27,422 --> 00:42:29,910
아마도 전체 세미나 수업을 가르 칠 수 있습니다.

817
00:42:29,910 --> 00:42:31,868
물체 탐지의 역사에

818
00:42:31,868 --> 00:42:33,902
그리고 거기에 적용된 다양한 기술.

819
00:42:33,902 --> 00:42:35,931
그래서 나는 비교적 짧게 갈 것입니다.

820
00:42:35,931 --> 00:42:39,691
객체 탐지와 깊은 학습의 주요 아이디어

821
00:42:39,691 --> 00:42:42,582
지난 몇 년 동안 사용 된

822
00:42:42,582 --> 00:42:44,731
그러나 물체 감지의 아이디어는

823
00:42:44,731 --> 00:42:47,942
고정 된 카테고리 세트로 다시 시작합니다.

824
00:42:47,942 --> 00:42:52,182
우리가 관심을 갖는, 어쩌면 고양이와 개 그리고 물고기

825
00:42:52,182 --> 00:42:55,321
그러나 우리가 관심을 가지고있는
카테고리의 일부 고정 세트.

826
00:42:55,321 --> 00:42:59,030
이제 우리의 임무는 우리의 입력
이미지가 주어진다는 것입니다,

827
00:42:59,030 --> 00:43:02,470
해당 카테고리 중 하나가 이미지에 나타날 때마다

828
00:43:02,470 --> 00:43:05,641
우리는 그 주위에 상자를 그리기를 원하며 우리는

829
00:43:05,641 --> 00:43:08,710
그 상자의 범주가 이렇게 다르다.

830
00:43:08,710 --> 00:43:10,902
분류 플러스 현지화에서

831
00:43:10,902 --> 00:43:13,620
다양한 출력이있을 수 있기 때문에

832
00:43:13,620 --> 00:43:15,302
모든 입력 이미지에 대해.

833
00:43:15,302 --> 00:43:17,910
당신은 당신이 예상하는 물체의 수를 미리 알지 못합니다.

834
00:43:17,910 --> 00:43:20,081
각 이미지에서 찾을 수 있도록

835
00:43:20,081 --> 00:43:22,870
이것은 꽤 어려운 문제가됩니다.

836
00:43:22,870 --> 00:43:25,630
그래서 우리는 그래프를 보았습니다.
그래서 이것은 재미 있습니다.

837
00:43:25,630 --> 00:43:28,988
우리는이 그래프를 여러 번 ImageNet에서 보았습니다.

838
00:43:28,988 --> 00:43:31,870
년의 함수로 분류 성능

839
00:43:31,870 --> 00:43:34,761
우리는 매년 더 좋아지고 나아 졌음을 보았습니다.

840
00:43:34,761 --> 00:43:37,342
객체 감지와 비슷한 경향이있었습니다.

841
00:43:37,342 --> 00:43:39,131
물체 감지가 다시 한 번 있었기 때문에

842
00:43:39,131 --> 00:43:41,291
컴퓨터 비전의 이러한 핵심 문제들

843
00:43:41,291 --> 00:43:44,110
사람들이 아주 오랫동안 관심을 가지고 있습니다.

844
00:43:44,110 --> 00:43:46,390
그래서이 슬라이드는 Ross Girshick

845
00:43:46,390 --> 00:43:48,742
누가이 문제에 대해 많은 노력을 기울 였는지 보여줍니다.

846
00:43:48,742 --> 00:43:51,070
물체 감지 성능의 진보

847
00:43:51,070 --> 00:43:54,441
PASCAL VOC라는이 특정 데이터 세트

848
00:43:54,441 --> 00:43:57,230
오래 동안 상대적으로 사용 되어온

849
00:43:57,230 --> 00:43:59,462
객체 감지 커뮤니티에서.

850
00:43:59,462 --> 00:44:02,428
그리고 2012 년경까지

851
00:44:02,428 --> 00:44:04,761
물체 감지 성능이 정체되기 시작했습니다.

852
00:44:04,761 --> 00:44:08,161
2013 년 조금씩 천천히

853
00:44:08,161 --> 00:44:10,039
첫 번째 깊은 학습 접근 방식 중 일부는

854
00:44:10,039 --> 00:44:12,141
물체 감지가 생겨서 당신이 보았습니다.

855
00:44:12,141 --> 00:44:13,982
그 성능은 매우 빨리 상승했다.

856
00:44:13,982 --> 00:44:16,171
해가 갈수록 좋아졌습니다.

857
00:44:16,171 --> 00:44:19,221
한가지 주목할 점은이 계획이
2015 년에 종료된다는 것입니다.

858
00:44:19,221 --> 00:44:21,422
그 이후로 실제로 계속 올라갑니다.

859
00:44:21,422 --> 00:44:23,411
이 데이터 세트의 최신 기술 수준

860
00:44:23,411 --> 00:44:25,651
사실 80 세 이상이며 사실 많은 최근 논문들입니다.

861
00:44:25,651 --> 00:44:28,051
더 이상이 데이터 세트에 대한 결과를보고하지 않습니다.

862
00:44:28,051 --> 00:44:29,929
그것은 너무 쉬운 것으로 간주되기 때문에.

863
00:44:29,929 --> 00:44:31,598
그래서 조금 알기가 어렵습니다.

864
00:44:31,598 --> 00:44:33,561
나는 예술 번호의 상태가 실제로 무엇인지 확신하지 못한다.

865
00:44:33,561 --> 00:44:37,422
이 데이터 세트에서는이 플롯의 맨 위에 있습니다.

866
00:44:37,422 --> 00:44:40,091
미안, 질문 있니?

867
00:44:40,091 --> 00:44:40,924
신경 쓰지 마.

868
00:44:42,051 --> 00:44:45,281
그래, 내가 이미 말했듯이 이것은 다르다.

869
00:44:45,281 --> 00:44:48,481
현지화가 다를 수 있으므로

870
00:44:48,481 --> 00:44:50,961
각 이미지의 개체 수.

871
00:44:50,961 --> 00:44:53,462
예를 들어 왼쪽 상단의 고양이

872
00:44:53,462 --> 00:44:55,142
개체가 하나뿐이므로 예측하기 만하면됩니다.

873
00:44:55,142 --> 00:44:57,771
네 개의 숫자가 있지만이 이미지는 중간에있다.

874
00:44:57,771 --> 00:45:01,431
거기에 3 마리의 동물이있어서
우리의 네트워크가 필요합니다.

875
00:45:01,431 --> 00:45:03,774
12 개의 숫자, 4 개의 좌표를 예측한다.

876
00:45:03,774 --> 00:45:05,552
각 경계 상자에 대해

877
00:45:05,552 --> 00:45:08,379
또는 많은 많은 오리들이있는이 예에서 당신은

878
00:45:08,379 --> 00:45:10,673
귀하의 네트워크는 수많은 숫자를 예측합니다.

879
00:45:10,673 --> 00:45:13,211
다시 한 번, 각 오리에 대해 4 개의 숫자.

880
00:45:13,211 --> 00:45:17,894
따라서 이것은 물체 감지와 아주 다릅니다.

881
00:45:17,894 --> 00:45:20,683
죄송 객체 감지는 현지화와 매우 다릅니다.

882
00:45:20,683 --> 00:45:24,382
왜냐하면 물체를 탐지 할 때 숫자가
다를 수 있기 때문입니다.

883
00:45:24,382 --> 00:45:26,633
이미지에있는 물체를 발견하고 미리 알지 못한다.

884
00:45:26,633 --> 00:45:28,870
얼마나 많은 사람들이 찾을 것으로 기대하는지.

885
00:45:28,870 --> 00:45:32,213
결과적으로 생각하기를 원한다면 다소 까다 롭습니다.

886
00:45:32,213 --> 00:45:34,568
회귀 문제로 객체 탐지의

887
00:45:34,568 --> 00:45:37,467
그래서 대신 사람들은 일하는 경향이
있고 다른 종류의 것을 사용합니다.

888
00:45:37,467 --> 00:45:40,768
물체 감지에 대해 생각할 때의 패러다임.

889
00:45:40,768 --> 00:45:44,797
매우 보편적이며 사용 된 하나의 접근법

890
00:45:44,797 --> 00:45:47,328
컴퓨터 비전에서 오랫동안이 아이디어는

891
00:45:47,328 --> 00:45:49,958
슬라이딩 윈도우가 객체 검출에 접근한다.

892
00:45:49,958 --> 00:45:52,920
그래서이 아이디어와 비슷합니다.

893
00:45:52,920 --> 00:45:55,138
작은 패치를 가져다가 적용하는 법

894
00:45:55,138 --> 00:45:57,099
의미 론적 세분화를 위해

895
00:45:57,099 --> 00:45:59,360
물체 감지와 비슷한 아이디어.

896
00:45:59,360 --> 00:46:01,733
그래서 아이디어는 우리가 다른 작물을 가져갈 것입니다.

897
00:46:01,733 --> 00:46:05,118
입력 이미지에서이 경우에는이 자르기가 있습니다.

898
00:46:05,118 --> 00:46:07,248
이미지의 왼쪽 하단에

899
00:46:07,248 --> 00:46:08,808
그리고 이제 우리는 그 작물을 가져 간다.

900
00:46:08,808 --> 00:46:10,359
우리의 길쌈 네트워크를 통해 그것을 먹인다.

901
00:46:10,359 --> 00:46:11,939
우리의 컨볼 루션 네트워크는

902
00:46:11,939 --> 00:46:14,829
그 입력 작물에 대한 분류 결정.

903
00:46:14,829 --> 00:46:18,160
여기에는 개가 없다고 말할 것입니다. 고양이는 없습니다.

904
00:46:18,160 --> 00:46:20,960
그런 다음 우리가 신경 쓰는 범주에 추가하여

905
00:46:20,960 --> 00:46:23,899
배경이라는 추가 카테고리를 추가하겠습니다.

906
00:46:23,899 --> 00:46:27,179
이제 우리 네트워크는 배경을 예측할 수 있습니다.

907
00:46:27,179 --> 00:46:29,399
카테고리가 표시되지 않는 경우

908
00:46:29,399 --> 00:46:32,288
우리가 관심을 가지는, 그래서 우리가이 작물을 먹을 때

909
00:46:32,288 --> 00:46:34,240
왼쪽 하단에서부터 여기

910
00:46:34,240 --> 00:46:36,389
우리의 네트워크는 희망적으로 배경을 예측할 것입니다.

911
00:46:36,389 --> 00:46:39,008
아니, 여기에는 아무 목표도 없다고.

912
00:46:39,008 --> 00:46:40,840
이제 우리가 다른 작물을 먹으면 우리의 네트워크

913
00:46:40,840 --> 00:46:44,128
개는 예, 고양이는 아니오, 배경은 없습니다.

914
00:46:44,128 --> 00:46:45,909
우리는 다른 작물을 먹습니다. 개를 얻습니다.

915
00:46:45,909 --> 00:46:47,680
고양이 아니, 배경 번호.

916
00:46:47,680 --> 00:46:51,789
또는 다른 작물, 개 아니오,
고양이 그렇습니다, 배경 아니오.

917
00:46:51,789 --> 00:46:54,372
누구는 여기에 문제가 보이나요?

918
00:47:00,324 --> 00:47:02,812
예, 문제는 농작물을 어떻게 선택 하느냐는 것입니다.

919
00:47:02,812 --> 00:47:04,764
이것은 큰 문제입니다.

920
00:47:04,764 --> 00:47:07,972
이 이미지에는 많은 수의 객체가있을 수 있으므로,

921
00:47:07,972 --> 00:47:10,543
이러한 객체는 이미지의 어느
위치 에나 나타날 수 있습니다.

922
00:47:10,543 --> 00:47:13,193
이러한 객체는 이미지의 어떤 크기에서도 나타날 수 있지만,

923
00:47:13,193 --> 00:47:15,583
이러한 객체는 모든 종횡비로 표시 될 수도 있습니다.

924
00:47:15,583 --> 00:47:18,571
이미지에서, 만약 당신이 무자비한 종류의 일을하고 싶다면

925
00:47:18,571 --> 00:47:21,052
슬라이딩 윈도우 접근 방식을
사용하면 테스트하지 않아도됩니다.

926
00:47:21,052 --> 00:47:23,850
수천, 수만, 많은 수 많은

927
00:47:23,850 --> 00:47:27,263
이 문제를 해결하기 위해 다른 작물

928
00:47:27,263 --> 00:47:29,523
brute force 슬라이딩 윈도우 접근법.

929
00:47:29,523 --> 00:47:32,025
그리고 그 작물들 모두가

930
00:47:32,025 --> 00:47:35,004
거대한 길쌈 네트워크 (convolutional
network)를 통해 공급 될 것입니다.

931
00:47:35,004 --> 00:47:37,532
이것은 완전히 계산적으로 다루기 어려울 것입니다.

932
00:47:37,532 --> 00:47:41,063
따라서 실제로 사람들은 이런 종류의
무차별 한 행동을하지 않습니다.

933
00:47:41,063 --> 00:47:43,503
객체 감지를위한 슬라이딩 윈도우 접근법

934
00:47:43,503 --> 00:47:45,920
컨벌루션 네트워크를 사용합니다.

935
00:47:47,044 --> 00:47:49,532
대신이 멋진 라인이 있습니다.

936
00:47:49,532 --> 00:47:52,572
지역 제안서,

937
00:47:52,572 --> 00:47:54,492
이것은 일반적으로 깊은 학습을 사용하지 않습니다.

938
00:47:54,492 --> 00:47:56,332
이들은 약간 더 전통적인 컴퓨터 비전입니다.

939
00:47:56,332 --> 00:47:59,732
기술이지만 아이디어는 지역 제안 네트워크

940
00:47:59,732 --> 00:48:02,353
종류는 전통적인 신호 처리를 사용합니다.

941
00:48:02,353 --> 00:48:05,401
일부 목록을 만들 이미지 처리 유형 것들

942
00:48:05,401 --> 00:48:08,343
입력 된 이미지가 주어 졌을 때,

943
00:48:08,343 --> 00:48:10,322
지역 제안 네트워크를 통해

944
00:48:10,322 --> 00:48:14,341
물체가있는 수천 개의 상자와 같습니다.

945
00:48:14,341 --> 00:48:17,023
그래서 우리는 아마도 우리가 지역 사회에서 어떤
일을 할지도 모른다고 상상할 수 있습니다.

946
00:48:17,023 --> 00:48:19,564
우리는 이미지의 가장자리를 찾고 박스를 그려 봅니다.

947
00:48:19,564 --> 00:48:22,382
닫힌 가장자리 또는 그와 비슷한 것을 포함합니다.

948
00:48:22,382 --> 00:48:24,650
이러한 다양한 유형의 이미지 프로세싱 접근법,

949
00:48:24,650 --> 00:48:27,004
하지만이 지역 제안 네트워크는 기본적으로

950
00:48:27,004 --> 00:48:30,132
우리의 입력 이미지에서 얼룩덜룩 한 지역에 대한

951
00:48:30,132 --> 00:48:32,873
일부 제안 후보 지역 집합

952
00:48:32,873 --> 00:48:35,604
물체가 잠재적으로 발견 될 수 있습니다.

953
00:48:35,604 --> 00:48:38,962
그리고 이것들은 비교적 빠르게 실행됩니다.

954
00:48:38,962 --> 00:48:42,193
그래서 지역 제안 방법의 한 일반적인 예

955
00:48:42,193 --> 00:48:44,703
당신이 볼 수있는 것은 Selective Search

956
00:48:44,703 --> 00:48:47,244
나는 실제로 당신에게 2000 개의
지역 제안을 준다라고 생각한다.

957
00:48:47,244 --> 00:48:49,284
슬라이드에서 말하는 1000이 아닙니다.

958
00:48:49,284 --> 00:48:51,713
그래서 너는이 일을 실행 한 다음에

959
00:48:51,713 --> 00:48:53,844
CPU를 켜는 데 약 2 초가 걸린다.

960
00:48:53,844 --> 00:48:57,364
입력 이미지에 2000 개의 지역 제안서가 누출됩니다.

961
00:48:57,364 --> 00:48:59,404
물체가 발견 될 가능성이있는 곳

962
00:48:59,404 --> 00:49:01,204
그래서 그들에는 많은 소음이있을 것입니다.

963
00:49:01,204 --> 00:49:03,252
대부분은 참된 대상이 아닙니다.

964
00:49:03,252 --> 00:49:05,052
하지만 꽤 높은 리콜이 있습니다.

965
00:49:05,052 --> 00:49:07,223
이미지에 객체가 있으면 경향이 있습니다.

966
00:49:07,223 --> 00:49:08,913
이 지역 제안들에 의해 보호받는

967
00:49:08,913 --> 00:49:11,204
선택 검색에서.

968
00:49:11,204 --> 00:49:14,212
이제는 분류 네트워크를 적용하는 것이 아니라

969
00:49:14,212 --> 00:49:17,103
이미지의 가능한 모든 위치 및 크기 조정

970
00:49:17,103 --> 00:49:19,930
대신 우리가 할 수있는 일은 먼저이
중 하나를 적용하는 것입니다.

971
00:49:19,930 --> 00:49:22,171
지역 제안 네트워크는 일부 설정을 얻습니다.

972
00:49:22,171 --> 00:49:25,164
물체가 위치 할 가능성이있는 제안서 지역

973
00:49:25,164 --> 00:49:28,783
분류를 위해 컨벌루션 네트워크를 적용합니다.

974
00:49:28,783 --> 00:49:30,772
이 제안서 영역 각각에

975
00:49:30,772 --> 00:49:33,135
훨씬 더 계산적으로 다루기 쉽다.

976
00:49:33,135 --> 00:49:36,903
모든 가능한 위치와 규모를 시도하는 것보다

977
00:49:36,903 --> 00:49:40,583
그리고이 아이디어는 모두이 논문에서 함께 모였습니다.

978
00:49:40,583 --> 00:49:45,583
몇 년 전 R-CNN이라고 불리는
것이 정확히 그 일을합니다.

979
00:49:45,583 --> 00:49:48,221
이 경우 입력 이미지가 주어집니다.

980
00:49:48,221 --> 00:49:50,673
지역 제안 네트워크를 운영 할 예정입니다.

981
00:49:50,673 --> 00:49:53,263
우리 제안을 얻기 위해, 이것들은 때로는

982
00:49:53,263 --> 00:49:56,724
관심 영역 또는 ROI가 다시 나타남 선택 검색

983
00:49:56,724 --> 00:49:59,692
2000 개의 관심 영역을 제공합니다.

984
00:49:59,692 --> 00:50:03,523
이제 여기에있는 문제 중 하나는 이러한 입력이,

985
00:50:03,523 --> 00:50:07,043
입력 이미지의 이러한 영역은 서로
다른 크기를 가질 수 있습니다.

986
00:50:07,043 --> 00:50:08,204
그러나 우리가 그들을 전부 달릴 예정이라면

987
00:50:08,204 --> 00:50:11,063
길쌈 네트워크 (convolutional
network)를 통해 우리의 분류,

988
00:50:11,063 --> 00:50:13,143
분류를위한 컨볼 루션 네트워크

989
00:50:13,143 --> 00:50:15,922
모두 동일한 입력 크기의 이미지를 원합니다.

990
00:50:15,922 --> 00:50:18,149
완전히 연결된 네트 레이어와 이것 저것 때문에

991
00:50:18,149 --> 00:50:21,058
그래서 우리는이 지역 제안들 각각을 취할 필요가 있습니다.

992
00:50:21,058 --> 00:50:24,029
고정 된 정사각형 크기로 그들을 휘게한다.

993
00:50:24,029 --> 00:50:26,855
이는 다운 스트림 네트워크에 대한 입력으로 예상됩니다.

994
00:50:26,855 --> 00:50:29,170
그래서 우리는 지역 제안서를 작성합니다.

995
00:50:29,170 --> 00:50:32,018
지역 제안에 해당하는 지역,

996
00:50:32,018 --> 00:50:34,090
우리는 고정 된 크기로 그들을 휘게 할 것이고,

997
00:50:34,090 --> 00:50:35,549
그리고 나서 우리는 각각을 실행할 것입니다.

998
00:50:35,549 --> 00:50:37,418
컨벌루션 네트워크를 통해

999
00:50:37,418 --> 00:50:40,488
이 경우에는 SVM을 사용합니다

1000
00:50:40,488 --> 00:50:44,237
그것들 각각에 대한 분류 결정을 내리기 위해서,

1001
00:50:44,237 --> 00:50:48,479
각 작물에 대한 카테고리를 예측할 수 있습니다.

1002
00:50:48,479 --> 00:50:52,506
그리고 나서 나는 슬라이드를 잃어 버렸다.

1003
00:50:52,506 --> 00:50:55,957
그러나 또한 슬라이드에 표시되지 않습니다.

1004
00:50:55,957 --> 00:50:59,757
그러나 R-CNN은 또한 회귀를 예측하며,

1005
00:50:59,757 --> 00:51:02,946
테두리 상자를 수정하는 것과 같습니다.

1006
00:51:02,946 --> 00:51:05,650
또한 각 입력 영역 제안서

1007
00:51:05,650 --> 00:51:07,770
문제는 입력 영역 제안서

1008
00:51:07,770 --> 00:51:10,498
일반적으로 물체의 올바른 위치에있다.

1009
00:51:10,498 --> 00:51:13,549
그러나 그것들은 완벽하지 않을 수도 있습니다.
그래서 R-CNN은,

1010
00:51:13,549 --> 00:51:17,038
각 제안서에 대한 카테고리 라벨 외에도,

1011
00:51:17,038 --> 00:51:19,610
그것도 일종의 네 가지 숫자를 예측할 것입니다.

1012
00:51:19,610 --> 00:51:22,469
오프셋 또는 예측 된 상자에 대한 수정

1013
00:51:22,469 --> 00:51:24,658
지역 제안 단계에서

1014
00:51:24,658 --> 00:51:26,418
다시 한번, 이것은 다중 작업 손실입니다

1015
00:51:26,418 --> 00:51:27,919
너는이 모든 것을 훈련시킬거야.

1016
00:51:27,919 --> 00:51:30,169
미안해, 질문 있니?

1017
00:51:35,511 --> 00:51:36,692
문제는 그 변화가 얼마나

1018
00:51:36,692 --> 00:51:39,359
종횡비에 영향을 미치는 정확도?

1019
00:51:40,698 --> 00:51:41,772
말하기는 조금 어렵습니다.

1020
00:51:41,772 --> 00:51:43,732
나는 통제 된 실험이 있다고 생각한다.

1021
00:51:43,732 --> 00:51:46,551
이 신문 중 일부는 잘 모르겠다.

1022
00:51:46,551 --> 00:51:48,738
나는 그에 대한 일반적인 답을 줄 수있다.

1023
00:51:48,738 --> 00:51:49,571
문제?

1024
00:51:53,602 --> 00:51:54,671
문제는 그것이 필요한 것입니다.

1025
00:51:54,671 --> 00:51:56,772
관심 영역이 직사각형일까요?

1026
00:51:56,772 --> 00:52:00,212
그래서 워프하기가 어렵 기 때문에 일반적으로

1027
00:52:00,212 --> 00:52:03,731
이 비 지역 일이지만 한 번 이동하면됩니다.

1028
00:52:03,731 --> 00:52:05,511
인스턴트 세그멘테이션과 같은 것으로

1029
00:52:05,511 --> 00:52:08,911
그러면 사각형이 아닌 제안서를받는 경우가 있습니다.

1030
00:52:08,911 --> 00:52:10,441
실제로 물건 예측에 관심이 있다면

1031
00:52:10,441 --> 00:52:12,071
직사각형이 아닙니다.

1032
00:52:12,071 --> 00:52:14,238
또 다른 질문이 있습니까?

1033
00:52:18,704 --> 00:52:21,317
네, 그렇다면 문제는 배운 지역 제안입니다.

1034
00:52:21,317 --> 00:52:24,375
그래서 R-CNN에서는 전통적인 것입니다.

1035
00:52:24,375 --> 00:52:27,134
이것들은 배웠지 만, 이것은 일종의 고정 알고리즘입니다

1036
00:52:27,134 --> 00:52:29,203
누군가가 적어 봤지만 몇 분 후에 보게 될거야.

1037
00:52:29,203 --> 00:52:31,866
우리가 실제로 할 수있는 것, 우리는 조금 바꿨습니다.

1038
00:52:31,866 --> 00:52:33,466
지난 몇 년 동안.

1039
00:52:33,466 --> 00:52:35,633
또 다른 질문이 있습니까?

1040
00:52:37,767 --> 00:52:39,486
문제는 항상 오프셋입니다.

1041
00:52:39,486 --> 00:52:40,735
관심 지역?

1042
00:52:40,735 --> 00:52:42,665
대답은 '아니오'일뿐입니다.

1043
00:52:42,665 --> 00:52:45,346
당신은 그 관심 영역을 상상할 수 있습니다.

1044
00:52:45,346 --> 00:52:48,687
사람의 주위에 상자를 놓고 머리를 놓쳤다.

1045
00:52:48,687 --> 00:52:50,786
그러면 당신은 네트워크 추론을 상상할 수 있습니다.

1046
00:52:50,786 --> 00:52:53,439
오,이 사람이 있지만 사람들은 대개 머리가 있습니다.

1047
00:52:53,439 --> 00:52:55,906
그래서 네트워크는 상자가 조금 더
높아야한다고 보여주었습니다.

1048
00:52:55,906 --> 00:52:57,515
때로는 최종 예측 상자

1049
00:52:57,515 --> 00:52:59,666
관심 영역 밖일 것입니다.

1050
00:52:59,666 --> 00:53:00,499
문제?

1051
00:53:08,110 --> 00:53:08,943
네.

1052
00:53:12,019 --> 00:53:13,619
네, 궁금한 점은 투자 수익 (ROI)이 많은 것입니다.

1053
00:53:13,619 --> 00:53:15,877
실제 물건과 일치하지 않는 것들?

1054
00:53:15,877 --> 00:53:18,179
그리고 우리가 말했듯이, 수업 외에도

1055
00:53:18,179 --> 00:53:20,078
너는 너를 정말로 걱정한다.

1056
00:53:20,078 --> 00:53:22,550
백그라운드 클래스를 사용하여 클래스
점수를 얻을 수도 있습니다.

1057
00:53:22,550 --> 00:53:26,289
여기에 물건이 없다고 말하는 배경을 예언해라.

1058
00:53:26,289 --> 00:53:27,122
문제?

1059
00:53:37,716 --> 00:53:40,894
그래, 문제는 우리가 어떤 종류의
데이터를 필요로하는지이다.

1060
00:53:40,894 --> 00:53:43,364
그리고 네, 이것은 완전히 감각적으로 감독됩니다.

1061
00:53:43,364 --> 00:53:47,385
우리의 훈련 데이터는 각 이미지를
가지고 있으며 이미지로 구성됩니다.

1062
00:53:47,385 --> 00:53:50,065
각 이미지에는 표시된 모든 객체 카테고리가 있습니다.

1063
00:53:50,065 --> 00:53:53,383
해당 범주의 각 인스턴스에 대한 경계 상자가 있습니다.

1064
00:53:53,383 --> 00:53:55,404
확실히 이것에 접근하려고하는 논문이 있습니다.

1065
00:53:55,404 --> 00:53:56,904
당신이 데이터를 가지고 있지 않다면 어떻게 될까요?

1066
00:53:56,904 --> 00:54:00,759
일부 이미지에 대해서만 데이터를 가지고 있다면 어떨까요?

1067
00:54:00,759 --> 00:54:02,945
아니면 그 데이터가 시끄 럽긴하지만 적어도

1068
00:54:02,945 --> 00:54:04,735
일반적인 경우 전체 감독을 맡는다.

1069
00:54:04,735 --> 00:54:08,568
교육 시간에 이미지의 모든 개체를

1070
00:54:09,835 --> 00:54:12,974
알았어. 그래서 우리가 이걸 암시한다고 생각해.

1071
00:54:12,974 --> 00:54:14,825
하지만 문제가 많습니다.

1072
00:54:14,825 --> 00:54:16,535
이 R-CNN 프레임 워크와

1073
00:54:16,535 --> 00:54:18,044
그리고 실제로 여기 오른쪽 그림을 보면

1074
00:54:18,044 --> 00:54:19,975
추가 경계 상자 머리를 볼 수 있습니다.

1075
00:54:19,975 --> 00:54:21,644
그래서 나는 그것을 되돌릴 것이다.

1076
00:54:21,644 --> 00:54:25,811
그러나 이것은 여전히 계산 상 꽤 비쌉니다.

1077
00:54:27,436 --> 00:54:30,004
2000 개의 지역 제안서가 있다면,

1078
00:54:30,004 --> 00:54:32,196
우리는 각 제안을 독립적으로 운영하고 있습니다.

1079
00:54:32,196 --> 00:54:34,415
그것은 꽤 비쌀 수 있습니다.

1080
00:54:34,415 --> 00:54:37,111
이 질문에 의거하여

1081
00:54:37,111 --> 00:54:40,015
고정 영역 제안 네트워크,이 고정 영역 제안,

1082
00:54:40,015 --> 00:54:42,895
우리는 그런 것들을 배우지 않고있는 것이 문제입니다.

1083
00:54:42,895 --> 00:54:46,015
그리고 실제로는 아주 천천히 끝납니다.

1084
00:54:46,015 --> 00:54:48,164
원래 구현에서 R-CNN

1085
00:54:48,164 --> 00:54:50,563
실제로 모든 기능을 디스크에 덤프합니다.

1086
00:54:50,563 --> 00:54:52,863
그래서 그것은 수백 기가 바이트의
디스크 공간을 필요로 할 것입니다.

1087
00:54:52,863 --> 00:54:54,721
이러한 모든 기능을 저장합니다.

1088
00:54:54,721 --> 00:54:56,862
그렇다면 훈련은 매우 느릴 것입니다.

1089
00:54:56,862 --> 00:54:58,472
이 모든 전방 및 후방 통과

1090
00:54:58,472 --> 00:55:01,569
이미지를 통해 84 시간이 걸렸습니다.

1091
00:55:01,569 --> 00:55:04,356
그들이 훈련 시간 동안 기록한 하나의 번호입니다.

1092
00:55:04,356 --> 00:55:06,134
그래서 이것은 슈퍼 슈퍼 슬로우입니다.

1093
00:55:06,134 --> 00:55:07,984
그리고 이제 테스트 시간에 그것은 또한 매우 천천히,

1094
00:55:07,984 --> 00:55:11,076
이미지 당 대략 30 초 정도의 시간

1095
00:55:11,076 --> 00:55:13,134
당신은 수천 번 전진 패스를 실행해야하기 때문에

1096
00:55:13,134 --> 00:55:14,454
컨벌루션 네트워크를 통해

1097
00:55:14,454 --> 00:55:16,004
각 지역 제안서

1098
00:55:16,004 --> 00:55:18,316
그래서 이것은 꽤 느리게 끝납니다.

1099
00:55:18,316 --> 00:55:21,505
고맙게도 우리는 빠른 R-CNN을 많이 고정 시켰습니다.

1100
00:55:21,505 --> 00:55:25,084
우리가 빨리 할 때 이렇게 문제의 R-CNN

1101
00:55:25,084 --> 00:55:27,404
그러면 똑같은 모양이 될 것입니다.

1102
00:55:27,404 --> 00:55:29,036
우리는 입력 이미지로 시작할 것입니다.

1103
00:55:29,036 --> 00:55:31,465
이제 각 관심 영역을 처리하는 것이 아니라

1104
00:55:31,465 --> 00:55:34,116
별도로 대신 전체 이미지를 실행합니다.

1105
00:55:34,116 --> 00:55:36,923
한 번에 일부 길쌈 레이어를 통해

1106
00:55:36,923 --> 00:55:39,494
이 고해상도 콘볼 루션 특징 맵 제공

1107
00:55:39,494 --> 00:55:41,924
전체 이미지에 해당합니다.

1108
00:55:41,924 --> 00:55:44,345
이제 우리는 여전히 일부 지역 제안을 사용하고 있습니다.

1109
00:55:44,345 --> 00:55:46,652
선택적 검색과 같은 고정 된 것에서

1110
00:55:46,652 --> 00:55:50,414
이미지의 픽셀을 잘라내 기보다는

1111
00:55:50,414 --> 00:55:52,334
지역 제안서에 해당하는

1112
00:55:52,334 --> 00:55:55,164
대신 우리는 그 지역 제안을 예상한다고 상상합니다.

1113
00:55:55,164 --> 00:55:57,705
이 길쌈 특성지도에

1114
00:55:57,705 --> 00:56:00,673
길쌈 특징지도에서 작물을 가져온다.

1115
00:56:00,673 --> 00:56:02,633
오히려 각 제안에 해당

1116
00:56:02,633 --> 00:56:04,745
이미지에서 작물을 직접 가져 오는 것보다.

1117
00:56:04,745 --> 00:56:06,713
그리고 이것으로 우리는 많은
비용을 재사용 할 수 있습니다.

1118
00:56:06,713 --> 00:56:09,532
전체 이미지에 대한 길쌈 연산

1119
00:56:09,532 --> 00:56:13,425
이미지 당 여러 작물이있을 때.

1120
00:56:13,425 --> 00:56:15,932
그러나 다시 말하지만, 우리가
완전히 연결된 레이어가 있다면

1121
00:56:15,932 --> 00:56:18,052
하류에 완전히 연결된 레이어

1122
00:56:18,052 --> 00:56:20,052
일부 고정 크기 입력을 예상하고 있습니다.

1123
00:56:20,052 --> 00:56:23,844
그래서 지금 우리는 그 작물의
재편성을 할 필요가 있습니다.

1124
00:56:23,844 --> 00:56:26,131
길쌈 특성 맵으로부터

1125
00:56:26,131 --> 00:56:28,572
차별화 된 방식으로

1126
00:56:28,572 --> 00:56:31,673
그들은 ROI 풀링 레이어라고 부르는 것을 사용합니다.

1127
00:56:31,673 --> 00:56:35,362
이 뒤틀린 작물을 가지고 나면

1128
00:56:35,362 --> 00:56:37,084
길쌈 특성 맵으로부터

1129
00:56:37,084 --> 00:56:38,622
그런 다음 당신은 어떤 것을 통해 이러한 것들을 실행할 수 있습니다.

1130
00:56:38,622 --> 00:56:41,191
완전히 연결된 레이어 및 분류 예측

1131
00:56:41,191 --> 00:56:43,853
점수 및 선형 회귀 옵셋

1132
00:56:43,853 --> 00:56:45,673
테두리 상자로.

1133
00:56:45,673 --> 00:56:47,484
이제 우리가이 일을 훈련하면 다시

1134
00:56:47,484 --> 00:56:49,062
서로 상쇄되는 다중 작업 손실이있다.

1135
00:56:49,062 --> 00:56:51,654
이 두 가지 제약 조건 사이 및 역 전파 중에

1136
00:56:51,654 --> 00:56:53,362
우리는이 모든 것을 통해 소품을지지 할 수 있습니다.

1137
00:56:53,362 --> 00:56:56,124
공동으로 모두 배우십시오.

1138
00:56:56,124 --> 00:56:59,833
이 ROI 풀링은 마치 최대 풀링과 비슷합니다.

1139
00:56:59,833 --> 00:57:00,973
나는 정말로 들어가고 싶지 않다.

1140
00:57:00,973 --> 00:57:03,575
지금 그 세부 사항.

1141
00:57:03,575 --> 00:57:07,887
그리고 우리가 R-CNN 대 빠른
R-CNN을 본다면 속도면에서

1142
00:57:07,887 --> 00:57:10,422
이 모델은 SPP net

1143
00:57:10,422 --> 00:57:12,014
두 사람 사이에 일종의

1144
00:57:12,014 --> 00:57:14,494
그 때 당신은 훈련 시간에 빨리 볼 수 있습니다 R-CNN

1145
00:57:14,494 --> 00:57:16,924
기차가 10 배 더 빠르다.

1146
00:57:16,924 --> 00:57:18,433
이 모든 계산을 공유하기 때문에

1147
00:57:18,433 --> 00:57:20,134
서로 다른 기능 맵간에

1148
00:57:20,134 --> 00:57:23,272
그리고 지금 시험 시간에 빠른 R-CNN은 초고속입니다.

1149
00:57:23,272 --> 00:57:27,222
실제로 빠른 R-CNN은 테스트 시간에 너무 빠릅니다.

1150
00:57:27,222 --> 00:57:31,352
계산 시간이 실제로 지배적이라는 것

1151
00:57:31,352 --> 00:57:33,764
지역 제안을 계산하여

1152
00:57:33,764 --> 00:57:36,433
그래서 우리는 2000 년 지역 제안서

1153
00:57:36,433 --> 00:57:39,334
선택 검색을 사용하면 2 초 정도 걸립니다.

1154
00:57:39,334 --> 00:57:41,553
이제는 이러한 지역 제안을 모두 얻은 후에

1155
00:57:41,553 --> 00:57:44,534
그렇다면 우리는 모든 것을 공유하고 있기 때문에

1156
00:57:44,534 --> 00:57:46,724
이러한 비싼 회선을 공유함으로써

1157
00:57:46,724 --> 00:57:49,724
이미지 전체에 걸쳐 이러한 모든
것을 처리 할 수 있습니다.

1158
00:57:49,724 --> 00:57:53,273
지역 제안을 1 초도 안 남았습니다.

1159
00:57:53,273 --> 00:57:55,494
이렇게 빨리 R-CNN이 병목 현상을 일으키게됩니다.

1160
00:57:55,494 --> 00:57:59,142
이 지역 제안을 계산하는 것만으로

1161
00:57:59,142 --> 00:58:03,804
고맙게도 우리는 빠른 R-CNN으로이 문제를 해결했습니다.

1162
00:58:03,804 --> 00:58:07,883
그래서 더 빠른 R-CNN에서의 아이디어는,

1163
00:58:07,883 --> 00:58:11,324
그래서 문제는 지역 제안을 계산하는 것이 었습니다.

1164
00:58:11,324 --> 00:58:13,734
이 고정 기능을 사용하는 것이 병목이었습니다.

1165
00:58:13,734 --> 00:58:15,832
그래서 대신 우리는 네트워크 자체를 만들 것입니다.

1166
00:58:15,832 --> 00:58:18,054
자체 지역 제안을 예측하십시오.

1167
00:58:18,054 --> 00:58:20,822
그래서 이런 종류의 일이 다시 일어난다는 것입니다.

1168
00:58:20,822 --> 00:58:23,993
입력 이미지를 가져 와서 전체 입력 이미지를 실행합니다.

1169
00:58:23,993 --> 00:58:26,433
모두 일부 길쌈 레이어를 통해

1170
00:58:26,433 --> 00:58:28,062
일부 길쌈 기능 맵 가져 오기

1171
00:58:28,062 --> 00:58:30,572
고해상도 이미지 전체를 나타내는

1172
00:58:30,572 --> 00:58:33,204
이제 별도의 지역 제안 네트워크가 있습니다.

1173
00:58:33,204 --> 00:58:35,913
그 길쌈 특징의 위에 작동하는

1174
00:58:35,913 --> 00:58:39,204
네트워크 내에서 자체 지역 제안을 예측합니다.

1175
00:58:39,204 --> 00:58:41,964
예측 된 지역 제안이 있으면

1176
00:58:41,964 --> 00:58:44,542
그러면 마치 빠른 R-CNN처럼 보입니다.

1177
00:58:44,542 --> 00:58:46,913
이제 우리는 지역 제안서에서 작물을 가져옵니다.

1178
00:58:46,913 --> 00:58:48,262
컨볼 루션 특징들로부터,

1179
00:58:48,262 --> 00:58:50,662
네트워크의 나머지 부분까지 그들을 전달하십시오.

1180
00:58:50,662 --> 00:58:53,108
이제는 다중 작업 손실에 대해 이야기했습니다.

1181
00:58:53,108 --> 00:58:55,182
및 다중 작업 교육 네트워크

1182
00:58:55,182 --> 00:58:57,094
한 번에 여러 가지 일을 할 수 있습니다.

1183
00:58:57,094 --> 00:58:59,372
이제 우리는 네 가지 일을하도록
네트워크에 말하고 있습니다.

1184
00:58:59,372 --> 00:59:02,978
한 번에 모든 것이 이루어 지므로이 4 가지 방법으로 균형을 이룬다.

1185
00:59:02,978 --> 00:59:05,019
다중 작업 손실은 다소 까다 롭습니다.

1186
00:59:05,019 --> 00:59:07,059
그러나 지역 제안 네트워크

1187
00:59:07,059 --> 00:59:09,648
두 가지 일을해야합니다.

1188
00:59:09,648 --> 00:59:11,979
각각의 잠재적 제안에 대해

1189
00:59:11,979 --> 00:59:14,848
또는 객체가 아니라 실제로 회귀해야합니다.

1190
00:59:14,848 --> 00:59:18,186
그 제안들 각각에 대한 바운딩 박스 좌표,

1191
00:59:18,186 --> 00:59:20,035
그리고 지금 최종 네트워크

1192
00:59:20,035 --> 00:59:21,787
이 두 가지 일을 다시해야합니다.

1193
00:59:21,787 --> 00:59:23,576
최종 분류 결정하기

1194
00:59:23,576 --> 00:59:26,288
이 제안들 각각에 대한 학급 점수는 얼마인가?

1195
00:59:26,288 --> 00:59:29,565
경계 상자 회귀의 두 번째 라운드가 있습니다.

1196
00:59:29,565 --> 00:59:31,059
가질 수있는 오류를 다시 수정하십시오.

1197
00:59:31,059 --> 00:59:34,086
지역 제안 단계에서 왔습니다.

1198
00:59:34,086 --> 00:59:34,919
문제?

1199
00:59:45,231 --> 00:59:47,453
그래서 질문은 때로는 다중 작업 학습

1200
00:59:47,453 --> 00:59:48,862
정규화로 볼 수있다.

1201
00:59:48,862 --> 00:59:50,703
우리가 여기에 영향을 미치고 있습니까?

1202
00:59:50,703 --> 00:59:52,602
수퍼 컨트롤 연구가 있는지 확실하지 않습니다.

1203
00:59:52,602 --> 00:59:55,562
그것에 있지만 원래 버전에서 실제로

1204
00:59:55,562 --> 00:59:58,903
더 빨랐던 R-CNN 논문의

1205
00:59:58,903 --> 01:00:01,162
우리가 공유하면 어떻게 될까?

1206
01:00:01,162 --> 01:00:03,951
지역 제안 네트워크, 우리가 공유하지 않으면 어떻게 될까?

1207
01:00:03,951 --> 01:00:05,530
별도의 컨벌루션 네트워크를 학습하면 어떨까요?

1208
01:00:05,530 --> 01:00:06,682
지역 제안 네트워크

1209
01:00:06,682 --> 01:00:08,522
분류 네트워크 대?

1210
01:00:08,522 --> 01:00:10,111
그리고 사소한 차이가 있다고 생각합니다.

1211
01:00:10,111 --> 01:00:12,970
그러나 어느 쪽이든 극적인 차이는 아니었다.

1212
01:00:12,970 --> 01:00:15,141
따라서 실제적으로 하나만 배우는 것이 더 친절합니다.

1213
01:00:15,141 --> 01:00:18,380
계산적으로 저렴하기 때문입니다.

1214
01:00:18,380 --> 01:00:19,713
미안 해요, 질문?

1215
01:00:33,583 --> 01:00:35,292
그래, 문제는 어떻게 훈련시키는거야?

1216
01:00:35,292 --> 01:00:38,143
이 지역 제안 네트워크는 모르기 때문에,

1217
01:00:38,143 --> 01:00:40,351
당신은 근거 진실 지역 제안을 가지고 있지 않다.

1218
01:00:40,351 --> 01:00:41,903
지역 제안 네트워크.

1219
01:00:41,903 --> 01:00:43,282
그래서 약간 털이 있습니다.

1220
01:00:43,282 --> 01:00:45,172
나는 그 세부 사항에 너무 많이 들어가고 싶지 않다.

1221
01:00:45,172 --> 01:00:49,092
그러나 아이디어는 언제든지 지역
제안서를 가지고 있다는 것입니다.

1222
01:00:49,092 --> 01:00:51,583
오버랩의 임계 값 이상을 갖는

1223
01:00:51,583 --> 01:00:53,452
지상 진실 물체들

1224
01:00:53,452 --> 01:00:55,652
그런 다음 긍정적 인 지역 제안이라고 말하면됩니다.

1225
01:00:55,652 --> 01:00:57,771
지역 제안으로 예측해야합니다.

1226
01:00:57,771 --> 01:01:01,642
오버랩이 매우 낮은 잠재적 인 제안

1227
01:01:01,642 --> 01:01:02,942
어떤 진실의 물건으로

1228
01:01:02,942 --> 01:01:04,471
부정적인 것으로 예측되어야합니다.

1229
01:01:04,471 --> 01:01:06,652
하지만 어두운 마법의 하이퍼 파라미터가 많이 있습니다.

1230
01:01:06,652 --> 01:01:09,550
그 과정에서 그것은 약간 털이 있습니다.

1231
01:01:09,550 --> 01:01:10,383
문제?

1232
01:01:15,394 --> 01:01:17,554
그래, 문제는 분류 손실이란 무엇인가?

1233
01:01:17,554 --> 01:01:19,793
지역 제안 네트워크에서 대답은

1234
01:01:19,793 --> 01:01:22,164
바이너리를 만들고있어. 그래서 얻고 싶지 않았어.

1235
01:01:22,164 --> 01:01:23,938
그 건축물에 대한 너무 많은 세부 사항들

1236
01:01:23,938 --> 01:01:25,320
그것이 조금 털이 많기 때문에

1237
01:01:25,320 --> 01:01:26,648
그러나 그것은 2 진 결정을 내리고있다.

1238
01:01:26,648 --> 01:01:29,258
그래서 잠재적 인 영역 집합을 가지고 있습니다.

1239
01:01:29,258 --> 01:01:30,686
그것을 고려하고 그것을 만들고있다.

1240
01:01:30,686 --> 01:01:32,269
각각에 대한 이진 결정.

1241
01:01:32,269 --> 01:01:34,078
이 개체 또는 개체가 아닌가요?

1242
01:01:34,078 --> 01:01:37,578
따라서 이진 분류 손실과 같습니다.

1243
01:01:38,520 --> 01:01:40,858
그래서 일단이 일을 훈련하면 빠른 R-CNN

1244
01:01:40,858 --> 01:01:43,658
매우 빨리 끝내야한다.

1245
01:01:43,658 --> 01:01:46,248
이제 우리는이 오버 헤드를 제거했기 때문에

1246
01:01:46,248 --> 01:01:48,706
네트워크 외부의 컴퓨팅 지역 제안들로부터,

1247
01:01:48,706 --> 01:01:51,008
이제는 더 빨라진 R-CNN이 매우 빨리 끝납니다.

1248
01:01:51,008 --> 01:01:53,588
이러한 다른 대안들에 비해.

1249
01:01:53,588 --> 01:01:56,693
또한 흥미로운 점 중 하나는

1250
01:01:56,693 --> 01:01:59,388
여기에있는 지역 제안은 당신이 상상할 수도 있습니다.

1251
01:01:59,388 --> 01:02:00,848
아마도 약간의 불일치가 있다면 어떨까요?

1252
01:02:00,848 --> 01:02:05,086
이 고정 영역 제안 알고리즘과 내 데이터 사이에?

1253
01:02:05,086 --> 01:02:06,938
그래서 이번 경우에 한 번 배우고 있습니다.

1254
01:02:06,938 --> 01:02:09,240
자신의 지역 제안서를 작성하면 극복 할 수 있습니다.

1255
01:02:09,240 --> 01:02:12,018
지역 제안 사항이 불일치하는 경우

1256
01:02:12,018 --> 01:02:16,320
다른 데이터 세트와 다소 이상하거나 다르다.

1257
01:02:16,320 --> 01:02:19,926
그래서 R-CNN 방법의 모든 가족,

1258
01:02:19,926 --> 01:02:22,914
R은 region을 나타내므로 이것들은
모두 region 기반 메소드입니다

1259
01:02:22,914 --> 01:02:25,116
어떤 종류의 지역 제안이 있기 때문에

1260
01:02:25,116 --> 01:02:27,796
그리고 나서 우리는 약간의 처리를하고 있습니다.

1261
01:02:27,796 --> 01:02:29,178
각각을위한 독립적 인 처리

1262
01:02:29,178 --> 01:02:30,716
그 잠재적 인 지역의.

1263
01:02:30,716 --> 01:02:32,447
그래서이 모든 종류의 메소드가 호출됩니다.

1264
01:02:32,447 --> 01:02:36,708
객체 검출을위한 이러한 영역 기반 방법.

1265
01:02:36,708 --> 01:02:38,196
하지만 또 다른 방법이 있습니다.

1266
01:02:38,196 --> 01:02:40,676
당신이 가끔씩 물체 감지를 위해 보게되는

1267
01:02:40,676 --> 01:02:43,818
이것은 한 번에 모든 피드를 전달하는 것입니다.

1268
01:02:43,818 --> 01:02:48,076
그래서 이것들 중 하나는 You Only
Look Once를위한 YOLO입니다.

1269
01:02:48,076 --> 01:02:50,796
또 하나의 SSD는 단발 탐지

1270
01:02:50,796 --> 01:02:54,067
이 두 사람은 같은시기에 다소 나왔습니다.

1271
01:02:54,067 --> 01:02:55,959
그러나 아이디어는 독립적 인 행동보다는

1272
01:02:55,959 --> 01:02:58,496
이들 각각의 잠재 영역에 대한 프로세싱

1273
01:02:58,496 --> 01:03:00,138
대신 우리는 이것을 대우하려고합니다.

1274
01:03:00,138 --> 01:03:02,348
회귀 문제와 마찬가지로

1275
01:03:02,348 --> 01:03:03,916
이 모든 예측은 한 번에

1276
01:03:03,916 --> 01:03:06,156
큰 길쌈 네트워크.

1277
01:03:06,156 --> 01:03:08,367
여러분이 상상하는 입력 이미지가 주어졌습니다.

1278
01:03:08,367 --> 01:03:11,327
그 입력 이미지를 거친 격자로 분할하고,

1279
01:03:11,327 --> 01:03:13,468
이 경우에는 7x7 격자입니다.

1280
01:03:13,468 --> 01:03:15,698
이제 각 그리드 셀 내에서

1281
01:03:15,698 --> 01:03:18,556
당신은 기본 테두리 상자 몇 세트를 상상해보십시오.

1282
01:03:18,556 --> 01:03:20,995
여기에 3 개의 기본 경계 상자가 그려져 있습니다.

1283
01:03:20,995 --> 01:03:23,418
키가 큰 것, 너비가 넓은 것, 사각형이되는 것

1284
01:03:23,418 --> 01:03:25,748
실제로는 3 개 이상을 사용합니다.

1285
01:03:25,748 --> 01:03:28,098
이제 각 그리드 셀에 대해

1286
01:03:28,098 --> 01:03:30,314
이들 각각의 기본 경계 상자

1287
01:03:30,314 --> 01:03:32,858
몇 가지 것을 예측하고 싶습니다.

1288
01:03:32,858 --> 01:03:37,025
하나, 기본 테두리 상자에서 오프셋을 예측하고 싶습니다.

1289
01:03:38,177 --> 01:03:40,087
실제 위치가 무엇인지 예측하기

1290
01:03:40,087 --> 01:03:43,020
이 기본 경계 상자에서 개체의

1291
01:03:43,020 --> 01:03:46,340
또한 분류 점수를 예측하기를 원합니다.

1292
01:03:46,340 --> 01:03:49,820
그래서 아마도 각각에 대한 분류 점수

1293
01:03:49,820 --> 01:03:51,460
이러한 기본 테두리 상자 중.

1294
01:03:51,460 --> 01:03:53,619
이 카테고리의 대상이 얼마나 될 가능성이 높습니까?

1295
01:03:53,619 --> 01:03:55,503
이 경계 상자에 나타납니다.

1296
01:03:55,503 --> 01:03:58,250
결국 결국 우리는 예측을 끝내게됩니다.

1297
01:03:58,250 --> 01:03:59,762
우리의 입력 이미지에서 우리는 결국

1298
01:03:59,762 --> 01:04:03,929
이 거대한 텐서는 7 × 7 격자로
5B + C로 나타납니다.

1299
01:04:04,951 --> 01:04:08,130
그래서 우리는 B 기본 경계 박스를 가지고 있습니다.

1300
01:04:08,130 --> 01:04:10,231
우리는 각각 오프셋을주는 다섯 개의 숫자가 있습니다.

1301
01:04:10,231 --> 01:04:12,700
기본 테두리 상자에 대한 우리의 확신

1302
01:04:12,700 --> 01:04:16,340
우리 C 범주의 C 분류 점수.

1303
01:04:16,340 --> 01:04:19,549
그러면 우리는이 입력으로 물체 감지를 보게됩니다.

1304
01:04:19,549 --> 01:04:23,522
이 3 차원 텐서의 출력

1305
01:04:23,522 --> 01:04:25,642
너는이 모든 것을 훈련하는 것을 상상할 수있다.

1306
01:04:25,642 --> 01:04:27,722
거대한 길쌈 네트워크.

1307
01:04:27,722 --> 01:04:30,682
그리고 그것은 이러한 단일 샷 방법이하는 일종의 것입니다.

1308
01:04:30,682 --> 01:04:33,320
그들은 단지 진실로 진실과 일치하는 곳에서

1309
01:04:33,320 --> 01:04:37,050
이러한 잠재적 인 기본 상자에 개체

1310
01:04:37,050 --> 01:04:41,180
조금 털이되지만 이것이 그 방법들입니다.

1311
01:04:41,180 --> 01:04:43,060
그런데 지역 제안 네트워크

1312
01:04:43,060 --> 01:04:45,388
더 빨라진 R-CNN에 익숙해 져서

1313
01:04:45,388 --> 01:04:48,539
그들이 세트를 가지고있는 이들과 아주 비슷합니다.

1314
01:04:48,539 --> 01:04:51,210
일부 바둑판 모양의 이미지 위에 기본 경계 상자 포함

1315
01:04:51,210 --> 01:04:53,899
다른 지역 제안 네트워크는 약간의 회귀를합니다.

1316
01:04:53,899 --> 01:04:55,279
일부 분류 플러스.

1317
01:04:55,279 --> 01:04:59,196
여기에는 몇 가지 겹쳐진 아이디어가 있습니다.

1318
01:05:00,388 --> 01:05:04,555
그래서 빠른 R-CNN에서 우리는
그 대상을 다루는 종류입니다.

1319
01:05:05,390 --> 01:05:08,372
이 문제의 종류로 지역 제안 단계

1320
01:05:08,372 --> 01:05:11,199
엔드 - 투 - 엔드 회귀 문제를 해결하고 우리는 별도의

1321
01:05:11,199 --> 01:05:13,892
지역별 처리는하지만 이러한 단일 촬영 방법을 사용합니다.

1322
01:05:13,892 --> 01:05:16,350
우리는 첫 번째 단계 만 수행하고 모두 수행합니다.

1323
01:05:16,350 --> 01:05:19,761
하나의 순방향 패스로 우리의 물체 감지.

1324
01:05:19,761 --> 01:05:21,740
따라서 물체 감지에는 많은 변수가 있습니다.

1325
01:05:21,740 --> 01:05:23,950
VGG와 같은 다른 기본 네트워크가있을 수 있습니다.

1326
01:05:23,950 --> 01:05:26,459
ResNet, 우리는 다른 전이를 보았습니다.

1327
01:05:26,459 --> 01:05:29,601
이 빠른 R-CNN을 포함하는 물체 탐지

1328
01:05:29,601 --> 01:05:31,820
타입 영역 기반의 패밀리,

1329
01:05:31,820 --> 01:05:34,060
이 단일 샷 탐지 패밀리 메소드.

1330
01:05:34,060 --> 01:05:35,492
내가 말하지 않은 종류의 잡종이있다.

1331
01:05:35,492 --> 01:05:38,153
사이에 다소있는 R-FCN이라고 불리는 것입니다.

1332
01:05:38,153 --> 01:05:39,580
다양한 하이퍼 파라미터가 있습니다.

1333
01:05:39,580 --> 01:05:40,911
이미지 크기와 마찬가지로,

1334
01:05:40,911 --> 01:05:43,590
얼마나 많은 지역 제안을 사용하십니까?

1335
01:05:43,590 --> 01:05:44,938
실제로이 멋진 종이가 있습니다.

1336
01:05:44,938 --> 01:05:48,022
이번 여름에 CVPR에 나타납니다.

1337
01:05:48,022 --> 01:05:50,102
이 많은 것들을 중심으로 제어 된 실험

1338
01:05:50,102 --> 01:05:53,102
다른 변수들과 당신에게 말하려고한다.

1339
01:05:53,102 --> 01:05:54,732
이 방법들은 모두 어떻게 수행합니까?

1340
01:05:54,732 --> 01:05:56,353
이 다른 변수들 하에서

1341
01:05:56,353 --> 01:05:58,676
그래서 당신이 관심이 있다면 나는 그것을
밖으로 체크하는 것이 좋습니다 것이

1342
01:05:58,676 --> 01:06:01,171
그러나 중요한 테이크 아웃의 종류 중 하나는

1343
01:06:01,171 --> 01:06:04,012
지역 기반 방법의 빠른 R-CNN 스타일

1344
01:06:04,012 --> 01:06:06,702
더 높은 정확도를주는 경향이 있지만

1345
01:06:06,702 --> 01:06:08,972
단일 샷 방법보다 훨씬 느림

1346
01:06:08,972 --> 01:06:10,612
단일 샷 방법은

1347
01:06:10,612 --> 01:06:12,486
지역별 처리 당.

1348
01:06:12,486 --> 01:06:14,542
하지만이 신문을 읽어 보시기 바랍니다.

1349
01:06:14,542 --> 01:06:17,204
더 자세한 정보가 필요하면.

1350
01:06:17,204 --> 01:06:20,062
또한 조금 곁에, 나는이 재미있는 종이를 가지고 있었다.

1351
01:06:20,062 --> 01:06:21,852
Andre와 2 년 전에 그런 종류의

1352
01:06:21,852 --> 01:06:24,621
결합 된 물체 감지와 이미지 캡션

1353
01:06:24,621 --> 01:06:27,273
이 문제는 조밀 한 자막이라고 불렀습니다.

1354
01:06:27,273 --> 01:06:30,324
그래서 이제 아이디어는 예측보다는

1355
01:06:30,324 --> 01:06:32,472
각 지역에 대한 고정 카테고리 라벨,

1356
01:06:32,472 --> 01:06:35,084
대신 우리는 각 지역에 대한 캡션을 작성하려고합니다.

1357
01:06:35,084 --> 01:06:37,902
그리고 다시, 우리는 이런 종류의 데이터를
가지고있는 데이터 세트를 가지고있었습니다.

1358
01:06:37,902 --> 01:06:41,033
캡션과 함께 데이터 세트가있는 곳

1359
01:06:41,033 --> 01:06:43,302
그런 다음 우리는 훈련 된이 거대한 종단 모델

1360
01:06:43,302 --> 01:06:46,153
방금 이러한 자막을 모두 공동으로 예측했습니다.

1361
01:06:46,153 --> 01:06:48,993
그리고 이것은 마치 좀 더 빨라진 R-CNN처럼 보입니다.

1362
01:06:48,993 --> 01:06:50,962
지역 제안 단계

1363
01:06:50,962 --> 01:06:53,764
다음 경계 상자, 그리고 지역별 처리 당.

1364
01:06:53,764 --> 01:06:56,657
하지만 SVM이나 소프트 맥스 손실보다

1365
01:06:56,657 --> 01:06:59,382
대신에 지역별 처리 당

1366
01:06:59,382 --> 01:07:03,454
각 지역에 대한 캡션을 예측하는 RNN 언어 모델입니다.

1367
01:07:03,454 --> 01:07:06,814
그래서 결국 빠른 R-CNN처럼 보입니다.

1368
01:07:06,814 --> 01:07:07,953
여기 비디오가 있지만 생각합니다.

1369
01:07:07,953 --> 01:07:11,524
우리는 시간이 없어서 나는 그것을 건너 뛸 것이다.

1370
01:07:11,524 --> 01:07:15,108
그러나 여기 아이디어는 일단 당신이 이것을 가지면,

1371
01:07:15,108 --> 01:07:17,897
당신은 이런 종류의 아이디어를 많이 묶을 수 있습니다.

1372
01:07:17,897 --> 01:07:19,727
관심이있는 새로운 문제가 생기면

1373
01:07:19,727 --> 01:07:21,508
조밀 한 자막과 같은 태클에서,

1374
01:07:21,508 --> 01:07:23,156
당신은 많은 구성 요소를 재활용 할 수 있습니다.

1375
01:07:23,156 --> 01:07:24,607
당신이 다른 문제들로부터 배웠던

1376
01:07:24,607 --> 01:07:26,860
유사 물체 감지 및 이미지 캡션

1377
01:07:26,860 --> 01:07:28,786
하나의 엔드 - 투 - 엔드
(end-to-end) 네트워크

1378
01:07:28,786 --> 01:07:30,356
당신이 신경 쓰는 출력을 만들어내는

1379
01:07:30,356 --> 01:07:32,565
당신 문제.

1380
01:07:32,565 --> 01:07:34,386
그래서 내가 얘기하고 싶은 마지막 과제

1381
01:07:34,386 --> 01:07:36,567
인스턴스 분할에 대한 아이디어입니다.

1382
01:07:36,567 --> 01:07:38,165
여기서 인스턴스 분할은

1383
01:07:38,165 --> 01:07:40,636
어떤면에서는 완전한 문제처럼

1384
01:07:40,636 --> 01:07:45,007
우리는 입력 이미지가 주어지며 우리는
하나의 이미지를 예측하기를 원합니다.

1385
01:07:45,007 --> 01:07:48,028
그 이미지 내의 객체의 위치와 동일성

1386
01:07:48,028 --> 01:07:50,594
물체 감지와 유사하지만 단지

1387
01:07:50,594 --> 01:07:52,847
각각의 객체에 대한 바운딩 박스를 예측하고,

1388
01:07:52,847 --> 01:07:55,385
대신 전체 세그먼트 마스크를 예측하려고합니다.

1389
01:07:55,385 --> 01:07:57,943
그 각각의 물체에 대해 그리고 어떤 픽셀을 예측할지

1390
01:07:57,943 --> 01:08:02,785
입력 이미지에서 각 객체 인스턴스에 해당합니다.

1391
01:08:02,785 --> 01:08:04,575
그래서 이것은 잡종과 같은 종류입니다.

1392
01:08:04,575 --> 01:08:07,484
의미 론적 세분화와 객체 검출 간의 관계

1393
01:08:07,484 --> 01:08:09,815
우리는 객체 감지와 같이

1394
01:08:09,815 --> 01:08:12,271
여러 개체와 우리는 ID를 구별합니다.

1395
01:08:12,271 --> 01:08:15,196
이 예제에서 다른 인스턴스의

1396
01:08:15,196 --> 01:08:17,215
이미지에는 두 마리의 개가 있기 때문에

1397
01:08:17,215 --> 01:08:19,385
인스턴스 분할 방법

1398
01:08:19,385 --> 01:08:21,924
실제로 두 개 인스턴스를 구별합니다.

1399
01:08:21,924 --> 01:08:25,425
같은 의미 론적 세분화의 출력과 종류

1400
01:08:25,425 --> 01:08:27,948
우리는이 픽셀 현명한 정확성을 가지고있다.

1401
01:08:27,948 --> 01:08:30,268
우리가 말하고 싶은이 물건들 각각에 대해

1402
01:08:30,268 --> 01:08:32,765
어떤 픽셀이 그 객체에 속하는지.

1403
01:08:32,765 --> 01:08:34,709
그래서 많은 다른 방법들이있었습니다.

1404
01:08:34,709 --> 01:08:38,247
예를 들어 세분화와 같은 사람들이 다뤄야 만합니다.

1405
01:08:38,247 --> 01:08:40,567
그러나 현재의 최신 기술은이 새로운 논문이다.

1406
01:08:40,567 --> 01:08:44,636
실제로 방금 나온 Mask R-CNN

1407
01:08:44,636 --> 01:08:47,846
약 한 달 전에 보관 용으로 제공되므로
아직 게시되지 않았습니다.

1408
01:08:47,846 --> 01:08:49,868
이것은 슈퍼 신선한 물건 같다.

1409
01:08:49,868 --> 01:08:52,675
그리고 이것은 더 빠른 R-CNN처럼 많이 보입니다.

1410
01:08:52,676 --> 01:08:55,296
따라서이 다단계 처리 방식을 사용합니다.

1411
01:08:55,296 --> 01:08:57,508
여기서 우리는 전체 입력 이미지를 취하고,

1412
01:08:57,509 --> 01:09:00,117
그 전체 입력 이미지가 어떤 길쌈
(convolutional)으로 들어간다.

1413
01:09:00,117 --> 01:09:03,127
네트워크 및 학습 된 지역 제안 네트워크

1414
01:09:03,127 --> 01:09:05,622
그것은 빠른 R-CNN과 정확히 동일합니다.

1415
01:09:05,622 --> 01:09:08,206
이제 우리는 배운 지역 제안을 한 번 가지고 있습니다.

1416
01:09:08,207 --> 01:09:09,557
그런 다음 제안서를 제출합니다.

1417
01:09:09,557 --> 01:09:11,247
길쌈 기능 맵에

1418
01:09:11,247 --> 01:09:14,796
우리가 빠르고 더 빠른 R-CNN에서했던 것처럼.

1419
01:09:14,796 --> 01:09:17,196
하지만 지금은 분류를하기보다는

1420
01:09:17,197 --> 01:09:19,167
회귀 결정을위한 바운딩 박스

1421
01:09:19,167 --> 01:09:21,229
그 상자들 각각에 대해서 우리는

1422
01:09:21,229 --> 01:09:23,419
세그먼테이션 마스크를 예측하고 싶다.

1423
01:09:23,420 --> 01:09:25,729
그 각각의 바운딩 박스에 대해,

1424
01:09:25,729 --> 01:09:27,478
해당 지역 제안서 각각에 대해

1425
01:09:27,478 --> 01:09:30,478
그래서 지금은 마치 미니처럼 보입니다.

1426
01:09:30,478 --> 01:09:32,529
의미 론적 세분화 문제처럼

1427
01:09:32,529 --> 01:09:34,408
각 지역 제안서 내부

1428
01:09:34,408 --> 01:09:36,888
지역 제안 네트워크에서 얻은 정보

1429
01:09:36,889 --> 01:09:40,288
이제 ROI를 warp에 맞추면됩니다.

1430
01:09:40,288 --> 01:09:42,888
제안 영역에 해당하는 우리의 기능

1431
01:09:42,889 --> 01:09:45,948
오른쪽 모양으로, 그럼 우리는 두 가지 가지가 있습니다.

1432
01:09:45,948 --> 01:09:48,209
하나의 가지가 정확히 생겼고,

1433
01:09:48,209 --> 01:09:50,198
상단의이 첫 번째 분기는 마치

1434
01:09:50,198 --> 01:09:53,750
보다 빠른 R-CNN을 통해 분류
점수를 예측할 수 있습니다.

1435
01:09:53,750 --> 01:09:55,580
해당 범주가 무엇인지 알려줍니다.

1436
01:09:55,580 --> 01:09:57,838
해당 제안 지역으로

1437
01:09:57,838 --> 01:09:59,318
그것이 배경이든 아니든.

1438
01:09:59,318 --> 01:10:01,369
그리고 경계 상자 좌표도 예측할 것입니다.

1439
01:10:01,369 --> 01:10:04,596
지역 제안을 조정했다.

1440
01:10:04,596 --> 01:10:06,830
그리고 이제 우리는이 지류를 바닥에 둘 것입니다.

1441
01:10:06,830 --> 01:10:09,738
기본적으로 의미 론적 세분화와 비슷하게 보입니다.

1442
01:10:09,738 --> 01:10:13,550
각 픽셀별로 분류 할 미니 네트워크

1443
01:10:13,550 --> 01:10:17,780
해당 입력 영역 제안서에 객체인지 여부

1444
01:10:17,780 --> 01:10:22,180
그래서이 마스크 R - CNN 문제,이 마스크 R
- CNN 아키텍처

1445
01:10:22,180 --> 01:10:24,249
이러한 종류의 문제를 모두 하나로 통합 할 수 있습니다.

1446
01:10:24,249 --> 01:10:26,928
우리가 오늘 한 가지 멋진 이야기를하고 있습니다.

1447
01:10:26,928 --> 01:10:29,230
공동으로 엔드 - 투 - 엔드 훈련 가능한 모델.

1448
01:10:29,230 --> 01:10:31,238
그리고 그것은 정말로 시원하고 실제로 작동합니다.

1449
01:10:31,238 --> 01:10:34,958
정말 정말 잘 그래서 예제를 보면

1450
01:10:34,958 --> 01:10:36,710
종이에서 그들은 일종의 놀랍습니다.

1451
01:10:36,710 --> 01:10:39,078
그들은 진실의 진리와 구별되지 않습니다.

1452
01:10:39,078 --> 01:10:41,012
왼쪽의이 예에서 볼 수 있습니다.

1453
01:10:41,012 --> 01:10:42,623
이 두 사람이 서있는 것을

1454
01:10:42,623 --> 01:10:44,838
오토바이 앞에서 상자가 그려져 있습니다.

1455
01:10:44,838 --> 01:10:46,820
이 사람들의 주위에, 그것은 또한
안으로 들어가고 레테르를 붙인다

1456
01:10:46,820 --> 01:10:49,497
그 사람들의 모든 픽셀과 그것은 정말로 작습니다.

1457
01:10:49,497 --> 01:10:51,038
하지만 실제로 그 이미지의 배경에

1458
01:10:51,038 --> 01:10:52,868
왼쪽에는 수많은 사람들이 또한 있습니다.

1459
01:10:52,868 --> 01:10:54,961
백그라운드에서 아주 작은 서.

1460
01:10:54,961 --> 01:10:56,478
또한 각 상자 주위에 상자가 그려져 있습니다.

1461
01:10:56,478 --> 01:10:58,628
그 이미지들 각각의 픽셀들을 움켜 잡았다.

1462
01:10:58,628 --> 01:11:00,729
그리고 당신은 이것이 단지,

1463
01:11:00,729 --> 01:11:02,118
그것은 정말로 정말로 잘 작동하게된다.

1464
01:11:02,118 --> 01:11:04,215
비교적 간단한 추가 작업입니다.

1465
01:11:04,215 --> 01:11:08,028
기존의 더 빨랐던 R-CNN 프레임 워크의 위에.

1466
01:11:08,028 --> 01:11:11,146
그래서 나는 마스크 R-CNN이

1467
01:11:11,146 --> 01:11:13,318
우리는 오늘에 대해서 이야기했고 그것은 또한합니다.

1468
01:11:13,318 --> 01:11:15,108
그런데 포즈 추정.

1469
01:11:15,108 --> 01:11:18,417
우리가 말했던 것처럼 포즈 추정을 할 수 있습니다.

1470
01:11:18,417 --> 01:11:20,478
이들 조인트 좌표를 예측함으로써

1471
01:11:20,478 --> 01:11:22,257
그 사람의 관절 각각을 위해

1472
01:11:22,257 --> 01:11:26,214
그래서 당신은 조준 물체 탐지를하기 위해
마스크 R-CNN을 할 수 있습니다.

1473
01:11:26,214 --> 01:11:29,388
자세 추정 및 인스턴스 세분화.

1474
01:11:29,388 --> 01:11:31,246
우리가 만들 수있는 유일한 추가

1475
01:11:31,246 --> 01:11:33,337
이 지역 제안들 각각에 대한 것입니다.

1476
01:11:33,337 --> 01:11:35,246
작은 지점을 더 추가합니다.

1477
01:11:35,246 --> 01:11:39,086
관절의 좌표를 예측합니다.

1478
01:11:39,086 --> 01:11:42,628
현재 지역 제안의 경우

1479
01:11:42,628 --> 01:11:44,506
이제 이것은 또 다른 손실 일뿐입니다.

1480
01:11:44,506 --> 01:11:46,137
우리가 추가하는 또 다른 레이어처럼,

1481
01:11:46,137 --> 01:11:47,836
다른 머리가 네트워크에서 나온다.

1482
01:11:47,836 --> 01:11:51,715
멀티 태스크 손실에 대한 추가 용어입니다.

1483
01:11:51,715 --> 01:11:54,027
그러나 일단이 작은 지점 하나를 추가하면

1484
01:11:54,027 --> 01:11:56,684
그러면이 모든 다른 문제들을 공동으로 해결할 수 있습니다.

1485
01:11:56,684 --> 01:11:59,406
당신은 이런 결과를 얻습니다.

1486
01:11:59,406 --> 01:12:02,705
이제이 네트워크는 단일 피드 전달 네트워크

1487
01:12:02,705 --> 01:12:06,126
얼마나 많은 사람들이 이미지에 있는지 결정하고 있습니다.

1488
01:12:06,126 --> 01:12:07,876
그 사람들이 어디에 있는지 감지하고,

1489
01:12:07,876 --> 01:12:09,792
각각에 해당하는 픽셀을 계산

1490
01:12:09,792 --> 01:12:12,283
그 사람들의 추측과 골격 추정

1491
01:12:12,283 --> 01:12:14,593
그 사람들의 자세와 이것이 정말로 잘 돌아 간다.

1492
01:12:14,593 --> 01:12:16,993
이 교실과 같이 붐비는 장면에서도

1493
01:12:16,993 --> 01:12:18,102
엄청난 사람들이 앉아있는 곳

1494
01:12:18,102 --> 01:12:19,273
그들 모두는 서로 겹쳐있다.

1495
01:12:19,273 --> 01:12:22,742
엄청나게 잘 작동하는 것 같습니다.

1496
01:12:22,742 --> 01:12:25,392
더 빠른 R-CNN 프레임 워크를 기반으로하기 때문에

1497
01:12:25,392 --> 01:12:28,291
또한 실시간으로 비교적 가깝게 실행됩니다.

1498
01:12:28,291 --> 01:12:31,153
그래서 이것은 초당 5 프레임과 같은 것을 실행합니다.

1499
01:12:31,153 --> 01:12:33,582
이것이 일종의 일종이기 때문에 GPU에서

1500
01:12:33,582 --> 01:12:36,061
네트워크의 단일 순방향 패스에서.

1501
01:12:36,061 --> 01:12:37,603
그래서 이것은 다시 새로운 슈퍼 종이입니다.

1502
01:12:37,603 --> 01:12:39,622
그러나 나는 이것이 아마 얻을 것이라고 생각한다.

1503
01:12:39,622 --> 01:12:42,833
앞으로 몇 달 동안 많은 주목을 받게 될 것입니다.

1504
01:12:42,833 --> 01:12:45,430
요약하자면, 우리는 이야기했습니다.

1505
01:12:45,430 --> 01:12:46,680
미안 해요?

1506
01:12:53,800 --> 01:12:55,781
문제는 얼마나 많은 교육 자료가 필요한가입니다.

1507
01:12:55,781 --> 01:12:58,610
따라서 이러한 모든 즉각적인 세분화 결과

1508
01:12:58,610 --> 01:13:00,948
Microsoft Coco 데이터
세트에 대한 교육을 받았습니다.

1509
01:13:00,948 --> 01:13:05,349
그래서 Microsoft Coco는 대략
200,000 개의 교육 이미지입니다.

1510
01:13:05,349 --> 01:13:08,320
80 개의 카테고리가 있습니다.

1511
01:13:08,320 --> 01:13:11,101
200,000 개의 교육용 이미지 각각에서

1512
01:13:11,101 --> 01:13:14,010
80 개 카테고리의 모든 인스턴스가 라벨링되어 있습니다.

1513
01:13:14,010 --> 01:13:17,139
그래서 훈련을 위해 20 만 개의 이미지가 있습니다.

1514
01:13:17,139 --> 01:13:18,548
내가 평균이라고 생각하는 것과 같은 것이있다.

1515
01:13:18,548 --> 01:13:21,069
이미지 당 5 개 또는 6 개의 인스턴스로 구성됩니다.

1516
01:13:21,069 --> 01:13:23,285
따라서 실제로는 많은 양의 데이터입니다.

1517
01:13:23,285 --> 01:13:26,970
모든 사람들을위한 Microsoft Coco

1518
01:13:26,970 --> 01:13:28,909
Microsoft Coco에는 모든 관절이 있습니다.

1519
01:13:28,909 --> 01:13:32,000
주석을 달아서 실제로 이것은 많은 것을 가지고있다.

1520
01:13:32,000 --> 01:13:34,320
훈련 시간에 당신이 옳다는 감독의,

1521
01:13:34,320 --> 01:13:36,669
실제로 많은 양의 데이터로 교육을 받았습니다.

1522
01:13:36,669 --> 01:13:39,638
그래서 나는 공부할 흥미로운
주제가 하나 있다고 생각합니다.

1523
01:13:39,638 --> 01:13:42,050
앞으로 나아가는 것은 우리가 알고있는 것입니다.

1524
01:13:42,050 --> 01:13:44,620
당신이 어떤 문제를 해결하기 위해
많은 양의 데이터를 가지고 있다면,

1525
01:13:44,620 --> 01:13:46,349
이 시점에서 우리는 당신이

1526
01:13:46,349 --> 01:13:48,088
일부 길쌈 네트워크를 꿰매다

1527
01:13:48,088 --> 01:13:50,701
아마 그 문제에서 합당한 직업을 할 수 있습니다.

1528
01:13:50,701 --> 01:13:53,701
이런 성능을 얻을 수있는 방법을 찾아 냈어.

1529
01:13:53,701 --> 01:13:55,809
훈련 데이터가 적 으면 매우 흥미 롭습니다.

1530
01:13:55,809 --> 01:13:57,700
연구 활동 영역이 활발합니다.

1531
01:13:57,700 --> 01:13:59,069
사람들이 쓸 돈입니다.

1532
01:13:59,069 --> 01:14:03,301
앞으로 몇 년 동안 많은 노력을 기울일 것입니다.

1533
01:14:03,301 --> 01:14:05,749
그래서 요점을 되풀이하기 위해, 오늘 우리는
일종의 회오리 바람 여행을 가지고 있었다.

1534
01:14:05,749 --> 01:14:08,068
컴퓨터 비전 주제의 전체 모음

1535
01:14:08,068 --> 01:14:10,141
우리는 우리가 만든 기계가 얼마나 많은지 보았습니다.

1536
01:14:10,141 --> 01:14:13,061
이미지 분류로부터 비교적 쉽게 적용 할 수있다.

1537
01:14:13,061 --> 01:14:15,925
이러한 다양한 컴퓨터 비전 주제를 해결할 수 있습니다.

1538
01:14:15,925 --> 01:14:18,013
그리고 다음에 우리가 얘기 할게,

1539
01:14:18,013 --> 01:14:20,835
CNN 기능을 시각화하는 데 정말
재미있는 강의가 진행됩니다.

1540
01:14:20,835 --> 01:14:22,835
또한 DeepDream과 신경 스타일
전달에 대해서도 이야기합니다.

