1
00:00:08,435 --> 00:00:10,602
자 시작합시다.

2
00:00:13,372 --> 00:00:21,193
이제 5강입니다. 5강에서는 CNN을 배우겠습니다.

3
00:00:22,493 --> 00:00:25,933
시작하기 전에 몇가지 공지사항이 있습니다.

4
00:00:25,933 --> 00:00:30,563
첫 번째 과제가 4월 20일 목요일 21:59분에 마감됩니다.

5
00:00:31,440 --> 00:00:35,607
그리고 그때 두 번째 과제가 나갈 예정입니다.

6
00:00:38,320 --> 00:00:40,434
우선 지난 강의를 복습해 봅시다.

7
00:00:40,434 --> 00:00:48,337
지난 몇차례 동안 Neural Networks와 선형 함수들을 살펴보았습니다.

8
00:00:48,337 --> 00:00:56,969
선형 레이어를 쌓고 그 사이에 비선형 레이어를 추가하여
Neural Network를 만들었습니다.

9
00:00:56,969 --> 00:01:01,500
또한 NN은  "Mode 문제" 를 해결할 수 있습니다.

10
00:01:01,500 --> 00:01:06,618
가령 다양한 종류의 자동차를 올바르게 분류하기 위해
"중간 단계의 템플릿"을 학습시키는 것이죠.

11
00:01:06,618 --> 00:01:09,006
빨간색 차 노란색 차 등을 말이죠.

12
00:01:09,006 --> 00:01:14,790
그리고 이 템플릿들을 결합해서
최종 클래스 스코어를 계산합니다.

13
00:01:14,790 --> 00:01:18,438
오늘은 CNN에 대해 말해보고자 합니다.

14
00:01:18,438 --> 00:01:20,825
기존의 NN과 같은 부류이긴 하지만

15
00:01:20,825 --> 00:01:23,300
이번에는 Convolutional Layer에 대해 배울 것입니다.

16
00:01:23,300 --> 00:01:29,217
이 레이어는 기본적으로 "공간적 구조"를 유지합니다.

17
00:01:31,817 --> 00:01:36,070
우선, Neural Networks에 대해 조금 얘기해 보려 합니다.

18
00:01:36,070 --> 00:01:39,067
그리고 CNN의 역사도 알아볼 것입니다.

19
00:01:39,067 --> 00:01:46,308
우선 1957년으로 돌아가보면, Frank Rosenblatt가
 Mark I Perceptron machine 을 개발했습니다.

20
00:01:46,308 --> 00:01:51,785
이 기계는 "perceptron"을 구현한 최초의 기계입니다.

21
00:01:51,785 --> 00:01:58,437
"Perceptron"은 우리가 배운 Wx + b 와
유사한 함수를 사용합니다.

22
00:01:58,437 --> 00:02:02,000
하지만 여기에서는 출력 값이 1 또는 0입니다.

23
00:02:02,000 --> 00:02:06,551
여기에서도 가중치 W를 Update 하는
Update Rule이 존재합니다.

24
00:02:06,551 --> 00:02:12,304
이 Update Rule은 Backprop과 유사합니다.

25
00:02:12,304 --> 00:02:22,349
하지만 당시에는 backprob이라는 개념이 없어서, 단지 W를
이리저리 조절하면서 맞추는 식이었죠

26
00:02:23,771 --> 00:02:29,673
그리고 1960년에는 Widrow와 Hoff가 \
Adaline and Madaline을 개발했습니다.

27
00:02:29,673 --> 00:02:37,457
이는 최초의 Multilayer Perceptron Network 이었습니다.

28
00:02:38,986 --> 00:02:46,658
이 시점에서야 비로소 Neural network와 비슷한
모양을 하기 시작하긴 했지만

29
00:02:46,658 --> 00:02:50,992
아직 Backprob같은 학습 알고리즘은 없었습니다.

30
00:02:50,992 --> 00:02:56,015
최초의 Backporp은 1986에 Rumelhart가 제안하였습니다.

31
00:02:56,015 --> 00:03:03,906
보시다시피 우리에게 익숙한
Chain rule과 Update rule을 볼 수 있습니다.

32
00:03:03,906 --> 00:03:09,874
이때 최초로 network를 학습시키는 것에 관한
개념이 정립되기 시작했습니다.

33
00:03:11,623 --> 00:03:18,076
하지만 그 이후로 NN을 더 크게 만들지는 못했습니다.

34
00:03:18,076 --> 00:03:26,237
그리고 한동안은 새로운 이론이 나오지 못했고
널리 쓰이지도 못 했습니다.

35
00:03:26,237 --> 00:03:32,790
그래서 2000년대가 되서야 다시 활기를 찾기 시작했습니다.

36
00:03:33,641 --> 00:03:40,719
Geoff Hinton 과 Ruslan Salakhutdinov의 2006년
논문에서 DNN의 학습가능성을 선보였고

37
00:03:40,719 --> 00:03:43,212
그것이 실제로 아주 효과적이라는 것을 보여주었습니다.

38
00:03:43,212 --> 00:03:47,428
하지막 그 때 까지도 아직 모던한 NN는 아니었습니다.

39
00:03:47,428 --> 00:03:52,439
backprop이 가능하려면 아주 세심하게
초기화를 해야 했습니다.

40
00:03:52,439 --> 00:03:57,601
그래서 여기에서는 전처리 과정이 필요했고

41
00:03:57,601 --> 00:04:07,331
초기화를 위해 RBM을 이용해서 각 히든레이어 가중치를
학습시켜야 했습니다.

42
00:04:07,331 --> 00:04:20,224
이렇게 초기화된 히든 레이어를 이용해서 전체 신경망을
backprop하거나 fine tune하는 것이었습니다.

43
00:04:23,057 --> 00:04:39,233
실제로 NN의 광풍이 불기 시작한 때는 2012년 이었습니다.

44
00:04:40,268 --> 00:04:44,980
NN이 음성 인식에서 아주 좋은 성능을 보였습니다.

45
00:04:44,980 --> 00:04:50,606
이는 Hintin lab에서 나온 것인데 acoustic modeling과
speech recognition에 관한 것이었습니다.

46
00:04:50,606 --> 00:04:58,604
또한 2012년에는 Hinton lab의 Alex Krizhevsky에서
영상 인식에 관한 landmark paper가 하나 나옵니다.

47
00:04:59,638 --> 00:05:06,813
이 논문에서는 ImageNet Classification에서 최초로 NN을
사용했고, 결과는 정말 놀라웠습니다.

48
00:05:06,813 --> 00:05:15,519
AlexNet은 ImageNet benchmark의 Error를
극적으로 감소시켰습니다.

49
00:05:16,793 --> 00:05:24,236
그 이후로  ConNets은 아주 널리 쓰이고 있습니다.

50
00:05:24,236 --> 00:05:31,714
다시 돌아가서 구체적으로 "CNN이 어떻게 유명해졌는지"
에 대해 한번 알아보도록 하겠습니다.

51
00:05:31,714 --> 00:05:42,538
다시 1950년대로 돌아가보면 Hubel과 Wiesel이 일차시각피질의
뉴런에 관한 연구를 수행했습니다.

52
00:05:42,538 --> 00:05:45,579
고양이에게 실험을 했습니다.

53
00:05:45,579 --> 00:05:53,526
첫 수업에서도 이야기하긴 했지만, 고양이의 뇌에 전극을
꽂았습니다.

54
00:05:53,526 --> 00:05:56,066
그리고 고양이에게 다양한 자극을 주며 실험을 했습니다.

55
00:05:56,066 --> 00:06:06,937
이 실험에서 뉴런이 oriented edges와 shapes같은 것에
반응한다는 것을 알아냈습니다.

56
00:06:09,029 --> 00:06:14,993
그리고 이 실험에서 내린 몇 가지 결론은 아주 중요했습니다.

57
00:06:14,993 --> 00:06:19,534
그중 하나는 바로 피질 내부에
지형적인 매핑(topographical mapping)이 있다는 것입니다.

58
00:06:19,534 --> 00:06:24,932
피질 내 서로 인접해 있는 세포들은 visual field내에
어떤 지역성을 띄고 있습니다.

59
00:06:24,932 --> 00:06:34,475
오른쪽 그림은 보면 해당하는 spatial mapping을 볼 수 있습니다.

60
00:06:34,475 --> 00:06:41,722
그리고 중심에서 더 벗어난 파란색 지역도 볼 수 있습니다.

61
00:06:41,722 --> 00:06:46,789
또한 이 실험에서 뉴런들이 계층구조를 지닌다는 것도 반견했습니다.

62
00:06:47,634 --> 00:06:57,837
다양한 종류의 시각자극을 관찰하면서 시각 신호가 가장 먼저
도달하는 곳이 바로 Retinal ganglion 이라는 것을 발견합니다.

63
00:06:57,837 --> 00:07:01,601
Retinal ganglion cell은 원형으로 생긴 지역입니다.

64
00:07:01,601 --> 00:07:11,146
가장 상위에는 Simple cells이 있는데, 이 세포들은 다양한
edges의 방향과 빛의 방향에 반응했습니다.

65
00:07:11,146 --> 00:07:15,448
그리고 더 나아가, 그런 Simple Cells 이
Complex cells과 연결되어 있다는 것을 발견했습니다.

66
00:07:15,448 --> 00:07:19,923
Complex cells는 빛의 방향 뿐만 아니라 움직임에서 반응했습니다.

67
00:07:19,923 --> 00:07:28,984
복잡도가 증가함게 따라, 가령  hypercomplex cells은
끝 점(end point) 과 같은것에 반응하게 되는 것입니다.

68
00:07:28,984 --> 00:07:34,175
이런 결과로부터  "corner" 나 "blob"에 대한
아이디어를 얻기 시작한 것입니다.

69
00:07:38,143 --> 00:07:52,454
1980의 neocognitron은 Hubel과 Wiesel이 발견한
simple/complex cells의 아이디어를 사용한 최초의 NN입니다.

70
00:07:52,454 --> 00:07:59,038
Fukishima는 simple/complex cells을 교차시켰습니다.
(SCSCSC..)

71
00:07:59,038 --> 00:08:03,129
Simple cells은 학습가능한 parameters를 가지고 있고

72
00:08:03,129 --> 00:08:12,958
Complex cells은 pooling과 같은 것으로 구현했는데
작은 변화에 Simple cells보다 좀 더 강인합니다.

73
00:08:14,786 --> 00:08:17,159
지금까지는 1980년대 까지의 업적이었습니다.

74
00:08:17,159 --> 00:08:27,743
1998년 Yann LeCun이 최초로 NN을 학습시키기 위해
Backprob과 gradient-based learning을 적용했고

75
00:08:27,743 --> 00:08:32,063
실제로 그 방법은 문서인식에 아주 잘 동작했습니다.

76
00:08:32,063 --> 00:08:37,610
그리고 우편번호의 숫자를 인식하는데도 아주 잘 동작했습니다.

77
00:08:37,610 --> 00:08:45,082
그리고 실제 우편 서비스에서 우편번호 인식에
널리 쓰였습니다.

78
00:08:45,082 --> 00:08:56,350
하지만 아직 이 Network를 더 크게만들 수는 없었습니다.
그리고 숫자 라는 데이터는 단순했습니다.

79
00:08:56,350 --> 00:09:08,900
2012년 Alex Krizhevsky가 CNN의 현대화 바람을 이르켰습니다.
이 Network는 AlexNet이라고도 불립니다.

80
00:09:08,900 --> 00:09:21,751
Yann LeCun의 CNN과 크게 달라보이진 않습니다.
다만 더 크고 깊어진 것입니다.

81
00:09:21,751 --> 00:09:37,724
가장 중요한 점은 지금은 ImageNet dataset과 같이 대규모의
데이터를 활용할 수 있다는 것입니다. 또한 GPU의 힘도 있었습니다.

82
00:09:37,724 --> 00:09:41,033
나중에 더 자세히 다루도록 하죠

83
00:09:41,033 --> 00:09:45,434
다시 오늘날로 돌아와보면
ConvNets은 모든 곳에 쓰입니다.

84
00:09:45,434 --> 00:09:55,188
AlexNet의 ImageNet 데이터 분류 결과를 살펴보자면
이미지 검색에 정말 좋은 성능을 보이고 있습니다.

85
00:09:55,188 --> 00:10:04,134
가령 꽃을 검색하는 것을 보면 학습된 특징이 유사한 것을
매칭시키는데 아주 강력하다는 것을 볼 수 있습니다.

86
00:10:04,134 --> 00:10:07,049
Detection에서도 ConvNet을 사용합니다.

87
00:10:07,049 --> 00:10:17,705
영상 내에 객체가 어디에 있는지를 아주 잘 찾아냅니다.
버스나 보트 등을 찾아내고 네모박스를 정확하게 그립니다.

88
00:10:17,705 --> 00:10:26,112
그리고 그보다 더 어려운 일들도 할 수 있는데 segmentation
은 단지 네모박스만 치는 것이 아니라

89
00:10:26,112 --> 00:10:32,125
나무나 사람 등을 구별하는데
픽셀 하나 하나에 모두 레이블링하는 것입니다.

90
00:10:34,126 --> 00:10:38,864
이런 알고리즘은 자율주행 자동차에 사용할 수 있습니다.

91
00:10:38,864 --> 00:10:48,812
대부분의 작업은 GPU가 수행할 수 있으며, 병렬처리를 통해
ConvNet을 아주 효과적으로 훈련하고 실행시킬 수 있습니다.

92
00:10:48,812 --> 00:10:59,207
자율 주행에 들어가는 임베디드 시스템에서도 동작할 뿐만 아니라
최신의 GPU에서도 가능합니다.

93
00:10:59,207 --> 00:11:03,399
이는 모두 Convnet 을 활용할 수 있는 다양한
애플리케이션의 예라고 할 수 있습니다.

94
00:11:03,399 --> 00:11:10,394
얼굴인식의 예를 보면 얼굴 이미지를 입력으로 받아서
이 사람이 누구인지에 대한 확률을 추정할 수 있습니다.

95
00:11:12,626 --> 00:11:25,951
ConvNets을 비디오에도 활용할 수 있는데, 단일 이미지의
정보 뿐만 아니라 시간적 정보도 같이 활용하는 방법입니다.

96
00:11:25,951 --> 00:11:32,770
또한 pose recognition도 가능합니다. 어깨나 팔꿈치와 같은
다양한 관절들을 인식해 낼 수 있습니다.

97
00:11:32,770 --> 00:11:42,234
여기 우리 조교 Lane의 이미지가 있습니다.
다양하고 비 정형적인 사람의 포즈를 아무 잘 잡아냅니다.

98
00:11:42,234 --> 00:11:48,465
오늘날 ConvNets을 이용한 pose recognotion은
아주 잘 동작합니다.

99
00:11:48,465 --> 00:11:51,741
Convnet을 가지고 게임도 할 수 있습니다.

100
00:11:51,741 --> 00:11:58,595
더 깊은 강화학습을 통해서 Atari 게임을 하거나
바둑을 두는 모습을 보신 적이 있을 것입니다.

101
00:11:58,595 --> 00:12:02,981
ConvNets은 이 모든 일들에서
아주 중요한 역할을 합니다.

102
00:12:02,981 --> 00:12:10,150
또다른 예로는 의학 영상을 가지고 해석을 하거나
진단을 하는데도 이용할 수 있습니다.

103
00:12:10,150 --> 00:12:14,317
또한 은하를 분류하거나 표지판을 인식하는데도 쓰입니다.

104
00:12:18,059 --> 00:12:22,342
최근의 Kaggle Chanllange에서는
고래를 분류하는 것도 있었습니다.

105
00:12:22,342 --> 00:12:33,249
또한 항공지도를 가지고 어디가 길이고 어디가 건물인지를
인식하기도 합니다.

106
00:12:35,089 --> 00:12:41,587
Classification이나 Detection에서 좀 더 나아가는 방법도
있습니다. Image Captioning같은 방법이죠

107
00:12:41,587 --> 00:12:48,644
이미지가 주어지면 이미지에 대한 설명을
문장으로 만들어 내는 것입니다.

108
00:12:48,644 --> 00:12:52,819
아마 나중에 배우게 될 것입니다.

109
00:12:52,819 --> 00:13:01,251
또한 Neural Network를 이용해 간지나는 예술작품도
만들어 낼 수 있습니다.

110
00:13:01,251 --> 00:13:12,412
왼쪽에 Deep Dream 알고리즘의 결과를 볼 수 있는데
다양한 어떤 객체가 보이고 약빨고 만든듯한 느낌을 줍니다

111
00:13:12,412 --> 00:13:23,808
또한 Style Transfer라는 방법은 원본 이미지를 가지고
특정 화풍으로 다시 그려주는 알고리즘도 있습니다.

112
00:13:23,808 --> 00:13:33,370
가령 맨 오른쪽은 반 고흐의 별의 빛나는 밤의 화풍으로 바뀐 것입니다.

113
00:13:33,370 --> 00:13:38,239
Jstin이 이와 관련된 연구를 많이 합니다.
만약 이에 관심이 있다면

114
00:13:38,239 --> 00:13:46,244
여기 예제 모두 Justin이 만든 코드이기 때문에
가서 물어보면 될 것입니다.

115
00:13:46,244 --> 00:13:52,727
지금까지는 오늘날 ConvNets이 어떻게 사용되는지
간략하게 한번 알아보았습니다.

116
00:13:52,727 --> 00:13:55,289
물론 이보다 더 많은 일들을 할 수 있을 것입니다.

117
00:13:55,289 --> 00:14:06,465
때문에 여러분도 무수히 많은 상상을 할 수 있을 것이고
저는 개인적으로 여러분들의 프로젝트가 몹시 기대됩니다.

118
00:14:06,465 --> 00:14:10,307
오늘은 Convolutional Neural Network가 어떻게
작동하는지를 살펴 볼 것입니다.

119
00:14:10,307 --> 00:14:22,835
이번에 CNN의 첫 시간이니, CNN이 어떻게 동작하는지에 대해서만 간단하게
이야기해 볼 것입니다.

120
00:14:25,453 --> 00:14:31,444
지난 강의에서 Fully Connected Layer에 대한
아이디어를 소개해 드렸습니다

121
00:14:32,878 --> 00:14:36,257
그리고 완전히 연결된 레이어의 경우

122
00:14:36,257 --> 00:14:48,443
FC Layer에서 하는 일은 어떤 벡터를 가지고 연산을 하는 것이었습니다.
우선 입력으로 32 x 32 x 3 의 이미지가 있었습니다.

123
00:14:48,443 --> 00:14:56,787
그리고 이 이미지를 길게 펴서
3072차원의 벡터로 만들었습니다.

124
00:14:56,787 --> 00:15:01,741
그리고 가중치 W가 있어서 벡터와 곱했습니다. (Wx)

125
00:15:01,741 --> 00:15:05,908
이 예시에서는 W가 10x3072 행렬입니다.

126
00:15:07,264 --> 00:15:13,943
그리고 activation 을 얻습니다.
이 Layer의 출력입니다.

127
00:15:13,943 --> 00:15:20,389
10개의 행으로 되어있는데 3072 차원의 입력와
내적을 한 결과라고 할 수 있습니다.

128
00:15:22,207 --> 00:15:27,892
그러면 어떤 숫자 하나를 얻게 되는데
이는 그 Neuron의 한 값이라고 할 수 있습니다.

129
00:15:27,892 --> 00:15:32,270
이 예시의 경우 10개의 출력이 있게 됩니다.

130
00:15:35,417 --> 00:15:44,165
Convolution Layer와 기존의 FC레이어의 주된 차이점이 있다면
Convolution Layer는 기존의 구조를 보존시킨다는 것입니다.

131
00:15:44,165 --> 00:15:57,750
기존의 FC Layer가 입력 이미지를 길게 쭉 폈다면
이제는 기존의 이미지 구조를 그대로 유지하게 됩니다.

132
00:15:57,750 --> 00:16:01,910
그리고 이 작은 필터가 우리가 가진 가중치가 되는 것이고

133
00:16:01,910 --> 00:16:13,153
이 예시에서는 5x5x3 필터가, 이 필터를 가지고 이미지를
슬라이딩하면서 공간적으로 내적을 수행하게 됩니다.

134
00:16:13,153 --> 00:16:17,320
이제 이것을 어떻게 수행하는지 자세하게 알아보겠습니다.

135
00:16:18,668 --> 00:16:23,957
우선 필터는 입력의 깊이(Depth)만큼 확장됩니다.

136
00:16:23,957 --> 00:16:33,425
여기에서 하나의 필터는 아주 작은 부분만 취할 수 있습니다.
전체 32x32 이미지의 5x5 만 취하는 것입니다.

137
00:16:33,425 --> 00:16:42,499
하지만 깊이를 보면 전체 깊이를 전부 취합니다.
여기에서는 5 x 5 x 3 가 되는 것입니다.

138
00:16:42,499 --> 00:16:52,901
이제 이 필터를 가지고 전체 이미지에 내적을 시킬 적입니다.

139
00:16:52,901 --> 00:16:58,636
이 필터를 이미지의 어떤 공간에 겹쳐놓고 내적을 수행합니다.

140
00:16:58,636 --> 00:17:09,732
그리고 필터의 각 w와, 이에 해당하는 이미지의 픽셀을 곱해줍니다.

141
00:17:09,733 --> 00:17:18,755
여기에 필터가 5 x 5 x 3 라는건 그만큼 곱셈연산을 한다는 것입니다.
물론 bias term도 하나 들어가겠지만요

142
00:17:18,755 --> 00:17:26,491
여기에서는 기본적으로 W^tx + b를 수행하는 것입니다.

143
00:17:27,722 --> 00:17:31,771
이해했나요?
질문있나요

144
00:17:31,771 --> 00:17:34,521
[학생이 질문]

145
00:17:35,656 --> 00:17:40,722
그럼 여기에서 내적을 할때는
5x5x3짜리 긴 벡터를 사용하는 것입니까? 입니다.

146
00:17:40,722 --> 00:17:42,907
맞습니다. 엄밀히 말하면 그렇습니다.

147
00:17:42,907 --> 00:17:57,891
각 원소끼리 Convolution 을 하는 거나 그것을 쭉 펴서
내적을 하는거나 똑같은 일을 하는 것입니다.

148
00:17:57,891 --> 00:18:01,111
다른 질문 있으십니까?

149
00:18:01,111 --> 00:18:03,867
[학생이 질문]

150
00:18:03,867 --> 00:18:07,997
질문은 바로 왜 W를 Transpose하는지에 대한
직관이 있습니까? 하는 것입니다.

151
00:18:07,997 --> 00:18:15,978
그런것은 따로 없습니다. 내적을 수학적으로 표현하기 위해서
표현만 그렇게 한 것일 뿐입니다.

152
00:18:15,978 --> 00:18:29,593
이는 W를 어떻게 표현하느냐의 차이일 뿐입니다.
단지 행벡터를 만들어 주려고 Transpose를 하는 것입니다.

153
00:18:29,593 --> 00:18:31,989
하지만 여기에 어떤 직관은 없습니다.

154
00:18:31,989 --> 00:18:42,862
W를 펴서 D차원 벡터로 만들어보면 내적을 하려면
다시 내적을 1 x N 행벡터로 만들어 줘야 겠죠

155
00:18:42,862 --> 00:18:45,612
[학생이 질문]

156
00:18:48,263 --> 00:18:49,829
그래, 문제는

157
00:18:49,829 --> 00:18:53,996
그럼 여기에서 W가 의미하는것은 5x5x3 가 아니라
1 x 75 인 것입니까? 입니다.

158
00:18:55,180 --> 00:19:02,550
네 맞습니다. Wx에 대해 생각해보면 우선 내적을 수행하기 앞서
W를 길게 펼 것입니다.

159
00:19:02,550 --> 00:19:09,629
다시말해 5x5x3의 입력값 x더 길게 펴진 벡터의 형태가 되겠죠

160
00:19:10,913 --> 00:19:16,706
이전 질문과도 유사한데요

161
00:19:16,706 --> 00:19:27,527
필터를 이미지에 겹쳐놓고 해당하는 값들을 서로 곱합니다
우리가 보기 좋으라고 저렇게 표현을 해 놨지만

162
00:19:27,527 --> 00:19:35,061
실제로는 모두 펴서 벡터간 내적을 구하는 것입니다.

163
00:19:35,061 --> 00:19:36,311
질문있나요?

164
00:19:37,232 --> 00:19:40,740
[학생이 질문]

165
00:19:40,740 --> 00:19:46,760
질문은 바로 필터를 이미지에 어떻게 슬라이딩 하는지 입니다.
그건 앞으로 배울 내용입니다.

166
00:19:46,760 --> 00:19:49,510
[학생이 질문]

167
00:19:52,071 --> 00:20:00,178
질문은 엄밀하게 Convolution을 수행하려면
커널에 180도 회전되어야 하지 않느냐는 것입니다.

168
00:20:00,178 --> 00:20:09,451
Convolution의 수식을 후에 볼 것이지만 여기에서의 Conv는
좀 더 느슨한 정의라고 할 수 있습니다.

169
00:20:09,451 --> 00:20:18,738
신호처리 분야에서의 convolution은 실제로
필터를 뒤집은 다음에 연산을 수행합니다.

170
00:20:18,738 --> 00:20:27,983
하지만 CNN의 Convolution은 의미적인 요소만 가져온
것이기 때문에 걱정하지 않으셔도 됩니다.

171
00:20:27,983 --> 00:20:37,246
이떤 분이 질문했던, 어떻게 슬라이딩을 하는지에 대해 알아보겠습니다.

172
00:20:37,246 --> 00:20:49,975
Convolution은 이미지의 좌상단부터 시작하게 됩니다.
그리고 필터의 중앙을 값들을 모으게 됩니다.

173
00:20:49,975 --> 00:20:57,511
필터의 모든 요소를 가지고 내적을 수행하게 되면
하나의 값을 얻게됩니다.

174
00:20:57,511 --> 00:21:00,927
그리고 슬라이딩하게 됩니다.

175
00:21:00,927 --> 00:21:09,442
Conv연산을 수행하는 값들을 다시 Output activation map의
해당하는 위치에 저장하게 됩니다.

176
00:21:10,352 --> 00:21:15,532
여기 보면 입력 이미지와 출력 activation map의 차원이
다르다는 것을 알 수 있습니다.

177
00:21:15,532 --> 00:21:20,126
입력은 32 x 32 이고 출력은 28 x  28 이죠

178
00:21:20,126 --> 00:21:26,364
그래서 우리는 나중에 수학에 대해 설명 할 것입니다. 이 방법이
차원 적으로 어떻게 작동하는지 정확히 알 수 있습니다.

179
00:21:26,364 --> 00:21:31,393
기본적으로는 어떻게 슬라이딩을 할 것인지를
선택할 수 있습니다.

180
00:21:31,393 --> 00:21:41,326
슬라이딩여부와 관계없이 입력 값을 두 개씩 뽑아서
연산을 수행할 수도 있을 것입니다.

181
00:21:41,326 --> 00:21:48,990
출력 행렬의 크기는 슬라이드를 어떻게 하느냐에 따라 다르게됩니다.
하지만 기본적으로는 하나씩 연산을 수행합니다.

182
00:21:50,180 --> 00:21:58,141
하나의 필터를 가지고 전체 이미지에 Convolution
연산을 수행합니다.

183
00:21:58,141 --> 00:22:04,731
그러면 activation map이라는 출력값을 얻게 되는 것입니다.

184
00:22:04,731 --> 00:22:16,250
보통 Convolution Layer에서는 여러개의 필터를 사용합니다.
왜냐하면 필터마다 다른 특징을 추출하고 싶기 때문입니다.

185
00:22:16,250 --> 00:22:26,359
따라서 우리는 보통 여러개의 필터를 사용합니다. 가령 여기에
두번째 필터가 있습니다. 초록색의 5 x 5 x 3 필터입니다.

186
00:22:26,359 --> 00:22:37,425
이 녹색 필터를 연산하고 나면, 앞서 계산했던 activate map과
같은 크기의 새로운 map이 만들어집니다.

187
00:22:40,081 --> 00:22:43,553
우리는 한 Layer에서 원하는 만큼 여러개의 필터를
사용할 수 있습니다.

188
00:22:43,553 --> 00:22:51,698
가령 5 x 5 필터가 6개가 있다면
총 6개의 activation map을 얻게 될 것입니다.

189
00:22:51,698 --> 00:22:58,368
출력 map의 크기는 28 x 28이 되겠죠.

190
00:23:01,607 --> 00:23:11,152
이 CNN을 어떻게 활용할 지를 조금 말씀드려보면
이런식으로  Cov Layer들의 연속된 형태가 될 것입니다.

191
00:23:11,152 --> 00:23:16,676
그리고 각각을 쌓아 올리게 되면 보시는 것과 같이
간단한 Linear Layer로 된 Neural Network가 됩니다.

192
00:23:16,676 --> 00:23:23,057
이제는 그 사이 사이에 activation function을 넣을 것입니다.
가령 ReLU 같은 것들을 사용할 수 있겠죠.

193
00:23:24,503 --> 00:23:31,257
그렇게 되면 Conv-ReLU 가 반복되겠죠
그리고 가끔은 pooling layer도 들어갑니다.

194
00:23:31,257 --> 00:23:40,465
그리고 각 Layer의 출력은 다음 Layer의 입력이 됩니다.

195
00:23:43,638 --> 00:23:52,957
그리고 말씀드렸듯 각 Layer는 여러개의 필터를 가지고 있습니다.
그리고 각 필터마다 각각의 출력 map을 만듭니다.

196
00:23:52,957 --> 00:24:01,175
그러므로 여러개의 Layer들을 쌓고나서 보면 결국
각 필터들이 계층적으로 학습을 하는것을 보게됩니다.

197
00:24:01,175 --> 00:24:09,257
앞쪽에 있는 필터들은 low-level feature를 학습하게 됩니다.
Edge와 같은것들이 보입니다.

198
00:24:09,257 --> 00:24:19,113
Mid-level을 보면 좀더 복잡한 특징을 가지게 됩니다.
코너나 blobs 등과 같이 보입니다.

199
00:24:19,113 --> 00:24:25,852
그리고 high-level features를 보면 좀 더 객체와 닮은 것들이
출력으로 나오는 것을 볼 수 있습니다.

200
00:24:25,852 --> 00:24:35,561
나중 수업에서 객 특징을 어떻게 시각화하는지, 그리고 특징들이
어떻게 학습되는지를 살펴보겠습니다.

201
00:24:35,561 --> 00:24:46,967
여기에서 이해하고 넘어가야 하는 것은 특징이 어떻게 생겼고,
Layer의 계층에 따라 단순/복잡한 특징을이 존재한다는 것을 아는 것입니다.

202
00:24:48,305 --> 00:24:49,138
[학생이 질문]

203
00:24:49,138 --> 00:25:03,113
질문은 바로 필터의 Depth를 늘리는데 어떤 직관을 가져야 하는지 입니다.

204
00:25:03,113 --> 00:25:08,814
이 예시에서 처음에는 3개의 필터가 그 다음에는
6개의 필터가 있었습니다.

205
00:25:08,814 --> 00:25:17,255
이는 어떻게 모델을 디자인해야 되는지의 문제인데
실제로는 어떤것이 더 좋은지를 찾아내야 합니다.

206
00:25:17,255 --> 00:25:28,344
나중 수업에서 다양한 CNN 아키텍쳐를 살펴보면서 왜 어떤
모델이 더 좋은지를 살펴볼 것입니다.

207
00:25:28,344 --> 00:25:33,238
하지만 기본적으로 여러분은 아주 다양하 방법으로
CNN 모델을 디자인할 수 있습니다.

208
00:25:33,238 --> 00:25:39,611
필터 사이즈라던가 Stride, 그리고 얼마나 많은 필터를
사용할지 등을 말이죠. 다음에 다시 이야기하겠습니다.

209
00:25:39,611 --> 00:25:41,246
질문있나요?

210
00:25:41,246 --> 00:25:43,996
[학생이 질문]

211
00:25:50,300 --> 00:26:00,177
질문은 바로 우리가 전체 이미지를 슬라이딩 하면서 필터링을 하는데
이미지의 가장자리는 필터가 덜 적용되지 않냐는 것입니다.

212
00:26:00,177 --> 00:26:07,900
아주 좋은 질문 입니다. 그리고 어떻게 그것을 다시 보완해야 
하는지가 앞으로 할 내용입니다. (ex zero-padding)

213
00:26:12,009 --> 00:26:26,228
지금까지는 Conv Layer를 계층적으로 쌓아서 단순한 특징을을 뽑고
그것을 또 조합해서 더 복잡한 특징으로 활용했습니다.

214
00:26:26,228 --> 00:26:32,549
그리고 이는 Hubel과 Wiesel의 이론과도 잘 맞습니다.

215
00:26:32,549 --> 00:26:39,532
네트워크에 앞쪽에서는 단순한 것들일 처리하고
뒤로 갈수록 점점 더 복잡해 지는 식이죠

216
00:26:39,532 --> 00:26:55,041
우리는 그것을 강제로 학습시킨 것이 아니라 계층적 구조를 설계하고
역전파로 학습시킨 것 뿐이지만 필터는 이렇게 학습되는 것입니다.

217
00:26:55,041 --> 00:26:57,791
[학생의 질문]

218
00:27:05,555 --> 00:27:10,979
질문은 바로 여기에서 시각화 한 것이
무엇인지 입니다.

219
00:27:10,979 --> 00:27:20,975
가령 Cov1을 보면 각 그리드의 요소가
하나의 뉴런(필터) 라고 보시면 됩니다.

220
00:27:20,975 --> 00:27:29,956
그리고 시각화 시킨 이 뉴런의 모습은 바로 이미지가 어떻게 생겨야 해당
뉴런의 활성을 최대화시킬 수 있는지는 나타내는 것입니다.

221
00:27:29,956 --> 00:27:36,594
이미지가 뉴런과 비슷하게 생겼으면 출력 값을 큰 값을 가지게 됩니다.

222
00:27:36,594 --> 00:27:56,280
시각화는 Backpopagation을 통해 해볼 수 있는데.
이를 시각화하는 방법은 나중에 더 자세하게 배울 것입니다.

223
00:27:56,280 --> 00:28:06,775
그러나 기본적으로 여기 그리드의 각 요소는 각 뉴런의 활성을
최대화시키는 입력의 모양을 나타내게 됩니다.

224
00:28:06,775 --> 00:28:10,608
그런 의미에서 뉴런이 어떻게 생겼는지를 의미합니다.

225
00:28:13,537 --> 00:28:19,835
Activation map의 예제를 한번 보겠습니다.
각 필터가 만든 출력값이죠

226
00:28:19,835 --> 00:28:30,407
위에 5 x 5 필터들을 시각화 한 것을 볼 수 있습니다.
실제 ConvNet을 학습시킨 결과입니다.

227
00:28:30,407 --> 00:28:38,511
5 x 5 필터가 어떻게 생겼는지를 보여 줍니다. 그리고
이미지와 필터간 Conv의 activation 결과를 볼 수 있습니다.

228
00:28:38,511 --> 00:28:44,346
이 경우 입력 이미지는 자동차의 한 부분인것 같습니다.

229
00:28:44,346 --> 00:28:51,330
우선 여기 빨간색 네모박스를 친 필터를 한번 봅시다.

230
00:28:51,330 --> 00:28:56,432
이 필터는 edge를 찾고 있는 것입니다.

231
00:28:56,432 --> 00:29:06,601
그리고 이 필터를 슬라이딩 시키면 이 필터와 비슷한 값들은 값이
더 커지게 됩니다.

232
00:29:06,601 --> 00:29:12,358
따라서 각 actavation은 이미지가 필터를 통과한
결과가 되며

233
00:29:12,358 --> 00:29:20,747
이미지 중 어느 위치에서 이 필터가 크게 반응하지는지를
보여줍니다.

234
00:29:20,747 --> 00:29:29,153
우리가 이걸 Convolution이러고 칭하는 이유는 바로 위에 언급
한 것이 바로 두 신호 사이에 cov를 하는것과 유사하기 때문입니다.

235
00:29:29,153 --> 00:29:38,927
여기 Conv 식이 있습니다. 예전에 신호처리에서 Conv를 본 적이
있는 학생이라면 이 식이 correlation 같아 보일 것입니다.

236
00:29:38,927 --> 00:29:50,149
우리는 사실 Conv의 뒤집힌 버전을 쓰고 있는 것입니다.
하지만 이 수업에서는 이를 더 자세히 다루지는 않겠습니다.

237
00:29:50,149 --> 00:29:58,385
하지만 손으로 직접 계산해보면 conv에 정확한 정의와
크게 다르지 않을 것입니다.

238
00:29:58,385 --> 00:30:06,432
하지만 기본적으로는 필터를 가지고 이미지에 슬라이딩하면서
모든 위치에서 내적을 수행하게 되는 것입니다.

239
00:30:09,088 --> 00:30:17,278
이전에도 언급했듯이 CNN이 어떻게 수행되는지를 살펴보면

240
00:30:17,278 --> 00:30:28,236
입력 이미지는 여러 레이어를 통과하게 됩니다. 가령 첫 번째 
Conv Layer 후에는  non-linear layer를 통과합니다.

241
00:30:28,236 --> 00:30:33,608
나중에 배우겠지만, ReLU를 가장 많이 사용합니다.

242
00:30:33,608 --> 00:30:41,244
Conv, ReLU, Conv, ReLU를 하고나면 pooling layer를
거치게 됩니다. 다시 배우겠지만-

243
00:30:41,244 --> 00:30:45,411
pooling 은 activation maps의 사이즈를
줄이는 역할을 합니다.

244
00:30:47,300 --> 00:30:56,872
그리고 CNN의 끝단에는 FC-Layer가 있습니다. 
FC-Layer는 지난시간까지 배운 레이어입니다.

245
00:30:56,872 --> 00:31:07,178
마지막 Conv 출력 모두와 연결되어 있으며 최종 스코어를 계산하기
위해 사용합니다.

246
00:31:08,445 --> 00:31:14,181
그럼 이제 "Spatial dimension"에 대해 알아보겠습니다.

247
00:31:18,363 --> 00:31:28,025
자 여기 32 x 32 x 3 이미지가 있습니다. 그리고 이 이미지를 
5 x 5 x 3 필터를 가지고 연산을 수행합니다.

248
00:31:28,025 --> 00:31:34,337
이제 어떻게 이 둘을 가지고 28 x 28 activation map이
생기는지를 알아보겠습니다.

249
00:31:34,337 --> 00:31:41,505
간단한 예시로 7 x 7  입력에 3 x 3 필터가 있다고 해봅시다.

250
00:31:41,505 --> 00:31:47,418
이제 이 필터를 이미지의 왼상당부터 씌웁니다.

251
00:31:47,418 --> 00:31:53,169
그리고 이제 해당 값들의 내적을 수행할 것입니다.

252
00:31:53,169 --> 00:31:56,764
이 값들은 activation map의 좌 상단에 위치하게 되겠죠

253
00:31:56,764 --> 00:32:02,389
그리고 다음 단계로 필터를 오른쪽으로 한칸 움직입니다.

254
00:32:02,389 --> 00:32:05,535
그러면 값 하나를 또 얻을 수 있을 것입니다.

255
00:32:05,535 --> 00:32:14,528
이렇게 계속 반복하게 되면  결국 5 x 5의 출력을 얻게 됩니다.

256
00:32:14,528 --> 00:32:25,381
이 슬라이드 필터는 좌우 방향으로는 5번만 수행가능하고
상하 방향으로도 5번만 수행가능합니다.

257
00:32:27,834 --> 00:32:31,906
그리고 여기에는 다양한 방법을 이용해 볼 수 있습니다.

258
00:32:31,906 --> 00:32:40,326
지금까지는 슬라이딩을 한칸씩만 진행했었죠. 
이때 움직이는 칸을  바로 "stride" 라고 합니다.

259
00:32:40,326 --> 00:32:46,700
지금까지는 stide = 1을 사용했습니다.
그럼 stride = 2 일때는 어떨까요?

260
00:32:46,700 --> 00:32:58,944
다시 왼쪽 위부터 시작해서 움직입니다. 다만 여기에서는 
1칸은 건너뛰고 그 다음칸으로 이동해서 계산을 합니다.

261
00:33:00,773 --> 00:33:11,257
이렇게 tride가 2 이면 3칸이면 못움직이고 
결국 출력은 3 x 3 이 됩니다.

262
00:33:13,035 --> 00:33:18,653
그렇다면 stride = 3 이면 출력의 사이즈는 몇일까요?

263
00:33:18,653 --> 00:33:27,905
stride가 3인 경우에는 이미지를 슬라이딩해도 필터가 
모든 이미지를 커버할 수 없습니다.

264
00:33:27,905 --> 00:33:32,363
이 예시에서 stride 가 3이면 이미지에 잘 맞아떨어지지 않습니다.

265
00:33:32,363 --> 00:33:41,903
실제로 이렇게 되면 잘 동작하지 않습니다. 이렇게 하면 안됩니다. 
이로 인해 불균형한 결과를 볼 수도 있기 때문입니다.

266
00:33:46,095 --> 00:33:54,690
그래서 상황에 따라 출력의 사이즈가 어떻게 될 것인지를 
계산할 수 있는 아주 유용한 수식이 있습니다.

267
00:33:54,690 --> 00:34:05,597
입력의 차원이 N이고 필터 사이즈가 F이고 
스트라이드가 몇이다 라고 주어지게 되면

268
00:34:06,992 --> 00:34:12,850
출력의 크기는 (N - F) / stride + 1 이 됩니다.

269
00:34:12,850 --> 00:34:18,619
이를 이용해서 어떤 필터 크기를 사용해야 하는지를 알 수 있습니다.

270
00:34:18,620 --> 00:34:27,326
그리고 어떤 stride를 사용했을때 이미지에 꼭 맞는지, 
그리고 몇 개의 출력값을 낼 수 있는지도 알 수 있습니다.

271
00:34:29,257 --> 00:34:32,546
지금까지 유용한 수식을 한번 알아봤습니다.

272
00:34:32,547 --> 00:34:38,637
앞서 보신바와 같이 N = 7 이고 F = 3 일때, 
그리고 stride가 1이면

273
00:34:38,637 --> 00:34:43,498
이걸 그대로 수식에 적용해보면 5 x 5 출력이 
나올 것이라는 것을 알 수 있습니다.

274
00:34:43,498 --> 00:34:47,665
stride가 3인 경우를 보면, 잘 동작하지 않겠죠. (2.33)

275
00:34:50,288 --> 00:34:59,552
그리고 가장 흔히 쓰는 기법은 zero-pad 입니다. 
출력의 사이즈 의도대로 만들어 주기 위해서죠

276
00:34:59,552 --> 00:35:04,140
이는 이전 질문이었던 "코너는 어떻게 처리하나요" 
와도 연결되는 문제입니다.

277
00:35:04,140 --> 00:35:09,222
이를 위해 할 일은, 이미지의 가장자리에 0을 채워 넣는 것입니다.

278
00:35:09,222 --> 00:35:19,134
이렇게 되면 좌 상단의 자리에서도 필터 연산을
수행할 수 있게 됩니다.

279
00:35:19,134 --> 00:35:33,654
자 이제 다시 질문입니다. 7 x 7 입력에 3 x 3 필터 연산을 수행할 때
zero-padding을 하면 출력이 어떻게 될까요?

280
00:35:33,654 --> 00:35:36,285
[학생들이 대답]

281
00:35:36,285 --> 00:35:44,847
몇 명이 6이라고 하는 것 같은데요 
저 수식을 한번 잘 생각해 보세요

282
00:35:44,847 --> 00:35:52,594
N에 7을, F에 3을 대입하고 stride를 1으로 하면

283
00:35:52,594 --> 00:35:57,264
그래서 우리가 실제로 얻는 것, 실제로
이것은 우리에게주는 것입니다.

284
00:35:57,264 --> 00:36:06,707
(7 - 3) /1 + 1 = 5 입니다. 이건 zero-padding이 없고
우리는 이 수식을 살짝 고쳐야합니다.

285
00:36:06,707 --> 00:36:12,161
이 수식은 zero-padding을 하지 않은 수식이죠

286
00:36:12,161 --> 00:36:24,173
하지만 zero-padding을 하면 출력이 7이 됩니다.
그래서 결국 7 x 7 출력을 얻게 되는 것입니다.

287
00:36:24,173 --> 00:36:30,178
원래 공식으로 돌아가보자면 N은 7이 아니라 9가 되겠죠

288
00:36:30,178 --> 00:36:42,253
N = 9 가 되고 필터 사이즈인 3을 빼면 6이 됩니다. 이를 stride
1나누면 다시 6이고 여기에 1을 더하면 7이 됩니다.

289
00:36:42,253 --> 00:36:47,974
padding을 하려면 수식을 이런식으로 적용하면 되겠습니다.

290
00:36:49,739 --> 00:36:51,646
질문 있나요?

291
00:36:51,646 --> 00:36:54,396
[학생이 질문]

292
00:37:00,717 --> 00:37:08,962
질문은 "실제 출력 값의 사이즈는 몇입니까? 
7 x 7 입니까 7 x 7 x 3 입니까?" 입니다.

293
00:37:08,962 --> 00:37:14,495
출력은 7 x 7 x "필터의 갯수" 가 됩니다.

294
00:37:14,495 --> 00:37:21,320
명심해야할 점은 각 필터가 입력의 모든 depth에 
내적을 수행한다는 것입니다.

295
00:37:21,320 --> 00:37:23,801
하나의 값만 나오겠죠

296
00:37:23,801 --> 00:37:37,124
다시 이전 슬라이드로 돌아가보겠습니다. 이전의 예제에서는 
각 필터는 7 x 7 x 1이 되겠죠

297
00:37:37,124 --> 00:37:40,493
activation map의 depth는 우리가 가진 필터의 갯수입니다.

298
00:37:40,493 --> 00:37:43,243
[학생이 질문]

299
00:37:50,161 --> 00:37:57,350
잘 못들었습니다?

300
00:37:57,350 --> 00:38:00,267
[다시 질문]

301
00:38:12,936 --> 00:38:19,735
질문은 바로, 이전 예제에서는 32 x 32 x 3 의 입력이었는데, 
방금 설명한 것을 어떻게 적용할 수 있는지 입니다.

302
00:38:19,735 --> 00:38:24,721
이전 예제에서는 depth가 있었는데 
지금 예제에서는 depth가 없었죠

303
00:38:24,721 --> 00:38:27,226
여기에서는 단순하게 예제를 만들었지만

304
00:38:27,226 --> 00:38:34,188
실제로는 이전에 했던것 처럼 depth만큼 곱해주면 됩니다.

305
00:38:34,188 --> 00:38:39,850
그러니 이 예제에서 3 x 3 x "depth" 가 되겠습니다.

306
00:38:39,850 --> 00:38:46,854
그러니 이전 예제의 경우 3 x 3 x 3 이 되겠고
다른 것을 다 똑같습니다.

307
00:38:46,854 --> 00:38:48,390
질문 있나요?

308
00:38:48,390 --> 00:38:51,307
[학생이 질문]

309
00:38:53,529 --> 00:38:58,664
질문은 바로 0 을 padding 하게되면 모서리에 
필요없는 특징을 추가하게 되는게 아닌지 입니다.

310
00:38:58,664 --> 00:39:06,289
우리가 지금 하고싶은 일은 영상 내에 어떤 모서리 부분에서
값을 얻고싶은 것이고

311
00:39:06,289 --> 00:39:10,343
zero-padding은 이를 할 수 있는 하나의 방법일 뿐입니다.

312
00:39:10,343 --> 00:39:16,097
우리는 지금  필터가 닿지 않는 모서리 부분에서도 값을
뽑을 수 있게 됩니다.

313
00:39:16,097 --> 00:39:18,323
물론 zero-padding 말고 다른 방법을 사용할 수도 있습니다.

314
00:39:18,323 --> 00:39:23,615
zero가 아닌 mirror나 extend하는 방법도 있습니다. 
꼭 zero-padding을 써야 하는 것은 아닙니다.

315
00:39:23,615 --> 00:39:26,530
하지만 zero-padding도 제법 잘 동작하는 방법 중 하나입니다.

316
00:39:26,530 --> 00:39:36,486
물론 모서리 부분에 약간의 artifact이 생긴 순 있습니다. 당연히
고려해야 하 부분이죠. 하지만 대부분의 경우 제법 잘 동잡합니다.

317
00:39:36,486 --> 00:39:41,283
다른 질문도 있었던 것 같은데요

318
00:39:41,283 --> 00:39:44,033
[학생이 질문]

319
00:39:48,015 --> 00:39:54,330
이미지가 정사각 행렬이 아니라면 수평, 수직방향의
stride를 다르게 적용해야 하는지 입니다.

320
00:39:54,330 --> 00:40:02,841
물론 당연히 가능합니다. 하지만 실제로 대부분은 정사각 행렬을
사용하고 같은 stride를 적용합니다.

321
00:40:02,841 --> 00:40:04,909
그리고 우린 그냥, 보통 우린 그냥

322
00:40:04,909 --> 00:40:08,238
똑같은 보폭을 도처에 가져 가세요.

323
00:40:08,238 --> 00:40:10,218
어떤 의미에서 그것은 조금 비슷합니다.

324
00:40:10,218 --> 00:40:12,900
그것은 당신이있는 해상도와 조금 비슷합니다.

325
00:40:12,900 --> 00:40:14,699
이 이미지를 보면,

326
00:40:14,699 --> 00:40:18,100
그리고 보통 그렇게 종류가 있습니다.

327
00:40:18,100 --> 00:40:20,693
당신의 수평 및 수직 해상도의 종류.

328
00:40:20,693 --> 00:40:22,886
하지만, 네, 그래서 실제로

329
00:40:22,886 --> 00:40:25,553
하지만 정말로 사람들은 그렇게하지 않습니다.

330
00:40:26,555 --> 00:40:28,373
다른 질문입니다.

331
00:40:28,373 --> 00:40:31,453
[희미한 말]

332
00:40:31,453 --> 00:40:33,710
질문은 왜 우리가 제로 패딩을하는 것입니까?

333
00:40:33,710 --> 00:40:35,247
그래서 우리는 제로 패딩을합니다.

334
00:40:35,247 --> 00:40:39,376
이전과 같은 입력 크기를 유지하는 것입니다.

335
00:40:39,376 --> 00:40:41,297
맞아, 그래서 7시 7 분부터 시작 했어.

336
00:40:41,297 --> 00:40:44,182
필터를 시작하기 만하면

337
00:40:44,182 --> 00:40:46,756
왼쪽 상단 모서리에서 모든 것을 채우고,

338
00:40:46,756 --> 00:40:49,019
그렇다면 우리는 더 작은 크기의 출력을 얻습니다.

339
00:40:49,019 --> 00:40:53,186
그러나 우리는 전체 크기 출력을 유지하려고합니다.

340
00:40:56,276 --> 00:40:57,109
그래,

341
00:40:59,251 --> 00:41:02,664
예, 우리는 패딩이 기본적으로 당신을
도울 수있는 방법을 보았습니다.

342
00:41:02,664 --> 00:41:05,527
원하는 출력의 크기를 유지하고,

343
00:41:05,527 --> 00:41:08,237
뿐만 아니라 이러한 필터를 적용 할 수도 있습니다.

344
00:41:08,237 --> 00:41:10,753
모서리 영역 및 모서리 영역을 포함 할 수있다.

345
00:41:10,753 --> 00:41:13,142
그리고 선택의 측면에서 일반적으로,

346
00:41:13,142 --> 00:41:15,772
당신은 당신의 보폭, 필터, 필터 크기,

347
00:41:15,772 --> 00:41:18,998
귀하의 보폭, 제로 패딩, 볼 수있는 공통점

348
00:41:18,998 --> 00:41:22,405
3 x 5, 5 x 5 크기의 필터입니다.

349
00:41:22,405 --> 00:41:25,427
7 개 7 개는 꽤 일반적인 필터 크기입니다.

350
00:41:25,427 --> 00:41:27,908
그리고 이것들 각각, 3 ~ 3

351
00:41:27,908 --> 00:41:30,232
당신은 1로 패드를 제로로하고 싶을 것이다.

352
00:41:30,232 --> 00:41:33,567
동일한 공간 크기를 유지하기 위해

353
00:41:33,567 --> 00:41:35,618
5 명씩 5 명을 할 계획이라면,

354
00:41:35,618 --> 00:41:37,470
수학을 해결할 수는 있어도 나오지.

355
00:41:37,470 --> 00:41:39,422
당신이 2로 제로 패드 싶어요.

356
00:41:39,422 --> 00:41:43,505
그리고 나서 7에 대해 3으로 제로를 넣고 싶습니다.

357
00:41:44,722 --> 00:41:47,316
자, 다시 알다시피, 동기 부여

358
00:41:47,316 --> 00:41:50,167
이 유형의 제로 패딩을 수행하는 경우

359
00:41:50,167 --> 00:41:52,184
입력 크기를 유지하려고하면

360
00:41:52,184 --> 00:41:54,500
그래서 우리는 일종의 이것에 대해 전에 암시했다.

361
00:41:54,500 --> 00:41:58,667
하지만이 여러 레이어가 서로 쌓여 있다면...

362
00:42:03,354 --> 00:42:07,015
따라서 서로 겹쳐진 여러 레이어가있는 경우

363
00:42:07,015 --> 00:42:08,689
우리가 이런 종류의 일을하지
않으면, 당신도 알게 될 것입니다.

364
00:42:08,689 --> 00:42:10,566
제로 패딩 (zero padding), 또는 어떤 종류의 패딩 (padding)

365
00:42:10,566 --> 00:42:12,848
우리는 정말로 크기를 줄이려고 할 것입니다.

366
00:42:12,848 --> 00:42:14,602
우리가 가지고있는 산출물의

367
00:42:14,602 --> 00:42:16,616
맞습니다. 그래서 이것은 우리가
원하는 어떤 것이 아닙니다.

368
00:42:16,616 --> 00:42:19,302
마치 꽤 깊은 네트워크가 있다면 상상할 수 있습니다.

369
00:42:19,302 --> 00:42:23,293
그런 다음 매우 빠르게 활성화 맵의 크기를

370
00:42:23,293 --> 00:42:25,907
매우 작은 것으로 축소 될 것입니다.

371
00:42:25,907 --> 00:42:28,790
그리고 이것은 우리가 일종의 잃는
것이기 때문에 모두 나쁜 것입니다.

372
00:42:28,790 --> 00:42:29,990
이 정보 중 일부는

373
00:42:29,990 --> 00:42:34,272
이제 훨씬 적은 수의 값을 사용하고 있습니다.

374
00:42:34,272 --> 00:42:36,578
원본 이미지를 나타 내기 위해

375
00:42:36,578 --> 00:42:38,568
그래서 당신은 그것을 원치 않습니다.

376
00:42:38,568 --> 00:42:41,318
그리고 같은 시간에

377
00:42:42,983 --> 00:42:46,249
우리는 이것에 관해서 일찍 이야기했습니다.

378
00:42:46,249 --> 00:42:48,589
이런 엣지 정보 중 일부를 잃어 버리고,

379
00:42:48,589 --> 00:42:49,923
매번 코너 정보

380
00:42:49,923 --> 00:42:53,590
우리는 그로부터 길을 잃고 줄어들고 있습니다.

381
00:42:55,203 --> 00:42:57,310
좋아, 몇 가지 예를 더 살펴 보자.

382
00:42:57,310 --> 00:43:00,060
이러한 크기의 일부를 계산할 수 있습니다.

383
00:43:00,991 --> 00:43:03,018
그러면 입력 음량이 있다고 가정 해 봅시다.

384
00:43:03,018 --> 00:43:05,611
32 x 32입니다.

385
00:43:05,611 --> 00:43:09,244
여기에는 5 5 x 5 필터가 10 개 있습니다.

386
00:43:09,244 --> 00:43:12,388
스트라이드 1과 패드 2를 사용합시다.

387
00:43:12,388 --> 00:43:13,550
그리고 나에게 말할 수있는 사람

388
00:43:13,550 --> 00:43:16,717
이것의 출력 볼륨 크기는 얼마입니까?

389
00:43:18,188 --> 00:43:20,353
따라서 이전 공식에 대해 생각할 수 있습니다.

390
00:43:20,353 --> 00:43:21,728
미안, 뭐야?

391
00:43:21,728 --> 00:43:23,263
[희미한 말]

392
00:43:23,263 --> 00:43:26,180
32 by 32 by 10, 맞습니다.

393
00:43:27,572 --> 00:43:30,324
그래서 우리가 이것을 볼 수있는 방법입니다, 맞습니다.

394
00:43:30,324 --> 00:43:33,707
우리가 입력 크기를 가지므로, F는 32입니다.

395
00:43:33,707 --> 00:43:36,401
그런 다음이 경우에 우리는 그것을 증가시키고 자한다.

396
00:43:36,401 --> 00:43:38,396
우리가 덧붙인 덧대는 것.

397
00:43:38,396 --> 00:43:41,209
그래서 우리는 각 차원에서 두 개의 패딩을했습니다.

398
00:43:41,209 --> 00:43:44,122
그래서 우리는 실제로 얻을 것입니다, 총 너비와 총 높이

399
00:43:44,122 --> 00:43:47,181
각면에 32 + 4가 될 것입니다.

400
00:43:47,181 --> 00:43:49,992
그리고 필터 크기 5를 뺀 것입니다.

401
00:43:49,992 --> 00:43:51,716
1을 더한 다음 32를 얻습니다.

402
00:43:51,716 --> 00:43:55,883
따라서 각 필터의 출력은 32 x 32가 될 것입니다.

403
00:43:57,213 --> 00:44:00,302
그리고 나서 총 10 개의 필터가 있습니다.

404
00:44:00,302 --> 00:44:02,193
그래서 우리는 10 개의 활성화 맵을 가지고 있습니다.

405
00:44:02,193 --> 00:44:06,360
총 출력량은 32 x 32 x 10이 될 것입니다.

406
00:44:08,244 --> 00:44:10,040
좋아, 다음 질문,

407
00:44:10,040 --> 00:44:14,478
이 레이어의 매개 변수 수는 얼마입니까?

408
00:44:14,478 --> 00:44:18,145
5 × 5 필터가 10 개 있다는 것을 기억하십시오.

409
00:44:19,769 --> 00:44:22,698
[희미한 말]

410
00:44:22,698 --> 00:44:26,365
나는 종류의 것을 들었다. 그러나 그것은 조용했다.

411
00:44:29,407 --> 00:44:31,240
너희들이 말할 수 있니?

412
00:44:32,809 --> 00:44:36,226
250, 알았어. 그래서 나는 250 번을 들었다.

413
00:44:37,829 --> 00:44:40,018
그러나 우리는 또한 우리의 입력량이며,

414
00:44:40,018 --> 00:44:42,149
이 필터들 각각은 깊이있게지나갑니다.

415
00:44:42,149 --> 00:44:44,237
그래서 여기에 명확하게 쓰여지지 않았을 수도 있습니다.

416
00:44:44,237 --> 00:44:46,855
각각의 필터가 공간적으로 5 × 5이기 때문에,

417
00:44:46,855 --> 00:44:50,300
그러나 암묵적으로 우리는 깊이가 있습니다.

418
00:44:50,300 --> 00:44:52,835
그것은 전체 볼륨을 통과 할 것입니다.

419
00:44:52,835 --> 00:44:55,876
그래서 들었습니다, 예, 750 나는 들었습니다.

420
00:44:55,876 --> 00:44:57,430
거의 거기, 이것은 일종의 간계 질문입니다.

421
00:44:57,430 --> 00:44:59,445
항상 우리가 항상 기억하고 있기 때문에

422
00:44:59,445 --> 00:45:03,374
편견 용어, 맞아. 그래서 실제로는 각 필터

423
00:45:03,374 --> 00:45:08,084
3 5 x 5, 플러스 1 바이어스 기간,

424
00:45:08,084 --> 00:45:10,483
우리는 필터 당 76 개의 매개 변수를 가지고 있습니다.

425
00:45:10,483 --> 00:45:12,609
그리고 나서 우리는이 총 10 개를 가지고 있습니다.

426
00:45:12,609 --> 00:45:15,609
760 개의 전체 매개 변수가 있습니다.

427
00:45:18,412 --> 00:45:20,464
좋아요, 그래서 여기에 단지 요약되어 있습니다.

428
00:45:20,464 --> 00:45:24,105
당신이 읽을 수있는 길쌈 층의

429
00:45:24,105 --> 00:45:25,890
나중에 조금 더 신중하게.

430
00:45:25,890 --> 00:45:28,924
그러나 우리는 특정 차원의 입력 볼륨을 가지고 있습니다.

431
00:45:28,924 --> 00:45:31,137
우리는이 모든 선택권을 가지고 있습니다, 우리는
우리의 필터를 가지고 있습니다. 맞습니다.

432
00:45:31,137 --> 00:45:33,751
여기서 우리는 필터의 수, 필터 크기,

433
00:45:33,751 --> 00:45:36,170
크기의 보폭, 제로 패딩의 양,

434
00:45:36,170 --> 00:45:38,682
기본적으로이 모든 것을 사용할 수 있습니다.

435
00:45:38,682 --> 00:45:41,167
우리가 이전에 말한 계산을 거쳐야한다.

436
00:45:41,167 --> 00:45:43,866
출력 볼륨이 실제로 무엇인지 알아 내기 위해

437
00:45:43,866 --> 00:45:48,033
당신이 가지고있는 총 매개 변수가
얼마나 많은지 그리고 얼마나 많은지

438
00:45:49,282 --> 00:45:51,951
그래서 이것의 일반적인 설정입니다.

439
00:45:51,951 --> 00:45:55,526
이전에 공통 필터 크기에 대해 이야기했습니다.

440
00:45:55,526 --> 00:45:58,555
3 명, 5 명, 5 명

441
00:45:58,555 --> 00:46:01,739
보폭은 대개 1이고 2가 꽤 일반적입니다.

442
00:46:01,739 --> 00:46:04,505
그리고 당신의 패딩 P는 어떤 것이 든 될 것입니다.

443
00:46:04,505 --> 00:46:08,518
당신의 공간적 범위를 보존 할 것이 무엇이든간에

444
00:46:08,518 --> 00:46:10,401
공통점입니다.

445
00:46:10,401 --> 00:46:13,623
그리고 나서 총 필터 수 K,

446
00:46:13,623 --> 00:46:16,759
보통 우리는 단지 두 가지의
힘을 사용하여 멋지게 만듭니다.

447
00:46:16,759 --> 00:46:19,009
32, 64, 128 등, 512,

448
00:46:19,903 --> 00:46:24,505
이것들은 꽤 일반적인 숫자입니다.

449
00:46:24,505 --> 00:46:26,511
그리고 그냥 제쳐두고,

450
00:46:26,511 --> 00:46:29,488
우리는 하나의 회선을 하나씩 할 수 있습니다.

451
00:46:29,488 --> 00:46:31,557
이것은 여전히 완벽한 의미를 갖습니다.

452
00:46:31,557 --> 00:46:33,459
주어진 하나씩의 회선

453
00:46:33,459 --> 00:46:35,852
우리는 각 공간 범위에서 여전히 그것을 슬라이드합니다,

454
00:46:35,852 --> 00:46:37,700
하지만 이제는 알다시피, 공간 영역

455
00:46:37,700 --> 00:46:38,888
실제로 5에 5가 아니다.

456
00:46:38,888 --> 00:46:42,574
하나 하나의 사소한 사건 일뿐입니다.

457
00:46:42,574 --> 00:46:44,819
그러나 우리는 여전히이 필터를 가지고 있습니다.

458
00:46:44,819 --> 00:46:46,680
전체 깊이로 가라.

459
00:46:46,680 --> 00:46:48,273
맞아, 이건 내면의 제품이 될거야.

460
00:46:48,273 --> 00:46:52,053
귀하의 입력 볼륨의 전체 깊이를 통해.

461
00:46:52,053 --> 00:46:55,067
여기 출력은 입력 음량이있는 경우 출력됩니다.

462
00:46:55,067 --> 00:46:59,804
56 × 56 × 64 깊이로 하나씩 처리 할 것입니다.

463
00:46:59,804 --> 00:47:03,895
32 개의 필터가있는 컨볼 루션은 출력이 될 것입니다.

464
00:47:03,895 --> 00:47:07,062
우리의 필터 수에 의해 56에 의해 56 56.

465
00:47:10,076 --> 00:47:13,419
자, 여기에 길쌈 레이어의 예제가 있습니다.

466
00:47:13,419 --> 00:47:16,210
깊은 학습 틀인 TORCH에서

467
00:47:16,210 --> 00:47:18,747
그래서 마지막 강의를 보게 될 것입니다.

468
00:47:18,747 --> 00:47:20,799
우리가 어떻게이 문제에 개입 할 수 있는지 이야기했습니다.

469
00:47:20,799 --> 00:47:23,427
심층 학습 프레임 워크를 사용하면
이러한 정의를 볼 수 있습니다.

470
00:47:23,427 --> 00:47:25,017
각 레이어의 오른쪽, 그들이 어디에 있는지

471
00:47:25,017 --> 00:47:26,665
정방향 및 역방향 패스

472
00:47:26,665 --> 00:47:28,667
각 레이어에 대해 구현됩니다.

473
00:47:28,667 --> 00:47:30,638
그리고 당신은 회선을 볼 것입니다,

474
00:47:30,638 --> 00:47:33,562
공간 컨볼 루션은 이들 중 하나 일뿐입니다.

475
00:47:33,562 --> 00:47:35,360
그리고 나서 그것이 취할 논쟁

476
00:47:35,360 --> 00:47:39,890
이 모든 디자인 선택이 될 것입니다. 아시다시피,

477
00:47:39,890 --> 00:47:42,781
제 말은, 당신의 입력과 출력 크기를 추측합니다.

478
00:47:42,781 --> 00:47:45,759
커널 너비와 같은 선택도 가능합니다.

479
00:47:45,759 --> 00:47:50,161
커널 크기, 패딩 및 이러한 종류의 것들.

480
00:47:50,161 --> 00:47:53,226
맞습니다. 그래서 다른 프레임 워크를 보면, Caffe,

481
00:47:53,226 --> 00:47:54,737
당신은 매우 비슷한 것을 보게 될 것입니다.

482
00:47:54,737 --> 00:47:56,950
네트워크를 정의 할 때 다시 지금 어디에 있습니까?

483
00:47:56,950 --> 00:48:00,880
당신은 이런 종류의 것을 사용하여
Caffe에서 네트워크를 정의합니다.

484
00:48:00,880 --> 00:48:03,982
지정하는 원시 텍스트 파일

485
00:48:03,982 --> 00:48:07,160
레이어에 대한 각 디자인 선택

486
00:48:07,160 --> 00:48:09,279
컨벌루션 레이어를 볼 수 있습니다.

487
00:48:09,279 --> 00:48:11,806
출력의 수를 알 수 있습니다.

488
00:48:11,806 --> 00:48:14,077
우리가 가지고있는 필터의 개수가 될 것입니다.

489
00:48:14,077 --> 00:48:18,244
Caffe의 경우, 커널 크기와 보폭 등이 포함됩니다.

490
00:48:21,144 --> 00:48:24,701
좋아, 그래서 나는 내가 계속하기 전에,

491
00:48:24,701 --> 00:48:26,512
회선에 관한 질문,

492
00:48:26,512 --> 00:48:29,512
컨볼 루션 연산은 어떻게 작동합니까?

493
00:48:30,868 --> 00:48:32,161
네, 질문.

494
00:48:32,161 --> 00:48:34,911
[희미한 말]

495
00:48:51,604 --> 00:48:52,940
그래, 문제는,

496
00:48:52,940 --> 00:48:55,902
당신이 당신의 보폭을 선택하는
방법 뒤에있는 직관은 무엇입니까?

497
00:48:55,902 --> 00:49:00,037
그리고 한 가지 의미에서 그것은 일종의 해결책입니다.

498
00:49:00,037 --> 00:49:02,401
당신이 그것을 미끄러지게 할 때,
그리고 보통 이것 뒤에있는 이유

499
00:49:02,401 --> 00:49:04,870
우리가 더 큰 보폭을 가질 때

500
00:49:04,870 --> 00:49:06,908
우리가 결과물로 얻는 결과

501
00:49:06,908 --> 00:49:09,258
다운 샘플링 된 이미지, 오른쪽,

502
00:49:09,258 --> 00:49:13,425
그래서이 다운 샘플링 된 이미지로 우리가
가질 수있는 것은 둘 다입니다.

503
00:49:14,715 --> 00:49:17,202
그것은 한 가지 방법입니다. 어떤
의미에서 풀링과 같은 것입니다.

504
00:49:17,202 --> 00:49:19,352
그러나 그것은 단지 다른 것이고 때로는 더 잘 작동합니다.

505
00:49:19,352 --> 00:49:23,025
풀링하는 방법은이 배후의 직감 중 하나입니다.

506
00:49:23,025 --> 00:49:27,192
이미지를 다운 샘플링하는 것과 동일한 효과를 얻으므로,

507
00:49:28,183 --> 00:49:32,691
그리고 나서이 작업을 할 때 크기를 줄이고 있습니다.

508
00:49:32,691 --> 00:49:35,502
당신이 다루고있는 활성화 맵들 중

509
00:49:35,502 --> 00:49:38,892
각 레이어에서 오른쪽, 그리고
이것도 나중에 영향을 미칩니다

510
00:49:38,892 --> 00:49:40,825
가지고있는 매개 변수의 총 개수

511
00:49:40,825 --> 00:49:44,973
예를 들어 모든 전환 계층의 끝에서

512
00:49:44,973 --> 00:49:48,611
이제 당신은 완전히 연결된 레이어를
맨 위에 올릴 수도 있습니다.

513
00:49:48,611 --> 00:49:51,092
예를 들어, 이제 완전히 연결된 레이어의

514
00:49:51,092 --> 00:49:53,362
모든 값에 연결됨

515
00:49:53,362 --> 00:49:56,099
당신의 컨볼 루션 출력 중, 오른쪽,

516
00:49:56,099 --> 00:49:59,058
그래서 작은 것이 더 적은 수를 줄 것입니다.

517
00:49:59,058 --> 00:50:02,596
매개 변수를 사용하면 이제는

518
00:50:02,596 --> 00:50:04,960
기본적으로 트레이드 오프를 생각하면,

519
00:50:04,960 --> 00:50:08,025
보유하고있는 매개 변수의 수, 모델의 크기,

520
00:50:08,025 --> 00:50:10,076
overfitting, 그런 것들, 그래서 그래,

521
00:50:10,076 --> 00:50:11,371
이것들은 일종의 것들이다.

522
00:50:11,371 --> 00:50:15,538
당신은 당신의 보폭을 선택하는
것에 대해 생각하고 싶습니다.

523
00:50:18,496 --> 00:50:22,421
좋아요, 그래서 지금 우리가 종류의 조금을 보면,

524
00:50:22,421 --> 00:50:25,356
당신은 알고 있습니다, convolutional
layer의 뇌 뉴런 뷰,

525
00:50:25,356 --> 00:50:29,627
우리가 뉴런을 보았던 것과 비슷합니다.

526
00:50:29,627 --> 00:50:31,599
마지막 강의에서.

527
00:50:31,599 --> 00:50:35,610
그래서 우리는 모든 공간적 위치에서,

528
00:50:35,610 --> 00:50:37,488
우리는 필터 사이에 점을 찍는다.

529
00:50:37,488 --> 00:50:39,216
이미지의 특정 부분, 오른쪽,

530
00:50:39,216 --> 00:50:42,077
우리는 여기에서 하나의 번호를 얻습니다.

531
00:50:42,077 --> 00:50:43,506
그리고 이것은 같은 생각입니다.

532
00:50:43,506 --> 00:50:46,042
이런 종류의 내적 제품을 만드는 것,

533
00:50:46,042 --> 00:50:49,270
귀하의 의견을 가지고,이 Ws에 의해 가중치, 오른쪽,

534
00:50:49,270 --> 00:50:53,659
필터의 값, 시냅스 인이 가중치,

535
00:50:53,659 --> 00:50:55,227
가치를 얻는 것.

536
00:50:55,227 --> 00:50:57,559
하지만 여기서 가장 큰 차이점은 바로 지금입니다.

537
00:50:57,559 --> 00:50:59,517
뉴런에는 로컬 연결이 있습니다.

538
00:50:59,517 --> 00:51:02,191
따라서 전체 입력에 연결되는 대신,

539
00:51:02,191 --> 00:51:06,536
그것은 단지 당신의 이미지의 공간적인
지역을 바라 보는 것입니다.

540
00:51:06,536 --> 00:51:08,701
그래서 이것은 지역을 바라본 것입니다.

541
00:51:08,701 --> 00:51:11,859
그리고 지금 당신은 종류를 얻게
될 것입니다, 당신도 알다시피,

542
00:51:11,859 --> 00:51:15,111
이,이 뉴런이 얼마나 많이 발생했는지

543
00:51:15,111 --> 00:51:17,500
이미지의 모든 공간 위치에서

544
00:51:17,500 --> 00:51:19,631
맞습니다. 이제는 공간 구조를 보존합니다.

545
00:51:19,631 --> 00:51:22,485
당신은 추론 할 수 있다고 말할 수 있습니다.

546
00:51:22,485 --> 00:51:26,652
이러한 종류의 활성화 맵을 최신 레이어에 추가합니다.

547
00:51:30,048 --> 00:51:33,181
그리고 약간의 전문 용어,

548
00:51:33,181 --> 00:51:36,931
다시 알다시피, 우리는 5 x 5 필터를 가지고 있습니다.

549
00:51:36,931 --> 00:51:40,015
우리는 이것을 5 x 5 수용성 장

550
00:51:40,015 --> 00:51:41,726
뉴런의 경우 이것은,

551
00:51:41,726 --> 00:51:44,300
수용 분야는 기본적으로, 당신도 알다시피,

552
00:51:44,300 --> 00:51:46,535
이 시야의 입력 필드

553
00:51:46,535 --> 00:51:48,518
이 뉴런이 받고있는, 맞아,

554
00:51:48,518 --> 00:51:51,758
그래서 이것은 또 다른 공통된 용어 일뿐입니다.

555
00:51:51,758 --> 00:51:53,315
당신이 이것을 듣게 될 것입니다.

556
00:51:53,315 --> 00:51:55,743
그런 다음 5 개의 필터로 5 개를 다시 기억하십시오.

557
00:51:55,743 --> 00:51:58,442
우리는 그것들을 공간적 위치 위로 미끄러 져 움직이고있다.

558
00:51:58,442 --> 00:52:00,506
그러나 그들은 같은 무게의 세트입니다,

559
00:52:00,506 --> 00:52:03,089
그들은 동일한 매개 변수를 공유합니다.

560
00:52:05,440 --> 00:52:08,045
우리가 얘기 한 것처럼 알았어.

561
00:52:08,045 --> 00:52:09,485
우리가이 산출물에서 얻게 될 것

562
00:52:09,485 --> 00:52:11,200
이 권이 될거야. 맞아.

563
00:52:11,200 --> 00:52:13,874
우리가 공간적으로 가지고있는 곳, 28시 28 분

564
00:52:13,874 --> 00:52:16,373
필터의 수는 깊이입니다.

565
00:52:16,373 --> 00:52:18,357
예를 들어 5 개의 필터가있는 경우,

566
00:52:18,357 --> 00:52:20,663
우리가 나갈 것은이 3D 그리드입니다.

567
00:52:20,663 --> 00:52:23,381
그것은 28에 의해 28에 의해 5입니다.

568
00:52:23,381 --> 00:52:26,606
필터를 가로 질러 보면

569
00:52:26,606 --> 00:52:30,654
활성화 볼륨의 한 공간 위치에

570
00:52:30,654 --> 00:52:33,825
그리고이 5 개의 뉴런을 깊이 훑어 보면,

571
00:52:33,825 --> 00:52:36,003
이 모든 뉴런들,

572
00:52:36,003 --> 00:52:37,408
기본적으로 당신이 이것을 해석 할 수있는 방법

573
00:52:37,408 --> 00:52:39,471
그들은 모두 같은 지역을보고있는 것입니까?

574
00:52:39,471 --> 00:52:40,590
입력 볼륨에서,

575
00:52:40,590 --> 00:52:42,344
그러나 그들은 단지 다른 것들을 찾고 있습니다. 맞습니다.

576
00:52:42,344 --> 00:52:43,953
그래서 그들은 다른 필터입니다.

577
00:52:43,953 --> 00:52:48,120
이미지의 동일한 공간 위치에 적용됩니다.

578
00:52:49,152 --> 00:52:52,391
그리고 다시 한 번 비교해 보겠습니다.

579
00:52:52,391 --> 00:52:55,443
이전에 이야기했던 완전히 연결된 레이어

580
00:52:55,443 --> 00:52:57,805
이 경우, 우리가 각각의 뉴런을 본다면

581
00:52:57,805 --> 00:53:01,607
우리의 활성화 또는 산출물에서, 각각의 뉴런

582
00:53:01,607 --> 00:53:03,983
전체 뻗어 입력,

583
00:53:03,983 --> 00:53:06,637
그래서 전체 전체 입력 볼륨을 살펴 보았습니다.

584
00:53:06,637 --> 00:53:08,802
지금과 비교할 때마다

585
00:53:08,802 --> 00:53:12,805
이 로컬 공간 영역을 봅니다.

586
00:53:12,805 --> 00:53:14,255
문제.

587
00:53:14,255 --> 00:53:17,088
[말하지 않는 이야기]

588
00:53:22,648 --> 00:53:25,054
그래, 문제는 주어진 레이어 내에서,

589
00:53:25,054 --> 00:53:28,137
필터가 완전히 대칭입니까?

590
00:53:30,158 --> 00:53:34,325
그렇다면 대칭성이란 정확히 무엇을 의미합니까?

591
00:53:42,200 --> 00:53:46,389
그래, 좋아. 그래서 필터들, 필터들,

592
00:53:46,389 --> 00:53:50,556
그들은 같은 차원, 같은 계산을하고 있습니다, 그렇습니다.

593
00:53:52,784 --> 00:53:54,444
좋아요, 그래서 다른 게 있어요.

594
00:53:54,444 --> 00:53:58,122
그들은 같은 매개 변수 값을 가지고 있습니까?

595
00:53:58,122 --> 00:53:59,624
아니, 네 말이 맞아.

596
00:53:59,624 --> 00:54:02,690
우리는 주어진 집합으로 필터를 가져 가고 있습니다.

597
00:54:02,690 --> 00:54:04,973
3 개의 매개 변수 값에 의해 5 x 5,

598
00:54:04,973 --> 00:54:07,335
우리는 정확히 같은 방식으로이 슬라이드를합니다.

599
00:54:07,335 --> 00:54:11,502
활성화 맵을 얻으려면 전체 입력 볼륨에서

600
00:54:14,596 --> 00:54:17,668
좋아, 알다시피, 우리는 많은 세부 사항에 도달했다.

601
00:54:17,668 --> 00:54:20,592
이 콘볼 루션 레이어가 어떻게 생겼는지,

602
00:54:20,592 --> 00:54:22,372
그래서 지금 나는 간단히 간다.

603
00:54:22,372 --> 00:54:25,196
우리가 가지고있는 다른 층들을 통해

604
00:54:25,196 --> 00:54:28,802
이 전체 컨벌루션 네트워크를 형성합니다.

605
00:54:28,802 --> 00:54:31,071
그래, 다시 기억해, 우리는 길쌈 레이어

606
00:54:31,071 --> 00:54:33,365
때때로 풀링 레이어가 산재되어있다.

607
00:54:33,365 --> 00:54:36,653
이러한 비선형 성뿐만 아니라

608
00:54:36,653 --> 00:54:39,017
좋습니다. 그래서 풀링 레이어가하는 일은 무엇입니까?

609
00:54:39,017 --> 00:54:41,112
그들은 표현을한다는 것입니다.

610
00:54:41,112 --> 00:54:42,716
작고 관리하기 쉽고,

611
00:54:42,716 --> 00:54:45,107
그래서 우리는 이것에 대해 이전에

612
00:54:45,107 --> 00:54:48,683
누군가가 왜 우리가 원하는지에 대한 질문을했습니다.

613
00:54:48,683 --> 00:54:51,562
표현은 더 작다.

614
00:54:51,562 --> 00:54:54,919
그리고 이것은 다시 그것을 가지고 있습니다.

615
00:54:54,919 --> 00:54:58,343
그것은 당신이 마지막에 가지고있는
매개 변수의 수에 영향을 미칩니다.

616
00:54:58,343 --> 00:55:01,614
기본적으로 일부는 수행합니다.

617
00:55:01,614 --> 00:55:04,425
주어진 지역에 대한 불변성.

618
00:55:04,425 --> 00:55:05,830
풀링 레이어가하는 역할

619
00:55:05,830 --> 00:55:09,460
정확한 다운 샘플링을 수행하고 있는지,

620
00:55:09,460 --> 00:55:13,415
그리고 그것은 당신의 입력 볼륨을 필요로합니다.
예를 들어,

621
00:55:13,415 --> 00:55:17,762
224 by 224 by 64, 그리고이를
공간적으로 다운 샘플링합니다.

622
00:55:17,762 --> 00:55:20,861
결국 결국 112 점을 얻게 될 것입니다.

623
00:55:20,861 --> 00:55:23,429
그리고 이것이 아무 것도하지 않는다는
것을 알아 두는 것이 중요합니다.

624
00:55:23,429 --> 00:55:26,588
깊이, 오른쪽, 우리는 공간적으로 만 풀링하고 있습니다.

625
00:55:26,588 --> 00:55:30,168
따라서 입력 깊이의 수

626
00:55:30,168 --> 00:55:33,215
출력 깊이와 같을 것입니다.

627
00:55:33,215 --> 00:55:36,948
예를 들어,이를 수행하는 일반적인 방법은 최대 풀링입니다.

628
00:55:36,948 --> 00:55:41,317
따라서이 경우 풀링 레이어에는 필터 크기가 있습니다

629
00:55:41,317 --> 00:55:44,289
이 필터 크기는 지역이 될 것입니다.

630
00:55:44,289 --> 00:55:46,825
우리가 끝내고, 바로이 경우에

631
00:55:46,825 --> 00:55:50,562
우리가 두 개씩 두 개의 필터를 가지고
있다면 이것을 슬라이드 할 것입니다.

632
00:55:50,562 --> 00:55:53,572
그리고 여기, 우리는 또한이 경우에 두 가지를 보았습니다.

633
00:55:53,572 --> 00:55:54,884
그래서 우리는이 필터를 사용하려고합니다.

634
00:55:54,884 --> 00:55:58,999
우리는 입력 볼륨을 따라 슬라이드 할 것입니다.

635
00:55:58,999 --> 00:56:01,672
우리가 컨볼 루션을했을 때와 똑같은 방식으로

636
00:56:01,672 --> 00:56:03,619
그러나 여기에이 제품들을 사용하는 대신에,

637
00:56:03,619 --> 00:56:06,205
우리는 단지 최대 값을 취한다.

638
00:56:06,205 --> 00:56:08,338
해당 영역의 입력 볼륨

639
00:56:08,338 --> 00:56:11,645
맞습니다. 여기 빨간색 값을 보면,

640
00:56:11,645 --> 00:56:13,416
그 값은 6이 될 것입니다.

641
00:56:13,416 --> 00:56:15,655
우리가 녹색을 보면 그것이 8을 줄 것입니다,

642
00:56:15,655 --> 00:56:18,655
그리고 우리는 3과 4를가집니다.

643
00:56:23,433 --> 00:56:24,931
네, 질문.

644
00:56:24,931 --> 00:56:27,848
[말장난]

645
00:56:29,010 --> 00:56:31,304
그래, 문제는 스트라이드를 설정하는
것이 일반적인 것인가하는 것입니다.

646
00:56:31,304 --> 00:56:34,406
중복이 없도록?

647
00:56:34,406 --> 00:56:36,850
그리고 네, 풀링 레이어는 그렇습니다.

648
00:56:36,850 --> 00:56:38,196
나는 할 일이 더 많다고 생각한다.

649
00:56:38,196 --> 00:56:41,256
그들에게 어떤 겹침도 갖지 말라는 것입니다.

650
00:56:41,256 --> 00:56:44,688
너는 이것에 대해 생각할 수있는 방법을 생각해.

651
00:56:44,688 --> 00:56:48,322
기본적으로 우리는 단지 다운 샘플을 원한다.

652
00:56:48,322 --> 00:56:50,560
그래서이 지역을 좀 더 자세히 보아도 좋습니다.

653
00:56:50,560 --> 00:56:52,977
이 영역을 나타 내기 위해 하나의 값을 얻습니다.

654
00:56:52,977 --> 00:56:55,874
그리고 나서 다음 지역을 보게됩니다.

655
00:56:55,874 --> 00:56:57,379
그래, 질문.

656
00:56:57,379 --> 00:57:00,129
[희미한 말]

657
00:57:02,415 --> 00:57:04,328
좋아, 그럼 질문은, 왜 최대 풀링인가

658
00:57:04,328 --> 00:57:05,710
그냥 복용하는 것보다 낫다.

659
00:57:05,710 --> 00:57:07,636
평균 풀링 같은 것을하고 있습니까?

660
00:57:07,636 --> 00:57:10,058
그렇습니다. 평균 풀링과 같은 좋은 점입니다.

661
00:57:10,058 --> 00:57:12,017
당신이 할 수있는 일이기도합니다.

662
00:57:12,017 --> 00:57:15,417
최대 풀링이 일반적으로 사용되는 이유에 대한 직감

663
00:57:15,417 --> 00:57:17,979
그것의 해석을 가질 수 있다는 것입니다,

664
00:57:17,979 --> 00:57:21,471
알다시피, 이것이 사실이라면,
이것은 내 뉴런의 활성화입니다.

665
00:57:21,471 --> 00:57:23,770
맞아. 그래서 각 가치는 종류가 비슷해.

666
00:57:23,770 --> 00:57:26,972
이 뉴런이이 위치에서 얼마나 많이 발사 됐는지,

667
00:57:26,972 --> 00:57:29,253
이 필터가이 위치에서 얼마나 많이 작동했는지.

668
00:57:29,253 --> 00:57:31,927
그래서 당신은 맥스 풀링 (max pooling)을
말하는 것으로 생각할 수 있습니다.

669
00:57:31,927 --> 00:57:36,094
이 필터가 얼마나 많이 작동했는지에
대한 신호를 제공합니다.

670
00:57:37,000 --> 00:57:39,133
이 이미지의 어느 위치에서나.

671
00:57:39,133 --> 00:57:41,264
맞습니다. 우리가 탐지를 생각하고 있다면,

672
00:57:41,264 --> 00:57:44,022
알다시피, 인정하고,

673
00:57:44,022 --> 00:57:46,535
이것은 당신이 말하는 곳에서
직관적으로 이해할 수 있습니다.

674
00:57:46,535 --> 00:57:49,034
글쎄, 당신도 알다시피, 빛이든, 어떤면

675
00:57:49,034 --> 00:57:52,206
당신이 찾고있는 이미지의

676
00:57:52,206 --> 00:57:53,990
이 지역의 어느 곳에서나 일어날 지 여부

677
00:57:53,990 --> 00:57:57,073
우리는 높은 가치로 발사하기를 원합니다.

678
00:57:57,940 --> 00:57:59,129
문제.

679
00:57:59,129 --> 00:58:02,046
[말장난]

680
00:58:06,200 --> 00:58:08,746
응, 그래서 문제는 풀링과 보폭 때문이다.

681
00:58:08,746 --> 00:58:10,959
둘 다 다운 샘플링의 동일한 효과를 가지며,

682
00:58:10,959 --> 00:58:14,223
풀링 대신 스트라이드를 사용할 수 있습니까?

683
00:58:14,223 --> 00:58:16,513
네, 그래서 실제로 저는 생각합니다.

684
00:58:16,513 --> 00:58:19,771
보다 최근의 뉴럴 네트워크 아키텍처 살펴보기

685
00:58:19,771 --> 00:58:23,103
사람들은 보폭을 더 많이 사용하기 시작했다.

686
00:58:23,103 --> 00:58:27,704
풀링 대신에 다운 샘플링을하기 위해서입니다.

687
00:58:27,704 --> 00:58:30,837
그리고 나는 이것이 마치 당신이 알고있는 것처럼,

688
00:58:30,837 --> 00:58:32,801
당신이 할 수있는 부분적인 진보와 일도 좋아합니다.

689
00:58:32,801 --> 00:58:36,968
하지만 실제로 이것은 약간의 의미가 있습니다.

690
00:58:38,721 --> 00:58:41,892
그것을 사용하여 더 나은 결과를 얻는 더 좋은 방법입니다.

691
00:58:41,892 --> 00:58:44,125
네, 보폭을 사용하는 것이 분명하다고 생각합니다.

692
00:58:44,125 --> 00:58:47,292
당신은 그것을 할 수 있고 사람들은 그것을하고 있습니다.

693
00:58:49,672 --> 00:58:52,505
좋아, 그럼 어디 보자.

694
00:58:53,544 --> 00:58:56,553
그래, 그래, 그래서이 풀링 레이어와 함께,

695
00:58:56,553 --> 00:59:00,358
다시 말하지만, 여러분이 디자인
선택을 할 수있는 권리가 있습니다.

696
00:59:00,358 --> 00:59:04,057
이 입력 볼륨을 H만큼 D만큼 D만큼 취하면,

697
00:59:04,057 --> 00:59:07,446
그런 다음 하이퍼 파라미터를 설정하려고합니다.

698
00:59:07,446 --> 00:59:10,107
필터 크기의 설계 선택을위한

699
00:59:10,107 --> 00:59:12,376
또는 풀링중인 공간 범위,

700
00:59:12,376 --> 00:59:15,101
보폭뿐만 아니라 다시 계산할 수 있습니다.

701
00:59:15,101 --> 00:59:18,676
사용한 방정식을 사용하여 출력량

702
00:59:18,676 --> 00:59:21,325
이전에 회선을 위해, 그것은 여전히 여기, 오른쪽,

703
00:59:21,325 --> 00:59:24,030
그래서 우리는 여전히 우리의 전체 범위를 가지고있다.

704
00:59:24,030 --> 00:59:27,780
마이너스 필터 크기를 보폭 + 나눈 값으로 나눈 값입니다.

705
00:59:30,880 --> 00:59:33,217
좋아요, 그래서 주목해야 할 또 하나의 것,

706
00:59:33,217 --> 00:59:37,172
또한 일반적으로 사람들은 제로
패딩을 실제로 사용하지 않습니다.

707
00:59:37,172 --> 00:59:39,647
당신이 그냥 시도하기 때문에 풀링 레이어

708
00:59:39,647 --> 00:59:41,262
직접 다운 샘플링, 오른쪽,

709
00:59:41,262 --> 00:59:43,003
그래서 이와 같은 문제는 없습니다.

710
00:59:43,003 --> 00:59:44,423
코너에 필터 적용하기

711
00:59:44,423 --> 00:59:47,045
필터의 일부가 입력 음량을 잃게됩니다.

712
00:59:47,045 --> 00:59:49,526
그래서 우리는 보통 이것에 대해 걱정할 필요가 없습니다.

713
00:59:49,526 --> 00:59:52,939
우리는 바로 직접 샘플링합니다.

714
00:59:52,939 --> 00:59:56,304
풀링 레이어의 일반적인 설정

715
00:59:56,304 --> 01:00:00,890
필터 크기는 2 또는 3 x 3 스트라이드입니다.

716
01:00:00,890 --> 01:00:03,609
두명의 두명, 알다시피, 당신은 가질 수 있습니다.

717
01:00:03,609 --> 01:00:06,269
또한 여전히 두 개씩 풀링 할 수 있습니다.

718
01:00:06,269 --> 01:00:09,091
필터 크기가 3 x 3 인 경우에도,

719
01:00:09,091 --> 01:00:10,789
나는 누군가가 일찌기 그것,

720
01:00:10,789 --> 01:00:14,956
그러나 실제로는 2 개씩 2 개를 갖는 것이 일반적입니다.

721
01:00:17,958 --> 01:00:21,527
자, 이제 우리는이 길쌈 층에 대해 이야기했습니다,

722
01:00:21,527 --> 01:00:24,370
ReLU 층은 이전에 가지고 있던 층과 동일했습니다.

723
01:00:24,370 --> 01:00:29,174
너는 알다시피, 기본 뉴럴 네트워크

724
01:00:29,174 --> 01:00:31,492
우리가 마지막 강의에 관해서 이야기했던 것.

725
01:00:31,492 --> 01:00:33,899
그래서 우리는 이것들을 섞어서 풀링 레이어를 만듭니다.

726
01:00:33,899 --> 01:00:37,865
때때로 우리는 다운 샘플링과 같은 느낌을 갖습니다.

727
01:00:37,865 --> 01:00:41,080
그리고 마지막으로 마지막은

728
01:00:41,080 --> 01:00:43,766
우리는 완전히 연결된 계층을 원합니다.

729
01:00:43,766 --> 01:00:46,210
그리고 이것은 정확히 똑같을 것입니다.

730
01:00:46,210 --> 01:00:48,790
이전에 보았던 완전히 연결되어있는 레이어입니다.

731
01:00:48,790 --> 01:00:50,506
그래서이 경우 지금 우리가하는 일

732
01:00:50,506 --> 01:00:54,173
우리는 컨벌루션 네트워크 출력을 취하고 있으며,

733
01:00:55,775 --> 01:00:57,503
마지막 층에는 약간의 음량이 있습니다.

734
01:00:57,503 --> 01:01:00,421
그래서 우리는 어느 정도 깊이만큼 높이를 가질 것입니다.

735
01:01:00,421 --> 01:01:01,626
우리는이 모든 것을 취합니다.

736
01:01:01,626 --> 01:01:04,212
우리는 본질적으로 이것들을 스트레칭합니다.

737
01:01:04,212 --> 01:01:06,322
그리고 이제 우리는 같은 종류의 것을 얻을 것입니다.

738
01:01:06,322 --> 01:01:08,795
알다시피, 기본적으로 우리가 익숙한 1D 입력

739
01:01:08,795 --> 01:01:12,962
바닐라 신경 회로망을 위해, 그리고 우리는

740
01:01:14,153 --> 01:01:16,275
이 위에 완전히 연결된 레이어,

741
01:01:16,275 --> 01:01:17,715
그래서 지금 우리는 연결을 할 것입니다.

742
01:01:17,715 --> 01:01:21,715
이 컨벌루션 맵 출력들 모두에.

743
01:01:22,676 --> 01:01:24,786
그래서 당신이 생각할 수있는 것은 기본적으로,

744
01:01:24,786 --> 01:01:26,457
이제는 보존하는 대신에

745
01:01:26,457 --> 01:01:28,616
우리가 공간 구조를 보존하기 전에,

746
01:01:28,616 --> 01:01:30,897
맞아요.하지만 결국 마지막 층에서,

747
01:01:30,897 --> 01:01:32,982
우리는이 모든 것을 하나로 모으고 싶다.

748
01:01:32,982 --> 01:01:34,787
기본적으로 이성을 잃고 싶다.

749
01:01:34,787 --> 01:01:37,081
이 모든 것은 우리가 전에했던 것처럼.

750
01:01:37,081 --> 01:01:40,518
그래서 당신이 얻는 것은 우리의 것입니다.

751
01:01:40,518 --> 01:01:43,185
우리가 이전에 가지고 있던 점수 산출물.

752
01:01:45,744 --> 01:01:47,232
좋아, 그럼 ..

753
01:01:47,232 --> 01:01:48,411
- [학생] 이것은 일종의 어리석은 질문입니다.

754
01:01:48,411 --> 01:01:49,911
이 비주얼에 대해서.

755
01:01:52,345 --> 01:01:56,123
맨 오른쪽에있는 16 픽셀과 마찬가지로,

756
01:01:56,123 --> 01:02:00,357
그걸 해석해야하는 것처럼?

757
01:02:00,357 --> 01:02:02,584
좋아요. 문제는 16 픽셀이란 무엇입니까?

758
01:02:02,584 --> 01:02:04,238
맨 오른쪽에 있습니다.

759
01:02:04,238 --> 01:02:05,888
- [학생] 그 칼럼처럼 -

760
01:02:05,888 --> 01:02:07,566
- [강사] 오, 각 칸.

761
01:02:07,566 --> 01:02:09,425
오른쪽 끝에있는 기둥, 네.

762
01:02:09,425 --> 01:02:11,031
- [강사] 녹색 것입니까, 아니면 흑인입니까?

763
01:02:11,031 --> 01:02:12,679
- [학생] 풀이라고 표시된 학생.

764
01:02:12,679 --> 01:02:14,472
- 잠깐 만요, 수영장.

765
01:02:14,472 --> 01:02:16,312
오, 알겠습니다. 그래, 질문은

766
01:02:16,312 --> 01:02:20,566
예를 들어 수영장에서이 열을 어떻게 해석할까요?

767
01:02:20,566 --> 01:02:24,645
여기에 우리가 보여주는 것은이 칼럼들 각각입니다.

768
01:02:24,645 --> 01:02:28,376
출력 활성화 맵입니다, 오른쪽,

769
01:02:28,376 --> 01:02:29,887
이 층들 중 하나의 출력.

770
01:02:29,887 --> 01:02:34,028
그래서 처음부터 우리는 차를 가지고 있습니다.

771
01:02:34,028 --> 01:02:35,465
컨벌루션 층 이후

772
01:02:35,465 --> 01:02:37,795
이제 각 필터의 활성화 맵이 생겼습니다.

773
01:02:37,795 --> 01:02:40,537
공간적으로 입력 이미지 위로 미끄러졌다.

774
01:02:40,537 --> 01:02:42,484
그런 다음 ReLU를 통해 전달합니다.

775
01:02:42,484 --> 01:02:45,306
그래서 거기에서 나오는 값을 볼 수 있습니다.

776
01:02:45,306 --> 01:02:46,636
그리고 모든 것을 끝내고,

777
01:02:46,636 --> 01:02:48,652
풀링 레이어로 얻는 것

778
01:02:48,652 --> 01:02:51,850
정말로 복용하고 있다는 것입니다.

779
01:02:51,850 --> 01:02:54,183
ReLU 층의 출력

780
01:02:55,548 --> 01:02:58,270
그 직전에 온 것이고 그 다음에 풀링을합니다.

781
01:02:58,270 --> 01:03:00,337
그래서 그것을 다운 샘플링하려고합니다.

782
01:03:00,337 --> 01:03:01,711
맞아, 그 다음에 갈거야.

783
01:03:01,711 --> 01:03:04,510
각 필터 위치의 최대치

784
01:03:04,510 --> 01:03:06,548
그리고 이제이 풀 레이어 출력을 보면,

785
01:03:06,548 --> 01:03:09,209
예를 들어, 마지막으로 언급 한 것과 같습니다.

786
01:03:09,209 --> 01:03:11,704
이 ReLU 출력과 동일하게 보입니다.

787
01:03:11,704 --> 01:03:15,871
단, 다운 샘플링이 가능하고, 이런 종류의

788
01:03:17,311 --> 01:03:18,952
모든 공간 위치에서 최대 값

789
01:03:18,952 --> 01:03:20,550
그래서 그것은 사소한 차이입니다

790
01:03:20,550 --> 01:03:22,534
당신은 그 둘 사이에서 볼 것입니다.

791
01:03:22,534 --> 01:03:25,451
[먼 거리]

792
01:03:30,523 --> 01:03:32,559
그래서 질문은, 지금 이것은 다음과 같이 보입니다.

793
01:03:32,559 --> 01:03:34,654
아주 적은 양의 정보, 바로,

794
01:03:34,654 --> 01:03:36,991
그래서 그것을 여기에서 분류하는
것을 어떻게 알 수 있습니까?

795
01:03:36,991 --> 01:03:39,553
그래서 당신이 이것에 대해 생각해야하는 방식입니다.

796
01:03:39,553 --> 01:03:41,886
이 값들 각각

797
01:03:43,365 --> 01:03:46,052
이 풀 출력 중 하나의 내부에는 실제로,

798
01:03:46,052 --> 01:03:49,004
그것은 당신이 한 모든 프로세싱의 축적입니다.

799
01:03:49,004 --> 01:03:50,696
이 전체 네트워크에서

800
01:03:50,696 --> 01:03:53,890
따라서 계층 구조의 맨 위에 있습니다.

801
01:03:53,890 --> 01:03:55,458
그래서 각각은 실제로 나타납니다.

802
01:03:55,458 --> 01:03:57,602
종류의 높은 수준의 개념.

803
01:03:57,602 --> 01:04:01,197
그래서 우리는 예전에 Hubel과
Wiesel을 보았습니다.

804
01:04:01,197 --> 01:04:03,571
이러한 계층 적 필터를 구축하고,

805
01:04:03,571 --> 01:04:07,466
하단에서 우리는 가장자리를 찾고 있습니다, 오른쪽,

806
01:04:07,466 --> 01:04:10,257
또는 가장자리 같은 매우 단순한 구조와 같은 것들.

807
01:04:10,257 --> 01:04:13,872
그래서 컨볼 루션 레이어 다음에

808
01:04:13,872 --> 01:04:15,991
이 첫 번째 열에서 본 출력물

809
01:04:15,991 --> 01:04:20,541
기본적으로 얼마나 구체적일까요? 예를 들어, 가장자리,

810
01:04:20,541 --> 01:04:22,700
이미지의 다른 위치에서 발사하십시오.

811
01:04:22,700 --> 01:04:25,268
그러나 당신이 지나갈 때 당신은 더 복잡해질 것입니다,

812
01:04:25,268 --> 01:04:26,915
그것은 더 복잡한 것들을 찾고 있습니다. 맞습니다.

813
01:04:26,915 --> 01:04:28,955
따라서 다음 컨볼 루션 계층

814
01:04:28,955 --> 01:04:31,205
얼마나 많은 돈을 벌어들이 겠어?

815
01:04:31,205 --> 01:04:34,674
어떤 종류의 구석이 이미지에 나타나면,

816
01:04:34,674 --> 01:04:36,080
그것이 추론이기 때문에 그렇습니다.

817
01:04:36,080 --> 01:04:37,957
그것의 입력은 원본 이미지가 아니며,

818
01:04:37,957 --> 01:04:42,627
그것의 입력은 산출이다, 이미 가장자리지도, 맞다,

819
01:04:42,627 --> 01:04:44,560
그래서 그것은 엣지지도 위에 추론하고 있습니다.

820
01:04:44,560 --> 01:04:47,680
그래서 더 복잡해질 수 있습니다.

821
01:04:47,680 --> 01:04:49,052
더 복잡한 것들을 탐지한다.

822
01:04:49,052 --> 01:04:50,756
그래서 모든 걸 얻으실 때까지

823
01:04:50,756 --> 01:04:53,212
이 마지막 풀링 레이어로, 각 값은

824
01:04:53,212 --> 01:04:57,379
비교적 복잡한 종류의 템플릿이
얼마나 많이 발사되고 있는지.

825
01:04:58,765 --> 01:05:01,613
맞아요, 그리고 그 때문에 지금 당신은 할 수 있습니다.

826
01:05:01,613 --> 01:05:04,460
완전히 연결된 레이어는 집계 중입니다.

827
01:05:04,460 --> 01:05:07,228
이 모든 정보를 종합 해 보면,

828
01:05:07,228 --> 01:05:10,511
알다시피, 당신 수업의 점수.

829
01:05:10,511 --> 01:05:13,134
그래서이 값들 각각은 얼마나 많은가?

830
01:05:13,134 --> 01:05:17,051
꽤 복잡한 복잡한 개념이 발사되고 있습니다.

831
01:05:19,043 --> 01:05:20,460
문제.

832
01:05:20,460 --> 01:05:23,239
[희미한 말]

833
01:05:23,239 --> 01:05:24,744
그래서 질문은, 언제 당신이 일을했는지 아십니까?

834
01:05:24,744 --> 01:05:27,296
분류를하기에 충분한 풀링?

835
01:05:27,296 --> 01:05:30,722
그리고 대답은 당신이 시도하고 보는 것입니다.

836
01:05:30,722 --> 01:05:34,639
그래서 실제로, 이것들은 모두 디자인 선택입니다.

837
01:05:34,639 --> 01:05:37,430
당신은 이것에 대해 조금 직관적으로 생각할 수 있습니다.

838
01:05:37,430 --> 01:05:41,203
맞아, 네가 수영장에 가고
싶어하지만 너가 너무 많이 갇히면

839
01:05:41,203 --> 01:05:43,585
당신은 가치가 거의 없을 것입니다.

840
01:05:43,585 --> 01:05:45,960
귀하의 전체 이미지를 나타내는 등,

841
01:05:45,960 --> 01:05:47,701
그래서 그것은 단순한 종류의 거래입니다.

842
01:05:47,701 --> 01:05:50,581
합리적인 것 대 사람들이 시도한 것

843
01:05:50,581 --> 01:05:52,290
다양한 구성

844
01:05:52,290 --> 01:05:54,614
그래서 당신은 아마 유효성 검사를 할 것입니다. 맞습니다.

845
01:05:54,614 --> 01:05:57,049
다른 풀링 크기를 시도해보십시오.

846
01:05:57,049 --> 01:05:59,492
다른 필터 크기, 다른 레이어 수,

847
01:05:59,492 --> 01:06:02,926
당신의 문제에 가장 적합한 것이 무엇인지보십시오. 예,

848
01:06:02,926 --> 01:06:05,350
다른 데이터가있는 모든 문제가 그러 하듯이,

849
01:06:05,350 --> 01:06:07,423
알다시피, 이런 종류의 다른 세트

850
01:06:07,423 --> 01:06:10,340
하이퍼 매개 변수가 가장 잘 작동 할 수 있습니다.

851
01:06:13,388 --> 01:06:16,836
좋아, 마지막으로, 너희들을 가리키고 싶었어.

852
01:06:16,836 --> 01:06:19,753
ConvNet을 훈련하는 데모로,

853
01:06:21,171 --> 01:06:24,143
앙드레 카르 파티 (Andre Karpathy)

854
01:06:24,143 --> 01:06:26,424
이 클래스의 작성자.

855
01:06:26,424 --> 01:06:28,755
그래서 그는이 데모를 썼습니다.

856
01:06:28,755 --> 01:06:33,000
기본적으로 CIFAR-10에서
ConvNet을 교육 할 수 있습니다.

857
01:06:33,000 --> 01:06:35,874
이전에 보았던 데이터 세트, 바로
10 개의 클래스로 구성됩니다.

858
01:06:35,874 --> 01:06:39,341
이 데모에 대한 좋은 점은 할 수 있다는 것입니다.

859
01:06:39,341 --> 01:06:42,014
그것은 기본적으로 각각의 필터

860
01:06:42,014 --> 01:06:44,260
활성화 맵이 어떻게 생겼는지 보입니다.

861
01:06:44,260 --> 01:06:46,137
그래서 이전에 보여 줬던 몇몇 이미지들

862
01:06:46,137 --> 01:06:47,835
이 데모에서 가져 왔습니다.

863
01:06:47,835 --> 01:06:50,048
그래서 당신은 그것을 밖으로 시도하고, 그것으로 놀고,

864
01:06:50,048 --> 01:06:52,640
그리고 너도 알다시피, 그냥 가서 감각을 익히 라.

865
01:06:52,640 --> 01:06:55,268
이 활성화지도가 어떻게 생겼는지.

866
01:06:55,268 --> 01:06:57,134
그리고 주목할 사실은,

867
01:06:57,134 --> 01:07:00,578
일반적으로 첫 번째 레이어 활성화 맵은

868
01:07:00,578 --> 01:07:01,709
너는 그걸 해석 할 수있어. 맞아.

869
01:07:01,709 --> 01:07:03,606
그들은 입력 이미지에서 직접 작동하기 때문에

870
01:07:03,606 --> 01:07:05,532
그래서 당신은이 템플릿들이 의미하는 것을 볼 수 있습니다.

871
01:07:05,532 --> 01:07:07,784
당신이 더 높은 수준의 레이어에 도착하면

872
01:07:07,784 --> 01:07:08,975
정말 열심히 시작합니다.

873
01:07:08,975 --> 01:07:11,163
어떻게 이런 의미를 실제로 해석합니까?

874
01:07:11,163 --> 01:07:13,877
그래서 대부분 해석하기가 어렵습니다.

875
01:07:13,877 --> 01:07:15,398
그래서 너는 걱정하지 말아야한다.

876
01:07:15,398 --> 01:07:17,535
당신이 정말로 무슨 일이 일어나고
있는지 이해할 수 없다면.

877
01:07:17,535 --> 01:07:19,604
그러나 전체 흐름을 보는 것만으로도 여전히 좋습니다.

878
01:07:19,604 --> 01:07:22,271
그리고 어떤 산출물이 나오고 있는지.

879
01:07:23,985 --> 01:07:27,313
좋습니다. 요약하면, 오늘 우리는

880
01:07:27,313 --> 01:07:29,946
길쌈 신경 네트워크가 작동하는 방식,

881
01:07:29,946 --> 01:07:31,257
그들이 기본적으로 스택 인 방법

882
01:07:31,257 --> 01:07:34,204
이러한 길쌈 및 풀링 계층

883
01:07:34,204 --> 01:07:38,291
끝에 완전히 연결된 층이 뒤 따른다.

884
01:07:38,291 --> 01:07:40,940
작은 필터를 사용하는 경향이있었습니다.

885
01:07:40,940 --> 01:07:44,069
더 심오한 아키텍처에 대해 더 자세히 이야기하겠습니다.

886
01:07:44,069 --> 01:07:47,364
나중에 이들 중 일부에 대한
사례 연구에 대해 알아보십시오.

887
01:07:47,364 --> 01:07:49,576
또한 이러한 문제를 없애는 경향이 있습니다.

888
01:07:49,576 --> 01:07:52,215
풀링 및 완전히 연결된 레이어.

889
01:07:52,215 --> 01:07:55,275
따라서 이것을 유지하는 것만으로도,

890
01:07:55,275 --> 01:07:57,391
Conv 레이어의 매우 깊은 네트워크,

891
01:07:57,391 --> 01:08:01,058
다시 한번 우리는이 모든 것을 나중에 논의 할 것입니다.

892
01:08:01,898 --> 01:08:04,591
그리고 전형적인 아키텍처는 다시 이렇게 보입니다.

893
01:08:04,591 --> 01:08:06,300
너도 알다시피, 우리가 이전에했던 것처럼.

894
01:08:06,300 --> 01:08:08,964
Conv, ReLU 일부 N 단계

895
01:08:08,964 --> 01:08:10,821
그 다음에 한 번씩 풀장이 뒤 따랐다.

896
01:08:10,821 --> 01:08:13,197
이 모든 일이 몇 번 반복되었습니다.

897
01:08:13,197 --> 01:08:16,314
그 다음에는 완전히 연결된 ReLU 층

898
01:08:16,314 --> 01:08:18,987
우리가 이전에 보았던 것, 당신도 알다시피, 하나 또는 둘

899
01:08:18,987 --> 01:08:20,287
또는 이들 중 단지 몇 가지 만,

900
01:08:20,287 --> 01:08:24,060
그리고 나서 당신의 학급 점수를위한
softmax가 끝납니다.

901
01:08:24,060 --> 01:08:26,100
그래서 몇 가지 일반적인 값이 있습니다.

902
01:08:26,100 --> 01:08:29,183
당신은 N 개까지 5 개까지 가질 수 있습니다.

903
01:08:30,408 --> 01:08:33,144
꽤 깊은 층이 생길거야.

904
01:08:33,145 --> 01:08:36,759
Conv, ReLU, 풀 시퀀스 및 일반적으로

905
01:08:36,759 --> 01:08:39,701
끝에 완전히 연결된 두 개의 레이어 만 있습니다.

906
01:08:39,701 --> 01:08:42,221
그러나 우리는 또한 새로운 아키텍처로 갈 것입니다.

907
01:08:42,221 --> 01:08:45,895
ResNet 및 GoogLeNet과 같이

908
01:08:45,895 --> 01:08:49,755
꽤 다른 유형의 아키텍처를 제공 할 것입니다.

909
01:08:49,756 --> 00:00:00,000
좋아요, 다음에 너희들을 만나서 고맙다.

