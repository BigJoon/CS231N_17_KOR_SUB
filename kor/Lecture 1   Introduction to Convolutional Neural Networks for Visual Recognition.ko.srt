1
00:00:07,041 --> 00:00:09,708
- CS231n 수업에 오신 것을 환영합니다.

2
00:00:07,641 --> 00:00:10,308


3
00:00:11,362 --> 00:00:15,107
이 수업은 다시 개설하게 되어 아주 좋습니다.

4
00:00:11,762 --> 00:00:14,235


5
00:00:15,107 --> 00:00:21,523
이 수업은 다른 어떤 것보다도 빠르게 성장하고 있습니다.

6
00:00:15,507 --> 00:00:17,568


7
00:00:17,568 --> 00:00:21,523


8
00:00:21,123 --> 00:00:24,034
이번으로 세 번째 개설하게 되었습니다.

9
00:00:21,523 --> 00:00:24,434


10
00:00:24,034 --> 00:00:26,066
처음에는 150명으로 시작했죠

11
00:00:24,434 --> 00:00:26,466


12
00:00:26,066 --> 00:00:28,600
지난해에는 두 배가 늘어 350명이 수강하였습니다.

13
00:00:26,466 --> 00:00:29,000


14
00:00:28,600 --> 00:00:34,406
올해에는 또 두 배가 늘어서, 오늘 아침 기준으로
약 730 명이 현재 수강하고 있습니다.

15
00:00:29,000 --> 00:00:32,852


16
00:00:32,852 --> 00:00:34,806


17
00:00:34,406 --> 00:00:39,694
공간의 제약으로 수업에 들어오지 못한 분들도 있는데

18
00:00:34,806 --> 00:00:38,428


19
00:00:38,428 --> 00:00:40,094


20
00:00:39,694 --> 00:00:44,531
강의 동영상이 두 시간 내로 
SCPD 웹 사이트에 게시 될 것입니다.

21
00:00:40,094 --> 00:00:43,189


22
00:00:43,189 --> 00:00:44,931


23
00:00:44,531 --> 00:00:50,489
오늘 여기 와서 수업을 듣지 못했어도,
몇 시간 후면 바로 확인 하실 수 있습니다.

24
00:00:44,931 --> 00:00:46,900


25
00:00:46,900 --> 00:00:50,889


26
00:00:50,489 --> 00:00:54,676
CS231n은 컴퓨터 비전에 관한 수업입니다.

27
00:00:50,889 --> 00:00:55,076


28
00:00:54,676 --> 00:00:57,012
그러면 과연 컴퓨터 비전(Computer Vision)이라는 것이 뭘까요?

29
00:00:55,076 --> 00:00:57,412


30
00:00:57,012 --> 00:00:59,741
컴퓨터비전은 시각데이터와 관련된 연구입니다.

31
00:00:57,412 --> 00:01:00,141


32
00:00:59,741 --> 00:01:05,819
워낙 컴퓨터비전이 유명해져서 
굳이 중요성을 설명할 필요는 없을 것 같지만

33
00:01:00,141 --> 00:01:02,578


34
00:01:02,578 --> 00:01:04,522


35
00:01:04,522 --> 00:01:06,219


36
00:01:05,819 --> 00:01:09,632
어쨌든 전 중요성을 계속 강조할 것입니다.

37
00:01:06,219 --> 00:01:10,032


38
00:01:09,632 --> 00:01:15,361
최근 몇 년간 엄청나게 많은 시각 데이터가
쏟아져 나오고 있습니다.

39
00:01:10,032 --> 00:01:11,895


40
00:01:11,895 --> 00:01:14,173


41
00:01:14,173 --> 00:01:15,761


42
00:01:15,361 --> 00:01:19,998
이런 데이터들은 이세상은 수많은 센서들로 비롯됩니다.

43
00:01:15,761 --> 00:01:17,613


44
00:01:17,613 --> 00:01:20,398


45
00:01:19,998 --> 00:01:22,664
여기계신 대다수가 스마트폰이 있을 것입니다.

46
00:01:20,398 --> 00:01:21,759


47
00:01:22,664 --> 00:01:26,589
여러분들의 스마트폰에는 한두개의 카메라가 내장되어 있습니다.

48
00:01:23,064 --> 00:01:25,004


49
00:01:25,004 --> 00:01:26,989


50
00:01:26,589 --> 00:01:30,714
아마 카메라의 수가 이세상의 인구수보다 많을 것입니다.

51
00:01:26,989 --> 00:01:28,974


52
00:01:28,974 --> 00:01:31,114


53
00:01:30,714 --> 00:01:38,108
이런 카메라들이 전 세계 각지에서 매일매일 
데이터를 쏟아내고 있습니다.

54
00:01:31,114 --> 00:01:32,765


55
00:01:32,765 --> 00:01:35,371


56
00:01:35,371 --> 00:01:37,524


57
00:01:38,108 --> 00:01:46,625
2015년에서 2017년까지 CISCO에서 만들었던 한 통계자료가 
이 사실을 아주 잘 보여줍니다.

58
00:01:38,508 --> 00:01:41,239


59
00:01:41,239 --> 00:01:43,858


60
00:01:43,858 --> 00:01:47,025


61
00:01:46,719 --> 00:01:54,084
통계를 보면 인터넷 트래픽 중 80% 가량은 바로 비디오 데이터입니다.

62
00:01:48,919 --> 00:01:51,784


63
00:01:51,784 --> 00:01:54,484


64
00:01:54,084 --> 00:02:00,125
심지어 단일 이미지나 다른 시각 데이터를 제외한 비율입니다.

65
00:01:54,484 --> 00:01:58,074


66
00:01:58,074 --> 00:02:00,525


67
00:02:00,125 --> 00:02:07,076
이 통계가 의미하는 바는 바로 인터넷에 돌아다니는 
대부분의 데이터가 바로 시각 데이터라는 것입니다.

68
00:02:00,525 --> 00:02:03,880


69
00:02:03,880 --> 00:02:06,002


70
00:02:06,002 --> 00:02:07,476


71
00:02:07,076 --> 00:02:12,757
그러니 가장 중요한 것은 이런 데이터를 잘 활용할 수 있는
알고리즘을 개발하는 것입니다.

72
00:02:07,476 --> 00:02:09,547


73
00:02:09,547 --> 00:02:13,157


74
00:02:12,757 --> 00:02:17,413
하지만 문제가 하나 있는데, 이런 시각데이터는
해석하기 몹시 까다롭다는 것입니다.

75
00:02:13,157 --> 00:02:15,370


76
00:02:15,370 --> 00:02:17,813


77
00:02:17,413 --> 00:02:24,126
몇몇 사람들은 시각 데이터를 암흑물질(dark matter)로 칭합니다.
물리학에서 나오는 암흑물질말이죠

78
00:02:17,813 --> 00:02:20,813


79
00:02:20,813 --> 00:02:24,526


80
00:02:24,126 --> 00:02:27,037
예전에 암흑물질에 대해 들어본 사람도 있겠지만,

81
00:02:24,526 --> 00:02:27,437


82
00:02:27,037 --> 00:02:32,977
암흑 물질은 우주의 대부분의 질량을 차지하고 있습니다.

83
00:02:27,437 --> 00:02:31,180


84
00:02:31,180 --> 00:02:33,377


85
00:02:32,977 --> 00:02:37,893
우리는 여러가지 간접적인 측정을 통해서 암흑물질이
존재한다는 것 까지는 알 수 있었지만

86
00:02:33,377 --> 00:02:35,167


87
00:02:35,167 --> 00:02:38,293


88
00:02:37,893 --> 00:02:40,135
우리는 이 암흑물질을 직접적으로 "관측" 할 수는 없습니다.

89
00:02:38,293 --> 00:02:40,535


90
00:02:40,135 --> 00:02:42,438
인터넷 상의 시각데이터도 그렇습니다

91
00:02:40,535 --> 00:02:42,838


92
00:02:42,438 --> 00:02:55,285
시각데이터가 대부분이긴 하지만, 사실상 우리가 이것을
이해하고 해석하는 일은 정말 어렵습니다.

93
00:02:42,838 --> 00:02:45,488


94
00:02:45,488 --> 00:02:49,164


95
00:02:49,164 --> 00:02:51,313


96
00:02:51,313 --> 00:02:54,222


97
00:02:54,222 --> 00:02:55,685


98
00:02:55,285 --> 00:02:58,066
또 다른 통계가 하나 있는데 Youtube의 통계입니다.

99
00:02:55,685 --> 00:02:58,466


100
00:02:58,066 --> 00:03:07,346
거의 매 초 Youtube에는 다섯 시간 분량의 비디오가 업로드됩니다.

101
00:02:58,466 --> 00:03:02,309


102
00:03:02,309 --> 00:03:05,303


103
00:03:05,303 --> 00:03:07,746


104
00:03:07,346 --> 00:03:15,196
우리가 여기서 하나... 둘... 셋... 이렇게 새고나면
Youtube에는 15 시간의 비디오가 새로 업로드 된 것입니다.

105
00:03:07,746 --> 00:03:09,305


106
00:03:09,305 --> 00:03:12,805


107
00:03:13,929 --> 00:03:15,596


108
00:03:16,676 --> 00:03:23,746
Google에 아무리 직원이 많아도 그 모든 비디오를 보고 이해하고
정리한다는 것은 사실상 불가능합니다.

109
00:03:17,076 --> 00:03:18,824


110
00:03:18,824 --> 00:03:21,219


111
00:03:21,219 --> 00:03:24,146


112
00:03:23,746 --> 00:03:28,961
따라서 그 비디오들을 잘 정리하고, 사람들에게 제공하고
또 비디오들에 적절한 광고를 달아야 한다면

113
00:03:24,146 --> 00:03:26,856


114
00:03:26,856 --> 00:03:29,361


115
00:03:28,961 --> 00:03:36,653
자동으로 시각데이터를 이해하고 분석하는
알고리즘을 개발하는게 가장 중요한 것입니다.

116
00:03:29,361 --> 00:03:32,057


117
00:03:32,057 --> 00:03:34,803


118
00:03:34,803 --> 00:03:37,053


119
00:03:38,249 --> 00:03:47,164
컴퓨터비전 이라는 분야는 상당이 많은 분야가 혼재해있습니다. 
따라서 다양한 분야의 과학, 공학을 다뤄야 합니다.

120
00:03:38,649 --> 00:03:41,379


121
00:03:41,379 --> 00:03:44,089


122
00:03:44,089 --> 00:03:45,864


123
00:03:45,864 --> 00:03:47,564


124
00:03:47,164 --> 00:03:50,422
컴퓨터비전이 우주(universe)의 중심이라 할 수 있겠죠

125
00:03:47,564 --> 00:03:50,822


126
00:03:50,422 --> 00:03:56,053
그러나 컴퓨터비전 이라는 우주를 도는 항성으로써,
물리학과 같은 분야 또한 다뤄야 합니다.

127
00:03:50,822 --> 00:03:53,914


128
00:03:53,914 --> 00:03:56,453


129
00:03:56,053 --> 00:04:01,384
왜냐하면 "광학", "이미지 형성" 그리고 실제로 물리학적으로 어떻게 
"이미지가 형성"되는지를 이해할 필요가 있기 때문입니다.

130
00:03:56,453 --> 00:03:59,418


131
00:03:59,418 --> 00:04:01,784


132
00:04:01,384 --> 00:04:03,595
생물학이나 심리학도 알아야 합니다.

133
00:04:01,784 --> 00:04:03,995


134
00:04:03,595 --> 00:04:09,494
어떻게 동물의 뇌가 시각정보를 물리적으로
"보고 처리하는지"  를 이해하기 위해서죠

135
00:04:03,995 --> 00:04:07,879


136
00:04:07,879 --> 00:04:09,894


137
00:04:09,494 --> 00:04:13,905
물론 많은 컴퓨터 과학, 수학, 그리고 공학을 다루는데,

138
00:04:09,894 --> 00:04:12,045


139
00:04:12,045 --> 00:04:14,305


140
00:04:13,905 --> 00:04:19,239
우리가 만든 컴퓨터 비전 알고리즘을 구현할
컴퓨터 시스템을 구축해야 하기 때문입니다.

141
00:04:14,305 --> 00:04:16,954


142
00:04:16,954 --> 00:04:19,639


143
00:04:19,240 --> 00:04:25,592
저를 포함한 이 수업의 교수진과 운영진을
간략히 설명해 드리도록 하겠습니다.

144
00:04:19,640 --> 00:04:22,595


145
00:04:22,595 --> 00:04:24,985


146
00:04:25,592 --> 00:04:33,206
저와, Serena는 Fei-Fei Li 교수님의 지도하에 있는
Stanford Vision Lab의 박사과정 (PhD) 학생 입니다.

147
00:04:25,992 --> 00:04:30,722


148
00:04:30,722 --> 00:04:33,606


149
00:04:33,206 --> 00:04:40,784
그리고 우리 Lab은 기계학습과 컴퓨터과학에 관한
연구를 하고 있습니다.

150
00:04:33,606 --> 00:04:37,184


151
00:04:37,184 --> 00:04:39,940


152
00:04:40,784 --> 00:04:42,908
저는 language와 vision 에 좀 더 집중하고 있습니다.

153
00:04:41,184 --> 00:04:43,308


154
00:04:42,908 --> 00:04:44,500
Lab에서 여러 연구를 진행해 오고 있습니다.

155
00:04:43,308 --> 00:04:44,900


156
00:04:44,500 --> 00:04:49,375
그 외에도 Lab에서는 신경과학과
인지과학과 같은 분야도 연구합니다.

157
00:04:44,900 --> 00:04:46,658


158
00:04:46,658 --> 00:04:48,525


159
00:04:48,525 --> 00:04:49,775


160
00:04:52,141 --> 00:04:57,157
아마 이 수업이 Stanford의 다른 수업과 
어떤 연관성이 있는지 궁금하실 것입니다.

161
00:04:52,541 --> 00:04:54,404


162
00:04:54,404 --> 00:04:57,557


163
00:04:57,157 --> 00:05:02,448
이 수업은 여러분이 컴퓨터비전의 기초 개론을
알고 있다고 가정하고 진행합니다.

164
00:04:57,557 --> 00:05:01,408


165
00:05:01,408 --> 00:05:02,848


166
00:05:02,448 --> 00:05:06,526
그러니 만약 여러분이 학부생이거나, 또는
컴퓨터 비전을 한번도 접해보지 못했다면

167
00:05:02,848 --> 00:05:04,787


168
00:05:04,787 --> 00:05:06,926


169
00:05:06,526 --> 00:05:13,829
아마도 여러분은 Fei-Fei 와 Juan Carlos Niebles이 금년
초에 개설한 CS131을 수강했어야만 했습니다.

170
00:05:06,926 --> 00:05:09,698


171
00:05:09,698 --> 00:05:14,229


172
00:05:13,829 --> 00:05:24,525
딥러닝과 자연어 처리의 관계에 관한 Chris Mannin 와
Richard Socher의 수업이 지난 학기에 있었습니다.

173
00:05:14,229 --> 00:05:17,361


174
00:05:17,361 --> 00:05:20,836


175
00:05:20,836 --> 00:05:22,705


176
00:05:22,705 --> 00:05:24,925


177
00:05:24,525 --> 00:05:28,195
아마 많은 분들이 지난 학기에 그 수업을
들었으리라 생각되는데요

178
00:05:24,925 --> 00:05:27,512


179
00:05:27,512 --> 00:05:28,595


180
00:05:31,082 --> 00:05:33,385
이 강의가 그 수업이랑 겹치는 부분이 있을 것입니다.

181
00:05:31,482 --> 00:05:33,785


182
00:05:33,385 --> 00:05:40,044
하지만 우리는 컴퓨터비전이라는 측면에서
좀더 초점을 맞추고 있습니다.

183
00:05:33,785 --> 00:05:35,769


184
00:05:35,769 --> 00:05:38,861


185
00:05:38,861 --> 00:05:40,444


186
00:05:40,961 --> 00:05:46,978
또한  Silvio Savarese 교수님이 이번 학기에
CS231a를 강의하고 계십니다.

187
00:05:41,361 --> 00:05:43,078


188
00:05:43,078 --> 00:05:47,378


189
00:05:46,978 --> 00:05:53,610
그리고 이 CS231a는 컴퓨터 비전을 둘러싼
좀 더 큼지막한 분야들에 초점을 맞추고 있습니다.

190
00:05:47,378 --> 00:05:52,306


191
00:05:52,306 --> 00:05:54,010


192
00:05:53,610 --> 00:06:03,413
3D reconstruction, 로봇 비전과 같은 것을 다루며,
지금 이 강의와 비교하면 좀 더 다루는 범위가 광범위합니다.

193
00:05:54,010 --> 00:05:57,569


194
00:05:57,569 --> 00:05:59,896


195
00:05:59,896 --> 00:06:01,412


196
00:06:01,412 --> 00:06:03,813


197
00:06:03,413 --> 00:06:13,386
그리고 지금 이 강의 CS231n은 뉴럴네트워크나 특히 CNN과
관련 세부적인 분야에 초점을 맞추고 있습니다.

198
00:06:03,813 --> 00:06:06,647


199
00:06:06,647 --> 00:06:09,358


200
00:06:09,358 --> 00:06:11,922


201
00:06:11,922 --> 00:06:13,786


202
00:06:13,386 --> 00:06:15,828
그리고 이런 알고리즘은 다양한
시각인식 테스크에(viisual recognition task)에 사용됩니다.

203
00:06:13,786 --> 00:06:16,228


204
00:06:15,828 --> 00:06:18,778
물론 세미나 수업도 진행할 예정입니다.

205
00:06:16,228 --> 00:06:17,725


206
00:06:17,725 --> 00:06:19,178


207
00:06:18,778 --> 00:06:27,467
세미나 일정이 매년 변하기 때문에 자세한 사항은
강의계획서와 수업시간표를 확인하시길 바랍니다.

208
00:06:19,178 --> 00:06:21,154


209
00:06:21,154 --> 00:06:24,631


210
00:06:24,631 --> 00:06:27,867


211
00:06:27,467 --> 00:06:31,272
보통 첫 수업은 Fei-Fei Li 교수님이 진행하시지만

212
00:06:27,867 --> 00:06:29,914


213
00:06:29,914 --> 00:06:31,672


214
00:06:31,272 --> 00:06:33,774
안타깝게도, 오늘 오실 수 없었습니다.

215
00:06:31,672 --> 00:06:34,174


216
00:06:33,774 --> 00:06:38,063
대신, Fei Fei 교수님이 없는 이번 수업을 위해
다른 방법을 준비하였 습니다.

217
00:06:34,174 --> 00:06:36,439


218
00:06:36,439 --> 00:06:38,463


219
00:06:38,063 --> 00:06:44,372
교수님께서 Computer Vision의 역사를 소개하는
오디오를 녹음하셨습니다.

220
00:06:38,463 --> 00:06:41,996


221
00:06:41,996 --> 00:06:44,772


222
00:06:44,372 --> 00:06:47,829
이 수업은 컴퓨터비전 수업이기 때문에

223
00:06:44,772 --> 00:06:48,229


224
00:06:47,829 --> 00:06:57,600
오늘날의 CNN을 발전시켜 온 기존의 연구에 대한 역사와 흐름을
이해하는 것은 필수적입니다.

225
00:06:48,229 --> 00:06:50,456


226
00:06:50,456 --> 00:06:53,289


227
00:06:53,289 --> 00:06:55,183


228
00:06:55,183 --> 00:06:58,000


229
00:06:58,100 --> 00:06:59,600
가상의 Fei Fei 교수님을 소개하겠습니다.

230
00:06:58,500 --> 00:07:00,000


231
00:06:59,998 --> 00:07:01,515
[웃음]

232
00:07:00,398 --> 00:07:01,915


233
00:07:01,515 --> 00:07:05,100
여러분께 컴퓨터비전의 역사에 대해
간략히 소개해 주실 것입니다.

234
00:07:01,915 --> 00:07:03,800


235
00:07:04,000 --> 00:07:05,500


236
00:07:08,210 --> 00:07:20,220
자, 우선 오늘의 주제에 관해서부터 시작해 봅시다. 두 주제가 있는데,
하나는 컴퓨터비전의 역사이고, 또 하나는 이번 CS231n 개요입니다.

237
00:07:08,610 --> 00:07:15,309


238
00:07:15,309 --> 00:07:20,620


239
00:07:20,220 --> 00:07:35,700
자 그럼 비전과 컴퓨터 비전이 언제, 어디에서 비롯됬고, 그리고 우리는 
현재  어디쯤에 있는지에 대해서 알아 보도록 하겠습니다.

240
00:07:20,620 --> 00:07:28,539


241
00:07:28,540 --> 00:07:36,100


242
00:07:35,700 --> 00:07:44,370
비전의 역사는 아주 오래전으로 돌아갑니다.
정확하게는 5억 4천만년 전이죠.

243
00:07:36,100 --> 00:07:44,770


244
00:07:44,370 --> 00:07:50,400
그 시대의 삶은 어떠했을까요?
지구의 대부분은 물이었고,

245
00:07:44,770 --> 00:07:50,800


246
00:07:50,520 --> 00:07:57,900
바다를 떠다니는 일부 생물들만 존재했습니다.

247
00:07:50,920 --> 00:07:58,300


248
00:07:57,900 --> 00:08:03,330
그들의 삶은 단조로웠습니다. 그들은 많이 움직이지 않았고,
눈(eyes)같은건 존재하지 않았습니다.

249
00:07:58,300 --> 00:08:03,730


250
00:08:03,330 --> 00:08:09,240
먹이가 주면에 있으면 잡아먹고
없으면 그저 둥둥 떠있는 것이 다였습니다.

251
00:08:03,730 --> 00:08:09,640


252
00:08:09,240 --> 00:08:16,740
하지만 정말 놀라운 일이 5억 4천만년 전에 벌어졌습니다.

253
00:08:09,640 --> 00:08:17,140


254
00:08:16,740 --> 00:08:33,420
동물 학자들은 화석을 연구하면서 천만년 이라는 아주 짧은 시기동안에
생물 종이 폭발적으로 늘어났다는 것을 발견했습니다.

255
00:08:17,140 --> 00:08:25,509


256
00:08:25,509 --> 00:08:33,820


257
00:08:33,420 --> 00:08:41,100
얼마 없던 종의 수가 수십만이 된 것입니다.
정말 신기한 일이었습니다. 이유가 무엇이었을까요?

258
00:08:33,820 --> 00:08:41,500


259
00:08:41,100 --> 00:08:55,140
많은 가설이 있었지만 여전히 수 년간 풀지못한 숙제였습니다. 
진화 생물학자들은 이를 "진화의 빅뱅" 이라고 불렀습니다.

260
00:08:41,500 --> 00:08:47,920


261
00:08:47,920 --> 00:08:55,540


262
00:08:55,140 --> 00:09:00,899
몇해 전 오스트레일리아의 동물학자인 앤드류 파커는 
화석 연구를 통해 가장 설득력 있는 가설 제안하였습니다.

263
00:08:55,540 --> 00:09:01,299


264
00:09:00,899 --> 00:09:18,910
그는 약 5억 4천만 년 전, 최초의 눈(eyes)이 생겨났다는
것을 발견했습니다. 비젼(시각)의 탄생이

265
00:09:01,299 --> 00:09:07,030


266
00:09:07,030 --> 00:09:19,310


267
00:09:18,910 --> 00:09:26,210
폭발적인 종 분화의 시기를 촉발시킨 것입니다. 생물들은
갑자기 볼 수 있게 되었습니다. 볼 수 있다면, 삶이라는 것은

268
00:09:19,310 --> 00:09:26,610


269
00:09:26,210 --> 00:09:32,180
훨씬 더 능동적이됩니다. 일부 포식자들은 먹이를 찾아다니고,

270
00:09:26,610 --> 00:09:32,580


271
00:09:32,180 --> 00:09:39,580
먹이들은 포식자로부터 달아나야만 했습니다.
그래서 비전의 도래는

272
00:09:32,580 --> 00:09:39,980


273
00:09:39,580 --> 00:09:46,460
진화적 군비경쟁을 촉발시켰고, 생물들은
한 종으로써 살아남기 위해서 빠르게 진화해야 했습니다.

274
00:09:39,980 --> 00:09:46,860


275
00:09:46,460 --> 00:09:54,470
이것이 비전의 시작이었습니다.
5억 4천만년 후,

276
00:09:46,860 --> 00:09:54,870


277
00:09:54,470 --> 00:10:00,980
비전은 거의 모든 동물, 특히 지능을 가진 동물들의

278
00:09:54,870 --> 00:10:01,380


279
00:10:00,980 --> 00:10:09,260
가장 큰 감각 체계로 발전되어 왔습니다.
우리 인간은 대뇌 피질의 50% 가량의 뉴런이

280
00:10:01,380 --> 00:10:09,660


281
00:10:09,260 --> 00:10:15,050
시각처리를 관여합니다.
이는 가장 큰 감각체계이며,

282
00:10:09,660 --> 00:10:15,450


283
00:10:15,050 --> 00:10:22,190
우리가 생존하고, 일을 하고,
움직이고, 어떤 것들을  다루고,

284
00:10:15,450 --> 00:10:22,590


285
00:10:22,190 --> 00:10:29,330
의사소통하고, 오락을 즐기는 등 많은 것들을 가능하게 해줍니다.
비전은 동물들에게 중요하며,

286
00:10:22,590 --> 00:10:29,730


287
00:10:29,330 --> 00:10:38,530
특히 지능을 가진 동물들에게 정말 중요합니다.
지금까지는 생물학적 비전의

288
00:10:29,730 --> 00:10:38,930


289
00:10:38,530 --> 00:10:47,929
 짧은 줄거리였습니다만, 그렇다면 인간이 만든 공학적 비전인
카메라의 역사는 어떨까요?

290
00:10:38,930 --> 00:10:48,329


291
00:10:47,929 --> 00:10:56,050
오늘날 우리가 알고있는 초창기의 카메라는 ,

292
00:10:48,329 --> 00:10:56,450


293
00:10:56,050 --> 00:11:04,010
1600년대, 르네상스 시대의 카메라인 obscura입니다.

294
00:10:56,450 --> 00:11:04,410


295
00:11:04,010 --> 00:11:13,330
이 카메라는 핀홀 카메라 이론을 기반으로한 카메라입니다.

296
00:11:04,410 --> 00:11:13,730


297
00:11:13,330 --> 00:11:20,990
Obscura는 생물학적으로 발전한 초기의 눈과 상당히 유사합니다.
빛을 모아주는 구멍이 하나 있고,

298
00:11:13,730 --> 00:11:21,390


299
00:11:20,990 --> 00:11:27,620
카메라 뒷편의 평평한 면은 정보를 모으고

300
00:11:21,390 --> 00:11:28,020


301
00:11:27,620 --> 00:11:36,160
이미지를 투영합니다. 카메라가 진화하면서,
오늘날 우리는 어디에서든 카메라를 가지고 있습니다.

302
00:11:28,020 --> 00:11:36,560


303
00:11:36,160 --> 00:11:40,510
카메라는 스마트폰 카메라나 다른 여러 기기에 이르기 까지
사람들이 사용하는 가장 인기있는 센서중 하나가 되었습니다.

304
00:11:36,560 --> 00:11:40,910


305
00:11:40,510 --> 00:11:56,110
그동안에, 생물학자들은 비전의 매카니즘에 대해 연구하기 시작했습니다.
인간과 동물의 비전에 대한 가장 영향력있었을 뿐만 아니라,

306
00:11:40,910 --> 00:11:49,040


307
00:11:49,040 --> 00:11:56,510


308
00:11:56,110 --> 00:12:10,450
컴퓨터 비전에도 영감을 줬던 한 연구가 50, 60년대에 전기생리학을 이용해
 Hubel과 Wiesel에 의해 이루어졌습니다.

309
00:11:56,510 --> 00:12:02,690


310
00:12:02,690 --> 00:12:10,850


311
00:12:10,450 --> 00:12:17,770
그들이 묻고싶었던 질문은 바로
"포유류의 시각적 처리 메커니즘은 무엇일까?" 였습니다.

312
00:12:10,850 --> 00:12:18,170


313
00:12:17,770 --> 00:12:26,200
그래서 그들은 고양이의 뇌를 연구하기로 하였습니다.

314
00:12:18,170 --> 00:12:26,600


315
00:12:26,200 --> 00:12:31,690
시각처리의 관점으로 봤을때
고양이의 뇌는 인간과 비슷합니다. 그들이 한 일은

316
00:12:26,600 --> 00:12:32,090


317
00:12:31,690 --> 00:12:45,430
고양이 두뇌의 뒷쪽에 몇 개의 전극을 꽂아 두는 것이었는데, 그곳엔
"일차 시각 피질" 영역이 위치해 있는 곳입니다.

318
00:12:32,090 --> 00:12:37,490


319
00:12:37,490 --> 00:12:45,830


320
00:12:45,430 --> 00:12:52,570
그들은 어떤 자극이 일차 시각 피질에 있는 뉴런들을 격렬하게
반응하게 만드는지를 관찰하였습니다.

321
00:12:45,830 --> 00:12:52,970


322
00:12:52,570 --> 00:12:59,980
그들이 배운 것은 일차 시각 피질에는
많은 종류의 세포가 존재한다는 것입니다.

323
00:12:52,970 --> 00:13:00,380


324
00:12:59,980 --> 00:13:11,680
그중 가장 중요한 세포중 하나는 아주 단순한 세포인데, 그 세포들은
edges가 특정 방향으로 움직일때, 그것에 반응했습니다.

325
00:13:00,380 --> 00:13:05,630


326
00:13:05,630 --> 00:13:12,080


327
00:13:11,680 --> 00:13:25,660
물론 더 복잡한 세포들도 있습니다만, 그들이 주된 발견은
시각 처리가 (콜록) 처음에는 단순한 구조로 시작되며,

328
00:13:12,080 --> 00:13:18,410


329
00:13:18,410 --> 00:13:26,060


330
00:13:25,660 --> 00:13:38,160
그리고 정보가 시각적 처리 통로를 거침에 따라
시각 정보의 복잡도가 점점 올라간다는 것입니다.

331
00:13:26,060 --> 00:13:32,210


332
00:13:32,210 --> 00:13:38,560


333
00:13:38,160 --> 00:13:45,880
복잡한 시각 정보를 제대로 인식할 수 있을때 까지 말이죠.

334
00:13:38,560 --> 00:13:46,280


335
00:13:45,880 --> 00:13:54,670
컴퓨터비전의 역사는 60 년대 초반부터 시작됩니다.
Block World는 Larry Roberts에 의해 발간된

336
00:13:46,280 --> 00:13:55,070


337
00:13:54,670 --> 00:14:06,850
일련의 연구인데, 아마도 컴퓨터비전 분야에서의 최초의
박사 학위 논문으로 널리 알려져 있습니다.

338
00:13:55,070 --> 00:14:00,410


339
00:14:00,410 --> 00:14:07,250


340
00:14:06,850 --> 00:14:13,450
이 연구에서는 눈에 보이는 사물들을
기하학적 모양으로 단순화시켰습니다.

341
00:14:07,250 --> 00:14:13,850


342
00:14:13,450 --> 00:14:23,019
그 목표는 우리의 눈에 보이는 세계를 인식해 내고,
그것들이 어떻게 생겼는지는 재현해 내려는 것이었습니다.

343
00:14:13,850 --> 00:14:23,419


344
00:14:23,019 --> 00:14:31,150
1966년에,  MIT의 여름 프로젝트인, 지금은 아주 유명하죠
"The Summer Vision Project" 가 있었습니다.

345
00:14:23,419 --> 00:14:31,550


346
00:14:31,150 --> 00:14:38,040
이 여름 비전 프로젝트의 목표는, 제가 읽어드리겠습니다.
"목표는 시각 시스템의 상당 부분을 구현해 내기 위해서,

347
00:14:31,550 --> 00:14:38,440


348
00:14:38,040 --> 00:14:43,840
우리의 summer workers 를 아주 효과적으로 사용하려는 시도."
였습니다.

349
00:14:38,440 --> 00:14:44,240


350
00:14:43,840 --> 00:14:47,380
다시 말해 그들의 목표는 바로 그 여름 안에 대부분의
시각 체계를 구현해 내려는 것이었습니다.

351
00:14:44,240 --> 00:14:47,780


352
00:14:47,380 --> 00:14:54,190
그것은 아주 야심 찬 목표였습니다.
그로부터 50년이 지났습니다.

353
00:14:47,780 --> 00:14:54,590


354
00:14:54,190 --> 00:15:01,840
컴퓨터비전 이라는 분야가 한 여름 프로젝트에서 피어나서는,

355
00:14:54,590 --> 00:15:02,240


356
00:15:01,840 --> 00:15:13,540
현재 전 세계 수천 명의 연구자들이 여전히 비전의
가장 근본적인 문제들에 대해 연구를 하고 있습니다.

357
00:15:02,240 --> 00:15:07,610


358
00:15:07,610 --> 00:15:13,940


359
00:15:13,540 --> 00:15:20,980
하지만, 비전은 인공지능 분야에서 가장 중요하면서도 가장 빠르게
성장하는 분야중에 하나입니다.

360
00:15:13,940 --> 00:15:21,380


361
00:15:20,980 --> 00:15:27,010
우리가 경의를 표해야 할 또 다른 한 사람이 있습니다.
그는 바로 David Marr입니다.

362
00:15:21,380 --> 00:15:27,410


363
00:15:27,010 --> 00:15:34,150
David Marr은 MIT의 비전 과학자였으며,
그는 70년대 후기에, 아주 영향력이 큰 책 하나를 저술했는데

364
00:15:27,410 --> 00:15:34,550


365
00:15:34,150 --> 00:15:47,800
이 책은 그가 비전을 무엇이라 생각하는지, 그리고 어떤 방향으로 컴퓨터
비전이 나아가야 하느지, 그리고 컴퓨터가 비전을 인식하게 하기 위해

366
00:15:34,550 --> 00:15:41,510


367
00:15:41,510 --> 00:15:48,200


368
00:15:47,800 --> 00:15:56,620
어떤 방향으로 알고리즘을 개발해야 하는지에 대한 책이었습니다.

369
00:15:48,200 --> 00:15:57,020


370
00:15:56,620 --> 00:16:10,239
그는 책에서, 우리가 받아드린 "이미지"를
 "최종적인 full3D 표현"으로 만드려면,

371
00:15:57,020 --> 00:16:02,440


372
00:16:02,440 --> 00:16:10,639


373
00:16:10,240 --> 00:16:15,960
여러 과정을 거쳐야만 한다고 주장했습니다.
첫 번째 과정은 그가 "Primal Sketch" 라 부르는 것입니다.

374
00:16:10,640 --> 00:16:16,360


375
00:16:15,960 --> 00:16:22,660
이 과정은 주로 가장자리(edges), 막대(bars),
끝(ends), 가상의 선(virtual lines) ,

376
00:16:16,360 --> 00:16:23,060


377
00:16:22,660 --> 00:16:28,570
커브(curves), 경계(boundaries)가 표현되는 과정이며,
이 과정은 신경과학자들에 의해 큰 영감을 받은 것이었습니다.

378
00:16:23,060 --> 00:16:28,970


379
00:16:28,570 --> 00:16:41,020
Hubel과 Wiesel은 시각처리의 초기단계에서 경계와 같은 단순한 구조와
밀접한 관계가 있다고 한 적이 있었죠.

380
00:16:28,970 --> 00:16:34,639


381
00:16:34,639 --> 00:16:41,420


382
00:16:41,020 --> 00:16:45,460
경계와 커브 이후의 다음단계는 바로, 그가 부르길

383
00:16:41,420 --> 00:16:45,860


384
00:16:45,460 --> 00:16:51,900
"two-and-a-half d sketch"이며, 여기에서는
시각장면을 구성하는 표면(surfaces),

385
00:16:45,860 --> 00:16:52,300


386
00:16:51,900 --> 00:16:58,440
깊이정보, 레이어, 불연속 점과 같은 것들을 종합합니다.

387
00:16:52,300 --> 00:16:58,840


388
00:16:58,450 --> 00:17:04,530
그리고 결국에 그 모든 것을 한데 모아서
surface and volumetric primives의 형태의,

389
00:16:58,850 --> 00:17:04,930


390
00:17:04,530 --> 00:17:11,179
계층적으로 조직화된 최종적인 3D 모델을 만들어 냅니다.

391
00:17:04,930 --> 00:17:11,579


392
00:17:11,179 --> 00:17:20,319
그리고 이런 방식은 는 "비전이 무엇인가" 라는 것에 대한 아주
이상적인 사고과정 이었습니다. 그리고 이런 방식의 사고방식은

393
00:17:11,579 --> 00:17:20,719


394
00:17:20,320 --> 00:17:25,390
실제로 수십 년간 컴퓨터비전을 지배해 왔으며

395
00:17:20,720 --> 00:17:25,790


396
00:17:25,390 --> 00:17:31,540
학생들이 비전이라는 분야에 처음 입문하고,
"어떻게 시각정보를 분석할 수 있을까"  라는 질문에

397
00:17:25,790 --> 00:17:31,940


398
00:17:31,540 --> 00:17:37,830
생각해 볼 수 있는 매우 직관적인 방법입니다.

399
00:17:31,940 --> 00:17:38,230


400
00:17:38,910 --> 00:17:47,980
또 다른 아주 중요한 일련의 연구가
70년대에 진행되었습니다. 사람들은,

401
00:17:39,310 --> 00:17:48,380


402
00:17:47,980 --> 00:17:54,760
"우리가 어떻게 단순한 블록 세계를 뛰어 넘어서,

403
00:17:48,380 --> 00:17:55,160


404
00:17:54,760 --> 00:18:02,109
실제 세계를 인식하고 표현할 수 있을까?" 라는 질문을 하기 시작했습니다.
70 년대를 생각해보면,

405
00:17:55,160 --> 00:18:02,509


406
00:18:02,109 --> 00:18:07,510
그떄는 사용할 수있는 데이터가 거의 없었습니다.
컴퓨터가 정말 느렸고,

407
00:18:02,509 --> 00:18:07,910


408
00:18:07,510 --> 00:18:19,770
심지어 PC가 흔지하지도 않았지만,  컴퓨터 과학자들은 우리가 어떻게
대상을 인식하고 표현할 수 있는지에 대해 생각하기 시작했습니다.

409
00:18:07,910 --> 00:18:13,360


410
00:18:13,360 --> 00:18:20,170


411
00:18:19,770 --> 00:18:26,249
그래서 Palo Alto의 Stanford와 SRI의 두 그룹의 과학자들이
서로 비슷한 아이디어를 제안했습니다.

412
00:18:20,170 --> 00:18:26,649


413
00:18:26,249 --> 00:18:32,340
 하나는 "commonized cylinde" 라 불리며,
다른 하나는 "pictorial structure"라고 불립니다.

414
00:18:26,649 --> 00:18:32,740


415
00:18:32,340 --> 00:18:39,660
기본 개념은 "모든 객체는 단순한
기하학적 형태로 이루어진다"는 것입니다.

416
00:18:32,740 --> 00:18:40,060


417
00:18:39,660 --> 00:18:45,110
예를들어, 사람은 원통모양을 조합해서 만들 수 있습니다.
(왼쪽 그림)

418
00:18:40,060 --> 00:18:45,510


419
00:18:45,110 --> 00:18:55,679
또는 사람을 "주요 부위"와 "부위 사이의 관절로" 로
표현할 수도 있을 것입니다.  (오른쪽 그림)

420
00:18:45,510 --> 00:18:51,339


421
00:18:51,339 --> 00:18:56,079


422
00:18:55,679 --> 00:19:10,740
두 표현 둘 다, 더 단순한 모양과 기하학적인 배치를 이용해서
객체의 복잡한 구조를 단순하게 만드는 방법입니다.

423
00:18:56,079 --> 00:19:03,880


424
00:19:03,880 --> 00:19:11,140


425
00:19:10,740 --> 00:19:18,820
이러한 연구는 몇 년 동안의 연구에 꽤 많은 영향을 주었습니다.

426
00:19:11,140 --> 00:19:19,220


427
00:19:18,820 --> 00:19:33,299
또 다른 예로, 80년대 David Lowe는 어떻게 단순한 구조를 이용해
실제 세계를 재구성하거나 인식할수 있을지를 고민했습니다.

428
00:19:19,220 --> 00:19:27,630


429
00:19:27,630 --> 00:19:33,699


430
00:19:33,299 --> 00:19:43,040
David Lowe는 이 연구에서 면도기를 인식하기 위해서

431
00:19:33,699 --> 00:19:43,440


432
00:19:43,040 --> 00:19:50,460
선(lines)과 경계(edges) 그리고 대게는
직선(straight lines) 그리고 그것들의 조합을 구성했습니다.

433
00:19:43,440 --> 00:19:50,860


434
00:19:50,460 --> 00:20:00,740
60, 70 그리고 80년대에 컴퓨터 비전으로 할 수 있는게 뭘까
에 대서 생각해 보려는 많은 노력이 있었지만,

435
00:19:50,860 --> 00:20:01,140


436
00:20:00,749 --> 00:20:10,010
솔직히 객체를 인식하는 문제를 푸는것은 너무 어려웠습니다.

437
00:20:01,149 --> 00:20:10,410


438
00:20:10,010 --> 00:20:17,580
지금까지 제가 보여드린 모든 연구들이
매우 대담했고 야망을 가진 시도였지만,

439
00:20:10,410 --> 00:20:17,980


440
00:20:17,580 --> 00:20:23,760
그들은 단순한 수준(toy example)에 불과했습니다.

441
00:20:17,980 --> 00:20:24,160


442
00:20:23,760 --> 00:20:30,419
현실 세계에서 제대로 동작할 수 있는지의 여부를 생각해본다면
많은 진보는 이루어지지 않았습니다.

443
00:20:24,160 --> 00:20:30,819


444
00:20:30,419 --> 00:20:37,619
그래서 사람들이

445
00:20:30,819 --> 00:20:38,019


446
00:20:37,619 --> 00:20:43,309
우리가 비전 문제를 푸는데 있어 뭐를 잘못했을까 를 고민하다가
와 한 질문이 떠올랐습니다.

447
00:20:38,019 --> 00:20:43,709


448
00:20:43,309 --> 00:20:49,800
객체 인식이 너무 어렵다면, 우선 객체를
분할(segmentation)을 해야하는 것이 아닌가 라는 것이었습니다.

449
00:20:43,709 --> 00:20:50,200


450
00:20:49,800 --> 00:20:58,360
객체 분할은 이미지의 픽셀을 의미있는 지역으로
군집화 하는 것입니다.

451
00:20:50,200 --> 00:20:58,760


452
00:20:58,360 --> 00:21:03,480
군집화된 픽셀중에 정확히 어떤것이 사람인지 모를수도 있지만

453
00:20:58,760 --> 00:21:03,880


454
00:21:03,480 --> 00:21:09,740
우리는 배경으로부터 사람이 속한 픽셀을 추출할 수 있었습니다.

455
00:21:03,880 --> 00:21:10,140


456
00:21:09,740 --> 00:21:14,939
이것을 우리는 영상 분할이라고 합니다.
영상 분할문제를 다룬 아주 중요한 연구가 있었는데.

457
00:21:10,140 --> 00:21:15,339


458
00:21:14,939 --> 00:21:21,359
이 연구는 Kerkeley의  Jitendra Malik와
그의 제자인 Jianbo Shi 연구였습니다.

459
00:21:15,339 --> 00:21:21,759


460
00:21:21,360 --> 00:21:29,480
이 연구는 영상 분할 문제를 풀기 위해
그래프 이론을 이용하였습니다.

461
00:21:21,760 --> 00:21:29,880


462
00:21:29,480 --> 00:21:39,200
그리고, 컴퓨터 비전의 다른 문제들보다
좀더 앞서고 있던 분야가 있는데

463
00:21:29,880 --> 00:21:39,600


464
00:21:39,210 --> 00:21:45,450
그것은 바로 얼굴인식 이었습니다.
얼굴은 인간에게 있어서 가장 중요한 부분중 하나입니다.

465
00:21:39,610 --> 00:21:45,850


466
00:21:45,450 --> 00:21:51,379
어쩌면 가장 중요한 부분일수도 있겠습니다.
1999에서 2000년대 쯤에는,

467
00:21:45,850 --> 00:21:51,779


468
00:21:51,379 --> 00:21:58,679
기계학습, 특히 통계적 기계학습 테크닉이

469
00:21:51,779 --> 00:21:59,079


470
00:21:58,679 --> 00:22:04,820
탄력을 얻기 시작했습니다. 그런 기술들 중에는

471
00:21:59,079 --> 00:22:05,220


472
00:22:04,820 --> 00:22:11,220
Support Vector Machine이나 Boosting,
Graphical models 그리고 초기의 신경망이 있습니다.

473
00:22:05,220 --> 00:22:11,620


474
00:22:11,220 --> 00:22:18,049
그 중 한 연구가 아주 큰 기여를 했었는데, 그것은 바로

475
00:22:11,620 --> 00:22:18,449


476
00:22:18,049 --> 00:22:24,539
Paul Viola와 Michael Jones이
AdaBoost 알고리즘을 사용하여 실시간 얼굴인식에 성공한 것입니다.

477
00:22:18,449 --> 00:22:24,939


478
00:22:24,539 --> 00:22:31,379
이 연구는 아주 대단한 연구였습니다.
이 연구는 2001년에 시행되었고,

479
00:22:24,939 --> 00:22:31,779


480
00:22:31,379 --> 00:22:36,330
 컴퓨터 칩은 여전히 엄청 느렸지만,
그들은 얼굴 인식 알고리즘은

481
00:22:31,779 --> 00:22:36,730


482
00:22:36,330 --> 00:22:42,150
영상에서 실시간과 가깝게(near-real-time)
수행할 수 있었고,이 논문이 발표되고 5년이

483
00:22:36,730 --> 00:22:42,550


484
00:22:42,150 --> 00:22:58,560
지난 후인 2006년에 Fujifilm은 실시간 얼굴인식이 가능한
최초의 디지털 카메라를 선보였습니다.

485
00:22:42,550 --> 00:22:50,800


486
00:22:50,800 --> 00:22:58,960


487
00:22:58,560 --> 00:23:05,560
이 사례는는 기초 과학연구의 성과가 실제 세상의 응용으로
가장 빨리 전달된 사례라고 알 수 있겠습니다.

488
00:22:58,960 --> 00:23:05,960


489
00:23:05,560 --> 00:23:13,520
이제 우리가 계속 알아봤던, "어떻게 해야 객체를 더 잘
인식할 것인가?"에 대한 문제로 돌아가보면,

490
00:23:05,960 --> 00:23:13,920


491
00:23:13,530 --> 00:23:22,320
90년대 후반부터 2010년도 까지
가장 영향력 있는 방식은 바로

492
00:23:13,930 --> 00:23:22,720


493
00:23:22,320 --> 00:23:30,900
특징 기반 객체 인식 알고리즘 이었습니다.
이때 나온 가장 중대한 연구중 하나는 바로

494
00:23:22,720 --> 00:23:31,300


495
00:23:30,900 --> 00:23:39,270
David Lowe의 SIFT feature입니다.
그의 아이디어는 전체 객체를

496
00:23:31,300 --> 00:23:39,670


497
00:23:39,270 --> 00:23:44,460
 예를들어 여기 정지표지판이 있습니다. 이 정지 표지판을
다른 정지 표지판에 완전히 매칭시키는 것은 너무 어렵다는 것입니다.

498
00:23:39,670 --> 00:23:44,860


499
00:23:44,460 --> 00:23:50,660
카메라 앵글이 변할수도 있고,

500
00:23:44,860 --> 00:23:51,060


501
00:23:50,660 --> 00:23:56,810
겹침, 화각, 빛,  또는 객체 자체가 얼마든지
변할 수 있기 때문입니다.

502
00:23:51,060 --> 00:23:57,210


503
00:23:56,810 --> 00:24:04,280
그러나 객체의 일부가 지닌 일부 특징들은 이런 다양한 변화에

504
00:23:57,210 --> 00:24:04,680


505
00:24:04,280 --> 00:24:14,600
좀 더 강인하고 불변하다는 점을 알 수 있었습니다.
그리하여 객체인식의 과제는

506
00:24:04,680 --> 00:24:15,000


507
00:24:14,610 --> 00:24:21,210
객체에서 그런 중요한 특징을 찾아내고,

508
00:24:15,010 --> 00:24:21,610


509
00:24:21,210 --> 00:24:28,169
그 다음 비슷한 객체에 그 특징을 매칭시키는 것으로 전환되었습니다.
그것은 전체 객체의 매턴을 매칭하는 것 보다 쉬는 일이었습니다.

510
00:24:21,610 --> 00:24:28,569


511
00:24:28,169 --> 00:24:35,670
이 그림은 그 논문에서 가져온 것입니다.

512
00:24:28,569 --> 00:24:36,070


513
00:24:35,670 --> 00:24:41,660
여기 에서는 한 정지표시판에서 추출한 몇 안되는 SIFT 특징이

514
00:24:36,070 --> 00:24:42,060


515
00:24:41,660 --> 00:24:49,040
또 다른 정지표시반의 SIFT 특징을 식별하고 매칭합니다.

516
00:24:42,060 --> 00:24:49,440


517
00:24:50,730 --> 00:24:58,930
이러한 영상 내 특징 이라는 구성 요소를 사용하게 되면서

518
00:24:51,130 --> 00:24:59,330


519
00:24:58,930 --> 00:25:04,380
컴퓨터 비전 분야는 다른 한걸음을 내딛을 수 있게 되었고,
전체적인 장면을 인식하기에 이르렀습니다.

520
00:24:59,330 --> 00:25:04,780


521
00:25:04,380 --> 00:25:11,920
여기 한 예가 있는데, Spatial Pyramid Matching 이라
불리는 알고리즘입니다.

522
00:25:04,780 --> 00:25:12,320


523
00:25:11,920 --> 00:25:18,220
아이디어는 우리가 어떤 특징을 잘 뽑는다면

524
00:25:12,320 --> 00:25:18,620


525
00:25:18,220 --> 00:25:23,350
그것이 우리에게 어떤 일종의 "단서"를 가져다 줄 수 있다는 것이었습니다.
이 이미지가 풍경이미지인지,

526
00:25:18,620 --> 00:25:23,750


527
00:25:23,350 --> 00:25:36,730
부엌인지, 또는 고속도로인지 하는 것을 말이죠.
이 연구는 이미지내 여러 부분과, 여러 해상도에서 뽑은 특징을

528
00:25:23,750 --> 00:25:31,580


529
00:25:31,580 --> 00:25:37,130


530
00:25:36,730 --> 00:25:44,380
하나의 특징 기술자 안에 넣어놓고,
마지막에 Support Vector Algorithm을 적용합니다.

531
00:25:37,130 --> 00:25:44,780


532
00:25:44,380 --> 00:25:53,530
이와 유사한 방식의 연구가 사람인식에도
탄력을 주게 됩니다.

533
00:25:44,780 --> 00:25:53,930


534
00:25:53,530 --> 00:26:02,590
어떻게 하면 특징들을 잘 조합할 수 있는지에 관한 것들이죠,
사람인식에 관련 많은 연구들이 있습니다.

535
00:25:53,930 --> 00:26:02,990


536
00:26:02,590 --> 00:26:10,090
이런 연구들은 어떻게 해야 사람의 몸은 좀더 현실적으로 모델링하여
사람을 인식할수 있을지에 관한 것이였습니다.

537
00:26:02,990 --> 00:26:10,490


538
00:26:10,090 --> 00:26:15,310
그중 한 연구가 바로 Histogram Of Gradients 입니다.
또다른 하나는

539
00:26:10,490 --> 00:26:15,710


540
00:26:15,310 --> 00:26:26,370
Deformable Part Models 입니다. 우리가
60년대. 70년대, 80년대를 거쳐오면서

541
00:26:15,710 --> 00:26:26,770


542
00:26:26,370 --> 00:26:33,760
21세기의 첫 10년을 맞이하였고
많은 것이 변하고 있었습니다.

543
00:26:26,770 --> 00:26:34,160


544
00:26:33,760 --> 00:26:40,300
사진의 품질은 문제가 되지 않았고,

545
00:26:34,160 --> 00:26:40,700


546
00:26:40,300 --> 00:26:45,280
인터넷의 발전에 힘입어, 디지털 카메라는
더더욱 좋은 실험 데이터를 가져다 줄 수 있었습니다.

547
00:26:40,700 --> 00:26:45,680


548
00:26:45,280 --> 00:26:53,980
2000년대 초에 이뤄낸 결과 중 하나는 바로

549
00:26:45,680 --> 00:26:54,380


550
00:26:53,980 --> 00:27:02,440
컴퓨터 비전 분야가 앞으로 해결해야 할 일련의 문제들이
무엇인지에 대해 어느정도 정의를 내렸다는 것입니다.

551
00:26:54,380 --> 00:27:02,840


552
00:27:02,440 --> 00:27:05,200
물론 해결해야 할 다른 문제들도 많지만,

553
00:27:02,840 --> 00:27:05,600


554
00:27:05,200 --> 00:27:10,720
인식 이라는 문제에서는 이것은 해결해야 할 매우 중요한
문제였습니다. 그것은 바로 객체 인식 입니다.

555
00:27:05,600 --> 00:27:11,120


556
00:27:10,720 --> 00:27:18,550
제가 지금것 객체 인식에 대해 말했지만, 2000년대 초

557
00:27:11,120 --> 00:27:18,950


558
00:27:18,550 --> 00:27:26,200
우리는 Benchmark Dataset을 보유하기 시작했습니다.
객체 인식이 얼마나 진보되었는가를 측정하기 위해서였죠.

559
00:27:18,950 --> 00:27:26,600


560
00:27:26,200 --> 00:27:32,530
가장 유명한 Benchmark Dataset중 하나는 바로

561
00:27:26,600 --> 00:27:32,930


562
00:27:32,530 --> 00:27:41,080
PASCAL Visual Object Challenge(VOC) 입니다.
이 데이터셋은 20가지의 데이터 클래스로 이뤄져 있고

563
00:27:32,930 --> 00:27:41,480


564
00:27:41,080 --> 00:27:48,100
그중 세개가 여기 보이는 것입니다 : 기차, 비행기, 사람

565
00:27:41,480 --> 00:27:48,500


566
00:27:48,100 --> 00:27:57,040
또한 암소, 병, 고양이 등이 있었던 것으로 기억합니다.
데이터셋은 클래스 당 수천 수만개의

567
00:27:48,500 --> 00:27:57,440


568
00:27:57,040 --> 00:28:03,880
이미지들로 구성되어 있었고, 그 분야에서
다양한 집단에서

569
00:27:57,440 --> 00:28:04,280


570
00:28:03,880 --> 00:28:11,350
테스트를 위한 알고리즘을 개발했으며 , 얼마나 우리가 진보했는지를
지켜보았습니다.

571
00:28:04,280 --> 00:28:11,750


572
00:28:11,350 --> 00:28:19,470
여기 2007년부터 2012년도 까지의 표가 있습니다.

573
00:28:11,750 --> 00:28:19,870


574
00:28:19,470 --> 00:28:30,700
20가지의 객체를 감지해내는 성능이 꾸준히 증가했다는 것을 볼 수 있습니다.

575
00:28:19,870 --> 00:28:31,100


576
00:28:30,700 --> 00:28:38,280
많은 진보가 이루어 졌습니다.

577
00:28:31,100 --> 00:28:38,680


578
00:28:38,280 --> 00:28:44,770
그 무렵 Princeton부터 Stanford에 이르는 우리 그룹은
우리 자신들 뿐만 아니라

579
00:28:38,680 --> 00:28:45,170


580
00:28:44,770 --> 00:28:52,930
우리의 분야 전체에게 더 어려운 질문을 던졌습니다.
: 우리는 실세계의 모든, 혹은 대부분의 객체를

581
00:28:45,170 --> 00:28:53,330


582
00:28:52,930 --> 00:28:59,860
인식할 준비가 되었는가? 였습니다.
이런 질문은 한 관찰로 부터 비롯된 것인데,

583
00:28:53,330 --> 00:29:00,260


584
00:28:59,860 --> 00:29:07,570
그것은 기계학습에서 기인했습니다. 거의 대
부분의 기계학습 알고리즘에서 말이죠

585
00:29:00,260 --> 00:29:07,970


586
00:29:07,570 --> 00:29:12,010
이 알고리즘이 Graphical Model이던

587
00:29:07,970 --> 00:29:12,410


588
00:29:12,010 --> 00:29:19,670
SVM이건, AdaBoost던 상관없이 대부분의 기계학습 알고리즘이
트레이닝 과정에서 Overfit을 하는것 같다는 것이었습니다.

589
00:29:12,410 --> 00:29:20,070


590
00:29:19,670 --> 00:29:25,010
이문제의 원인 중 하나는 바로, 시작 데이터가 너무 복잡하다는 것이었습니다.

591
00:29:20,070 --> 00:29:25,410


592
00:29:25,010 --> 00:29:32,300
데이터가 너무 복잡해서, 모델은 고차원의 입력을 받아야 했기 때문에

593
00:29:25,410 --> 00:29:32,700


594
00:29:32,300 --> 00:29:37,159
모델은 fit해야 할 너무나 많은 매개변수를 가져야 했습니다.

595
00:29:32,700 --> 00:29:37,559


596
00:29:37,159 --> 00:29:43,760
그래서 우리가 학습데이터가 충분하지 않은 상황이라면,
Overfiting이 아무 빠르게 일어났고, 일반화를 잘 할 수 없었습니다.

597
00:29:37,559 --> 00:29:44,160


598
00:29:43,760 --> 00:29:52,040
그래서, 우리는 이 세상의 모든 객체를 인식하고 싶었다는 것 그리고

599
00:29:44,160 --> 00:29:52,440


600
00:29:52,040 --> 00:29:57,940
기계학습이  병목인 Overfilting을 극복하게 하려는
것이었습니다.

601
00:29:52,440 --> 00:29:58,340


602
00:29:57,940 --> 00:30:04,220
두가지 동기를 통해서

603
00:29:58,340 --> 00:30:04,620


604
00:30:04,220 --> 00:30:10,740
ImageNet이라는 프로젝트를 시작하였습니다. 가능한 우리가 구할 수 있는
모든 이미지를 가진, 가장 규모가 큰 데이터셋을 만들고 싶었습니다.

605
00:30:04,620 --> 00:30:11,140


606
00:30:10,740 --> 00:30:17,500
그리고 이 데이터셋을 통해 학습 뿐만 아니라
Benchmarking도 할 수 있습니다.

607
00:30:11,140 --> 00:30:17,900


608
00:30:17,510 --> 00:30:22,850
이 프로젝트는 약 3년정도 걸렸습니다.

609
00:30:17,910 --> 00:30:23,250


610
00:30:22,850 --> 00:30:29,930
어려운 일도 많았습니다, 우선 우리는 수십억개의

611
00:30:23,250 --> 00:30:30,330


612
00:30:29,930 --> 00:30:37,220
이미지를 인터넷에서 다운받았고, 사전으로 조직화했습니다.
이 사전은 바로 WordNet 인데,

613
00:30:30,330 --> 00:30:37,620


614
00:30:37,220 --> 00:30:45,370
WordNet에는 수십 수천가지의 객체 클래스가 존재하고,
우리는

615
00:30:37,620 --> 00:30:45,770


616
00:30:45,370 --> 00:30:51,830
Clever Crowd Engineering trick 를 써야 했습니다.
이는 Amazon Mechanical Turk에서 사용하는

617
00:30:45,770 --> 00:30:52,230


618
00:30:51,830 --> 00:31:01,870
이미지의 정렬, 정제, 그리고 각 이미지의 레이블을 제공하는
플랫폼 입니다. 마지막 결과로  ImageNet은

619
00:30:52,230 --> 00:31:02,270


620
00:31:01,870 --> 00:31:10,430
거의 천 5천만 개에서 4천만 개에 달하는 이미지를 보유하게 되었고,
22만개의 클래스 카테고리를 가지게 되었습니다.

621
00:31:02,270 --> 00:31:10,830


622
00:31:10,430 --> 00:31:20,480
정말 거대했고, 아마

623
00:31:10,830 --> 00:31:20,880


624
00:31:20,480 --> 00:31:28,889
그 당시 AI분야에서 만든 가장 큰 데이터셋 이었을 것입니다.
그리고 ImageNet은 객체 인식 알고리즘을

625
00:31:20,880 --> 00:31:29,289


626
00:31:28,889 --> 00:31:35,359
다른 국면으로 접어들게 하였습니다.

627
00:31:29,289 --> 00:31:35,759


628
00:31:35,359 --> 00:31:40,800
특히 중요한점은 어떻게 발전에 대해 Benchmark 하느냐 였습니다.

629
00:31:35,759 --> 00:31:41,200


630
00:31:40,800 --> 00:31:49,019
그래서 2009 년부터 ImageNet 팀은 국제규모의 대회를
주최했습니다.

631
00:31:41,200 --> 00:31:49,419


632
00:31:49,019 --> 00:31:56,909
그 대회는 바로 ILSVRC 입니다.
이 대회를 위해서

633
00:31:49,419 --> 00:31:57,309


634
00:31:56,909 --> 00:32:05,790
1000개의 객체에서 140만개의 test set 이미지를
엄선했습니다.

635
00:31:57,309 --> 00:32:06,190


636
00:32:05,790 --> 00:32:13,229
이 대회는 이미지 분류 문제를 푸는 알고리즘들을
테스트하기 위한 것이였습니다.

637
00:32:06,190 --> 00:32:13,629


638
00:32:13,229 --> 00:32:21,589
여기 예제 사진이 있습니다. 만약 알고리즘이

639
00:32:13,629 --> 00:32:21,989


640
00:32:21,589 --> 00:32:31,859
5개의 후보 레이블을 출력할 수 있고, 5개 중에
정답이 있으면 우리는 성공한 것이라 하였습니다.

641
00:32:21,989 --> 00:32:32,259


642
00:32:31,859 --> 00:32:42,509
여기에 ImageNet Challenge 2010의 결과가 있습니다.

643
00:32:32,259 --> 00:32:42,909


644
00:32:42,509 --> 00:32:49,320
이 그래프는 영상 분류의 결과입니다.

645
00:32:42,909 --> 00:32:49,720


646
00:32:49,320 --> 00:33:00,340
2015년도 까지의 결과이며, x축으로 연도를
y축으로 오류율을 볼 수 있습니다.

647
00:32:49,720 --> 00:33:00,740


648
00:33:00,340 --> 00:33:06,420
좋은 소식은 오류율이 점차 감소한 다는 것입니다.

649
00:33:00,740 --> 00:33:06,820


650
00:33:06,420 --> 00:33:14,969
2012 오류율이 너무 낮아서 사람이 할 수있는 것과 동등합니다.
여기에서의 사람은

651
00:33:06,820 --> 00:33:15,369


652
00:33:14,969 --> 00:33:32,070
Stanford의 한 박사과정(PhD) 학생입니다
이 대회에 참여한 컴퓨터처럼 이 일로 몇 주를 보냈죠.

653
00:33:15,369 --> 00:33:25,359


654
00:33:25,359 --> 00:33:32,470


655
00:33:32,070 --> 00:33:42,710
앞으로 여러분이 이 수업에서 배우게 될테지만 객체 인식에 대한
모든 문제를 해결하진 못했지만, 분명 진전은 있었습니다.

656
00:33:32,470 --> 00:33:39,669


657
00:33:39,669 --> 00:33:43,110


658
00:33:42,710 --> 00:33:50,090
하지만 실 생활에 적용하기 역부족이었던
오류율에서 부터

659
00:33:43,110 --> 00:33:50,490


660
00:33:50,090 --> 00:33:56,000
ImageNet 챌린지에서 인간과 거의 동등한 수준의
오류율로 오기까지는, 불과 몇년뿐지 걸리지 않았습니다.

661
00:33:50,490 --> 00:33:56,400


662
00:33:56,000 --> 00:34:05,240
그리고 이 그래프에서 여러분이 놓쳐서는 안될
특별한 순간이 있습니다.

663
00:33:56,400 --> 00:34:05,640


664
00:34:05,240 --> 00:34:15,319
바로 2012년 입니다. 처음 2년동안은 오류률이
약 25%였습니다만

665
00:34:05,640 --> 00:34:15,719


666
00:34:15,319 --> 00:34:25,249
2012년에는 오류율이 16%로, 거의 10%가량 떨어졌고,

667
00:34:15,719 --> 00:34:25,649


668
00:34:25,250 --> 00:34:32,569
물론 현재가 더 오류율이 낫긴 하지만
2012년도의 오류율 감소는 매우 중요합니다.

669
00:34:25,650 --> 00:34:32,969


670
00:34:32,569 --> 00:34:42,169
2012년도에 우승한 알고리즘은
CNN 모델입니다.

671
00:34:32,969 --> 00:34:42,569


672
00:34:42,170 --> 00:34:49,450
CNN은 그 당시 다른 모든 알고리즘을 능가하고
ImageNet Challenge에서 우승하였습니다.

673
00:34:42,570 --> 00:34:49,850


674
00:34:49,450 --> 00:34:57,800
그리고 CNN이 바로 우리 강의에서 한 학기동안
주목할 바로 그것입니다.

675
00:34:49,850 --> 00:34:58,200


676
00:34:57,800 --> 00:35:05,300
CNN 모델이 무엇인지를 심도싶게 다룰 것입니다.
그리고 CNN의 다른이름은

677
00:34:58,200 --> 00:35:05,700


678
00:35:05,300 --> 00:35:09,970
Deep Learning 이죠,

679
00:35:05,700 --> 00:35:10,370


680
00:35:10,120 --> 00:35:14,930
유명한 이름으로 CNN을 Deep leraning이라고도 불립니다.

681
00:35:10,520 --> 00:35:15,330


682
00:35:14,930 --> 00:35:20,029
이 모델이 무엇인지, 어떤 법칙이 있는지, 어떤 선례가 있는지,
이 모델의 최근 행보는 어떠한지 를 살펴볼 것입니다.

683
00:35:15,330 --> 00:35:20,429


684
00:35:20,029 --> 00:35:26,000
하지만 여기에 역사가 만들어진 곳이 있습니다.

685
00:35:20,429 --> 00:35:26,400


686
00:35:26,000 --> 00:35:32,600
2012년의 CNN 이라는 Deep learning 모델은

687
00:35:26,400 --> 00:35:33,000


688
00:35:32,600 --> 00:35:40,909
컴퓨터비전 분야의 진보를 이뤄냄으로서,
CNN의 훌륭한 역량과 능력을 보여주었습니다.

689
00:35:33,000 --> 00:35:41,309


690
00:35:40,909 --> 00:35:46,970
자연어 처리나 음성 인식과 같은 다른 자매분야들과도
함께 말이죠

691
00:35:41,309 --> 00:35:47,370


692
00:35:46,970 --> 00:35:51,500
소개는 이쯤 해두고,

693
00:35:47,370 --> 00:35:51,900


694
00:35:51,500 --> 00:36:02,100
CS231n의 개괄에 대한 내용을 위해 이번 강의의 나머지를
Justin에게 맡기도록 하겠습니다.

695
00:35:51,900 --> 00:36:00,630


696
00:36:00,630 --> 00:36:02,500


697
00:36:02,600 --> 00:36:04,363
좋습니다 Fei-Fei 교수님 정말 감사합니다.

698
00:36:03,000 --> 00:36:04,763


699
00:36:04,600 --> 00:36:07,758
제가 여기서 이어 받겠습니다.

700
00:36:05,000 --> 00:36:08,158


701
00:36:07,789 --> 00:36:09,510
지금부터는 다른 이야기를 해야겠네요

702
00:36:08,189 --> 00:36:09,910


703
00:36:09,510 --> 00:36:13,677
좀더 이 CS231n 에 대해
이야기해 보겠습니다.

704
00:36:09,910 --> 00:36:14,077


705
00:36:15,036 --> 00:36:18,236
이 수업은 오로지 한가지에
중점을 둘 것입니다

706
00:36:15,436 --> 00:36:18,636


707
00:36:18,236 --> 00:36:20,414
가장 중요하게 다룰 것은

708
00:36:18,636 --> 00:36:20,814


709
00:36:20,414 --> 00:36:22,550
바로 이미지 분류 문제입니다

710
00:36:20,814 --> 00:36:22,950


711
00:36:22,550 --> 00:36:26,637
우리가 방금 전에 ImageNet Challenge
이야기에서 조금은 들었었죠

712
00:36:22,950 --> 00:36:25,269


713
00:36:25,269 --> 00:36:27,037


714
00:36:26,637 --> 00:36:28,448
다시 이미지 분류로 돌아가 보자면

715
00:36:27,037 --> 00:36:28,848


716
00:36:28,448 --> 00:36:31,070
기본 설정은, 여러분의 알고리즘이 한 장의 이미지를 보고는

717
00:36:28,848 --> 00:36:31,470


718
00:36:31,070 --> 00:36:33,648
몇 개의 고정된 카테고리 안에서 하나는 고르는거죠

719
00:36:31,470 --> 00:36:34,048


720
00:36:33,648 --> 00:36:36,043
이미지를 분류하기 위해서죠

721
00:36:34,048 --> 00:36:36,443


722
00:36:36,043 --> 00:36:39,150
이것이 다소 제한적이거나

723
00:36:36,443 --> 00:36:39,550


724
00:36:39,150 --> 00:36:42,106
인공적으로 보일수 있지만, 사실 매우 일반적이 것입니다.

725
00:36:39,550 --> 00:36:42,506


726
00:36:42,106 --> 00:36:45,121
이 문제는 다양한 환경에 적용될 수 있습니다.

727
00:36:42,506 --> 00:36:45,521


728
00:36:45,121 --> 00:36:49,230
산업현상에서든, 학술적으로든 말이죠, 많은 다양한 곳에서 가능합니다.

729
00:36:45,521 --> 00:36:49,630


730
00:36:49,230 --> 00:36:52,557
예를들어 음식을 인식하거나,

731
00:36:49,630 --> 00:36:52,957


732
00:36:52,557 --> 00:36:54,506
음식의 칼로리를 인식하거나,

733
00:36:52,957 --> 00:36:54,906


734
00:36:54,506 --> 00:36:57,643
다양한 미술작품들을 인식하거나, 이 세상에에 존재하는 여러가지
제품을 일식하는데도 적용할 수 있습니다.

735
00:36:54,906 --> 00:36:58,043


736
00:36:57,643 --> 00:37:01,176
그러니 영상 분류라는 상대적으로 기본적인 이 도구가

737
00:36:58,043 --> 00:37:01,576


738
00:37:01,176 --> 00:37:03,872
독자적으로도 엄청 유용할 수 있고,

739
00:37:01,576 --> 00:37:04,272


740
00:37:03,872 --> 00:37:08,103
다양한 응용을 통해 어느 곳이든 적용할 수 있을 것입니다.

741
00:37:04,272 --> 00:37:08,503


742
00:37:08,103 --> 00:37:13,406
하지만 이 코스에서는 몇 가지 다른 시각 인식 문제에 대해서도
이야기 할 것입니다.

743
00:37:08,503 --> 00:37:10,685


744
00:37:10,685 --> 00:37:13,806


745
00:37:13,406 --> 00:37:19,260
그리고 그것들은 우리가 영상 분류를 위해 개발한
여러 도구들 기반으로 합니다.

746
00:37:13,806 --> 00:37:16,673


747
00:37:16,673 --> 00:37:19,660


748
00:37:19,260 --> 00:37:20,866
우리는 다른 문제들에 대해서도 다룰 것입니다.

749
00:37:19,660 --> 00:37:21,266


750
00:37:20,866 --> 00:37:24,383
객체 디텍션이나
이미지 캡셔닝과 같은 것들이죠

751
00:37:21,266 --> 00:37:24,783


752
00:37:24,383 --> 00:37:26,265
객체 디텍션의 설정은

753
00:37:24,783 --> 00:37:26,665


754
00:37:26,265 --> 00:37:28,035
조금 다릅니다.

755
00:37:26,665 --> 00:37:28,435


756
00:37:28,035 --> 00:37:30,309
전체 이미지를 분류하는 대신에 전체 이미지를

757
00:37:28,435 --> 00:37:30,709


758
00:37:30,309 --> 00:37:33,327
이 이미지는 고양이다, 개다, 말이다 같이 뭐다 라고 하는 대신에

759
00:37:30,709 --> 00:37:33,727


760
00:37:33,327 --> 00:37:35,451
우리는 좀 더 들어가서
경계박스를 그려야 합니다.

761
00:37:33,727 --> 00:37:35,851


762
00:37:35,451 --> 00:37:38,061
그리고 개는 여기있고 고양이는 저기있다는 것을
말해야만 합니다.

763
00:37:35,851 --> 00:37:38,461


764
00:37:38,061 --> 00:37:39,951
저기 뒤에 차가 있다는 것도 말이죠

765
00:37:38,461 --> 00:37:40,351


766
00:37:39,951 --> 00:37:43,710
이미지 안에 객체들이 어디에 있는지를
묘사하는 박스를 그려야 합니다.

767
00:37:40,351 --> 00:37:42,186


768
00:37:42,186 --> 00:37:44,110


769
00:37:43,710 --> 00:37:45,922
이미지 캡션에 대해서도 이야기 할 것입니다.

770
00:37:44,110 --> 00:37:46,322


771
00:37:45,922 --> 00:37:47,345
이미지가 주어지면, 시스템은

772
00:37:46,322 --> 00:37:47,745


773
00:37:47,345 --> 00:37:49,711
이제 자연어 문장을 만들어내야 합니다.

774
00:37:47,745 --> 00:37:50,111


775
00:37:49,711 --> 00:37:51,075
그 문장은 이미지를 설명합니다.

776
00:37:51,075 --> 00:37:53,291
정말 힘들고, 복잡하고

777
00:37:51,475 --> 00:37:53,691


778
00:37:53,291 --> 00:37:55,199
서로 별 상관이 없어보일 수도 있지만, 우리는

779
00:37:53,691 --> 00:37:55,599


780
00:37:55,199 --> 00:37:58,563
이미지 분류 서비스를 위해 개발한
많은 도구들을

781
00:37:55,599 --> 00:37:57,219


782
00:37:57,219 --> 00:37:58,963


783
00:37:58,563 --> 00:38:02,480
다른 문제에서도 똑같이 적용할 수 있습니다.

784
00:37:58,963 --> 00:38:02,880


785
00:38:06,082 --> 00:38:10,845
지금까지는 ImageNet Challenge의 맥락에서 말씀드렸습니다.
 하지만,

786
00:38:06,482 --> 00:38:08,451


787
00:38:08,451 --> 00:38:11,245


788
00:38:10,845 --> 00:38:13,998
최근의 컴퓨터 비전 분야의 진보를 이끌어낸 것 중 하나는 바로

789
00:38:11,245 --> 00:38:12,966


790
00:38:12,966 --> 00:38:14,398


791
00:38:13,998 --> 00:38:19,950
Convolutional neural networks, 즉
CNN입니다. 또는 convnet으로도 불리죠

792
00:38:14,398 --> 00:38:17,933


793
00:38:17,933 --> 00:38:20,350


794
00:38:19,950 --> 00:38:26,427
최근 몇해 간 ImageNet Challenge의 우승을 이끈
알고리즘에 대해 살표보자면

795
00:38:20,350 --> 00:38:24,008


796
00:38:24,008 --> 00:38:26,827


797
00:38:26,427 --> 00:38:32,231
2011년에서 Lin et al의 알고리즘을 볼 수 있는데
여전히 계층적이죠.

798
00:38:26,827 --> 00:38:30,479


799
00:38:30,479 --> 00:38:32,631


800
00:38:32,231 --> 00:38:34,460
이 알고리즘은 여러 층으로 구성되어 있습니다.

801
00:38:32,631 --> 00:38:34,860


802
00:38:34,460 --> 00:38:36,369
우선 몇 개의 특징을 계산하고

803
00:38:34,860 --> 00:38:36,769


804
00:38:36,369 --> 00:38:38,342
그다음 몇 개의 지역 불면 특징들을 계산하고

805
00:38:36,769 --> 00:38:38,742


806
00:38:38,342 --> 00:38:42,539
pooling을 하고, 몇 개의 더 레이어를 거칩니다.

807
00:38:38,742 --> 00:38:41,211


808
00:38:41,211 --> 00:38:42,939


809
00:38:42,539 --> 00:38:45,876
그러고 나서 생긴 기술자를 선형 SVM에 넣는 것이죠.

810
00:38:42,939 --> 00:38:46,276


811
00:38:45,876 --> 00:38:48,830
여기서 주목할 점은 바로, 여전히 "계층적"이라는 것 입니다.

812
00:38:46,276 --> 00:38:49,230


813
00:38:48,830 --> 00:38:50,153
우리는 여전히 edges를 감지하고,

814
00:38:50,153 --> 00:38:52,183
여전히 불변성 이라는 개념을 지니고 있죠.

815
00:38:50,553 --> 00:38:52,583


816
00:38:52,183 --> 00:38:55,777
그리고 대부분의 그런 직관들은
여전히 CNN으로 까지 영향을 미칩니다.

817
00:38:52,583 --> 00:38:54,411


818
00:38:54,411 --> 00:38:56,177


819
00:38:55,777 --> 00:38:58,715
그러나 가장 획기적이었던 순간은 바로 2012년 이었죠

820
00:38:56,177 --> 00:38:59,115


821
00:38:58,715 --> 00:39:06,666
이때 토론토의 Jeff Hinton의 연구실이 Alex Krizhevsky,
그리고 Ilya Sutskever와 함께 하던 해 였습니다.

822
00:38:59,115 --> 00:39:02,032


823
00:39:03,693 --> 00:39:07,066


824
00:39:06,666 --> 00:39:12,104
그 두 사람은 박사과정(PHD) 였으며, 그때 당시 7개의 레이러를 가진
Convolutional neural network를 만들었었죠.

825
00:39:07,066 --> 00:39:09,225


826
00:39:09,225 --> 00:39:12,504


827
00:39:12,104 --> 00:39:14,812
현재 아주 잘 알려진 AlexNet 입니다,
Supervision으로도 불렸죠

828
00:39:12,504 --> 00:39:15,212


829
00:39:14,812 --> 00:39:19,251
AlexNet은 2012년의 ImageNet 대회에서 정말로 잘 해냈습니다.

830
00:39:15,212 --> 00:39:18,169


831
00:39:18,169 --> 00:39:19,651


832
00:39:19,251 --> 00:39:23,797
그 후로는 ImageNet의 승자는
매년 Newral Network의 몫이었습니다.

833
00:39:19,651 --> 00:39:22,484


834
00:39:22,484 --> 00:39:24,197


835
00:39:23,797 --> 00:39:27,696
그리고 이러한 추세는 CNN이 매년
더 깊어지게 만들었죠.

836
00:39:24,197 --> 00:39:25,911


837
00:39:25,911 --> 00:39:28,096


838
00:39:27,696 --> 00:39:33,192
AlexNet은 층이 7개 또는 8개인 Neural Network였습니다.
어떻게 층을 세느냐에 따라 조금 다릅니다.

839
00:39:28,096 --> 00:39:31,561


840
00:39:31,561 --> 00:39:33,592


841
00:39:33,192 --> 00:39:39,118
2015 년에 우리는 훨씬 더 깊은 네트워크를 가졌습니다.
Google의 GoogleNet 그리고 Oxford의 VGG가 바로 그것이죠.

842
00:39:33,592 --> 00:39:35,561


843
00:39:35,561 --> 00:39:39,518


844
00:39:39,118 --> 00:39:42,772
VGGnet은 약 19층의 레이어를 가지고 있었죠.

845
00:39:39,518 --> 00:39:43,172


846
00:39:42,772 --> 00:39:44,571
그러고 나서 2015년에는 정말 놀라웠습니다.

847
00:39:43,172 --> 00:39:44,971


848
00:39:44,571 --> 00:39:48,198
한 논문아 Microsoft Research Asis에서 나왔는데,

849
00:39:44,971 --> 00:39:48,598


850
00:39:48,198 --> 00:39:51,973
Residual Networks라 불리는 이 네트워크는
그 당시 152층의 레이러를 가지고 있었습니다.

851
00:39:48,598 --> 00:39:52,373


852
00:39:51,973 --> 00:39:58,105
그 이후에도, 200층 까지 쌓아 올리면 더 좋은 성능을 보일 수
있다고 했지만, 아마도 여러분의 GPU 메모리가 감당할 수 없을 것입니다.

853
00:39:52,373 --> 00:39:55,037


854
00:39:55,037 --> 00:39:56,745


855
00:39:56,745 --> 00:39:58,505


856
00:39:58,105 --> 00:39:59,952
이 모든건 다음에 더 다루기로 하죠

857
00:39:58,505 --> 00:40:00,352


858
00:39:59,952 --> 00:40:02,696
하지만 이 강의에서 중점적으로 다루는 것은
바로 convolutional neural networks 가

859
00:40:00,352 --> 00:40:03,096


860
00:40:02,696 --> 00:40:04,424
2012년에 아주 하나의 돌파구를 만들었다는 것이고,

861
00:40:03,096 --> 00:40:04,824


862
00:40:04,424 --> 00:40:08,383
그때 이후로, CNN이 성능을 개선하고 객체 분류를 더 잘 하도록 하기 위해서

863
00:40:04,824 --> 00:40:06,825


864
00:40:06,825 --> 00:40:08,783


865
00:40:08,383 --> 00:40:13,079
CNN을 개선하고 튜닝하려는 많은 시도를이 있었습니다.

866
00:40:08,783 --> 00:40:11,340


867
00:40:11,340 --> 00:40:13,479


868
00:40:13,079 --> 00:40:15,079
그리고 이번 학기의 남은 시간동안은

869
00:40:13,479 --> 00:40:15,479


870
00:40:15,079 --> 00:40:16,700
우리는 더 깊이 파고 들 것입니다.

871
00:40:15,479 --> 00:40:17,100


872
00:40:16,700 --> 00:40:19,549
그리고 아마도 여러분은 어떻게 서로 다른 모델이
동작하는지 정확히 이해할 수 있을 것입니다.

873
00:40:17,100 --> 00:40:19,116


874
00:40:19,116 --> 00:40:19,949


875
00:40:22,114 --> 00:40:24,265
하지만 한가지 중요한점은

876
00:40:22,514 --> 00:40:24,665


877
00:40:24,265 --> 00:40:29,860
2012년에 CNN이 돌파구를 열었고,

878
00:40:24,665 --> 00:40:27,348


879
00:40:27,348 --> 00:40:30,260


880
00:40:29,860 --> 00:40:36,151
ImageNet Chllenge에서 아주 좋은 성적을 낸 것은 사실이지만,
CNN이 2012년에 발명된 것은 아니라는 점입니다.

881
00:40:30,260 --> 00:40:32,394


882
00:40:32,394 --> 00:40:34,822


883
00:40:34,822 --> 00:40:36,551


884
00:40:36,151 --> 00:40:39,910
이  CNN이란 알고리즘은 실제로
오래 전부터 존재해 왔습니다.

885
00:40:36,551 --> 00:40:38,186


886
00:40:38,186 --> 00:40:40,310


887
00:40:39,910 --> 00:40:45,757
CNN이라는 분야의 일종의 기초연구 라고 할 수 있는 것은

888
00:40:40,310 --> 00:40:43,796


889
00:40:43,796 --> 00:40:46,157


890
00:40:45,757 --> 00:40:53,233
90년도의 Jan LeCun과 Bell Labs와의 공동 과제 였습니다.

891
00:40:46,157 --> 00:40:50,450


892
00:40:50,450 --> 00:40:53,633


893
00:40:53,233 --> 00:40:58,429
1998년에 그들이 CNN이란 것을 구축했습니다.
숫자 인식을 위한 것이었죠.

894
00:40:53,633 --> 00:40:57,332


895
00:40:57,332 --> 00:40:58,829


896
00:40:58,429 --> 00:41:06,966
그들은 이 CNN을 이용해서 자필 수표와 우체국의
우편 주소를 자동으로 인식하길 원했습니다.

897
00:40:58,829 --> 00:41:02,591


898
00:41:02,591 --> 00:41:04,668


899
00:41:04,668 --> 00:41:07,366


900
00:41:06,966 --> 00:41:08,984
그래서 그들이 바로  CNN을 만든 것입니다.

901
00:41:07,366 --> 00:41:09,384


902
00:41:08,984 --> 00:41:11,258
CNN은 Image의 Pixel을 입력으로 받아서,

903
00:41:09,384 --> 00:41:11,658


904
00:41:11,258 --> 00:41:16,837
이 숫자가 몇이고, 이 글자가 무엇인지를 분류할 수 있었습니다.

905
00:41:11,658 --> 00:41:14,582


906
00:41:14,582 --> 00:41:17,237


907
00:41:16,837 --> 00:41:18,806
이 네트워크의 구조는

908
00:41:17,237 --> 00:41:19,206


909
00:41:18,806 --> 00:41:20,806
사실 AlexNet의 아키텍쳐와 아주 유사합니다.

910
00:41:19,206 --> 00:41:21,206


911
00:41:20,806 --> 00:41:23,218
AlexNet은 2012년도였죠

912
00:41:21,206 --> 00:41:23,618


913
00:41:23,218 --> 00:41:26,278
우리가 저 그림에서 볼 수 있듯이,
raw 픽셀을 입력으로 받아서는

914
00:41:23,618 --> 00:41:25,449


915
00:41:26,278 --> 00:41:28,680
수많은 Convolution 레이어를 거치고,
서브 샘플링을 합니다

916
00:41:26,678 --> 00:41:29,080


917
00:41:28,680 --> 00:41:30,998
 Fully Connected Layer 라고 부르는 것으로
모아줍니다.

918
00:41:29,080 --> 00:41:31,398


919
00:41:30,998 --> 00:41:34,314
이 모든건 다음 강의 부터 더 자세히 다루도록 하겠습니다.

920
00:41:31,398 --> 00:41:33,395


921
00:41:34,314 --> 00:41:36,316
하지만, 여러분이 이 두 그림을 보고 있자면

922
00:41:34,714 --> 00:41:36,716


923
00:41:36,316 --> 00:41:37,997
둘이 꽤 비슷해 보일겁니다.

924
00:41:36,716 --> 00:41:38,397


925
00:41:37,997 --> 00:41:48,899
2012년의 CNN 아키텍쳐들은 서로 비슷비슷 했습니다.
90년대의 LeNet을의 아키텍처를 서로 공유했기 때문입니다.

926
00:41:38,397 --> 00:41:41,730


927
00:41:42,609 --> 00:41:44,449


928
00:41:44,449 --> 00:41:49,299


929
00:41:48,899 --> 00:41:52,977
그럼 이런 질문을 할 수 있겠군요
90년대부터 알고리즘이 었었다면

930
00:41:49,299 --> 00:41:50,816


931
00:41:50,816 --> 00:41:53,377


932
00:41:52,977 --> 00:41:57,054
왜 최근 몇년간이 되어서야 갑자기 인기있어 진 걸까요?

933
00:41:53,377 --> 00:41:55,815


934
00:41:55,815 --> 00:41:57,454


935
00:41:57,054 --> 00:42:02,877
90년대 이래로 아주 큰 혁신적인 것들이 있었습니다.

936
00:41:57,454 --> 00:41:59,303


937
00:41:59,303 --> 00:42:03,277


938
00:42:02,877 --> 00:42:04,951
하나는 바로 계산능력입니다.

939
00:42:03,277 --> 00:42:05,351


940
00:42:04,951 --> 00:42:08,817
무어의 법칙 덕분에, 우리는
점점 더 빠른 컴퓨터를 쓸 수 있게 되었고

941
00:42:05,351 --> 00:42:07,021


942
00:42:07,021 --> 00:42:09,217


943
00:42:08,817 --> 00:42:10,833
그리고 완벽한 척도는 아니겠지만,

944
00:42:09,217 --> 00:42:11,233


945
00:42:10,833 --> 00:42:18,174
칩 안의 트랜지스터의 수만 봤을때 90년대와 지금을
비교해보면 몇십배 이상 발전해 왔음을 알 수 있습니다.

946
00:42:11,233 --> 00:42:13,234


947
00:42:13,234 --> 00:42:15,129


948
00:42:15,129 --> 00:42:18,574


949
00:42:18,174 --> 00:42:22,643
우리는 또한 graphics processing units의
진보 겪었습니다.

950
00:42:18,574 --> 00:42:23,043


951
00:42:22,643 --> 00:42:25,478
GPU라고도 하죠, 이는 강력한 병렬처리가 가능한데

952
00:42:23,043 --> 00:42:25,878


953
00:42:25,478 --> 00:42:32,632
계산 집약적인 CNN 모델을 고속으로 처리하기 위한
아주 완벽한 툴로 거듭났습니다.

954
00:42:25,878 --> 00:42:28,105


955
00:42:28,105 --> 00:42:30,866


956
00:42:30,866 --> 00:42:33,032


957
00:42:32,632 --> 00:42:39,324
그러니, 단지 좀더 많은 계산이 가능하다는 것 만으로
연구자들이 더 큰 아키텍쳐를 연구할 수 있었고,

958
00:42:33,032 --> 00:42:35,941


959
00:42:35,941 --> 00:42:39,724


960
00:42:39,324 --> 00:42:43,726
좀 더 큰 모델을 연구할 수 있었습니다.
경우 따라서는 모델 사이즈만 키웠음에도,

961
00:42:39,724 --> 00:42:42,150


962
00:42:42,150 --> 00:42:44,126


963
00:42:43,726 --> 00:42:48,076
기존의 고전적인 방법과 알고리즘은 아무 잘 동작했습니다.

964
00:42:44,126 --> 00:42:46,838


965
00:42:46,838 --> 00:42:48,476


966
00:42:48,076 --> 00:42:55,154
그러므로 계산할 수 있는 양이 늘어났다는 것은
딥 러닝의 역사에서 아주 중요한 것입니다.

967
00:42:48,476 --> 00:42:51,415


968
00:42:51,415 --> 00:42:55,554


969
00:42:55,154 --> 00:43:00,159
지금과 90년대 사이에 변화한 두번째 주요 혁신은
바로 데이터가 아닐까 생각합니다.

970
00:42:55,554 --> 00:42:58,647


971
00:42:58,647 --> 00:43:00,559


972
00:43:00,159 --> 00:43:03,858
이런 알고리즘들은 데이터가 아주 부족할 수 있습니다.

973
00:43:00,559 --> 00:43:04,258


974
00:43:03,858 --> 00:43:08,995
CNN 알고리즘이 잘 동작하게 하기 위해서는
여러분은 아주 많은 레이블된 이미지 그리고 픽셀을 학습시켜야 합니다.

975
00:43:04,258 --> 00:43:06,319


976
00:43:06,319 --> 00:43:09,395


977
00:43:08,995 --> 00:43:13,741
그리고 90년대에는 충분한 레이블 데이터가
존재하지 않았습니다.

978
00:43:09,395 --> 00:43:11,653


979
00:43:11,653 --> 00:43:14,141


980
00:43:13,741 --> 00:43:19,832
그때 당시에는 Mechanical Turk이 생겨나기 전이었고
인터넷이 아주 널리 쓰이기도 전이었습니다.

981
00:43:14,141 --> 00:43:17,489


982
00:43:17,489 --> 00:43:20,232


983
00:43:19,832 --> 00:43:23,214
아무 크고 다양한 데이터셋을 수집하기도 힘들었습니다.

984
00:43:20,232 --> 00:43:21,871


985
00:43:21,871 --> 00:43:23,614


986
00:43:23,214 --> 00:43:33,828
하지만 지금은 PASCAL이나 ImageNet같은 데이터셋과 같이,
더 규모가 크고 고퀄의 레이블을 가진 데이터셋이 많이 있습니다.

987
00:43:23,614 --> 00:43:27,531


988
00:43:28,583 --> 00:43:31,633


989
00:43:31,633 --> 00:43:34,228


990
00:43:33,828 --> 00:43:38,375
이들은, 90년대에 사용가능했던 데이터셋에 비하면
수십제곱만큼이나 더 크다고 할 수 있습니다.

991
00:43:34,228 --> 00:43:36,590


992
00:43:36,590 --> 00:43:38,775


993
00:43:38,375 --> 00:43:42,753
또 이런 엄청 큰 데이터셋들은
우리가 Higher Capacity Model을 만들 수 있게 하였습니다.

994
00:43:38,775 --> 00:43:40,622


995
00:43:40,622 --> 00:43:43,153


996
00:43:42,753 --> 00:43:46,757
그런 모델을 학습하게 되면 실생활 문제에 실제로도 잘 동작합니다.

997
00:43:43,153 --> 00:43:45,261


998
00:43:45,261 --> 00:43:47,157


999
00:43:46,757 --> 00:43:48,862
하지만 여기에서 비평한만한 것이 있다면,

1000
00:43:47,157 --> 00:43:49,262


1001
00:43:48,862 --> 00:43:53,759
 convolution neural network가 간지나고, 새로워 보이고

1002
00:43:49,262 --> 00:43:51,023


1003
00:43:51,023 --> 00:43:54,159


1004
00:43:53,759 --> 00:43:57,127
지난 몇 해동안 갑자기 튀어 나온 것 처럼 보일 수도 있지만,
그건 정말 사실이 아니라는 것 입니다.

1005
00:43:54,159 --> 00:43:56,117


1006
00:43:56,117 --> 00:43:57,527


1007
00:43:57,127 --> 00:44:03,266
CNN과 같은 부류의 알고리즘은 아주 오래 전부터 존재했습니다.

1008
00:43:57,527 --> 00:43:59,583


1009
00:43:59,583 --> 00:44:03,666


1010
00:44:04,615 --> 00:44:12,355
내가 집고 넘어가고 싶은 것은, 컴퓨터 비전에서 우리가 하는 일은
"사람 처럼 볼 수 있는" 기계를 만드려는 노력 이라는 것입니다.

1011
00:44:05,015 --> 00:44:07,915


1012
00:44:07,915 --> 00:44:09,724


1013
00:44:09,724 --> 00:44:12,755


1014
00:44:12,355 --> 00:44:16,250
그리고 실제로 사람들은 우리의 시각 체계를
이동해서 아주 많은 것을 할 수 잇습니다.

1015
00:44:12,755 --> 00:44:15,257


1016
00:44:16,250 --> 00:44:18,098
여러분이 이 세상을 살아가면서

1017
00:44:16,650 --> 00:44:18,498


1018
00:44:18,098 --> 00:44:24,588
여러분은 고양이나 강아지에 사각형을 그리고
분류하는 것 이상의 일을 할 수 있습니다.

1019
00:44:18,498 --> 00:44:21,034


1020
00:44:21,034 --> 00:44:24,988


1021
00:44:24,588 --> 00:44:27,311
여러분의 시각체계는 컴퓨터비전보다 훤씬 더 강력합니다.

1022
00:44:24,988 --> 00:44:27,711


1023
00:44:27,311 --> 00:44:29,015
다시 이 분야로 돌아가 보자면,

1024
00:44:27,711 --> 00:44:29,415


1025
00:44:29,015 --> 00:44:33,647
아직도 우리가 다뤄야 할 엄청나게 많은 도전과제와
해결하지 못한 문제가 있다고 생각합니다.

1026
00:44:29,415 --> 00:44:31,612


1027
00:44:31,612 --> 00:44:34,047


1028
00:44:33,647 --> 00:44:39,820
그리고 우리는 더 나은 일을 하고, 더 야심찬 문제에 도전할 수 있도록
알고리즘을 계속해서 개발해 나갈 필요가 있습니다.

1029
00:44:34,047 --> 00:44:36,630


1030
00:44:36,630 --> 00:44:40,220


1031
00:44:39,820 --> 00:44:43,643
몇가지 예를 들어보자면, 사실은 오래 전부터 있던 아이디어 이기는 합니다만

1032
00:44:40,220 --> 00:44:42,964


1033
00:44:43,643 --> 00:44:46,523
Semantic Segmentation, 즉
 Perceptual Grouping 같은 것들이죠

1034
00:44:44,043 --> 00:44:46,923


1035
00:44:46,523 --> 00:44:48,892
여기에서는 한장의 이미지 전체에
레이블링을 하는 것이 아니라

1036
00:44:46,923 --> 00:44:49,292


1037
00:44:48,892 --> 00:44:51,569
이미지 내의 모든 픽셀 하나 하나를
이해하는 것입니다.

1038
00:44:49,292 --> 00:44:51,969


1039
00:44:51,569 --> 00:44:53,466
뭘 하고있는지, 뭘 의미하는지를 말이죠

1040
00:44:51,969 --> 00:44:53,866


1041
00:44:53,466 --> 00:44:56,446
이건 좀 더 뒤에 다시 다루도록 하겠습니다.

1042
00:44:53,866 --> 00:44:55,661


1043
00:44:56,446 --> 00:44:59,734
실제 세계를 재 구성하는것에 관한 3D 이해에 관한 아이디어로
거슬러 올라가 보자면,

1044
00:44:56,846 --> 00:44:58,453


1045
00:44:58,453 --> 00:45:00,134


1046
00:44:59,734 --> 00:45:05,727
제 생각에는 여전히 풀지못한 문제입니다.

1047
00:45:00,134 --> 00:45:02,377


1048
00:45:02,377 --> 00:45:06,127


1049
00:45:07,098 --> 00:45:09,778
여러분이 상상할 수 있는
엄청나게 많은 과제들이 있습니다.

1050
00:45:07,498 --> 00:45:09,010


1051
00:45:09,778 --> 00:45:11,417
예를들어 행동인식이 있겠네요,

1052
00:45:10,178 --> 00:45:11,817


1053
00:45:11,417 --> 00:45:16,325
만약 여러분에게 어떤 사람이 무언가를 하고있는 비디오가 있다고 했을때,
그 활동을 인식할 수 있는 최고의 방법이 과연 무엇일까요?

1054
00:45:11,817 --> 00:45:13,438


1055
00:45:13,438 --> 00:45:15,212


1056
00:45:15,212 --> 00:45:16,725


1057
00:45:16,325 --> 00:45:19,069
그것은 꽤 도전적인 문제 이기도 합니다.

1058
00:45:16,725 --> 00:45:19,469


1059
00:45:19,069 --> 00:45:22,874
그리고 나서 우리가 증강현실, 가상현실로 뻗어나가고

1060
00:45:19,469 --> 00:45:21,286


1061
00:45:21,286 --> 00:45:23,274


1062
00:45:22,874 --> 00:45:27,178
새로운 종류의 센서들과 마주하게 된다면,

1063
00:45:23,274 --> 00:45:25,332


1064
00:45:25,332 --> 00:45:27,578


1065
00:45:27,178 --> 00:45:32,055
제 생각에, 우리는 한 분야로 다룰 수 있을만큼
새롭고 흥미롭고, 어렵고 아주 도전적인 문제들을 또 만나게 될 것입니다.

1066
00:45:27,578 --> 00:45:29,955


1067
00:45:29,955 --> 00:45:32,455


1068
00:45:33,516 --> 00:45:41,828
지금부터 보여드릴 예는 제가 비전연구실에서 하고있는 일중에 일부인데,
Visual Genome 이라는 데이터셋입니다.

1069
00:45:33,916 --> 00:45:37,924


1070
00:45:37,924 --> 00:45:42,228


1071
00:45:41,828 --> 00:45:47,074
여기에서 주된 아이디어는 바로 복잡한 실제 세상에서 일부를
포착해 내는 것입니다.

1072
00:45:42,228 --> 00:45:45,426


1073
00:45:45,426 --> 00:45:47,474


1074
00:45:47,074 --> 00:45:51,908
박스만 치는 것으로는 부족하고 이미지를

1075
00:45:47,474 --> 00:45:49,793


1076
00:45:49,793 --> 00:45:52,308


1077
00:45:51,908 --> 00:45:57,125
하나의 커다란 의미론적인 그래프로 표현하는 것입니다.
이 그래프는, 객체를 식별하는것 뿐만 아니라

1078
00:45:52,308 --> 00:45:55,056


1079
00:45:55,056 --> 00:45:57,525


1080
00:45:57,125 --> 00:46:02,190
그 장면에 나타난 객체의 관계, 객체의 성격, 행동 등을
나타낼 수 있습니다.

1081
00:45:57,525 --> 00:46:00,451


1082
00:46:00,451 --> 00:46:02,590


1083
00:46:02,190 --> 00:46:09,127
그리고 이런 방식의 표현방법을 통해서 어쩌면 실제 세계를
일부 만이라도 포착할 수 있지 않을까 예상합니다.

1084
00:46:02,590 --> 00:46:06,971


1085
00:46:06,971 --> 00:46:09,527


1086
00:46:09,127 --> 00:46:12,489
그리고 그것들은 우리가 단순한 분류만 하고 있을때
활용하지 못했던 것들이죠

1087
00:46:09,527 --> 00:46:11,225


1088
00:46:11,225 --> 00:46:12,889


1089
00:46:12,489 --> 00:46:14,870
이것이 현 시점에서 표준 접근법 이라는 말은 아니지만,

1090
00:46:12,889 --> 00:46:15,270


1091
00:46:14,870 --> 00:46:19,235
우리 인간의 시각 체계라는 것이 단순한 이미지 분류 알고리즘으로는
포착해 낼 수 없는

1092
00:46:15,270 --> 00:46:17,330


1093
00:46:17,330 --> 00:46:19,635


1094
00:46:19,235 --> 00:46:24,440
훨씬 더 많은 것을 할 수 있다는 것을 여러분들이 깨달게
해 주는 것 만으로도 충분합니다.

1095
00:46:19,635 --> 00:46:22,590


1096
00:46:22,590 --> 00:46:24,840


1097
00:46:27,603 --> 00:46:31,192
그런 관점에서 봤을때, 정말 재밌는 연구가 하나 있는데

1098
00:46:28,003 --> 00:46:29,744


1099
00:46:29,744 --> 00:46:31,592


1100
00:46:31,192 --> 00:46:33,745
Fei-Fei 교수님의 학부시절의 연구입니다.

1101
00:46:31,592 --> 00:46:34,145


1102
00:46:33,745 --> 00:46:38,552
그 당시 그녀는 지도 교수님과 Cal Tech에서 박사과정을 진행하고
있었습니다.

1103
00:46:34,145 --> 00:46:36,843


1104
00:46:36,843 --> 00:46:38,952


1105
00:46:38,552 --> 00:46:41,292
이 연구에서는, 사람들을 붙잡아서

1106
00:46:38,952 --> 00:46:41,692


1107
00:46:41,292 --> 00:46:44,204
사람들에게 이 사진을 아주 잠시 동안만 보여줬습니다.

1108
00:46:41,692 --> 00:46:44,604


1109
00:46:44,204 --> 00:46:47,496
그들에게 아무 짧은 시간만 이 이미지를 보여준 것이죠,

1110
00:46:44,604 --> 00:46:46,302


1111
00:46:46,302 --> 00:46:47,896


1112
00:46:47,496 --> 00:46:51,708
이미지를 본 시간이 아무 짧음에도 불구하고, 사람들은

1113
00:46:47,896 --> 00:46:50,169


1114
00:46:50,169 --> 00:46:52,108


1115
00:46:51,708 --> 00:46:56,073
위와 같이 그 이미지에 관한 아주 긴 문장을 쓸 수 있었습니다.

1116
00:46:52,108 --> 00:46:54,033


1117
00:46:54,033 --> 00:46:56,473


1118
00:46:56,073 --> 00:47:03,292
그리고 이것은 아주 주목할만한 것입니다.
이미지를 아무 잠깐만 본 후에도

1119
00:46:56,473 --> 00:47:00,284


1120
00:47:00,284 --> 00:47:03,692


1121
00:47:03,292 --> 00:47:05,160
인간은 이미지에 대해 말할 수 있었습니다.

1122
00:47:03,692 --> 00:47:05,560


1123
00:47:05,160 --> 00:47:09,975
일종의 게임, 또는 싸움을 하고 있고, 두 무리의 남자기 있고, 왼쪽에
있는 남자는 뭘 던지고 있고,

1124
00:47:05,560 --> 00:47:08,481


1125
00:47:08,481 --> 00:47:10,375


1126
00:47:09,975 --> 00:47:14,176
이곳이 밖이고, 잔디와 같은 느낌이 들어서, 등등

1127
00:47:10,375 --> 00:47:13,134


1128
00:47:13,134 --> 00:47:14,576


1129
00:47:14,176 --> 00:47:17,217
그리고 아마 사람이 이 이미지를 좀더 오래 보게 된다면
어떨지 상상할 수 있을 것입니다.

1130
00:47:14,576 --> 00:47:16,016


1131
00:47:16,016 --> 00:47:17,617


1132
00:47:17,217 --> 00:47:18,769
아마도, 그들이 누구이고

1133
00:47:17,617 --> 00:47:19,169


1134
00:47:18,769 --> 00:47:21,907
왜 그들이 저기에서 게임을 하고있는지에 대해서
소설 한편을 쓸지도 모르겠습니다.

1135
00:47:19,169 --> 00:47:20,942


1136
00:47:21,907 --> 00:47:23,285
아마 끝도없이 계속 할 수도 있을 것입니다.

1137
00:47:23,285 --> 00:47:26,787
외부의 지식과, 선행 경험을 통해서 말이죠

1138
00:47:23,685 --> 00:47:25,613


1139
00:47:25,613 --> 00:47:27,187


1140
00:47:26,787 --> 00:47:29,897
이는 어찌보면 컴퓨터 비전의 성배라고 할 수 있습니다.

1141
00:47:27,187 --> 00:47:30,297


1142
00:47:29,897 --> 00:47:34,263
이미지의 스토리를 아주 풍부하고 깊은 방법으로
이해 한다는 면에서 말이죠

1143
00:47:30,297 --> 00:47:32,659


1144
00:47:32,659 --> 00:47:34,663


1145
00:47:34,263 --> 00:47:39,306
그리고 제 생각에는, 지난 컴퓨터비전이라는 분야의
수년간의 큰 진보에서 불구하고

1146
00:47:34,663 --> 00:47:36,932


1147
00:47:36,932 --> 00:47:39,706


1148
00:47:39,306 --> 00:47:44,060
성배를 얻기위한 길은 아직도 멀고도 험난합니다.

1149
00:47:39,706 --> 00:47:44,460


1150
00:47:44,060 --> 00:47:50,072
이것에 대해 예를 들고싶은 이미지가 하나 더 있습니다.
Andrej Karpathy의 블로그에 있는 이미지입니다.

1151
00:47:44,460 --> 00:47:46,563


1152
00:47:46,563 --> 00:47:50,472


1153
00:47:50,072 --> 00:47:52,490
아주 놀라운 것이죠

1154
00:47:50,472 --> 00:47:52,890


1155
00:47:52,490 --> 00:47:53,991
많은 사람들이 웃었습니다.

1156
00:47:52,890 --> 00:47:54,391


1157
00:47:53,991 --> 00:47:55,812
제생각에 이 이미지는 상당히 재밌다고 생각합니다.

1158
00:47:54,391 --> 00:47:56,212


1159
00:47:55,812 --> 00:47:57,296
왜 이게 웃기죠?

1160
00:47:56,212 --> 00:47:57,696


1161
00:47:57,296 --> 00:48:01,207
한 남자가 체중계에 서 있습니다. 우리는 보통 사람들이 가끔씩

1162
00:47:57,696 --> 00:47:59,895


1163
00:47:59,895 --> 00:48:01,607


1164
00:48:01,207 --> 00:48:03,980
자신의 체중을 알아보기 위해 체중계를 사용한다는 것을 알고 있습니다.

1165
00:48:01,607 --> 00:48:04,380


1166
00:48:03,980 --> 00:48:08,391
그리고 우린 뒤에서 체중계를 밟고 있는 다른 한 사람을 볼 수 있습니다.

1167
00:48:04,380 --> 00:48:06,899


1168
00:48:06,899 --> 00:48:08,791


1169
00:48:08,391 --> 00:48:10,500
그리고 우리는 체중계가 어떻게 동작할 지 짐작할 수 있고,

1170
00:48:08,791 --> 00:48:10,900


1171
00:48:10,500 --> 00:48:13,467
저 사람이 보게될 부풀려진 체중의 이유를 알고 있습니다.

1172
00:48:10,900 --> 00:48:12,958


1173
00:48:13,467 --> 00:48:14,495
그러나 더 많은 것이 있습니다.

1174
00:48:14,495 --> 00:48:16,419
우리는 저 사람이 평범한 사람이 아니란 것을 알고 있습니다.

1175
00:48:14,895 --> 00:48:16,819


1176
00:48:16,419 --> 00:48:20,505
저 사람은 당의 미국 대통령 Barack Obama 입니다.

1177
00:48:16,819 --> 00:48:19,500


1178
00:48:19,500 --> 00:48:20,905


1179
00:48:20,505 --> 00:48:24,341
그리고 우리는 미국 대통령은 존경받는 정치인이
되어야 한다고 알 고 있습니다.

1180
00:48:20,905 --> 00:48:22,541


1181
00:48:22,541 --> 00:48:24,741


1182
00:48:24,341 --> 00:48:26,645
[웃음]

1183
00:48:24,741 --> 00:48:27,045


1184
00:48:26,645 --> 00:48:30,904
아마도 이런식으로 동료에게 장난을 치지 않아야 하겠죠

1185
00:48:27,045 --> 00:48:29,154


1186
00:48:29,154 --> 00:48:31,304


1187
00:48:30,904 --> 00:48:34,164
우리는 뒤 쪽의 사람들이 웃고 있다는 것을 알 수 있습니다.

1188
00:48:31,304 --> 00:48:32,713


1189
00:48:32,713 --> 00:48:34,564


1190
00:48:34,164 --> 00:48:37,512
우리는 뒤쪽의 사람들이 이 장면을 어떻게
이해하는지를 알 수도 있습니다.

1191
00:48:34,564 --> 00:48:36,066


1192
00:48:36,066 --> 00:48:37,912


1193
00:48:37,512 --> 00:48:42,466
그들도 우리처럼 오바마대통령이 존경받는 사람이라는 것을 알고 있다는
것을 이해할 수 있습니다.

1194
00:48:37,912 --> 00:48:39,597


1195
00:48:39,597 --> 00:48:41,575


1196
00:48:42,466 --> 00:48:43,367
이건 정말 놀라운 것입니다.

1197
00:48:43,367 --> 00:48:45,430
이 이미지에는 많은 것이 있습니다.

1198
00:48:43,767 --> 00:48:45,830


1199
00:48:45,430 --> 00:48:47,767
그리고 우리의 컴퓨터 비전 알고리즘은

1200
00:48:45,830 --> 00:48:48,167


1201
00:48:47,767 --> 00:48:52,602
이미지에 대한 이런 진정한 깊은 이해를 하기까지는
아직 갈 길이 멀다고 생각합니다.

1202
00:48:48,167 --> 00:48:51,108


1203
00:48:51,108 --> 00:48:53,002


1204
00:48:52,602 --> 00:48:58,377
저는 이 분야의 큰 진보에도 불구하고,
아직 갈이 멀다고 생각합니다.

1205
00:48:53,002 --> 00:48:56,032


1206
00:48:56,032 --> 00:48:58,777


1207
00:48:58,377 --> 00:49:00,985
저에게 이것은 연구자로서 정말 흥분되는 것입니다.

1208
00:48:58,777 --> 00:49:01,385


1209
00:49:00,985 --> 00:49:06,294
왜냐하면 앞으로 나가갈 수 있는 정말 흥미진진하고
재미있는 문제들이 우리에게 아직 많이 남아있기 때문입니다.

1210
00:49:01,385 --> 00:49:02,630


1211
00:49:02,630 --> 00:49:04,611


1212
00:49:04,611 --> 00:49:06,694


1213
00:49:07,513 --> 00:49:12,654
그래서 저는 컴퓨터비전이 정말 재미있다는 것을
여러분들에게 알리고 싶습니다.

1214
00:49:07,913 --> 00:49:10,202


1215
00:49:10,202 --> 00:49:13,054


1216
00:49:12,654 --> 00:49:13,808
정말 재밌습니다.

1217
00:49:13,808 --> 00:49:15,929
그리고 매우 유용합니다.

1218
00:49:14,208 --> 00:49:16,329


1219
00:49:15,929 --> 00:49:19,643
그리고 나아 가서 다양한 방법으로
이 세상을 좋은 곳으로 만들어 줄 수 있습니다.

1220
00:49:16,329 --> 00:49:18,315


1221
00:49:18,315 --> 00:49:20,043


1222
00:49:19,643 --> 00:49:27,734
컴퓨터비전은 의학진단이나 자율주행 자동차, 로보틱스 등
어느 곳이든 적용할 수 있습니다.

1223
00:49:20,043 --> 00:49:21,591


1224
00:49:21,591 --> 00:49:24,559


1225
00:49:24,559 --> 00:49:28,134


1226
00:49:27,734 --> 00:49:32,720
게다가 인간의 지능을 이해하기 위한 여러가지 핵심 아이디어를
서로 묶어주는 일존의 매듭이 될 수도 있습니다.

1227
00:49:28,134 --> 00:49:30,713


1228
00:49:30,713 --> 00:49:33,120


1229
00:49:32,720 --> 00:49:36,741
제 생각에는 컴퓨터비전은 정말 기상천외하고 재밌는 분야입니다.

1230
00:49:33,120 --> 00:49:34,849


1231
00:49:34,849 --> 00:49:37,141


1232
00:49:36,741 --> 00:49:40,075
그리고 여러분들과 이 수업을 통해서 오늘날 알고리즘들이
실제로 어떻게 동작하는지에 대해서

1233
00:49:37,141 --> 00:49:38,775


1234
00:49:38,775 --> 00:49:40,475


1235
00:49:40,075 --> 00:49:45,834
여러분들과 심도깊은 이야기를 할수 있게 되어서 정말 좋습니다.

1236
00:49:40,475 --> 00:49:42,337


1237
00:49:42,337 --> 00:49:46,234


1238
00:49:45,834 --> 00:49:50,273
여기까지는 컴퓨터비전에 대한 개인적인 견해와
컴퓨터 비전의 역사에 대해서 였습니다.

1239
00:49:46,234 --> 00:49:48,949


1240
00:49:48,949 --> 00:49:50,673


1241
00:49:50,273 --> 00:49:52,966
혹시 궁금한 점이 있으신가요?

1242
00:49:50,673 --> 00:49:52,283


1243
00:49:52,283 --> 00:49:53,366


1244
00:49:55,307 --> 00:49:56,655
좋습니다.

1245
00:49:56,655 --> 00:50:02,008
그러면 이제 앞으로의 수업 계획에 대해 말해보죠

1246
00:49:57,055 --> 00:49:58,345


1247
00:49:58,345 --> 00:50:00,408


1248
00:50:00,408 --> 00:50:02,408


1249
00:50:02,008 --> 00:50:03,982
어쩌면 여러분은 우리가 누구냐고 물으실 수도 있습니다.

1250
00:50:02,408 --> 00:50:04,382


1251
00:50:03,982 --> 00:50:06,504
이 수업은 Fei-Fei Li 교수님께서 가르치십니다.

1252
00:50:04,382 --> 00:50:06,904


1253
00:50:06,504 --> 00:50:10,871
이곳 Stanford의 컴퓨터 과학 교수님이십니다.

1254
00:50:06,904 --> 00:50:11,271


1255
00:50:10,871 --> 00:50:14,116
그리고 제 지도 교수님이시기도 하고
Stanford Vision Lab의 교수님이십니다.

1256
00:50:11,271 --> 00:50:14,516


1257
00:50:14,116 --> 00:50:16,452
Stanford AI Lab에 계시기도 하죠

1258
00:50:14,516 --> 00:50:16,852


1259
00:50:16,452 --> 00:50:22,119
그리고 다른 두명, 저 Justin Tohnson과 Serena
Yeung, 여기 앞에 서있습니다.

1260
00:50:16,852 --> 00:50:20,081


1261
00:50:20,081 --> 00:50:22,519


1262
00:50:22,119 --> 00:50:26,979
우리 둘은 Fei-Fei 교수님의 지도 하에
다양한 컴퓨터 비전 과제를 수행하고 있는 PHD 학생입니다.

1263
00:50:22,519 --> 00:50:25,219


1264
00:50:25,219 --> 00:50:27,379


1265
00:50:26,979 --> 00:50:31,520
우리에게 18명의 훌륭한 조교가 있습니다.

1266
00:50:27,379 --> 00:50:29,996


1267
00:50:29,996 --> 00:50:31,920


1268
00:50:31,520 --> 00:50:33,779
대부분은 여기 앞에 앉아 있습니다.

1269
00:50:31,920 --> 00:50:34,179


1270
00:50:33,779 --> 00:50:39,920
우리가 수업을 잘 진행하고, 모든것이 잘 돌아갈 수 있도록
도와주는 얼굴없는 영웅들 입니다.

1271
00:50:34,179 --> 00:50:35,921


1272
00:50:35,921 --> 00:50:38,527


1273
00:50:38,527 --> 00:50:40,320


1274
00:50:39,920 --> 00:50:41,965
그러니 그들에게 잘해주세요.

1275
00:50:40,320 --> 00:50:42,365


1276
00:50:41,965 --> 00:50:43,796
[웃음]

1277
00:50:42,365 --> 00:50:44,196


1278
00:50:43,796 --> 00:50:48,816
말씀 드려야 할 점이 있다면, 이 강의는 세 번째 열리는 강의이지만

1279
00:50:44,196 --> 00:50:47,153


1280
00:50:47,153 --> 00:50:49,216


1281
00:50:48,816 --> 00:50:52,650
Andrej Karpathy가 강의를 하지 않는 첫 번째 강의이기도 합니다.

1282
00:50:49,216 --> 00:50:51,652


1283
00:50:52,650 --> 00:50:55,792
그는 저와 아주 친한 친구입니다.

1284
00:50:53,050 --> 00:50:56,192


1285
00:50:55,792 --> 00:50:56,693
그는 아직 살아 있습니다.

1286
00:50:56,693 --> 00:50:57,953
그는 괜찮습니다. 걱정하지 마세요.

1287
00:50:57,953 --> 00:50:59,212
[웃음]

1288
00:50:59,212 --> 00:51:02,380
그는 졸업을 했고 사실 여기에 있습니다.

1289
00:50:59,612 --> 00:51:02,780


1290
00:51:02,380 --> 00:51:05,324
강당 어딘가에 있겠죠

1291
00:51:02,780 --> 00:51:05,724


1292
00:51:05,324 --> 00:51:11,217
이 수업의 발전과 역사의 대부분은 수년동안 저와 함께 일해준
그의 덕분 이었습니다.

1293
00:51:05,724 --> 00:51:07,662


1294
00:51:07,662 --> 00:51:09,570


1295
00:51:09,570 --> 00:51:11,617


1296
00:51:11,217 --> 00:51:14,998
그 사실은 여러분도 알고 계셨으면 좋겠습니다.

1297
00:51:11,617 --> 00:51:15,398


1298
00:51:14,998 --> 00:51:21,809
강의에 대해 말해보자면, 조교들과 연락할 수 있는 가장
좋은 방법은 Piazza를 이용하는 것입니다.

1299
00:51:15,398 --> 00:51:18,194


1300
00:51:18,194 --> 00:51:20,904


1301
00:51:21,809 --> 00:51:24,812
당장 가서 가입하세요

1302
00:51:22,209 --> 00:51:25,212


1303
00:51:24,812 --> 00:51:29,953
Piazza는 이 수업에 대한 의사소통을 할 수 있는
우리가 가장 선호하는 방법입니다.

1304
00:51:25,212 --> 00:51:27,597


1305
00:51:27,597 --> 00:51:30,353


1306
00:51:29,953 --> 00:51:33,913
만약 친구들 앞에서 질문하는 것이 꺼려진다면,

1307
00:51:30,353 --> 00:51:32,621


1308
00:51:32,621 --> 00:51:34,313


1309
00:51:33,913 --> 00:51:40,172
Piazza에 가서 익명으로 질문을 하세요 private
질문을 올릴수도 있습니다. 교직원에게 직접 연락하십시오.

1310
00:51:34,313 --> 00:51:36,067


1311
00:51:36,067 --> 00:51:38,602


1312
00:51:38,602 --> 00:51:40,572


1313
00:51:40,172 --> 00:51:44,052
기본적으로 여러분이 필요한것은 그저 Piazza를 경험하는 것입니다.

1314
00:51:40,572 --> 00:51:42,269


1315
00:51:42,269 --> 00:51:44,452


1316
00:51:44,052 --> 00:51:48,022
조교들의 메일링 리스트가 있긴 하지만

1317
00:51:44,452 --> 00:51:46,445


1318
00:51:46,445 --> 00:51:48,422


1319
00:51:48,022 --> 00:51:53,117
Piazza에 올리기 껄끄러운 개인적이거나 비공개적인 것들을 위해서만 쓰고

1320
00:51:48,422 --> 00:51:51,302


1321
00:51:51,302 --> 00:51:53,517


1322
00:51:53,117 --> 00:52:01,725
혹시나 정말 중요한 말못할 사항이 있다면, 저나, Serena, Fei-Fei
교수님께 직접 메일을 주셔도 되겠습니다.

1323
00:51:53,517 --> 00:51:55,773


1324
00:51:55,773 --> 00:51:58,365


1325
00:51:58,365 --> 00:52:02,125


1326
00:52:01,725 --> 00:52:05,696
하지만 그 외의 조교와의 커뮤니케이션은 Piazza을
통해서여만 합니다.

1327
00:52:02,125 --> 00:52:03,900


1328
00:52:03,900 --> 00:52:06,096


1329
00:52:05,696 --> 00:52:08,260
올해는 부교재도 있습니다.

1330
00:52:06,096 --> 00:52:08,660


1331
00:52:08,260 --> 00:52:10,001
필수는 아닙니다.

1332
00:52:08,660 --> 00:52:10,401


1333
00:52:10,001 --> 00:52:12,216
이 책없이도 이 강의를 들을 수 있습니다.

1334
00:52:10,401 --> 00:52:12,616


1335
00:52:12,216 --> 00:52:13,972
모든걸 스스로 챙겨야 할 것입니다.

1336
00:52:12,616 --> 00:52:14,372


1337
00:52:13,972 --> 00:52:19,386
정말 흥분되는 것은, 이 책이 아마 딥 러닝에 관해서 처음 출간된
교과서 라는 것 떄문입니다.

1338
00:52:14,372 --> 00:52:17,770


1339
00:52:17,770 --> 00:52:19,786


1340
00:52:19,386 --> 00:52:23,678
올해 초에 출간된 E.N. Goodfellow, U
oshua Bengio, Aaron Courville이 쓴 책 입니다.

1341
00:52:19,786 --> 00:52:21,889


1342
00:52:21,889 --> 00:52:24,078


1343
00:52:23,678 --> 00:52:26,284
슬라이드에 아마존 링크를 주가했습니다.

1344
00:52:24,078 --> 00:52:26,684


1345
00:52:26,284 --> 00:52:27,797
원한다면 구입하도록 하세요

1346
00:52:26,684 --> 00:52:28,197


1347
00:52:27,797 --> 00:52:31,407
하지만 온라인에 무료 컨텐츠도 있기 떄문에,
반드시 살 필요는 없습니다.

1348
00:52:28,197 --> 00:52:30,079


1349
00:52:30,079 --> 00:52:31,807


1350
00:52:31,407 --> 00:52:32,543
사고 싶지 않다면 말이죠

1351
00:52:32,543 --> 00:52:33,861
다시 한번 말하지만 이것은 완전히 선택 사항입니다.

1352
00:52:33,861 --> 00:52:40,214
하지만 아마도 학기동안 이 책의 일부를 읽으라고 공지할 수도 있습니다.
이 책은 여러분에게 추가적인 관점을 얻는데 도움을 줄 것입니다.

1353
00:52:34,261 --> 00:52:35,778


1354
00:52:35,778 --> 00:52:37,614


1355
00:52:37,614 --> 00:52:40,614


1356
00:52:41,297 --> 00:52:48,394
이 수업의 철학은 여러분이 딥러닝에 관한 모든 알고리즘을 정말로
이해해야 한다는 것입니다.

1357
00:52:41,697 --> 00:52:43,259


1358
00:52:43,259 --> 00:52:47,035


1359
00:52:47,035 --> 00:52:48,794


1360
00:52:48,394 --> 00:52:50,271
아주 깊은 수준에서 이해해야 합니다.

1361
00:52:48,794 --> 00:52:50,671


1362
00:52:50,271 --> 00:52:52,317
이 알고리듬이 정확히 어떻게 작동하는지

1363
00:52:50,671 --> 00:52:52,717


1364
00:52:52,317 --> 00:52:55,697
여러분이 뉴럴 네트워크들을 연결했을때 정확이 무슨 일이 일어나는지,

1365
00:52:52,717 --> 00:52:54,295


1366
00:52:54,295 --> 00:52:56,097


1367
00:52:55,697 --> 00:53:01,914
그런 아키텍쳐의 선택이 어떤 영향을 미치는, 네트워크가 어떻게
학습되고 테스팅 되는지 와 같은 것들입니다.

1368
00:52:56,097 --> 00:52:58,128


1369
00:52:58,128 --> 00:53:00,144


1370
00:53:00,144 --> 00:53:02,314


1371
00:53:01,914 --> 00:53:04,811
그리고 과제를 통해 코스 전반에 걸쳐셔

1372
00:53:02,314 --> 00:53:05,211


1373
00:53:04,811 --> 00:53:08,357
여러분은 아마 여러분만의 CNN을 파이썬을 이용해서
밑바닥부터 구현할 것입니다.

1374
00:53:05,211 --> 00:53:07,163


1375
00:53:07,163 --> 00:53:08,757


1376
00:53:08,357 --> 00:53:12,860
여러분은 전체 foward, backward passes을 구현할 것입니다.

1377
00:53:08,757 --> 00:53:11,560


1378
00:53:11,560 --> 00:53:13,260


1379
00:53:12,860 --> 00:53:15,920
결국, 여러분은 전체 CNN을 완벽히 구현하게 될 것입니다.

1380
00:53:13,260 --> 00:53:15,106


1381
00:53:15,920 --> 00:53:17,920
저는 이게 멋지다고 생각합니다.

1382
00:53:16,320 --> 00:53:18,320


1383
00:53:17,920 --> 00:53:23,120
하지만 실용적인 측면에서, 아마 대부분의 사람들이
이런 것들을 밑바닥부터 하지는 않을 것이라는 것을 알고 있습니다.

1384
00:53:18,320 --> 00:53:20,569


1385
00:53:20,569 --> 00:53:23,520


1386
00:53:23,120 --> 00:53:30,926
떄문에, 여러분에이 실용적으로 쓸 수 있는 일부
최신의 소프트웨어 툴을 소개해 드릴 것입니다.

1387
00:53:23,520 --> 00:53:25,613


1388
00:53:25,613 --> 00:53:27,769


1389
00:53:27,769 --> 00:53:31,326


1390
00:53:30,926 --> 00:53:37,263
Tensor Flow, Torch, PyTorch 와 같은 최신 소프트웨어에
대해서도 이야기할 것입니다.

1391
00:53:31,326 --> 00:53:33,373


1392
00:53:33,373 --> 00:53:36,392


1393
00:53:37,263 --> 00:53:44,128
아마 그럴 툴들을 이 강의의 과제나 프로젝트를
통해서 접할 수 있을 것입니다.

1394
00:53:37,663 --> 00:53:39,890


1395
00:53:39,890 --> 00:53:42,636


1396
00:53:42,636 --> 00:53:44,528


1397
00:53:44,128 --> 00:53:47,420
또 한 가지 말씀드릴 것은, 이 강의는
매우 state-of-the-art 하다는 것입니다.

1398
00:53:44,528 --> 00:53:46,303


1399
00:53:46,303 --> 00:53:47,820


1400
00:53:47,420 --> 00:53:48,722
저는 이점이 매우 흥분됩니다.

1401
00:53:48,722 --> 00:53:50,315
이 분야는 매우 빠르게 변하는 분야입니다.

1402
00:53:49,122 --> 00:53:50,715


1403
00:53:50,315 --> 00:53:55,211
여러분도 ImageNet Challenge의 그래프에서 보았듯이
2012년 이래로 엄청난 변화가 있었습니다.

1404
00:53:50,715 --> 00:53:53,337


1405
00:53:53,337 --> 00:53:55,611


1406
00:53:55,211 --> 00:54:00,138
제가 대학원에 있는 동안, 이 분야는 일년 내내 변했습니다.

1407
00:53:55,611 --> 00:53:58,840


1408
00:53:58,840 --> 00:54:00,538


1409
00:54:00,138 --> 00:54:03,349
그리고, 그것은 매우 흥분되고 매우 유망하다는 것입니다.

1410
00:54:00,538 --> 00:54:03,749


1411
00:54:03,349 --> 00:54:08,732
어쨌든, 말하고 싶었던 것은 어쩌면 우리가 저번 해에 다뤘던 내용이

1412
00:54:03,749 --> 00:54:07,177


1413
00:54:07,177 --> 00:54:09,132


1414
00:54:08,732 --> 00:54:12,493
올해에는 없을 수도 있다는 것을 의미합니다.

1415
00:54:09,132 --> 00:54:12,893


1416
00:54:12,493 --> 00:54:16,229
그것은 매우 흥미로운 부분이고, 제가 이 과목을 가르칠때
가장 좋아하는 부분 중 하나입니다.

1417
00:54:12,893 --> 00:54:14,417


1418
00:54:14,417 --> 00:54:16,629


1419
00:54:16,229 --> 00:54:23,641
이 분야는 모든 과학적인 새로운 것들을 모조리 빨아드릴 수 있고
저는 여러분들에게 이것을 알려줄 수 있다는 것입니다.

1420
00:54:16,629 --> 00:54:18,826


1421
00:54:18,826 --> 00:54:21,041


1422
00:54:21,041 --> 00:54:24,041


1423
00:54:23,641 --> 00:54:25,671
재밌는 것들도 있습니다.

1424
00:54:24,041 --> 00:54:26,071


1425
00:54:25,671 --> 00:54:30,053
심각하지 않은 재미있는 주제에 관해서도 다룰 것입니다.

1426
00:54:26,071 --> 00:54:27,770


1427
00:54:27,770 --> 00:54:30,453


1428
00:54:30,053 --> 00:54:32,722
이미지 캡셔닝과 같은 것인데, 매우 재밌습니다.

1429
00:54:30,453 --> 00:54:33,122


1430
00:54:32,722 --> 00:54:34,949
이미지 캡셔닝은 이미지에 관해 기술하는 것입니다.

1431
00:54:33,122 --> 00:54:35,349


1432
00:54:34,949 --> 00:54:39,496
그리고 여기 왼쪽에 보이는 DeepDream과 같은
좀 더 예술적인 것들에 관해서는 다룰 것입니다.

1433
00:54:35,349 --> 00:54:37,177


1434
00:54:37,177 --> 00:54:39,896


1435
00:54:39,496 --> 00:54:43,877
이것은 우리가 Neural Network를 통해
이런 사이키델릭한 이미지를 만들게도 해줍니다.

1436
00:54:39,896 --> 00:54:42,261


1437
00:54:42,261 --> 00:54:44,277


1438
00:54:43,877 --> 00:54:46,477
그리고 코스가 끝날 쯤이면, 어떻게 동작하는지 알 수 있을 겁니다.

1439
00:54:44,277 --> 00:54:45,975


1440
00:54:46,477 --> 00:54:54,940
오른쪽 그림의, style tranfer라는 아이디어는 우리에게 이미지가
있을때, 이를 피카소나 반 고흐와 같은 유명화가의 풍으로 바꿔줍니다.

1441
00:54:46,877 --> 00:54:48,900


1442
00:54:48,900 --> 00:54:50,628


1443
00:54:50,628 --> 00:54:54,507


1444
00:54:54,940 --> 00:54:56,254
그리고 다시 이 수업을 마치면

1445
00:54:56,254 --> 00:54:59,254
여러분은 어떻게 동작하는지 알게 될 것입니다.

1446
00:54:56,654 --> 00:54:59,654


1447
00:54:59,254 --> 00:55:03,394
여러분에게 수업동안 세가지 문제를 던져줄 것입니다.

1448
00:54:59,654 --> 00:55:02,519


1449
00:55:03,394 --> 00:55:07,852
첫 번째 문제는 잘하면 일주일 내로 끝날 수도 있습니다.

1450
00:55:03,794 --> 00:55:07,039


1451
00:55:07,852 --> 00:55:10,306
그리고 중간고사가 있습니다.

1452
00:55:08,252 --> 00:55:10,706


1453
00:55:10,306 --> 00:55:17,007
그리고 여러분의 학점에서 가장 큰 비율을 차지하는 것이 바로
최종 코스 프로젝트인데, 3인 1조로 진행할 것이며,

1454
00:55:10,706 --> 00:55:12,511


1455
00:55:12,511 --> 00:55:15,056


1456
00:55:15,056 --> 00:55:17,407


1457
00:55:17,007 --> 00:55:20,114
여러분들은 모든 사람들의 마음을 날려버릴만큼
놀라운 프로젝트를 만들 것입니다.

1458
00:55:17,407 --> 00:55:20,514


1459
00:55:20,114 --> 00:55:25,980
제출기한에 대한 정책도 있습니다. 도합 7일정도는 늦을 수
있고, 여러분들의 과제 수행 중 자유롭게 분배할 수 있습니다.

1460
00:55:20,514 --> 00:55:23,871


1461
00:55:23,871 --> 00:55:26,380


1462
00:55:25,980 --> 00:55:33,804
몸이 조금 아프거나, 여행을 가거나, 컨퍼런스에 참가하거나 할때
쓸 수 있을 것입니다.

1463
00:55:26,380 --> 00:55:29,549


1464
00:55:29,549 --> 00:55:34,204


1465
00:55:33,804 --> 00:55:39,571
하지만, 갑자기 학기 말에 와서는
"이번에 컨퍼런스에서 발표를 해야만 해요" 라고 말한다면

1466
00:55:34,204 --> 00:55:36,188


1467
00:55:36,188 --> 00:55:38,757


1468
00:55:39,571 --> 00:55:40,480
아마 좋지 않을것입니다.

1469
00:55:40,480 --> 00:55:42,224
이것이 바로 late days가 의미하는 것입니다.

1470
00:55:40,880 --> 00:55:42,624


1471
00:55:42,224 --> 00:55:46,243
그렇긴 해도, 만약 여러분이 정상참작할만한
이유가 있었다면

1472
00:55:42,624 --> 00:55:44,111


1473
00:55:44,111 --> 00:55:46,643


1474
00:55:46,243 --> 00:55:49,895
언제든지 조교들에게 이메일을 보내주시길 바랍니다.
피지못할 사정이 있었다면 말이죠.

1475
00:55:46,643 --> 00:55:48,705


1476
00:55:48,705 --> 00:55:50,295


1477
00:55:49,895 --> 00:55:53,777
또 한가지 알려드릴 점은
협업 정책입니다.

1478
00:55:50,295 --> 00:55:52,404


1479
00:55:52,404 --> 00:55:54,177


1480
00:55:53,777 --> 00:56:03,209
Stanford 학생으로서, 여러분은 항상 규율에 대해 알고 있어야 합니다.
이것은 아주 중요합니다.

1481
00:55:54,177 --> 00:55:55,921


1482
00:55:55,921 --> 00:55:58,389


1483
00:55:58,389 --> 00:56:00,785


1484
00:56:00,785 --> 00:56:03,609


1485
00:56:03,209 --> 00:56:07,220
우리는 여러분이 어떻게 협력하고 있는지에 대해, 그리고 그것을

1486
00:56:03,609 --> 00:56:05,635


1487
00:56:05,635 --> 00:56:07,620


1488
00:56:07,220 --> 00:56:10,637
규율의 테두리 안에 있도록 하는 것에 대해 아주
조심스럽게 생각하는 것을 장려합니다.

1489
00:56:07,620 --> 00:56:11,037


1490
00:56:11,904 --> 00:56:17,092
Pre-requisites에 대해서라면, 가장 중요한 것은
아마도 얼마나 Python에 익숙한지 일 것입니다.

1491
00:56:12,304 --> 00:56:14,378


1492
00:56:14,378 --> 00:56:17,492


1493
00:56:17,092 --> 00:56:21,939
모든 프로그래밍 과제는 Python
으로 진행 될 것이기 때문입니다.

1494
00:56:17,492 --> 00:56:20,081


1495
00:56:20,081 --> 00:56:22,339


1496
00:56:21,939 --> 00:56:25,666
C나 C++에 익숙한 것도
어느정도는 유용할 것입니다.

1497
00:56:22,339 --> 00:56:26,066


1498
00:56:25,666 --> 00:56:31,305
이번 코스에서 C나 C++을 쓰진 않을 거지만,
아마 과제를 하다 보면

1499
00:56:26,066 --> 00:56:29,354


1500
00:56:29,354 --> 00:56:31,705


1501
00:56:31,305 --> 00:56:39,479
여러 소프트웨어 패키지의 코드를 살펴볼 것이고, C++ 코드는
패키지들이 어떻게 동작하는지 이해하는데 아주 도움이 될 것입니다.

1502
00:56:31,705 --> 00:56:33,676


1503
00:56:33,676 --> 00:56:35,922


1504
00:56:35,922 --> 00:56:39,879


1505
00:56:39,479 --> 00:56:42,039
이 코스에서는 여러분이 미분에 대해 한다고
가정하고 수업을 진행할 것입니다.

1506
00:56:39,879 --> 00:56:42,439


1507
00:56:42,039 --> 00:56:44,571
여러분이 모든 종류의 미분을 할 줄 안다고도 가정할 것입니다

1508
00:56:42,439 --> 00:56:44,971


1509
00:56:44,571 --> 00:56:46,133
또한 일부 선형대수도 안다고 가정할 것입니다.

1510
00:56:44,971 --> 00:56:46,533


1511
00:56:46,133 --> 00:56:47,479
매트릭스가 뭔지 알고,

1512
00:56:47,479 --> 00:56:51,672
어떻게 곱하고 하는것들을 미리 알아야 합니다.

1513
00:56:47,879 --> 00:56:52,072


1514
00:56:51,672 --> 00:56:55,291
우리가 도함수를 계산하는 방법같은 것을
전부 다 가르칠 순 없습니다.

1515
00:56:52,072 --> 00:56:53,660


1516
00:56:53,660 --> 00:56:55,691


1517
00:56:55,291 --> 00:57:00,838
또한 우리는 CS131 또는 231a 정도 수준의 컴퓨터 비전
지식을 어느정도 알 고 있다고 가정할 것입니다.

1518
00:56:55,691 --> 00:56:57,321


1519
00:56:57,321 --> 00:56:59,821


1520
00:56:59,821 --> 00:57:01,238


1521
00:57:01,967 --> 00:57:04,720
이 과목들을 수강한 적이 있는 분들은
괜찮을 것입니다.

1522
00:57:02,367 --> 00:57:03,923


1523
00:57:04,720 --> 00:57:09,453
그렇지 않다 해도, 수업을 듣는데는 지장이 없겠지만,
따라 잡으려면 좀 더 노력해야 할 것입니다.

1524
00:57:05,120 --> 00:57:07,347


1525
00:57:07,347 --> 00:57:09,853


1526
00:57:09,453 --> 00:57:11,150
그래도 아마 큰 문제는 없으이라 봅니다.

1527
00:57:09,853 --> 00:57:11,550


1528
00:57:11,150 --> 00:57:13,304
완전 완전 필수인 prerequisites은 없습니다.

1529
00:57:11,550 --> 00:57:13,704


1530
00:57:13,304 --> 00:57:20,140
우리는 또한 CS229 정도 수준의 기계학습에
어느정도의 배경지식이 있다고 가정합니다.

1531
00:57:13,704 --> 00:57:16,964


1532
00:57:16,964 --> 00:57:20,540


1533
00:57:20,140 --> 00:57:25,323
하지만, 기계학습에서 정말 중요하고
핵심적인 개념에 대해서는 아마 제가 다시 설명해 드릴 것입니다.

1534
00:57:20,540 --> 00:57:23,556


1535
00:57:23,556 --> 00:57:25,723


1536
00:57:25,323 --> 00:57:27,355
수업 중 그 개념이 나오고, 그것이 아주 중요할때 말이죠

1537
00:57:25,723 --> 00:57:27,755


1538
00:57:27,355 --> 00:57:32,016
뭐 그렇긴 해도, 미리 익숙해 지는 것이 수업 진도를
따라가는 데 더 도움일 될 것입니다.

1539
00:57:27,755 --> 00:57:29,916


1540
00:57:29,916 --> 00:57:32,416


1541
00:57:34,374 --> 00:57:35,646
우리는 강의 홈페이지를 가지고 있습니다.

1542
00:57:35,646 --> 00:57:36,550
가서 확인해 보세요

1543
00:57:36,550 --> 00:57:39,342
많은 정보나 링크, 교수과목 등 많은 것들이 있습니다.

1544
00:57:36,950 --> 00:57:38,303


1545
00:57:38,303 --> 00:57:39,742


1546
00:57:39,342 --> 00:57:43,256
그 모든 것들이 제가 이번 수업에서
정말로 다루고 싶은 것들 입니다.

1547
00:57:39,742 --> 00:57:43,656


1548
00:57:43,256 --> 00:57:48,757
그리고 이번 주 목요일에, 우리는 첫번째
학습 알고리즘부터 시작할 것이고, 세부사항을 알아 볼 것입니다.

1549
00:57:43,656 --> 00:57:46,157


1550
00:57:46,157 --> 00:57:48,733


1551
00:57:48,733 --> 00:00:00,000

