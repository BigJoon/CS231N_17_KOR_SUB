1
00:00:00,000 --> 00:00:06,000
Translated by visionNoob, KNU
https://github.com/insurgent92/CS231N_17_KOR_SUB

2
00:00:07,041 --> 00:00:09,708
 CS231n 수업에 오신 것을 환영합니다.

3
00:00:11,362 --> 00:00:15,107
이번 수업을 다시 진행하게 되어 영광입니다.

4
00:00:15,107 --> 00:00:21,523
CS231n 수업은 정말 빠르게 성장하고 있습니다.

5
00:00:21,123 --> 00:00:24,034
이번으로 세 번째 개설되었는데요

6
00:00:24,034 --> 00:00:26,066
처음에는 150명으로 시작했죠

7
00:00:26,066 --> 00:00:28,600
지난 해에는 350명이 수강하였습니다. 두 배지요.

8
00:00:28,600 --> 00:00:34,406
올해에는 또 두 배가 늘어서 오늘 아침에 확인했을 때
약 730 명의 학생이 수강신청을 해주셨습니다.

9
00:00:34,406 --> 00:00:39,694
안타깝게도 강의실 제한으로 수업에 참여하지 못하는 분들도 계십니다.

10
00:00:39,694 --> 00:00:44,531
하지만 강의 동영상이 두 시간 내로
SCPD 웹 사이트에 게시 될 것입니다.

11
00:00:44,531 --> 00:00:50,489
오늘 여기 와서 수업을 듣지 못했어도
몇 시간 후면 바로 확인 하실 수 있습니다.

12
00:00:44,931 --> 00:00:46,900


13
00:00:46,900 --> 00:00:50,889


14
00:00:50,489 --> 00:00:54,676
CS231n은 컴퓨터 비전에 관한 수업입니다.

15
00:00:50,889 --> 00:00:55,076


16
00:00:54,676 --> 00:00:57,012
그렇다면 컴퓨터 비전(Computer Vision)이 무엇일까요?

17
00:00:55,076 --> 00:00:57,412


18
00:00:57,012 --> 00:00:59,741
컴퓨터비전은 시각데이터(visual data)와
관련된 연구입니다.

19
00:00:57,412 --> 00:01:00,141


20
00:00:59,741 --> 00:01:05,819
요즘은 워낙 컴퓨터비전이 유명해서 제가 굳이
이 분야의 중요성을 강조할 필요는 없겠지만

21
00:01:00,141 --> 00:01:02,578


22
00:01:02,578 --> 00:01:04,522


23
00:01:04,522 --> 00:01:06,219


24
00:01:05,819 --> 00:01:09,632
어쨌든 전 계속 컴퓨터비전의 중요성을 강조할 것입니다.

25
00:01:06,219 --> 00:01:10,032


26
00:01:06,622 --> 00:01:10,134


27
00:01:09,632 --> 00:01:15,361
최근 몇 년간 엄청나게 많은 시각 데이터가
쏟아져 나오고 있습니다.

28
00:01:10,032 --> 00:01:11,895


29
00:01:11,895 --> 00:01:14,173


30
00:01:14,173 --> 00:01:15,761


31
00:01:15,361 --> 00:01:19,998
이런 수 많은 데이터들은 전 세계 각처에 퍼져있는
무수한 센서들로 비롯됩니다.

32
00:01:15,761 --> 00:01:17,613


33
00:01:17,613 --> 00:01:20,398


34
00:01:19,998 --> 00:01:22,664
요즘은 스마트폰이 없는 분들을 더 찾기 힘듭니다.

35
00:01:20,398 --> 00:01:21,759


36
00:01:22,664 --> 00:01:26,589
여러분의 스마트폰에는 한 두개의 카메라가 내장되어 있습니다.
많으면 세 개까지도 말이죠

37
00:01:23,064 --> 00:01:25,004


38
00:01:25,004 --> 00:01:26,989


39
00:01:26,589 --> 00:01:30,714
아마 카메라의 수가 전 세계 인구수보다 많을지도 모릅니다.

40
00:01:26,989 --> 00:01:28,974


41
00:01:28,974 --> 00:01:31,114


42
00:01:30,714 --> 00:01:38,108
이런 카메라와 같은 센서들이 전 세계 각지에서
매일매일 데이터를 쏟아내고 있는 실정입니다.

43
00:01:31,114 --> 00:01:32,765


44
00:01:32,765 --> 00:01:35,371


45
00:01:33,225 --> 00:01:36,475


46
00:01:35,371 --> 00:01:37,524


47
00:01:38,108 --> 00:01:46,625
CISCO에서 수행한 2015 ~ 2017년도 까지의 한 통계자료가
이 사실을 아주 적나라하게 보여줍니다.

48
00:01:38,508 --> 00:01:41,239


49
00:01:41,239 --> 00:01:43,858


50
00:01:43,858 --> 00:01:47,025


51
00:01:46,719 --> 00:01:54,084
통계에 따르면 인터넷 트래픽 중 80%의 지분은 바로
비디오 데이터입니다.

52
00:01:48,919 --> 00:01:51,784


53
00:01:50,738 --> 00:01:59,214


54
00:01:51,784 --> 00:01:54,484


55
00:01:54,084 --> 00:02:00,125
심지어 이 결과는 사진과 같은 다른 시각
데이터들을 모두 제외한 결과이죠

56
00:01:54,484 --> 00:01:58,074


57
00:01:58,074 --> 00:02:00,525


58
00:02:00,125 --> 00:02:07,076
이 통계는 인터넷의 대부분의 데이터가
시각 데이터라는 사실을 보여줍니다.

59
00:02:00,525 --> 00:02:03,880


60
00:02:03,880 --> 00:02:06,002


61
00:02:06,002 --> 00:02:07,476


62
00:02:07,076 --> 00:02:12,757
그러니 시각 데이터들을 잘 활용할 수 있는
알고리즘을 잘 개발하는 것이 무엇보다 중요하겠죠

63
00:02:07,476 --> 00:02:09,547


64
00:02:09,547 --> 00:02:13,157


65
00:02:12,757 --> 00:02:17,413
하지만 문제 있습니다. 이런 시각데이터는
해석하기 상당히 까다롭다는 점이죠

66
00:02:13,157 --> 00:02:15,370


67
00:02:15,370 --> 00:02:17,813


68
00:02:17,413 --> 00:02:24,126
일부는 시각 데이터를 암흑물질(dark matter)이라고 합니다.

69
00:02:17,813 --> 00:02:20,813


70
00:02:20,813 --> 00:02:24,526


71
00:02:22,935 --> 00:02:28,895


72
00:02:24,126 --> 00:02:27,037
물리학 수업에서 암흑물질을 들어본 분들도 계실테지만

73
00:02:24,526 --> 00:02:27,437


74
00:02:27,037 --> 00:02:32,977
우주의 대부분의 질량을 차지하고
있는 물질이 바로 암흑 물질입니다.

75
00:02:27,437 --> 00:02:31,180


76
00:02:28,895 --> 00:02:44,581


77
00:02:31,180 --> 00:02:33,377


78
00:02:32,977 --> 00:02:37,893
우리는 여러가지 간접적인 측정실험을 통해서
암흑물질의 "존재" 까지는 알 수 있었지만

79
00:02:33,377 --> 00:02:35,167


80
00:02:35,167 --> 00:02:38,293


81
00:02:37,893 --> 00:02:40,135
암흑물질을 직접적으로 "관측" 할 수는 없습니다.

82
00:02:38,293 --> 00:02:40,535


83
00:02:40,135 --> 00:02:42,438
시각데이터 사실 그렇습니다

84
00:02:40,535 --> 00:02:42,838


85
00:02:42,438 --> 00:02:55,285
시각 데이터가 대부분이지만 사실상 이들을
이해하고 해석하는 일은 상당히 어렵습니다.

86
00:02:42,838 --> 00:02:45,488


87
00:02:45,488 --> 00:02:49,164


88
00:02:47,632 --> 00:02:51,649


89
00:02:49,164 --> 00:02:51,313


90
00:02:51,313 --> 00:02:54,222


91
00:02:51,649 --> 00:02:56,413


92
00:02:54,222 --> 00:02:55,685


93
00:02:55,285 --> 00:02:58,066
Youtube의 통계자료도 있습니다.

94
00:02:55,685 --> 00:02:58,466


95
00:02:56,413 --> 00:03:06,588


96
00:02:58,066 --> 00:03:07,346
 YouTube는 매 초마다 다섯 시간 분량의
비디오가 업로드된다고 합니다.

97
00:02:58,466 --> 00:03:02,309


98
00:03:02,309 --> 00:03:05,303


99
00:03:05,303 --> 00:03:07,746


100
00:03:07,346 --> 00:03:15,196
우리가 "하나... 둘... 셋..." 세고 나면
YouTube에는 15시간 분량의 비디오가 새로 추가된 것이지요

101
00:03:07,746 --> 00:03:09,305


102
00:03:09,305 --> 00:03:12,805


103
00:03:10,145 --> 00:03:15,130


104
00:03:13,929 --> 00:03:15,596


105
00:03:16,676 --> 00:03:23,746
Google 직원이 아무리 많아도 이 모든 비디오를  직접 보고,
이해하고, 정리한다는 것은 사실상 불가능한 일입니다.

106
00:03:17,076 --> 00:03:18,824


107
00:03:18,824 --> 00:03:21,219


108
00:03:21,219 --> 00:03:24,146


109
00:03:23,746 --> 00:03:28,961
따라서 그들이 비디오들을 잘 정리해서 유저들에게 제공하고
또 비디오에 적절한 광고를 달기 위해서는

110
00:03:24,146 --> 00:03:26,856


111
00:03:26,856 --> 00:03:29,361


112
00:03:28,961 --> 00:03:36,653
자동으로 시각데이터를 이해, 분석하는 알고리즘을
개발하는 것이 관건인 셈입니다.

113
00:03:29,361 --> 00:03:32,057


114
00:03:32,057 --> 00:03:34,803


115
00:03:34,803 --> 00:03:37,053


116
00:03:38,249 --> 00:03:47,164
컴퓨터 비전이라는 분야 주변에는 상당이 많은 분야들이 혼재합니다.
따라서 다양한 과학, 공학 분야들과 맞닥뜨리게 됩니다.

117
00:03:38,649 --> 00:03:41,379


118
00:03:41,379 --> 00:03:44,089


119
00:03:44,089 --> 00:03:45,864


120
00:03:45,864 --> 00:03:47,564


121
00:03:47,164 --> 00:03:50,422
컴퓨터비전이 우주(universe)의 중심이라 할 수 있겠죠

122
00:03:47,564 --> 00:03:50,822


123
00:03:48,822 --> 00:03:57,237


124
00:03:50,422 --> 00:03:56,053
하지만 컴퓨터비전 뿐만 아니라
물리학을 다뤄야 할 수도 있습니다.

125
00:03:50,822 --> 00:03:53,914


126
00:03:53,914 --> 00:03:56,453


127
00:03:56,053 --> 00:04:01,384
 광학, 이미지 구성, 이미지의 물리학적 형성등을 이해하려면
물리학적인 현상들을 이해할 필요가 있기 때문입니다.

128
00:03:56,453 --> 00:03:59,418


129
00:03:59,418 --> 00:04:01,784


130
00:04:01,384 --> 00:04:03,595
생물학이나 심리학도 알아야 합니다.

131
00:04:01,784 --> 00:04:03,995


132
00:04:03,595 --> 00:04:09,494
동물의 뇌가 어떤 방식으로 시각정보를
물리적으로 "보고 처리하는지" 를 이해하려면 말이죠

133
00:04:03,995 --> 00:04:07,879


134
00:04:04,232 --> 00:04:10,576


135
00:04:07,879 --> 00:04:09,894


136
00:04:09,494 --> 00:04:13,905
물론 그 밖에 컴퓨터 과학, 수학, 그리고 공학 등도 다룹니다.

137
00:04:09,894 --> 00:04:12,045


138
00:04:10,576 --> 00:04:19,197


139
00:04:12,045 --> 00:04:14,305


140
00:04:13,905 --> 00:04:19,239
컴퓨터비전 알고리즘을 구현할 컴퓨터시스템을
실제로 구축할 때 필요한 분야들이죠

141
00:04:14,305 --> 00:04:16,954


142
00:04:16,954 --> 00:04:19,639


143
00:04:19,240 --> 00:04:25,592
그럼 이제 저를 포함한 이 수업의 교수진과
운영진을 간단히 설명해 드리겠습니다.

144
00:04:19,640 --> 00:04:22,595


145
00:04:22,595 --> 00:04:24,985


146
00:04:25,592 --> 00:04:33,206
저와 Serena는 Fei-Fei Li 교수님의 지도 하에 있는
Stanford Vision Lab의 박사과정 (PhD) 학생 입니다.

147
00:04:25,992 --> 00:04:30,722


148
00:04:26,740 --> 00:04:33,938


149
00:04:30,722 --> 00:04:33,606


150
00:04:33,206 --> 00:04:40,784
그리고 저희 Lab은 기계학습과 컴퓨터과학에
관련된 연구들을 진행하고 있습니다.

151
00:04:33,606 --> 00:04:37,184


152
00:04:33,938 --> 00:04:44,003


153
00:04:37,184 --> 00:04:39,940


154
00:04:40,784 --> 00:04:42,908
저 같은 경우에는 Language와 Vision에 좀 더 집중하고 있습니다.

155
00:04:41,184 --> 00:04:43,308


156
00:04:42,908 --> 00:04:44,500
저희 Lab에서는 다양한 연구를 진행하고 있습니다.

157
00:04:43,308 --> 00:04:44,900


158
00:04:44,500 --> 00:04:49,375
그 밖에도 Lab에서는 신경과학과 인지과학과 관련된 분야도 연구합니다.

159
00:04:44,900 --> 00:04:46,658


160
00:04:46,658 --> 00:04:48,525


161
00:04:48,525 --> 00:04:49,775


162
00:04:52,141 --> 00:04:57,157
아마도 여러분은 CS231n이 Stanford의 다른 수업들과
어떤 연관성이 있는지 궁금하실 것입니다.

163
00:04:52,541 --> 00:04:54,404


164
00:04:54,404 --> 00:04:57,557


165
00:04:57,157 --> 00:05:02,448
이 수업은 여러분이 컴퓨터비전의 기초개론을
알고 있다고 가정하고 수업을 진행합니다.

166
00:04:57,557 --> 00:05:01,408


167
00:04:58,579 --> 00:05:12,251


168
00:05:01,408 --> 00:05:02,848


169
00:05:02,448 --> 00:05:06,526
그러니 만일 여러분이 학부생이거나
혹은 컴퓨터비전이 처음이시라면

170
00:05:02,848 --> 00:05:04,787


171
00:05:04,787 --> 00:05:06,926


172
00:05:06,526 --> 00:05:13,829
Fei-Fei 와 Juan Carlos Niebles의 CS131를
선수과목을 수강하셨어야 합니다.

173
00:05:06,926 --> 00:05:09,698


174
00:05:09,698 --> 00:05:14,229


175
00:05:12,251 --> 00:05:18,442


176
00:05:13,829 --> 00:05:24,525
그리고 Chris Mannin & Richard Socher의
딥러닝 & 자연어처리 수업이 지난학기에 있었습니다.

177
00:05:14,229 --> 00:05:17,361


178
00:05:17,361 --> 00:05:20,836


179
00:05:18,442 --> 00:05:27,729


180
00:05:20,836 --> 00:05:22,705


181
00:05:22,705 --> 00:05:24,925


182
00:05:24,525 --> 00:05:28,195
아마 대다수가 지난 학기에 그 수업을 수강 하셨을것 같습니다.

183
00:05:24,925 --> 00:05:27,512


184
00:05:27,512 --> 00:05:28,595


185
00:05:27,729 --> 00:05:30,633


186
00:05:31,082 --> 00:05:33,385
CS231n은 그 수업과 일부 겹치는 부분이 있습니다.

187
00:05:31,482 --> 00:05:33,785


188
00:05:33,385 --> 00:05:40,044
하지만 여기에서는 컴퓨터비전에 초점을 맞춥니다.

189
00:05:33,785 --> 00:05:35,769


190
00:05:35,769 --> 00:05:38,861


191
00:05:38,861 --> 00:05:40,444


192
00:05:40,961 --> 00:05:46,978
또한 Silvio Savarese 교수께서 이번
학기에 CS231a를 강의하십니다.

193
00:05:41,361 --> 00:05:43,078


194
00:05:43,078 --> 00:05:47,378


195
00:05:46,978 --> 00:05:53,610
그리고 CS231a는 컴퓨터비전을 둘러싼
조금 더 넓은 분야들에 초점을 맞추고 있습니다.

196
00:05:47,378 --> 00:05:52,306


197
00:05:50,296 --> 00:05:53,629


198
00:05:52,306 --> 00:05:54,010


199
00:05:53,610 --> 00:06:03,413
3D reconstruction, 로봇 비전 등
CS231n보다 광범위한 분야를 다루게 됩니다.

200
00:05:54,010 --> 00:05:57,569


201
00:05:55,661 --> 00:05:58,563


202
00:05:57,569 --> 00:05:59,896


203
00:05:58,563 --> 00:06:01,563


204
00:05:59,896 --> 00:06:01,412


205
00:06:01,412 --> 00:06:03,813


206
00:06:03,413 --> 00:06:13,386
여기 CS231n은 신경망(Neural Network), 특히 CNN과
관련된 세부 분야를 중점적으로 배우게 될 것입니다.

207
00:06:03,813 --> 00:06:06,647


208
00:06:06,647 --> 00:06:09,358


209
00:06:09,358 --> 00:06:11,922


210
00:06:11,922 --> 00:06:13,786


211
00:06:13,386 --> 00:06:15,828
그리고 이런 알고리즘들은 다양한 테스크에 사용됩니다.

212
00:06:13,786 --> 00:06:16,228


213
00:06:14,442 --> 00:06:19,793


214
00:06:15,828 --> 00:06:18,778
물론 세미나 수업도 진행할 예정입니다.

215
00:06:16,228 --> 00:06:17,725


216
00:06:17,725 --> 00:06:19,178


217
00:06:18,778 --> 00:06:27,467
세미나 일정이 매년 변동하므로 자세한 사항은
강의계획서와 수업시간표를 확인하시길 바랍니다.

218
00:06:19,178 --> 00:06:21,154


219
00:06:19,793 --> 00:06:23,960


220
00:06:21,154 --> 00:06:24,631


221
00:06:24,631 --> 00:06:27,867


222
00:06:27,467 --> 00:06:31,272
보통 첫 수업은 Fei-Fei Li 교수님이 진행하시지만

223
00:06:27,867 --> 00:06:29,914


224
00:06:29,914 --> 00:06:31,672


225
00:06:31,272 --> 00:06:33,774
안타깝게도 오늘 오실 수 없으셨습니다.

226
00:06:31,672 --> 00:06:34,174


227
00:06:33,774 --> 00:06:38,063
대신 Fei Fei 교수님이 안계시므로 다른 방법을 고안했습니다.

228
00:06:34,174 --> 00:06:36,439


229
00:06:34,814 --> 00:06:38,981


230
00:06:36,439 --> 00:06:38,463


231
00:06:38,063 --> 00:06:44,372
교수님께서 Computer Vision의 역사를 소개하는
비디오를  녹화하셨습니다.

232
00:06:38,463 --> 00:06:41,996


233
00:06:41,996 --> 00:06:44,772


234
00:06:44,372 --> 00:06:47,829
이 수업은 컴퓨터비전 수업이기 때문에

235
00:06:44,772 --> 00:06:48,229


236
00:06:47,829 --> 00:06:57,600
오늘날의 CNN을 발전시킨 기존연구의
역사와 흐름을 이해해야만 합니다.

237
00:06:48,229 --> 00:06:50,456


238
00:06:50,456 --> 00:06:53,289


239
00:06:52,061 --> 00:06:57,077


240
00:06:53,289 --> 00:06:55,183


241
00:06:55,183 --> 00:06:58,000


242
00:06:58,100 --> 00:06:59,600
가상의 Fei Fei 교수님을 소개하겠습니다.

243
00:06:58,500 --> 00:07:00,000


244
00:06:59,998 --> 00:07:01,515
[웃음]

245
00:07:00,398 --> 00:07:01,915


246
00:07:01,515 --> 00:07:05,100
여러분께 컴퓨터비전의 역사를 간단히 소개해 주실 것입니다.

247
00:07:01,915 --> 00:07:03,800


248
00:07:02,338 --> 00:07:17,465


249
00:07:04,000 --> 00:07:05,500


250
00:07:08,210 --> 00:07:20,220
자 우선 오늘의 강의목표를 살펴 보겠습니다. 두 가지 주제가 있습니다.
컴퓨터비전의 역사와 우리 CS231n 수업의 개요입니다.

251
00:07:08,610 --> 00:07:15,309


252
00:07:15,309 --> 00:07:20,620


253
00:07:17,465 --> 00:07:22,337


254
00:07:20,220 --> 00:07:35,700
그렇다면 비전(시각)과 컴퓨터비전이 언제 어디에서 비롯됬고
현재는 어디쯤에 왔는지를 알아 보겠습니다.

255
00:07:20,620 --> 00:07:28,539


256
00:07:23,635 --> 00:07:28,937


257
00:07:28,540 --> 00:07:36,100


258
00:07:32,256 --> 00:07:35,164


259
00:07:35,700 --> 00:07:44,370
비전의 역사는 아주 오래 전으로 돌아갑니다.
정확하게는 5억 4천만년 전이죠.

260
00:07:36,100 --> 00:07:44,770


261
00:07:37,715 --> 00:07:41,611


262
00:07:44,370 --> 00:07:50,400
그 시대의 삶은 어땠을까요?
지구의 대부분은 물이었고

263
00:07:44,770 --> 00:07:50,800


264
00:07:46,082 --> 00:07:48,002


265
00:07:48,002 --> 00:07:52,990


266
00:07:50,520 --> 00:07:57,900
바다를 부유하는 일부 생물들만 존재했습니다.

267
00:07:50,920 --> 00:07:58,300


268
00:07:52,990 --> 00:07:55,361


269
00:07:55,361 --> 00:07:57,321


270
00:07:57,900 --> 00:08:03,330
이들의 삶은 단조로웠습니다. 그들은 많이 움직이지 않았고
눈(eyes)같은건 존재하지 않았습니다.

271
00:07:58,300 --> 00:08:03,730


272
00:08:03,330 --> 00:08:09,240
먹이가 주변에 있으면 잡아먹고 없으면
그저 둥둥 떠있는 것이 다였습니다.

273
00:08:03,730 --> 00:08:09,640


274
00:08:06,520 --> 00:08:15,060


275
00:08:09,240 --> 00:08:16,740
하지만 5억 4천만년 전에 아주 놀라운 사건이 벌어졌습니다.

276
00:08:09,640 --> 00:08:17,140


277
00:08:16,740 --> 00:08:33,420
동물 학자들은 화석을 연구하면서 천 만년 이라는 아주 짧은 시기동안에
생물의 종이 폭발적으로 늘어났다는 것을 발견했습니다.

278
00:08:17,140 --> 00:08:25,509


279
00:08:23,498 --> 00:08:32,730


280
00:08:25,509 --> 00:08:33,820


281
00:08:33,420 --> 00:08:41,100
얼마 없던 종의 수가 수십 만이 된 것입니다.
정말 신기한 일이었습니다. 이유가 무엇이었을까요?

282
00:08:33,820 --> 00:08:41,500


283
00:08:39,933 --> 00:08:42,350


284
00:08:41,100 --> 00:08:55,140
많은 가설이 있었지만 여전히 수 년간 풀지못한 숙제였습니다.
진화 생물학자들은 이를 "진화의 빅뱅" 이라고 불렀습니다.

285
00:08:41,500 --> 00:08:47,920


286
00:08:43,499 --> 00:08:47,166


287
00:08:47,920 --> 00:08:55,540


288
00:08:48,849 --> 00:08:57,162


289
00:08:55,140 --> 00:09:00,899
몇해 전 오스트레일리아의 동물학자인 앤드류 파커는
화석 연구를 통해 가장 설득력 있는 가설 제안하였습니다.

290
00:08:55,540 --> 00:09:01,299


291
00:08:57,162 --> 00:09:08,201


292
00:09:00,899 --> 00:09:18,910
그는 약 5억 4천만 년 전 최초의 눈(eyes)이 생겨났다는
것을 발견했습니다. 비젼(시각)의 탄생이

293
00:09:01,299 --> 00:09:07,030


294
00:09:07,030 --> 00:09:19,310


295
00:09:08,201 --> 00:09:12,747


296
00:09:12,747 --> 00:09:22,579


297
00:09:18,910 --> 00:09:26,210
폭발적인 종 분화의 시기를 촉발시킨 것입니다. 생물들은
갑자기 볼 수 있게 되었습니다. 볼 수 있다면 삶은

298
00:09:19,310 --> 00:09:26,610


299
00:09:22,579 --> 00:09:29,537


300
00:09:26,210 --> 00:09:32,180
훨씬 더 능동적이됩니다. 일부 포식자들은 먹이를 찾아다니고

301
00:09:26,610 --> 00:09:32,580


302
00:09:29,537 --> 00:09:33,229


303
00:09:32,180 --> 00:09:39,580
먹이들은 포식자로부터 달아나야만 했죠.
그래서 비전의 도래는

304
00:09:32,580 --> 00:09:39,980


305
00:09:33,229 --> 00:09:37,993


306
00:09:37,993 --> 00:09:43,105


307
00:09:39,580 --> 00:09:46,460
진화적 군비경쟁을 촉발시켰고  생물들은
한 종으로써 살아남기 위해서 빠르게 진화해야 했습니다.

308
00:09:39,980 --> 00:09:46,860


309
00:09:43,105 --> 00:09:50,955


310
00:09:46,460 --> 00:09:54,470
이것이 바로 비전의 태동입니다  5억 4천만년 후(현재)

311
00:09:46,860 --> 00:09:54,870


312
00:09:50,955 --> 00:09:59,822


313
00:09:54,470 --> 00:10:00,980
비전은 거의 모든 동물들, 특히 지능을 가진 동물들의

314
00:09:54,870 --> 00:10:01,380


315
00:09:59,822 --> 00:10:03,972


316
00:10:00,980 --> 00:10:09,260
가장 큰 감각 체계로 발전했습니다.
우리 인간은 대뇌 피질의 50% 가량의 뉴런이

317
00:10:01,380 --> 00:10:09,660


318
00:10:05,215 --> 00:10:09,591


319
00:10:09,260 --> 00:10:15,050
시각처리를 관여합니다.
비전은 가장 큰 감각체계이며

320
00:10:09,660 --> 00:10:15,450


321
00:10:15,050 --> 00:10:22,190
우리가 생존하고, 일을 하고,
움직이고, 어떤 것들을 다루고,

322
00:10:15,450 --> 00:10:22,590


323
00:10:16,045 --> 00:10:22,747


324
00:10:22,190 --> 00:10:29,330
의사소통하고, 오락을 즐기는 등 많은 것들을 가능하게 해줍니다.
비전은 동물들에게 중요하며

325
00:10:22,590 --> 00:10:29,730


326
00:10:23,987 --> 00:10:33,715


327
00:10:29,330 --> 00:10:38,530
특히 지능을 가진 동물들에게 정말 중요합니다.
지금까지는 생물학적 비전의

328
00:10:29,730 --> 00:10:38,930


329
00:10:34,916 --> 00:10:38,065


330
00:10:38,530 --> 00:10:47,929
짧은 줄거리였습니다만, 그렇다면 인간이 만든 공학적 비전인
카메라의 역사는 어떨까요?

331
00:10:38,930 --> 00:10:48,329


332
00:10:42,583 --> 00:10:47,265


333
00:10:47,929 --> 00:10:56,050
오늘날 우리가 알고있는 초창기의 카메라는

334
00:10:48,329 --> 00:10:56,450


335
00:10:56,050 --> 00:11:04,010
1600년대 르네상스 시대의 카메라인 obscura입니다.

336
00:10:56,450 --> 00:11:04,410


337
00:11:04,010 --> 00:11:13,330
이 카메라는 핀홀 카메라 이론을 기반으로한 카메라입니다.

338
00:11:04,410 --> 00:11:13,730


339
00:11:05,859 --> 00:11:09,403


340
00:11:11,098 --> 00:11:18,177


341
00:11:13,330 --> 00:11:20,990
Obscura는 생물학적으로 발전한 초기의 눈과 상당히 유사합니다.
빛을 모아주는 구멍이 하나 있고

342
00:11:13,730 --> 00:11:21,390


343
00:11:18,177 --> 00:11:30,493


344
00:11:20,990 --> 00:11:27,620
카메라 뒷편의 평평한 면은 정보를 모으고

345
00:11:21,390 --> 00:11:28,020


346
00:11:27,620 --> 00:11:36,160
이미지를 투영합니다. 카메라 기술이 발전하면서
오늘날 카메라는 어디에나 있습니다.

347
00:11:28,020 --> 00:11:36,560


348
00:11:30,493 --> 00:11:34,660


349
00:11:36,160 --> 00:11:40,510
카메라는 스마트폰 카메라나 다른 여러 기기에 이르기까지
사람들이 사용하는 가장 인기있는 센서중 하나가 되었습니다.

350
00:11:36,560 --> 00:11:40,910


351
00:11:40,510 --> 00:11:56,110
그동안에 생물학자들은 비전의 매커니즘을 연구하기 시작했습니다.
인간과 동물의 비전에 연구에 가장 영향력있었을 뿐만 아니라

352
00:11:40,910 --> 00:11:49,040


353
00:11:49,040 --> 00:11:56,510


354
00:11:55,001 --> 00:11:56,437


355
00:11:56,110 --> 00:12:10,450
컴퓨터비전에도 영감을  준 한 연구가 있었습니다. 1950/60년대
전기생리학을 이용한 Hubel과 Wiesel의 연구입니다.

356
00:11:56,510 --> 00:12:02,690


357
00:12:02,690 --> 00:12:10,850


358
00:12:06,393 --> 00:12:10,843


359
00:12:10,450 --> 00:12:17,770
그들이 묻고싶었던 질문은 바로
"포유류의 시각적 처리 메커니즘은 무엇일까?" 였습니다.

360
00:12:10,850 --> 00:12:18,170


361
00:12:17,770 --> 00:12:26,200
그래서 그들은 고양이의 뇌를 연구하기로 합니다.

362
00:12:18,170 --> 00:12:26,600


363
00:12:19,846 --> 00:12:26,078


364
00:12:26,200 --> 00:12:31,690
시각 처리 매커니즘만 보면
고양이와 인간은 비슷합니다.

365
00:12:26,600 --> 00:12:32,090


366
00:12:31,690 --> 00:12:45,430
그들의 고양이 두뇌 뒷 면에 전극 몇 개를 꽂았습니다.
"일차 시각 피질"이 있는 곳이었죠

367
00:12:32,090 --> 00:12:37,490


368
00:12:37,490 --> 00:12:45,830


369
00:12:39,668 --> 00:12:53,531


370
00:12:45,430 --> 00:12:52,570
그리고 어떤 자극을 줘야 일차 시각 피질의 뉴런들이
격렬하게 반응 하는지 관찰하였습니다.

371
00:12:45,830 --> 00:12:52,970


372
00:12:52,570 --> 00:12:59,980
그들은일차 시각 피질에는 댜양한 종류의
세포가 있다는 것을 알았습니다.

373
00:12:52,970 --> 00:13:00,380


374
00:12:55,792 --> 00:13:05,071


375
00:12:59,980 --> 00:13:11,680
그중 가장 중요한 세포가 있었는데 그 세포들은 아주 단순했습니다.
경계(edges)가 움직이면 이에 반응하는 세포들이었습니다.

376
00:13:00,380 --> 00:13:05,630


377
00:13:05,630 --> 00:13:12,080


378
00:13:06,056 --> 00:13:15,003


379
00:13:11,680 --> 00:13:25,660
물론 더 복잡한 세포들도 있긴 하지만, 주된 발견은
시각 처리가 처음에는 단순한 구조로 시작되며

380
00:13:12,080 --> 00:13:18,410


381
00:13:16,530 --> 00:13:18,790


382
00:13:18,410 --> 00:13:26,060


383
00:13:18,790 --> 00:13:24,881


384
00:13:25,660 --> 00:13:38,160
그 정보가 통로를 거치면서 점점 복잡해 진다는 것입니다.

385
00:13:26,060 --> 00:13:32,210


386
00:13:32,210 --> 00:13:38,560


387
00:13:34,012 --> 00:13:40,092


388
00:13:38,160 --> 00:13:45,880
실제 세상을 제대로 인지할 수 있을 때 까지 말이죠.

389
00:13:38,560 --> 00:13:46,280


390
00:13:41,663 --> 00:13:48,623


391
00:13:45,880 --> 00:13:54,670
컴퓨터비전의 역사는 60년대 초반에 태동합니다.
Block World는 Larry Roberts의 연구는

392
00:13:46,280 --> 00:13:55,070


393
00:13:48,623 --> 00:13:49,528


394
00:13:49,528 --> 00:13:53,539


395
00:13:53,539 --> 00:13:57,422


396
00:13:54,670 --> 00:14:06,850
아마도 컴퓨터비전 분야에서의 최초의 박사 학위논문입니다.

397
00:13:55,070 --> 00:14:00,410


398
00:13:57,422 --> 00:14:05,596


399
00:14:00,410 --> 00:14:07,250


400
00:14:05,596 --> 00:14:09,814


401
00:14:06,850 --> 00:14:13,450
이 연구에서는 우리 눈에 보이는 사물들을
기하학적 모양으로 단순화 시켰습니다.

402
00:14:07,250 --> 00:14:13,850


403
00:14:13,450 --> 00:14:23,019
이 연구의 목표는 우리 눈에 보이는 세상을 인식하고
그 모양을 재구성 하는 일이었습니다.

404
00:14:13,850 --> 00:14:23,419


405
00:14:19,108 --> 00:14:24,559


406
00:14:23,019 --> 00:14:31,150
1966년에는 MIT 여름 프로젝트가 하나 진행되었는데, 아주 유명하죠
바로 "The Summer Vision Project" 입니다.

407
00:14:23,419 --> 00:14:31,550


408
00:14:24,559 --> 00:14:36,545


409
00:14:31,150 --> 00:14:38,040
당시 프로젝트의 목표는, 제가 읽어드리겠습니다.
"시각 시스템의 전반을 구현하기 위해서

410
00:14:31,550 --> 00:14:38,440


411
00:14:36,545 --> 00:14:42,179


412
00:14:38,040 --> 00:14:43,840
프로젝트 참가자들을 효율적으로 이용하는 것."
이였습니다.

413
00:14:38,440 --> 00:14:44,240


414
00:14:42,179 --> 00:14:50,653


415
00:14:43,840 --> 00:14:47,380
다시 말해  그들은 그 여름 안에 대부분의 시각 체계를 구현해
내려는 야심찬 목표를 세우고 있었던 것입니다.

416
00:14:44,240 --> 00:14:47,780


417
00:14:47,380 --> 00:14:54,190
이는 아주 야심 찬 목표였습니다.
그로부터 50년이 지났습니다.

418
00:14:47,780 --> 00:14:54,590


419
00:14:50,653 --> 00:14:58,988


420
00:14:54,190 --> 00:15:01,840
"컴퓨터비전"이라는 분야가 한 여름 프로젝트에서 피어나서는

421
00:14:54,590 --> 00:15:02,240


422
00:14:58,988 --> 00:15:13,131


423
00:15:01,840 --> 00:15:13,540
현재 전 세계 수천 명의 연구자들이 아직도 비전의
가장 근본적인 문제들을 연구를 하고 있습니다.

424
00:15:02,240 --> 00:15:07,610


425
00:15:07,610 --> 00:15:13,940


426
00:15:13,540 --> 00:15:20,980
컴퓨터비전은 인공지능 분야에서 가장 중요하면서도
가장 빠르게 성장하는 분야중 하나입니다.

427
00:15:13,940 --> 00:15:21,380


428
00:15:17,312 --> 00:15:20,986


429
00:15:20,980 --> 00:15:27,010
언급하지 않을 수 없는 인물하 한 명 더 있습니다.
그는 바로 David Marr입니다.

430
00:15:21,380 --> 00:15:27,410


431
00:15:27,010 --> 00:15:34,150
David Marr은 MIT의 비전 과학자였으며
그는 70년대 후기에 아주 유명한 책을 한권 저술합니다.

432
00:15:27,410 --> 00:15:34,550


433
00:15:28,231 --> 00:15:32,768


434
00:15:32,768 --> 00:15:35,473


435
00:15:34,150 --> 00:15:47,800
이 책은 그가 비전을 무엇이라 생각하는지, 그리고 어떤 방향으로 컴퓨터
비전이 나아가야 하느지, 그리고 컴퓨터가 비전을 인식하게 하기 위해

436
00:15:34,550 --> 00:15:41,510


437
00:15:35,473 --> 00:15:41,628


438
00:15:41,510 --> 00:15:48,200


439
00:15:47,800 --> 00:15:56,620
어떤 방향으로 알고리즘을 개발해야 하는지를 다룬 책이었습니다.

440
00:15:48,200 --> 00:15:57,020


441
00:15:53,100 --> 00:16:04,726


442
00:15:56,620 --> 00:16:10,239
그는 그의 저서에서, 우리가 눈으로 받아드린 "이미지"를
 "최종적인 full3D 표현"으로 만드려면

443
00:15:57,020 --> 00:16:02,440


444
00:16:02,440 --> 00:16:10,639


445
00:16:04,726 --> 00:16:12,295


446
00:16:10,240 --> 00:16:15,960
몇 단계의 과정을 거쳐야만 한다고 주장했습니다.
첫 단계는, 그가 부르길  "Primal Sketch" 라고 하는 단계입니다.

447
00:16:10,640 --> 00:16:16,360


448
00:16:12,295 --> 00:16:20,758


449
00:16:15,960 --> 00:16:22,660
이 과정은 주로 경계(edges), 막대(bars),
끝(ends), 가상의 선(virtual lines),

450
00:16:16,360 --> 00:16:23,060


451
00:16:22,660 --> 00:16:28,570
커브(curves), 경계(boundaries)가 표현되는 과정입니다.
이 과정은 신경과학자들에게 영감을 받은 것들이죠.

452
00:16:23,060 --> 00:16:28,970


453
00:16:23,461 --> 00:16:28,252


454
00:16:28,570 --> 00:16:41,020
Hubel과 Wiesel은 시각처리의 초기 단계는 경계와 같은
단순한 구조와 아주 밀접한 관계가 있다고 했었죠

455
00:16:28,970 --> 00:16:34,639


456
00:16:34,639 --> 00:16:41,420


457
00:16:41,020 --> 00:16:45,460
경계와 커브 이후의 다음 단계는, 그가 부르기로는

458
00:16:41,420 --> 00:16:45,860


459
00:16:45,460 --> 00:16:51,900
"2.5-D sketch"라는 단계이며 이 단계에서는
시각 장면을 구성하는 표면(surfaces) 정보,

460
00:16:45,860 --> 00:16:52,300


461
00:16:48,012 --> 00:16:56,276


462
00:16:51,900 --> 00:16:58,440
깊이 정보, 레이어, 불연속 점과 같은 것들을 종합합니다.

463
00:16:52,300 --> 00:16:58,840


464
00:16:56,276 --> 00:17:01,999


465
00:16:58,450 --> 00:17:04,530
그리고 결국에 그 모든 것을 한데 모아서
surface and volumetric primives의 형태의

466
00:16:58,850 --> 00:17:04,930


467
00:17:01,999 --> 00:17:10,564


468
00:17:04,530 --> 00:17:11,179
계층적으로 조직화된 최종적인 3D 모델을 만들어 냅니다.

469
00:17:04,930 --> 00:17:11,579


470
00:17:11,179 --> 00:17:20,319
그리고 이런 방식은 "비전이 무엇인가" 라는 것에 대한 아주
"이상적인" 사고과정 이었습니다. 그리고 이런 방식의 사고방식은

471
00:17:11,579 --> 00:17:20,719


472
00:17:13,123 --> 00:17:16,797


473
00:17:16,797 --> 00:17:21,419


474
00:17:20,320 --> 00:17:25,390
실제로 수십 년간 컴퓨터비전 분야를 지배했으며

475
00:17:20,720 --> 00:17:25,790


476
00:17:21,419 --> 00:17:28,179


477
00:17:25,390 --> 00:17:31,540
학생들이 컴퓨터비전을 처음 입문 하고나서
"어떻게 시각정보를 분석할 수 있을까"라는 질문을 던졌을 때

478
00:17:25,790 --> 00:17:31,940


479
00:17:28,179 --> 00:17:36,478


480
00:17:31,540 --> 00:17:37,830
직관적인 생각해 볼 수 있는 방법이었습니다.

481
00:17:31,940 --> 00:17:38,230


482
00:17:36,478 --> 00:17:44,003


483
00:17:38,910 --> 00:17:47,980
70년대에는 또 다른 아주 중요한 연구들이 있었습니다.

484
00:17:39,310 --> 00:17:48,380


485
00:17:44,003 --> 00:17:52,486


486
00:17:47,980 --> 00:17:54,760
"우리는 어떻게 해야 장난감 같은 단순한 블록 세계를 뛰어 넘어서

487
00:17:48,380 --> 00:17:55,160


488
00:17:52,486 --> 00:17:57,233


489
00:17:54,760 --> 00:18:02,109
실제 세계를 인식하고 표현할 수 있을까?" 라는 질문을 하기 시작했습니다.
70 년대를 생각해보면

490
00:17:55,160 --> 00:18:02,509


491
00:17:57,233 --> 00:18:04,850


492
00:18:02,109 --> 00:18:07,510
그 당시에는 사용할 수있는 데이터가 거의 없었습니다.
컴퓨터도 정말 느렸고

493
00:18:02,509 --> 00:18:07,910


494
00:18:04,850 --> 00:18:07,717


495
00:18:07,510 --> 00:18:19,770
심지어 PC가 보급되기도 전이죠. 이 상황에서 컴퓨터 과학자들은 어떻게
해야 대상을 인식하고 표현할 수 있을 지를 고민하기 시작했습니다.

496
00:18:07,910 --> 00:18:13,360


497
00:18:13,360 --> 00:18:20,170


498
00:18:16,836 --> 00:18:22,356


499
00:18:19,770 --> 00:18:26,249
 Stanford와 SRI에서 과학자들이
서로 비슷한 아이디어를 제안했습니다.

500
00:18:20,170 --> 00:18:26,649


501
00:18:22,356 --> 00:18:27,011


502
00:18:26,249 --> 00:18:32,340
하나는 "commonized cylinde"이고
하나는 "pictorial structure"입니다.

503
00:18:26,649 --> 00:18:32,740


504
00:18:27,011 --> 00:18:37,346


505
00:18:32,340 --> 00:18:39,660
기본 개념은 "모든 객체는 단순한 기하학적 형태로 이루어진다"는 것입니다.

506
00:18:32,740 --> 00:18:40,060


507
00:18:39,660 --> 00:18:45,110
가령 사람은 원통모양을 조합해서 만들 수 있습니다. (왼쪽 그림)

508
00:18:40,060 --> 00:18:45,510


509
00:18:45,110 --> 00:18:55,679
혹은 사람을 "주요 부위"와  "관절" 로 표현할 수도 있을 것입니다.
(오른쪽 그림)

510
00:18:45,510 --> 00:18:51,339


511
00:18:51,339 --> 00:18:56,079


512
00:18:51,844 --> 00:19:00,975


513
00:18:55,679 --> 00:19:10,740
두 방법 모두 단순한 모양과 기하학적인 구성을 이용해서
복잡한 객체를 단순화 시키는 방법입니다.

514
00:18:56,079 --> 00:19:03,880


515
00:19:00,975 --> 00:19:08,219


516
00:19:03,880 --> 00:19:11,140


517
00:19:08,219 --> 00:19:11,842


518
00:19:10,740 --> 00:19:18,820
이러한 연구들은 수 년간 다른 연구에 상당히 많은 영향을 미쳤습니다.

519
00:19:11,140 --> 00:19:19,220


520
00:19:16,380 --> 00:19:24,971


521
00:19:18,820 --> 00:19:33,299
80년대 또 다른 사례로, David Lowe는 어떻게 하면 단순한 구조로
실제 세계를 재구성/인식할 수 있을지 고민했습니다.

522
00:19:19,220 --> 00:19:27,630


523
00:19:24,971 --> 00:19:31,526


524
00:19:27,630 --> 00:19:33,699


525
00:19:31,526 --> 00:19:33,327


526
00:19:33,299 --> 00:19:43,040
David Lowe는 이 연구에서 면도기를 인식하기 위해서 면도기를

527
00:19:33,699 --> 00:19:43,440


528
00:19:43,040 --> 00:19:50,460
선(lines)과 경계(edges) 그리고 직선(straight lines)
그리고 이들의 조합을 이용해서 구성했습니다.

529
00:19:43,440 --> 00:19:50,860


530
00:19:46,644 --> 00:19:53,241


531
00:19:50,460 --> 00:20:00,740
정리해보면 60/70/80년대에는 사람들이 컴퓨터비전으로 어떤 일을
할 수 있을까를 고민한 시대였습니다.

532
00:19:50,860 --> 00:20:01,140


533
00:19:53,241 --> 00:20:01,288


534
00:20:00,749 --> 00:20:10,010
하지만 객체를 인식하는 문제는 너무 어려웠습니다.

535
00:20:01,149 --> 00:20:10,410


536
00:20:03,831 --> 00:20:06,415


537
00:20:06,415 --> 00:20:18,006


538
00:20:10,010 --> 00:20:17,580
지금까지 제가 보여드린 연구들이 모두 아주 대담했고
큰 야망을 가진 시도였지만

539
00:20:10,410 --> 00:20:17,980


540
00:20:17,580 --> 00:20:23,760
그들은 단순한 수준(toy example)에 불과했습니다.

541
00:20:17,980 --> 00:20:24,160


542
00:20:23,760 --> 00:20:30,419
현실 세계에서 제대로 동작할 수 있는지의 여부를 생각해본다면
많은 진보는 이루어지지 않았습니다.

543
00:20:24,160 --> 00:20:30,819


544
00:20:30,419 --> 00:20:37,619
그래서 비전은 연구하는 사람들은

545
00:20:30,819 --> 00:20:38,019


546
00:20:36,280 --> 00:20:45,220


547
00:20:37,619 --> 00:20:43,309
우리가 도대체 무슨 실수를 하고 있을까 고민하다가
한가지 질문을 떠올리게 됩니다.

548
00:20:38,019 --> 00:20:43,709


549
00:20:43,309 --> 00:20:49,800
객체 인식이 너무 어렵다면, 우선 객체를
분할(segmentation)을 해야하는 것이 아닌가 라는 것이었습니다.

550
00:20:43,709 --> 00:20:50,200


551
00:20:48,110 --> 00:20:56,941


552
00:20:49,800 --> 00:20:58,360
객체 분할은 이미지의 픽셀을 의미있는 지역으로
군집화 하는 것입니다.

553
00:20:50,200 --> 00:20:58,760


554
00:20:56,941 --> 00:20:58,291


555
00:20:58,360 --> 00:21:03,480
군집화된 픽셀중에 정확히 어떤것이 사람인지 모를수도 있지만

556
00:20:58,760 --> 00:21:03,880


557
00:21:03,480 --> 00:21:09,740
우리는 배경으로부터 사람이 속한 픽셀을 추출할 수 있었습니다.

558
00:21:03,880 --> 00:21:10,140


559
00:21:07,014 --> 00:21:10,730


560
00:21:09,740 --> 00:21:14,939
이것을 우리는 영상 분할이라고 합니다.
영상 분할문제를 다룬 아주 중요한 연구가 있었는데.

561
00:21:10,140 --> 00:21:15,339


562
00:21:10,730 --> 00:21:14,897


563
00:21:14,939 --> 00:21:21,359
이 연구는 Kerkeley의  Jitendra Malik와
그의 제자인 Jianbo Shi 연구였습니다.

564
00:21:15,339 --> 00:21:21,759


565
00:21:16,415 --> 00:21:26,026


566
00:21:21,360 --> 00:21:29,480
이 연구는 영상 분할 문제를 풀기 위해
그래프 이론을 이용하였습니다.

567
00:21:21,760 --> 00:21:29,880


568
00:21:27,752 --> 00:21:35,108


569
00:21:29,480 --> 00:21:39,200
그리고 컴퓨터 비전의 다른 분야들보다
발전이 좀 더 빨랐던 분야가 있었습니다.

570
00:21:29,880 --> 00:21:39,600


571
00:21:35,108 --> 00:21:44,178


572
00:21:39,210 --> 00:21:45,450
바로 얼굴인식 입니다.
얼굴은 인간에게 있어서 가장 중요한 부분중 하나죠.

573
00:21:39,610 --> 00:21:45,850


574
00:21:44,178 --> 00:21:47,678


575
00:21:45,450 --> 00:21:51,379
어쩌면 제일 중요한 부분일수도 있겠습니다.
1999에서 2000년대 쯤에는

576
00:21:45,850 --> 00:21:51,779


577
00:21:51,379 --> 00:21:58,679
기계학습, 특히 통계적 기계학습 테크닉이

578
00:21:51,779 --> 00:21:59,079


579
00:21:58,679 --> 00:22:04,820
탄력을 얻기 시작했습니다. 그런 기술들 중에는

580
00:21:59,079 --> 00:22:05,220


581
00:22:01,620 --> 00:22:06,984


582
00:22:04,820 --> 00:22:11,220
Support Vector Machine이나 Boosting,
Graphical models 그리고 초기의 신경망이 있습니다.

583
00:22:05,220 --> 00:22:11,620


584
00:22:06,984 --> 00:22:13,853


585
00:22:11,220 --> 00:22:18,049
그 중 한 연구가 아주 큰 기여를 했었는데, 그것은 바로

586
00:22:11,620 --> 00:22:18,449


587
00:22:13,853 --> 00:22:28,426


588
00:22:18,049 --> 00:22:24,539
Paul Viola와 Michael Jones이
AdaBoost 알고리즘을 사용하여 실시간 얼굴인식에 성공한 것입니다.

589
00:22:18,449 --> 00:22:24,939


590
00:22:24,539 --> 00:22:31,379
이 연구는 아주 대단한 연구였습니다.
이 연구는 2001년에 시행되었고,

591
00:22:24,939 --> 00:22:31,779


592
00:22:28,426 --> 00:22:32,764


593
00:22:31,379 --> 00:22:36,330
컴퓨터 칩은 여전히 엄청 느렸지만
그들은 얼굴 인식 알고리즘은

594
00:22:31,779 --> 00:22:36,730


595
00:22:32,764 --> 00:22:40,456


596
00:22:36,330 --> 00:22:42,150
실시간과 가깝게(near-real-time)
수행할 수 있었고 이 논문이 발표되고 5년이

597
00:22:36,730 --> 00:22:42,550


598
00:22:40,456 --> 00:22:49,178


599
00:22:42,150 --> 00:22:58,560
지난 후인 2006년에 Fujifilm은 실시간 얼굴인식이 가능한
최초의 디지털 카메라를 선보였습니다.

600
00:22:42,550 --> 00:22:50,800


601
00:22:49,178 --> 00:22:56,991


602
00:22:50,800 --> 00:22:58,960


603
00:22:58,560 --> 00:23:05,560
이는 기초 과학연구의 성과가 실제 응용으로
적용되기 까지 시간이 가장 빨랐던 사례입니다.

604
00:22:58,960 --> 00:23:05,960


605
00:22:59,571 --> 00:23:01,036


606
00:23:01,036 --> 00:23:04,453


607
00:23:05,560 --> 00:23:13,520
이제 다시 "어떻게 해야 객체를 더 잘
인식할 것인가?" 라는 질문으로 돌아가보면

608
00:23:05,960 --> 00:23:13,920


609
00:23:08,275 --> 00:23:17,543


610
00:23:13,530 --> 00:23:22,320
90년대 후반부터 2010년도 까지
가장 영향력있던 알고리즘은

611
00:23:13,930 --> 00:23:22,720


612
00:23:18,486 --> 00:23:22,576


613
00:23:22,320 --> 00:23:30,900
특징 기반 객체 인식 알고리즘 이었습니다.
이때 나온 유명한 알고리즘이 있는데

614
00:23:22,720 --> 00:23:31,300


615
00:23:25,151 --> 00:23:31,408


616
00:23:30,900 --> 00:23:39,270
David Lowe의 SIFT feature입니다.
그의 아이디어는 전체 객체를

617
00:23:31,300 --> 00:23:39,670


618
00:23:39,270 --> 00:23:44,460
가령, 여기 정지표지판이 있습니다. 이 정지 표지판을
다른 정지표지판에 매칭하는 것은 정말 어렵습니다.

619
00:23:39,670 --> 00:23:44,860


620
00:23:40,416 --> 00:23:46,569


621
00:23:44,460 --> 00:23:50,660
카메라 앵글이 변할수도 있고

622
00:23:44,860 --> 00:23:51,060


623
00:23:46,569 --> 00:23:54,177


624
00:23:50,660 --> 00:23:56,810
겹치거나 화각이 변하고 빛도 변하고
객체 자체도 얼마든지 변할 수 있기 때문이죠

625
00:23:51,060 --> 00:23:57,210


626
00:23:54,177 --> 00:23:55,526


627
00:23:55,526 --> 00:23:58,943


628
00:23:56,810 --> 00:24:04,280
그러나 객체의 일부가 지닌 특징들은 이런 다양한 변화에

629
00:23:57,210 --> 00:24:04,680


630
00:24:00,682 --> 00:24:05,463


631
00:24:04,280 --> 00:24:14,600
좀 더 강인하고 불변하다는 점을 알 수 있었습니다.
그리하여 객체인식의 과제는

632
00:24:04,680 --> 00:24:15,000


633
00:24:05,463 --> 00:24:10,571


634
00:24:10,571 --> 00:24:18,052


635
00:24:14,610 --> 00:24:21,210
객체에서 그런 중요한 특징들을 찾아내고

636
00:24:15,010 --> 00:24:21,610


637
00:24:19,319 --> 00:24:20,833


638
00:24:21,210 --> 00:24:28,169
다른 객체에 그 특징들을 매칭시키는 것으로 전환되었습니다.
객체 전체의 패턴을 매칭하는 것 보다 쉬는 일이었습니다.

639
00:24:21,610 --> 00:24:28,569


640
00:24:28,169 --> 00:24:35,670
이 그림은 그 논문에서 가져온 것입니다.

641
00:24:28,569 --> 00:24:36,070


642
00:24:35,670 --> 00:24:41,660
여기에서 한 표시판에서 추출한 일부 SIFT 특징을 가지고

643
00:24:36,070 --> 00:24:42,060


644
00:24:38,712 --> 00:24:46,208


645
00:24:41,660 --> 00:24:49,040
또 다른 표지판의 SIFT 특징을 식별하고 매칭합니다.

646
00:24:42,060 --> 00:24:49,440


647
00:24:46,208 --> 00:24:50,031


648
00:24:50,730 --> 00:24:58,930
이러한 영상 내 특징 이라는 것을 사용하면서

649
00:24:51,130 --> 00:24:59,330


650
00:24:58,930 --> 00:25:04,380
컴퓨터 비전 분야는 또 다른 도약을 할 수 있었습니다.
전체적인 장면을 인식하기에 이르렀습니다.

651
00:24:59,330 --> 00:25:04,780


652
00:25:04,380 --> 00:25:11,920
여기 한 예가 있는데, Spatial Pyramid Matching 이라
불리는 알고리즘입니다.

653
00:25:04,780 --> 00:25:12,320


654
00:25:11,920 --> 00:25:18,220
아이디어는 우리가 어떤 특징을 잘 뽑는다면

655
00:25:12,320 --> 00:25:18,620


656
00:25:15,250 --> 00:25:24,864


657
00:25:18,220 --> 00:25:23,350
그것이 우리에게 어떤 일종의 "단서"를 가져다 줄 수 있다는 것이었습니다.
이 이미지가 풍경이미지인지,

658
00:25:18,620 --> 00:25:23,750


659
00:25:23,350 --> 00:25:36,730
부엌인지, 또는 고속도로인지 하는 것을 말이죠.
이 연구는 이미지내 여러 부분과, 여러 해상도에서 뽑은 특징을

660
00:25:23,750 --> 00:25:31,580


661
00:25:24,864 --> 00:25:29,647


662
00:25:29,647 --> 00:25:37,809


663
00:25:31,580 --> 00:25:37,130


664
00:25:36,730 --> 00:25:44,380
하나의 특징 기술자 안에 넣어놓고,
마지막에 Support Vector Algorithm을 적용합니다.

665
00:25:37,130 --> 00:25:44,780


666
00:25:37,809 --> 00:25:43,155


667
00:25:43,155 --> 00:25:48,869


668
00:25:44,380 --> 00:25:53,530
이와 유사한 방식의 연구가 사람인식에도
탄력을 주게 됩니다.

669
00:25:44,780 --> 00:25:53,930


670
00:25:48,869 --> 00:25:57,000


671
00:25:53,530 --> 00:26:02,590
어떻게 하면 특징들을 잘 조합할 수 있는지에 관한 것들이죠,
사람인식에 관련 많은 연구들이 있습니다.

672
00:25:53,930 --> 00:26:02,990


673
00:25:57,000 --> 00:26:06,000


674
00:26:02,590 --> 00:26:10,090
이런 연구들은 어떻게 해야 사람의 몸은 좀더 현실적으로 모델링하여
사람을 인식할수 있을지에 관한 것이였습니다.

675
00:26:02,990 --> 00:26:10,490


676
00:26:06,000 --> 00:26:12,632


677
00:26:10,090 --> 00:26:15,310
그중 한 연구가 바로 Histogram Of Gradients 입니다.
또다른 하나는

678
00:26:10,490 --> 00:26:15,710


679
00:26:12,632 --> 00:26:15,465


680
00:26:15,310 --> 00:26:26,370
Deformable Part Models 입니다. 우리가
60년대. 70년대, 80년대를 거쳐오면서

681
00:26:15,710 --> 00:26:26,770


682
00:26:17,404 --> 00:26:22,930


683
00:26:22,930 --> 00:26:25,593


684
00:26:26,370 --> 00:26:33,760
21세기의 첫 10년을 맞이하였고
많은 것이 변하고 있었습니다.

685
00:26:26,770 --> 00:26:34,160


686
00:26:29,847 --> 00:26:39,574


687
00:26:33,760 --> 00:26:40,300
사진의 품질은 문제가 되지 않았고,

688
00:26:34,160 --> 00:26:40,700


689
00:26:40,300 --> 00:26:45,280
인터넷의 발전에 힘입어, 디지털 카메라는
더더욱 좋은 실험 데이터를 가져다 줄 수 있었습니다.

690
00:26:40,700 --> 00:26:45,680


691
00:26:45,280 --> 00:26:53,980
2000년대 초에 이뤄낸 결과 중 하나는 바로

692
00:26:45,680 --> 00:26:54,380


693
00:26:50,425 --> 00:27:01,176


694
00:26:53,980 --> 00:27:02,440
컴퓨터 비전 분야가 앞으로 해결해야 할 일련의 문제들이
무엇인지에 대해 어느정도 정의를 내렸다는 것입니다.

695
00:26:54,380 --> 00:27:02,840


696
00:27:02,440 --> 00:27:05,200
물론 해결해야 할 다른 문제들도 많지만,

697
00:27:02,840 --> 00:27:05,600


698
00:27:05,200 --> 00:27:10,720
인식 이라는 문제에서는 이것은 해결해야 할 매우 중요한
문제였습니다. 그것은 바로 객체 인식 입니다.

699
00:27:05,600 --> 00:27:11,120


700
00:27:10,720 --> 00:27:18,550
제가 지금것 객체 인식에 대해 말했지만, 2000년대 초

701
00:27:11,120 --> 00:27:18,950


702
00:27:18,550 --> 00:27:26,200
우리는 Benchmark Dataset을 보유하기 시작했습니다.
객체 인식이 얼마나 진보되었는가를 측정하기 위해서였죠.

703
00:27:18,950 --> 00:27:26,600


704
00:27:20,968 --> 00:27:27,273


705
00:27:26,200 --> 00:27:32,530
가장 유명한 Benchmark Dataset중 하나는 바로

706
00:27:26,600 --> 00:27:32,930


707
00:27:27,273 --> 00:27:35,865


708
00:27:32,530 --> 00:27:41,080
PASCAL Visual Object Challenge(VOC) 입니다.
이 데이터셋은 20가지의 데이터 클래스로 이뤄져 있고

709
00:27:32,930 --> 00:27:41,480


710
00:27:35,865 --> 00:27:38,602


711
00:27:38,602 --> 00:27:39,952


712
00:27:39,952 --> 00:27:45,242


713
00:27:41,080 --> 00:27:48,100
그중 세개가 여기 보이는 것입니다 : 기차, 비행기, 사람

714
00:27:41,480 --> 00:27:48,500


715
00:27:46,749 --> 00:27:50,846


716
00:27:48,100 --> 00:27:57,040
또한 암소, 병, 고양이 등이 있었던 것으로 기억합니다.
데이터셋은 클래스 당 수천 수만개의

717
00:27:48,500 --> 00:27:57,440


718
00:27:50,846 --> 00:27:57,973


719
00:27:57,040 --> 00:28:03,880
이미지들로 구성되어 있었고, 그 분야에서
다양한 집단에서

720
00:27:57,440 --> 00:28:04,280


721
00:27:57,973 --> 00:28:04,015


722
00:28:03,880 --> 00:28:11,350
테스트를 위한 알고리즘을 개발했으며 , 얼마나 우리가 진보했는지를
지켜보았습니다.

723
00:28:04,280 --> 00:28:11,750


724
00:28:10,243 --> 00:28:16,963


725
00:28:11,350 --> 00:28:19,470
여기 2007년부터 2012년도 까지의 표가 있습니다.

726
00:28:11,750 --> 00:28:19,870


727
00:28:16,963 --> 00:28:23,481


728
00:28:19,470 --> 00:28:30,700
20가지의 객체를 감지해내는 성능이 꾸준히 증가했다는 것을 볼 수 있습니다.

729
00:28:19,870 --> 00:28:31,100


730
00:28:26,153 --> 00:28:33,192


731
00:28:30,700 --> 00:28:38,280
많은 진보가 이루어 졌습니다.

732
00:28:31,100 --> 00:28:38,680


733
00:28:33,192 --> 00:28:37,413


734
00:28:38,280 --> 00:28:44,770
그 무렵 Princeton부터 Stanford에 이르는 우리 그룹은
우리 자신들 뿐만 아니라

735
00:28:38,680 --> 00:28:45,170


736
00:28:44,770 --> 00:28:52,930
우리의 분야 전체에게 더 어려운 질문을 던졌습니다.
: 우리는 실세계의 모든, 혹은 대부분의 객체를

737
00:28:45,170 --> 00:28:53,330


738
00:28:48,586 --> 00:28:58,676


739
00:28:52,930 --> 00:28:59,860
인식할 준비가 되었는가? 였습니다.
이런 질문은 한 관찰로 부터 비롯된 것인데,

740
00:28:53,330 --> 00:29:00,260


741
00:28:58,676 --> 00:29:05,833


742
00:28:59,860 --> 00:29:07,570
그것은 기계학습에서 기인했습니다. 거의 대
부분의 기계학습 알고리즘에서 말이죠

743
00:29:00,260 --> 00:29:07,970


744
00:29:05,833 --> 00:29:09,146


745
00:29:07,570 --> 00:29:12,010
이 알고리즘이 Graphical Model이던

746
00:29:07,970 --> 00:29:12,410


747
00:29:09,146 --> 00:29:20,651


748
00:29:12,010 --> 00:29:19,670
SVM이건, AdaBoost던 상관없이 대부분의 기계학습 알고리즘이
트레이닝 과정에서 Overfit을 하는것 같다는 것이었습니다.

749
00:29:12,410 --> 00:29:20,070


750
00:29:19,670 --> 00:29:25,010
이문제의 원인 중 하나는 바로, 시작 데이터가 너무 복잡하다는 것이었습니다.

751
00:29:20,070 --> 00:29:25,410


752
00:29:20,651 --> 00:29:25,118


753
00:29:25,010 --> 00:29:32,300
데이터가 너무 복잡해서, 모델은 고차원의 입력을 받아야 했기 때문에

754
00:29:25,410 --> 00:29:32,700


755
00:29:32,300 --> 00:29:37,159
모델은 fit해야 할 너무나 많은 매개변수를 가져야 했습니다.

756
00:29:32,700 --> 00:29:37,559


757
00:29:37,159 --> 00:29:43,760
그래서 우리가 학습데이터가 충분하지 않은 상황이라면,
Overfiting이 아무 빠르게 일어났고, 일반화를 잘 할 수 없었습니다.

758
00:29:37,559 --> 00:29:44,160


759
00:29:40,833 --> 00:29:53,151


760
00:29:43,760 --> 00:29:52,040
그래서, 우리는 이 세상의 모든 객체를 인식하고 싶었다는 것 그리고

761
00:29:44,160 --> 00:29:52,440


762
00:29:52,040 --> 00:29:57,940
기계학습이  병목인 Overfilting을 극복하게 하려는
것이었습니다.

763
00:29:52,440 --> 00:29:58,340


764
00:29:53,151 --> 00:29:59,197


765
00:29:57,940 --> 00:30:04,220
두가지 동기를 통해서

766
00:29:58,340 --> 00:30:04,620


767
00:29:59,197 --> 00:30:07,948


768
00:30:04,220 --> 00:30:10,740
ImageNet이라는 프로젝트를 시작하였습니다. 가능한 우리가 구할 수 있는
모든 이미지를 가진, 가장 규모가 큰 데이터셋을 만들고 싶었습니다.

769
00:30:04,620 --> 00:30:11,140


770
00:30:07,948 --> 00:30:12,706


771
00:30:10,740 --> 00:30:17,500
그리고 이 데이터셋을 통해 학습 뿐만 아니라
Benchmarking도 할 수 있습니다.

772
00:30:11,140 --> 00:30:17,900


773
00:30:12,706 --> 00:30:26,457


774
00:30:17,510 --> 00:30:22,850
이 프로젝트는 약 3년정도 걸렸습니다.

775
00:30:17,910 --> 00:30:23,250


776
00:30:22,850 --> 00:30:29,930
어려운 일도 많았습니다, 우선 우리는 수십억개의

777
00:30:23,250 --> 00:30:30,330


778
00:30:26,457 --> 00:30:32,309


779
00:30:29,930 --> 00:30:37,220
이미지를 인터넷에서 다운받았고, 사전으로 조직화했습니다.
이 사전은 바로 WordNet 인데,

780
00:30:30,330 --> 00:30:37,620


781
00:30:32,309 --> 00:30:39,703


782
00:30:37,220 --> 00:30:45,370
WordNet에는 수십 수천가지의 객체 클래스가 존재하고,
우리는

783
00:30:37,620 --> 00:30:45,770


784
00:30:41,830 --> 00:30:50,825


785
00:30:45,370 --> 00:30:51,830
Clever Crowd Engineering trick 를 써야 했습니다.
이는 Amazon Mechanical Turk에서 사용하는

786
00:30:45,770 --> 00:30:52,230


787
00:30:50,825 --> 00:30:53,196


788
00:30:51,830 --> 00:31:01,870
이미지의 정렬, 정제, 그리고 각 이미지의 레이블을 제공하는
플랫폼 입니다. 마지막 결과로  ImageNet은

789
00:30:52,230 --> 00:31:02,270


790
00:30:53,196 --> 00:30:58,527


791
00:30:59,792 --> 00:31:11,966


792
00:31:01,870 --> 00:31:10,430
거의 천 5천만 개에서 4천만 개에 달하는 이미지를 보유하게 되었고,
22만개의 클래스 카테고리를 가지게 되었습니다.

793
00:31:02,270 --> 00:31:10,830


794
00:31:10,430 --> 00:31:20,480
정말 거대했고, 아마

795
00:31:10,830 --> 00:31:20,880


796
00:31:11,966 --> 00:31:20,208


797
00:31:20,480 --> 00:31:28,889
그 당시 AI분야에서 만든 가장 큰 데이터셋 이었을 것입니다.
그리고 ImageNet은 객체 인식 알고리즘을

798
00:31:20,880 --> 00:31:29,289


799
00:31:22,151 --> 00:31:30,041


800
00:31:28,889 --> 00:31:35,359
다른 국면으로 접어들게 하였습니다.

801
00:31:29,289 --> 00:31:35,759


802
00:31:35,359 --> 00:31:40,800
특히 중요한점은 어떻게 발전에 대해 Benchmark 하느냐 였습니다.

803
00:31:35,759 --> 00:31:41,200


804
00:31:36,720 --> 00:31:40,720


805
00:31:40,800 --> 00:31:49,019
그래서 2009 년부터 ImageNet 팀은 국제규모의 대회를
주최했습니다.

806
00:31:41,200 --> 00:31:49,419


807
00:31:41,798 --> 00:31:53,969


808
00:31:49,019 --> 00:31:56,909
그 대회는 바로 ILSVRC 입니다.
이 대회를 위해서

809
00:31:49,419 --> 00:31:57,309


810
00:31:53,969 --> 00:32:01,004


811
00:31:56,909 --> 00:32:05,790
1000개의 객체에서 140만개의 test set 이미지를
엄선했습니다.

812
00:31:57,309 --> 00:32:06,190


813
00:32:01,004 --> 00:32:03,171


814
00:32:05,790 --> 00:32:13,229
이 대회는 이미지 분류 문제를 푸는 알고리즘들을
테스트하기 위한 것이였습니다.

815
00:32:06,190 --> 00:32:13,629


816
00:32:13,229 --> 00:32:21,589
여기 예제 사진이 있습니다. 만약 알고리즘이

817
00:32:13,629 --> 00:32:21,989


818
00:32:15,749 --> 00:32:21,189


819
00:32:21,589 --> 00:32:31,859
5개의 후보 레이블을 출력할 수 있고, 5개 중에
정답이 있으면 우리는 성공한 것이라 하였습니다.

820
00:32:21,989 --> 00:32:32,259


821
00:32:25,369 --> 00:32:35,522


822
00:32:31,859 --> 00:32:42,509
여기에 ImageNet Challenge 2010의 결과가 있습니다.

823
00:32:32,259 --> 00:32:42,909


824
00:32:35,522 --> 00:32:41,002


825
00:32:42,509 --> 00:32:49,320
이 그래프는 영상 분류의 결과입니다.

826
00:32:42,909 --> 00:32:49,720


827
00:32:49,320 --> 00:33:00,340
2015년도 까지의 결과이며, x축으로 연도를
y축으로 오류율을 볼 수 있습니다.

828
00:32:49,720 --> 00:33:00,740


829
00:32:52,308 --> 00:33:00,140


830
00:33:00,340 --> 00:33:06,420
좋은 소식은 오류율이 점차 감소한 다는 것입니다.

831
00:33:00,740 --> 00:33:06,820


832
00:33:01,923 --> 00:33:11,018


833
00:33:06,420 --> 00:33:14,969
2012 오류율이 너무 낮아서 사람이 할 수있는 것과 동등합니다.
여기에서의 사람은

834
00:33:06,820 --> 00:33:15,369


835
00:33:12,276 --> 00:33:18,064


836
00:33:14,969 --> 00:33:32,070
Stanford의 한 박사과정(PhD) 학생입니다
이 대회에 참여한 컴퓨터처럼 이 일로 몇 주를 보냈죠.

837
00:33:15,369 --> 00:33:25,359


838
00:33:18,064 --> 00:33:18,998


839
00:33:18,998 --> 00:33:22,715


840
00:33:22,715 --> 00:33:26,356


841
00:33:25,359 --> 00:33:32,470


842
00:33:26,356 --> 00:33:30,117


843
00:33:30,117 --> 00:33:34,213


844
00:33:32,070 --> 00:33:42,710
앞으로 여러분이 이 수업에서 배우게 될테지만 객체 인식에 대한
모든 문제를 해결하진 못했지만, 분명 진전은 있었습니다.

845
00:33:32,470 --> 00:33:39,669


846
00:33:35,205 --> 00:33:37,043


847
00:33:37,043 --> 00:33:40,460


848
00:33:39,669 --> 00:33:43,110


849
00:33:42,710 --> 00:33:50,090
하지만 실 생활에 적용하기 역부족이었던
오류율에서 부터

850
00:33:43,110 --> 00:33:50,490


851
00:33:45,634 --> 00:33:48,615


852
00:33:48,615 --> 00:33:54,624


853
00:33:50,090 --> 00:33:56,000
ImageNet 챌린지에서 인간과 거의 동등한 수준의
오류율로 오기까지는, 불과 몇년뿐지 걸리지 않았습니다.

854
00:33:50,490 --> 00:33:56,400


855
00:33:54,624 --> 00:34:01,316


856
00:33:56,000 --> 00:34:05,240
그리고 이 그래프에서 여러분이 놓쳐서는 안될
특별한 순간이 있습니다.

857
00:33:56,400 --> 00:34:05,640


858
00:34:01,316 --> 00:34:09,248


859
00:34:05,240 --> 00:34:15,319
바로 2012년 입니다. 처음 2년동안은 오류률이
약 25%였습니다만

860
00:34:05,640 --> 00:34:15,719


861
00:34:09,248 --> 00:34:10,725


862
00:34:10,726 --> 00:34:14,143


863
00:34:15,319 --> 00:34:25,249
2012년에는 오류율이 16%로, 거의 10%가량 떨어졌고,

864
00:34:15,719 --> 00:34:25,649


865
00:34:17,849 --> 00:34:23,991


866
00:34:23,991 --> 00:34:34,868


867
00:34:25,250 --> 00:34:32,569
물론 현재가 더 오류율이 낫긴 하지만
2012년도의 오류율 감소는 매우 중요합니다.

868
00:34:25,650 --> 00:34:32,969


869
00:34:32,569 --> 00:34:42,169
2012년도에 우승한 알고리즘은
CNN 모델입니다.

870
00:34:32,969 --> 00:34:42,569


871
00:34:36,295 --> 00:34:42,766


872
00:34:42,170 --> 00:34:49,450
CNN은 그 당시 다른 모든 알고리즘을 능가하고
ImageNet Challenge에서 우승하였습니다.

873
00:34:42,570 --> 00:34:49,850


874
00:34:47,793 --> 00:34:59,121


875
00:34:49,450 --> 00:34:57,800
그리고 CNN이 바로 우리 강의에서 한 학기동안
주목할 바로 그것입니다.

876
00:34:49,850 --> 00:34:58,200


877
00:34:57,800 --> 00:35:05,300
CNN 모델이 무엇인지를 심도싶게 다룰 것입니다.
그리고 CNN의 다른이름은

878
00:34:58,200 --> 00:35:05,700


879
00:35:01,860 --> 00:35:05,610


880
00:35:05,300 --> 00:35:09,970
Deep Learning 이죠,

881
00:35:05,700 --> 00:35:10,370


882
00:35:06,619 --> 00:35:11,213


883
00:35:10,120 --> 00:35:14,930
유명한 이름으로 CNN을 Deep leraning이라고도 불립니다.

884
00:35:10,520 --> 00:35:15,330


885
00:35:11,213 --> 00:35:23,363


886
00:35:14,930 --> 00:35:20,029
이 모델이 무엇인지, 어떤 법칙이 있는지, 어떤 선례가 있는지,
이 모델의 최근 행보는 어떠한지 를 살펴볼 것입니다.

887
00:35:15,330 --> 00:35:20,429


888
00:35:20,029 --> 00:35:26,000
하지만 여기에 역사가 만들어진 곳이 있습니다.

889
00:35:20,429 --> 00:35:26,400


890
00:35:26,000 --> 00:35:32,600
2012년의 CNN 이라는 Deep learning 모델은

891
00:35:26,400 --> 00:35:33,000


892
00:35:29,168 --> 00:35:38,675


893
00:35:32,600 --> 00:35:40,909
컴퓨터비전 분야의 진보를 이뤄냄으로서,
CNN의 훌륭한 역량과 능력을 보여주었습니다.

894
00:35:33,000 --> 00:35:41,309


895
00:35:38,675 --> 00:35:54,669


896
00:35:40,909 --> 00:35:46,970
자연어 처리나 음성 인식과 같은 다른 자매분야들과도
함께 말이죠

897
00:35:41,309 --> 00:35:47,370


898
00:35:46,970 --> 00:35:51,500
소개는 이쯤 해두고,

899
00:35:47,370 --> 00:35:51,900


900
00:35:51,500 --> 00:36:02,100
CS231n의 개괄에 대한 내용을 위해 이번 강의의 나머지를
Justin에게 맡기도록 하겠습니다.

901
00:35:51,900 --> 00:36:00,630


902
00:35:54,669 --> 00:36:02,031


903
00:36:00,630 --> 00:36:02,500


904
00:36:02,600 --> 00:36:04,363
좋습니다 Fei-Fei 교수님 정말 감사합니다.

905
00:36:03,000 --> 00:36:04,763


906
00:36:04,600 --> 00:36:07,758
제가 여기서 이어 받겠습니다.

907
00:36:05,000 --> 00:36:08,158


908
00:36:07,789 --> 00:36:09,510
지금부터는 다른 이야기를 해야겠네요

909
00:36:08,189 --> 00:36:09,910


910
00:36:09,510 --> 00:36:13,677
좀더 이 CS231n 에 대해
이야기해 보겠습니다.

911
00:36:09,910 --> 00:36:14,077


912
00:36:11,159 --> 00:36:17,500


913
00:36:15,036 --> 00:36:18,236
이 수업은 오로지 한가지에
중점을 둘 것입니다

914
00:36:15,436 --> 00:36:18,636


915
00:36:18,236 --> 00:36:20,414
가장 중요하게 다룰 것은

916
00:36:18,636 --> 00:36:20,814


917
00:36:20,414 --> 00:36:22,550
바로 이미지 분류 문제입니다

918
00:36:20,814 --> 00:36:22,950


919
00:36:22,550 --> 00:36:26,637
우리가 방금 전에 ImageNet Challenge
이야기에서 조금은 들었었죠

920
00:36:22,950 --> 00:36:25,269


921
00:36:25,269 --> 00:36:27,037


922
00:36:26,637 --> 00:36:28,448
다시 이미지 분류로 돌아가 보자면

923
00:36:27,037 --> 00:36:28,848


924
00:36:28,448 --> 00:36:31,070
기본 설정은, 여러분의 알고리즘이 한 장의 이미지를 보고는

925
00:36:28,848 --> 00:36:31,470


926
00:36:29,854 --> 00:36:36,404


927
00:36:31,070 --> 00:36:33,648
몇 개의 고정된 카테고리 안에서 하나는 고르는거죠

928
00:36:31,470 --> 00:36:34,048


929
00:36:33,648 --> 00:36:36,043
이미지를 분류하기 위해서죠

930
00:36:34,048 --> 00:36:36,443


931
00:36:36,043 --> 00:36:39,150
이것이 다소 제한적이거나

932
00:36:36,443 --> 00:36:39,550


933
00:36:39,150 --> 00:36:42,106
인공적으로 보일수 있지만, 사실 매우 일반적이 것입니다.

934
00:36:39,550 --> 00:36:42,506


935
00:36:42,106 --> 00:36:45,121
이 문제는 다양한 환경에 적용될 수 있습니다.

936
00:36:42,506 --> 00:36:45,521


937
00:36:45,121 --> 00:36:49,230
산업현상에서든, 학술적으로든 말이죠, 많은 다양한 곳에서 가능합니다.

938
00:36:45,521 --> 00:36:49,630


939
00:36:45,899 --> 00:36:49,856


940
00:36:49,230 --> 00:36:52,557
예를들어 음식을 인식하거나,

941
00:36:49,630 --> 00:36:52,957


942
00:36:49,856 --> 00:36:56,317


943
00:36:52,557 --> 00:36:54,506
음식의 칼로리를 인식하거나,

944
00:36:52,957 --> 00:36:54,906


945
00:36:54,506 --> 00:36:57,643
다양한 미술작품들을 인식하거나, 이 세상에에 존재하는 여러가지
제품을 일식하는데도 적용할 수 있습니다.

946
00:36:54,906 --> 00:36:58,043


947
00:36:57,643 --> 00:37:01,176
그러니 영상 분류라는 상대적으로 기본적인 이 도구가

948
00:36:58,043 --> 00:37:01,576


949
00:37:01,176 --> 00:37:03,872
독자적으로도 엄청 유용할 수 있고,

950
00:37:01,576 --> 00:37:04,272


951
00:37:03,872 --> 00:37:08,103
다양한 응용을 통해 어느 곳이든 적용할 수 있을 것입니다.

952
00:37:04,272 --> 00:37:08,503


953
00:37:08,103 --> 00:37:13,406
하지만 이 코스에서는 몇 가지 다른 시각 인식 문제에 대해서도
이야기 할 것입니다.

954
00:37:08,503 --> 00:37:10,685


955
00:37:10,685 --> 00:37:13,806


956
00:37:11,323 --> 00:37:19,770


957
00:37:13,406 --> 00:37:19,260
그리고 그것들은 우리가 영상 분류를 위해 개발한
여러 도구들 기반으로 합니다.

958
00:37:13,806 --> 00:37:16,673


959
00:37:16,673 --> 00:37:19,660


960
00:37:19,260 --> 00:37:20,866
우리는 다른 문제들에 대해서도 다룰 것입니다.

961
00:37:19,660 --> 00:37:21,266


962
00:37:20,866 --> 00:37:24,383
객체 디텍션이나
이미지 캡셔닝과 같은 것들이죠

963
00:37:21,266 --> 00:37:24,783


964
00:37:22,730 --> 00:37:26,251


965
00:37:24,383 --> 00:37:26,265
객체 디텍션의 설정은

966
00:37:24,783 --> 00:37:26,665


967
00:37:26,265 --> 00:37:28,035
조금 다릅니다.

968
00:37:26,665 --> 00:37:28,435


969
00:37:28,035 --> 00:37:30,309
전체 이미지를 분류하는 대신에 전체 이미지를

970
00:37:28,435 --> 00:37:30,709


971
00:37:30,309 --> 00:37:33,327
이 이미지는 고양이다, 개다, 말이다 같이 뭐다 라고 하는 대신에

972
00:37:30,709 --> 00:37:33,727


973
00:37:33,327 --> 00:37:35,451
우리는 좀 더 들어가서
경계박스를 그려야 합니다.

974
00:37:33,727 --> 00:37:35,851


975
00:37:35,451 --> 00:37:38,061
그리고 개는 여기있고 고양이는 저기있다는 것을
말해야만 합니다.

976
00:37:35,851 --> 00:37:38,461


977
00:37:36,991 --> 00:37:43,984


978
00:37:38,061 --> 00:37:39,951
저기 뒤에 차가 있다는 것도 말이죠

979
00:37:38,461 --> 00:37:40,351


980
00:37:39,951 --> 00:37:43,710
이미지 안에 객체들이 어디에 있는지를
묘사하는 박스를 그려야 합니다.

981
00:37:40,351 --> 00:37:42,186


982
00:37:42,186 --> 00:37:44,110


983
00:37:43,710 --> 00:37:45,922
이미지 캡션에 대해서도 이야기 할 것입니다.

984
00:37:44,110 --> 00:37:46,322


985
00:37:45,922 --> 00:37:47,345
이미지가 주어지면, 시스템은

986
00:37:46,322 --> 00:37:47,745


987
00:37:47,345 --> 00:37:49,711
이제 자연어 문장을 만들어내야 합니다.

988
00:37:47,745 --> 00:37:50,111


989
00:37:49,711 --> 00:37:51,075
그 문장은 이미지를 설명합니다.

990
00:37:51,075 --> 00:37:53,291
정말 힘들고, 복잡하고

991
00:37:51,475 --> 00:37:53,691


992
00:37:53,291 --> 00:37:55,199
서로 별 상관이 없어보일 수도 있지만, 우리는

993
00:37:53,691 --> 00:37:55,599


994
00:37:55,199 --> 00:37:58,563
이미지 분류 서비스를 위해 개발한
많은 도구들을

995
00:37:55,599 --> 00:37:57,219


996
00:37:57,219 --> 00:37:58,963


997
00:37:58,563 --> 00:38:02,480
다른 문제에서도 똑같이 적용할 수 있습니다.

998
00:37:58,963 --> 00:38:02,880


999
00:38:00,951 --> 00:38:06,949


1000
00:38:06,082 --> 00:38:10,845
지금까지는 ImageNet Challenge의 맥락에서 말씀드렸습니다.
 하지만,

1001
00:38:06,482 --> 00:38:08,451


1002
00:38:06,949 --> 00:38:11,325


1003
00:38:08,451 --> 00:38:11,245


1004
00:38:10,845 --> 00:38:13,998
최근의 컴퓨터 비전 분야의 진보를 이끌어낸 것 중 하나는 바로

1005
00:38:11,245 --> 00:38:12,966


1006
00:38:12,966 --> 00:38:14,398


1007
00:38:13,998 --> 00:38:19,950
Convolutional neural networks, 즉
CNN입니다. 또는 convnet으로도 불리죠

1008
00:38:14,398 --> 00:38:17,933


1009
00:38:17,933 --> 00:38:20,350


1010
00:38:19,950 --> 00:38:26,427
최근 몇해 간 ImageNet Challenge의 우승을 이끈
알고리즘에 대해 살표보자면

1011
00:38:20,350 --> 00:38:24,008


1012
00:38:24,008 --> 00:38:26,827


1013
00:38:26,427 --> 00:38:32,231
2011년에서 Lin et al의 알고리즘을 볼 수 있는데
여전히 계층적이죠.

1014
00:38:26,827 --> 00:38:30,479


1015
00:38:30,479 --> 00:38:32,631


1016
00:38:32,231 --> 00:38:34,460
이 알고리즘은 여러 층으로 구성되어 있습니다.

1017
00:38:32,631 --> 00:38:34,860


1018
00:38:34,460 --> 00:38:36,369
우선 몇 개의 특징을 계산하고

1019
00:38:34,860 --> 00:38:36,769


1020
00:38:36,369 --> 00:38:38,342
그다음 몇 개의 지역 불면 특징들을 계산하고

1021
00:38:36,769 --> 00:38:38,742


1022
00:38:36,972 --> 00:38:43,125


1023
00:38:38,342 --> 00:38:42,539
pooling을 하고, 몇 개의 더 레이어를 거칩니다.

1024
00:38:38,742 --> 00:38:41,211


1025
00:38:41,211 --> 00:38:42,939


1026
00:38:42,539 --> 00:38:45,876
그러고 나서 생긴 기술자를 선형 SVM에 넣는 것이죠.

1027
00:38:42,939 --> 00:38:46,276


1028
00:38:44,094 --> 00:38:48,419


1029
00:38:45,876 --> 00:38:48,830
여기서 주목할 점은 바로, 여전히 "계층적"이라는 것 입니다.

1030
00:38:46,276 --> 00:38:49,230


1031
00:38:48,830 --> 00:38:50,153
우리는 여전히 edges를 감지하고,

1032
00:38:50,153 --> 00:38:52,183
여전히 불변성 이라는 개념을 지니고 있죠.

1033
00:38:50,553 --> 00:38:52,583


1034
00:38:52,183 --> 00:38:55,777
그리고 대부분의 그런 직관들은
여전히 CNN으로 까지 영향을 미칩니다.

1035
00:38:52,583 --> 00:38:54,411


1036
00:38:54,411 --> 00:38:56,177


1037
00:38:55,777 --> 00:38:58,715
그러나 가장 획기적이었던 순간은 바로 2012년 이었죠

1038
00:38:56,177 --> 00:38:59,115


1039
00:38:58,715 --> 00:39:06,666
이때 토론토의 Jeff Hinton의 연구실이 Alex Krizhevsky,
그리고 Ilya Sutskever와 함께 하던 해 였습니다.

1040
00:38:59,115 --> 00:39:02,032


1041
00:38:59,399 --> 00:39:13,666


1042
00:39:03,693 --> 00:39:07,066


1043
00:39:06,666 --> 00:39:12,104
그 두 사람은 박사과정(PHD) 였으며, 그때 당시 7개의 레이러를 가진
Convolutional neural network를 만들었었죠.

1044
00:39:07,066 --> 00:39:09,225


1045
00:39:09,225 --> 00:39:12,504


1046
00:39:12,104 --> 00:39:14,812
현재 아주 잘 알려진 AlexNet 입니다,
Supervision으로도 불렸죠

1047
00:39:12,504 --> 00:39:15,212


1048
00:39:14,812 --> 00:39:19,251
AlexNet은 2012년의 ImageNet 대회에서 정말로 잘 해냈습니다.

1049
00:39:15,212 --> 00:39:18,169


1050
00:39:18,169 --> 00:39:19,651


1051
00:39:19,251 --> 00:39:23,797
그 후로는 ImageNet의 승자는
매년 Newral Network의 몫이었습니다.

1052
00:39:19,651 --> 00:39:22,484


1053
00:39:22,484 --> 00:39:24,197


1054
00:39:23,797 --> 00:39:27,696
그리고 이러한 추세는 CNN이 매년
더 깊어지게 만들었죠.

1055
00:39:24,197 --> 00:39:25,911


1056
00:39:25,911 --> 00:39:28,096


1057
00:39:27,696 --> 00:39:33,192
AlexNet은 층이 7개 또는 8개인 Neural Network였습니다.
어떻게 층을 세느냐에 따라 조금 다릅니다.

1058
00:39:28,096 --> 00:39:31,561


1059
00:39:31,561 --> 00:39:33,592


1060
00:39:33,192 --> 00:39:39,118
2015 년에 우리는 훨씬 더 깊은 네트워크를 가졌습니다.
Google의 GoogleNet 그리고 Oxford의 VGG가 바로 그것이죠.

1061
00:39:33,592 --> 00:39:35,561


1062
00:39:35,561 --> 00:39:39,518


1063
00:39:39,118 --> 00:39:42,772
VGGnet은 약 19층의 레이어를 가지고 있었죠.

1064
00:39:39,518 --> 00:39:43,172


1065
00:39:42,772 --> 00:39:44,571
그러고 나서 2015년에는 정말 놀라웠습니다.

1066
00:39:43,172 --> 00:39:44,971


1067
00:39:44,571 --> 00:39:48,198
한 논문아 Microsoft Research Asis에서 나왔는데,

1068
00:39:44,971 --> 00:39:48,598


1069
00:39:48,198 --> 00:39:51,973
Residual Networks라 불리는 이 네트워크는
그 당시 152층의 레이러를 가지고 있었습니다.

1070
00:39:48,598 --> 00:39:52,373


1071
00:39:51,973 --> 00:39:58,105
그 이후에도, 200층 까지 쌓아 올리면 더 좋은 성능을 보일 수
있다고 했지만, 아마도 여러분의 GPU 메모리가 감당할 수 없을 것입니다.

1072
00:39:52,373 --> 00:39:55,037


1073
00:39:55,037 --> 00:39:56,745


1074
00:39:56,745 --> 00:39:58,505


1075
00:39:58,105 --> 00:39:59,952
이 모든건 다음에 더 다루기로 하죠

1076
00:39:58,505 --> 00:40:00,352


1077
00:39:59,952 --> 00:40:02,696
하지만 이 강의에서 중점적으로 다루는 것은
바로 convolutional neural networks 가

1078
00:40:00,352 --> 00:40:03,096


1079
00:40:02,696 --> 00:40:04,424
2012년에 아주 하나의 돌파구를 만들었다는 것이고,

1080
00:40:03,096 --> 00:40:04,824


1081
00:40:03,309 --> 00:40:11,248


1082
00:40:04,424 --> 00:40:08,383
그때 이후로, CNN이 성능을 개선하고 객체 분류를 더 잘 하도록 하기 위해서

1083
00:40:04,824 --> 00:40:06,825


1084
00:40:06,825 --> 00:40:08,783


1085
00:40:08,383 --> 00:40:13,079
CNN을 개선하고 튜닝하려는 많은 시도를이 있었습니다.

1086
00:40:08,783 --> 00:40:11,340


1087
00:40:11,340 --> 00:40:13,479


1088
00:40:11,723 --> 00:40:15,112


1089
00:40:13,079 --> 00:40:15,079
그리고 이번 학기의 남은 시간동안은

1090
00:40:13,479 --> 00:40:15,479


1091
00:40:15,079 --> 00:40:16,700
우리는 더 깊이 파고 들 것입니다.

1092
00:40:15,479 --> 00:40:17,100


1093
00:40:16,700 --> 00:40:19,549
그리고 아마도 여러분은 어떻게 서로 다른 모델이
동작하는지 정확히 이해할 수 있을 것입니다.

1094
00:40:17,100 --> 00:40:19,116


1095
00:40:19,116 --> 00:40:19,949


1096
00:40:22,114 --> 00:40:24,265
하지만 한가지 중요한점은

1097
00:40:22,514 --> 00:40:24,665


1098
00:40:24,265 --> 00:40:29,860
2012년에 CNN이 돌파구를 열었고,

1099
00:40:24,665 --> 00:40:27,348


1100
00:40:25,923 --> 00:40:32,658


1101
00:40:27,348 --> 00:40:30,260


1102
00:40:29,860 --> 00:40:36,151
ImageNet Chllenge에서 아주 좋은 성적을 낸 것은 사실이지만,
CNN이 2012년에 발명된 것은 아니라는 점입니다.

1103
00:40:30,260 --> 00:40:32,394


1104
00:40:32,394 --> 00:40:34,822


1105
00:40:32,658 --> 00:40:43,333


1106
00:40:34,822 --> 00:40:36,551


1107
00:40:36,151 --> 00:40:39,910
이  CNN이란 알고리즘은 실제로
오래 전부터 존재해 왔습니다.

1108
00:40:36,551 --> 00:40:38,186


1109
00:40:38,186 --> 00:40:40,310


1110
00:40:38,455 --> 00:40:41,565


1111
00:40:39,910 --> 00:40:45,757
CNN이라는 분야의 일종의 기초연구 라고 할 수 있는 것은

1112
00:40:40,310 --> 00:40:43,796


1113
00:40:41,565 --> 00:40:45,065


1114
00:40:43,796 --> 00:40:46,157


1115
00:40:45,757 --> 00:40:53,233
90년도의 Jan LeCun과 Bell Labs와의 공동 과제 였습니다.

1116
00:40:46,157 --> 00:40:50,450


1117
00:40:46,675 --> 00:40:48,433


1118
00:40:48,433 --> 00:40:50,647


1119
00:40:50,450 --> 00:40:53,633


1120
00:40:53,233 --> 00:40:58,429
1998년에 그들이 CNN이란 것을 구축했습니다.
숫자 인식을 위한 것이었죠.

1121
00:40:53,633 --> 00:40:57,332


1122
00:40:55,565 --> 00:41:00,232


1123
00:40:57,332 --> 00:40:58,829


1124
00:40:58,429 --> 00:41:06,966
그들은 이 CNN을 이용해서 자필 수표와 우체국의
우편 주소를 자동으로 인식하길 원했습니다.

1125
00:40:58,829 --> 00:41:02,591


1126
00:41:00,232 --> 00:41:03,954


1127
00:41:02,591 --> 00:41:04,668


1128
00:41:04,668 --> 00:41:07,366


1129
00:41:06,966 --> 00:41:08,984
그래서 그들이 바로  CNN을 만든 것입니다.

1130
00:41:07,366 --> 00:41:09,384


1131
00:41:08,984 --> 00:41:11,258
CNN은 Image의 Pixel을 입력으로 받아서,

1132
00:41:09,384 --> 00:41:11,658


1133
00:41:11,258 --> 00:41:16,837
이 숫자가 몇이고, 이 글자가 무엇인지를 분류할 수 있었습니다.

1134
00:41:11,658 --> 00:41:14,582


1135
00:41:14,582 --> 00:41:17,237


1136
00:41:16,837 --> 00:41:18,806
이 네트워크의 구조는

1137
00:41:17,237 --> 00:41:19,206


1138
00:41:18,806 --> 00:41:20,806
사실 AlexNet의 아키텍쳐와 아주 유사합니다.

1139
00:41:19,206 --> 00:41:21,206


1140
00:41:20,806 --> 00:41:23,218
AlexNet은 2012년도였죠

1141
00:41:21,206 --> 00:41:23,618


1142
00:41:23,218 --> 00:41:26,278
우리가 저 그림에서 볼 수 있듯이,
raw 픽셀을 입력으로 받아서는

1143
00:41:23,618 --> 00:41:25,449


1144
00:41:24,068 --> 00:41:30,176


1145
00:41:26,278 --> 00:41:28,680
수많은 Convolution 레이어를 거치고,
서브 샘플링을 합니다

1146
00:41:26,678 --> 00:41:29,080


1147
00:41:28,680 --> 00:41:30,998
 Fully Connected Layer 라고 부르는 것으로
모아줍니다.

1148
00:41:29,080 --> 00:41:31,398


1149
00:41:29,651 --> 00:41:31,701


1150
00:41:30,998 --> 00:41:34,314
이 모든건 다음 강의 부터 더 자세히 다루도록 하겠습니다.

1151
00:41:31,398 --> 00:41:33,395


1152
00:41:31,701 --> 00:41:33,583


1153
00:41:34,314 --> 00:41:36,316
하지만, 여러분이 이 두 그림을 보고 있자면

1154
00:41:34,714 --> 00:41:36,716


1155
00:41:36,316 --> 00:41:37,997
둘이 꽤 비슷해 보일겁니다.

1156
00:41:36,716 --> 00:41:38,397


1157
00:41:37,997 --> 00:41:48,899
2012년의 CNN 아키텍쳐들은 서로 비슷비슷 했습니다.
90년대의 LeNet을의 아키텍처를 서로 공유했기 때문입니다.

1158
00:41:38,397 --> 00:41:41,730


1159
00:41:38,703 --> 00:41:40,602


1160
00:41:39,717 --> 00:41:42,012


1161
00:41:40,602 --> 00:41:42,678


1162
00:41:42,609 --> 00:41:44,449


1163
00:41:44,449 --> 00:41:49,299


1164
00:41:46,888 --> 00:41:49,380


1165
00:41:48,899 --> 00:41:52,977
그럼 이런 질문을 할 수 있겠군요
90년대부터 알고리즘이 었었다면

1166
00:41:49,299 --> 00:41:50,816


1167
00:41:50,816 --> 00:41:53,377


1168
00:41:52,977 --> 00:41:57,054
왜 최근 몇년간이 되어서야 갑자기 인기있어 진 걸까요?

1169
00:41:53,377 --> 00:41:55,815


1170
00:41:55,815 --> 00:41:57,454


1171
00:41:57,054 --> 00:42:02,877
90년대 이래로 아주 큰 혁신적인 것들이 있었습니다.

1172
00:41:57,454 --> 00:41:59,303


1173
00:41:59,303 --> 00:42:03,277


1174
00:42:00,004 --> 00:42:01,706


1175
00:42:01,288 --> 00:42:03,002


1176
00:42:01,706 --> 00:42:06,047


1177
00:42:02,877 --> 00:42:04,951
하나는 바로 계산능력입니다.

1178
00:42:03,277 --> 00:42:05,351


1179
00:42:04,951 --> 00:42:08,817
무어의 법칙 덕분에, 우리는
점점 더 빠른 컴퓨터를 쓸 수 있게 되었고

1180
00:42:05,351 --> 00:42:07,021


1181
00:42:07,021 --> 00:42:09,217


1182
00:42:08,817 --> 00:42:10,833
그리고 완벽한 척도는 아니겠지만,

1183
00:42:09,217 --> 00:42:11,233


1184
00:42:09,792 --> 00:42:12,875


1185
00:42:10,833 --> 00:42:18,174
칩 안의 트랜지스터의 수만 봤을때 90년대와 지금을
비교해보면 몇십배 이상 발전해 왔음을 알 수 있습니다.

1186
00:42:11,233 --> 00:42:13,234


1187
00:42:13,234 --> 00:42:15,129


1188
00:42:15,129 --> 00:42:18,574


1189
00:42:17,057 --> 00:42:19,676


1190
00:42:18,174 --> 00:42:22,643
우리는 또한 graphics processing units의
진보 겪었습니다.

1191
00:42:18,574 --> 00:42:23,043


1192
00:42:19,676 --> 00:42:24,083


1193
00:42:21,204 --> 00:42:30,586


1194
00:42:22,643 --> 00:42:25,478
GPU라고도 하죠, 이는 강력한 병렬처리가 가능한데

1195
00:42:23,043 --> 00:42:25,878


1196
00:42:24,083 --> 00:42:27,036


1197
00:42:25,478 --> 00:42:32,632
계산 집약적인 CNN 모델을 고속으로 처리하기 위한
아주 완벽한 툴로 거듭났습니다.

1198
00:42:25,878 --> 00:42:28,105


1199
00:42:27,036 --> 00:42:30,027


1200
00:42:28,105 --> 00:42:30,866


1201
00:42:30,866 --> 00:42:33,032


1202
00:42:32,632 --> 00:42:39,324
그러니, 단지 좀더 많은 계산이 가능하다는 것 만으로
연구자들이 더 큰 아키텍쳐를 연구할 수 있었고,

1203
00:42:33,032 --> 00:42:35,941


1204
00:42:35,941 --> 00:42:39,724


1205
00:42:36,512 --> 00:42:39,376


1206
00:42:39,324 --> 00:42:43,726
좀 더 큰 모델을 연구할 수 있었습니다.
경우 따라서는 모델 사이즈만 키웠음에도,

1207
00:42:39,724 --> 00:42:42,150


1208
00:42:42,150 --> 00:42:44,126


1209
00:42:43,726 --> 00:42:48,076
기존의 고전적인 방법과 알고리즘은 아무 잘 동작했습니다.

1210
00:42:44,126 --> 00:42:46,838


1211
00:42:46,838 --> 00:42:48,476


1212
00:42:48,076 --> 00:42:55,154
그러므로 계산할 수 있는 양이 늘어났다는 것은
딥 러닝의 역사에서 아주 중요한 것입니다.

1213
00:42:48,476 --> 00:42:51,415


1214
00:42:49,699 --> 00:42:52,562


1215
00:42:51,415 --> 00:42:55,554


1216
00:42:52,562 --> 00:42:54,891


1217
00:42:53,518 --> 00:43:00,004


1218
00:42:55,154 --> 00:43:00,159
지금과 90년대 사이에 변화한 두번째 주요 혁신은
바로 데이터가 아닐까 생각합니다.

1219
00:42:55,554 --> 00:42:58,647


1220
00:42:58,647 --> 00:43:00,559


1221
00:43:00,159 --> 00:43:03,858
이런 알고리즘들은 데이터가 아주 부족할 수 있습니다.

1222
00:43:00,559 --> 00:43:04,258


1223
00:43:00,861 --> 00:43:02,950


1224
00:43:03,858 --> 00:43:08,995
CNN 알고리즘이 잘 동작하게 하기 위해서는
여러분은 아주 많은 레이블된 이미지 그리고 픽셀을 학습시켜야 합니다.

1225
00:43:04,258 --> 00:43:06,319


1226
00:43:06,319 --> 00:43:09,395


1227
00:43:07,450 --> 00:43:08,593


1228
00:43:08,995 --> 00:43:13,741
그리고 90년대에는 충분한 레이블 데이터가
존재하지 않았습니다.

1229
00:43:09,395 --> 00:43:11,653


1230
00:43:10,323 --> 00:43:11,708


1231
00:43:11,653 --> 00:43:14,141


1232
00:43:13,741 --> 00:43:19,832
그때 당시에는 Mechanical Turk이 생겨나기 전이었고
인터넷이 아주 널리 쓰이기도 전이었습니다.

1233
00:43:14,141 --> 00:43:17,489


1234
00:43:17,489 --> 00:43:20,232


1235
00:43:17,885 --> 00:43:21,521


1236
00:43:19,832 --> 00:43:23,214
아무 크고 다양한 데이터셋을 수집하기도 힘들었습니다.

1237
00:43:20,232 --> 00:43:21,871


1238
00:43:20,502 --> 00:43:37,733


1239
00:43:21,871 --> 00:43:23,614


1240
00:43:23,214 --> 00:43:33,828
하지만 지금은 PASCAL이나 ImageNet같은 데이터셋과 같이,
더 규모가 크고 고퀄의 레이블을 가진 데이터셋이 많이 있습니다.

1241
00:43:23,614 --> 00:43:27,531


1242
00:43:25,166 --> 00:43:27,622


1243
00:43:28,583 --> 00:43:31,633


1244
00:43:30,284 --> 00:43:34,451


1245
00:43:31,633 --> 00:43:34,228


1246
00:43:33,828 --> 00:43:38,375
이들은, 90년대에 사용가능했던 데이터셋에 비하면
수십제곱만큼이나 더 크다고 할 수 있습니다.

1247
00:43:34,228 --> 00:43:36,590


1248
00:43:36,590 --> 00:43:38,775


1249
00:43:38,375 --> 00:43:42,753
또 이런 엄청 큰 데이터셋들은
우리가 Higher Capacity Model을 만들 수 있게 하였습니다.

1250
00:43:38,775 --> 00:43:40,622


1251
00:43:40,622 --> 00:43:43,153


1252
00:43:42,753 --> 00:43:46,757
그런 모델을 학습하게 되면 실생활 문제에 실제로도 잘 동작합니다.

1253
00:43:43,153 --> 00:43:45,261


1254
00:43:45,261 --> 00:43:47,157


1255
00:43:46,757 --> 00:43:48,862
하지만 여기에서 비평한만한 것이 있다면,

1256
00:43:47,157 --> 00:43:49,262


1257
00:43:48,862 --> 00:43:53,759
 convolution neural network가 간지나고, 새로워 보이고

1258
00:43:49,262 --> 00:43:51,023


1259
00:43:51,023 --> 00:43:54,159


1260
00:43:51,385 --> 00:44:00,384


1261
00:43:53,759 --> 00:43:57,127
지난 몇 해동안 갑자기 튀어 나온 것 처럼 보일 수도 있지만,
그건 정말 사실이 아니라는 것 입니다.

1262
00:43:54,159 --> 00:43:56,117


1263
00:43:56,117 --> 00:43:57,527


1264
00:43:57,127 --> 00:44:03,266
CNN과 같은 부류의 알고리즘은 아주 오래 전부터 존재했습니다.

1265
00:43:57,527 --> 00:43:59,583


1266
00:43:57,915 --> 00:44:01,332


1267
00:43:59,583 --> 00:44:03,666


1268
00:44:00,384 --> 00:44:06,130


1269
00:44:04,615 --> 00:44:12,355
내가 집고 넘어가고 싶은 것은, 컴퓨터 비전에서 우리가 하는 일은
"사람 처럼 볼 수 있는" 기계를 만드려는 노력 이라는 것입니다.

1270
00:44:05,015 --> 00:44:07,915


1271
00:44:06,130 --> 00:44:09,328


1272
00:44:07,915 --> 00:44:09,724


1273
00:44:09,724 --> 00:44:12,755


1274
00:44:12,355 --> 00:44:16,250
그리고 실제로 사람들은 우리의 시각 체계를
이동해서 아주 많은 것을 할 수 잇습니다.

1275
00:44:12,755 --> 00:44:15,257


1276
00:44:16,250 --> 00:44:18,098
여러분이 이 세상을 살아가면서

1277
00:44:16,650 --> 00:44:18,498


1278
00:44:16,954 --> 00:44:20,739


1279
00:44:18,098 --> 00:44:24,588
여러분은 고양이나 강아지에 사각형을 그리고
분류하는 것 이상의 일을 할 수 있습니다.

1280
00:44:18,498 --> 00:44:21,034


1281
00:44:21,034 --> 00:44:24,988


1282
00:44:24,588 --> 00:44:27,311
여러분의 시각체계는 컴퓨터비전보다 훤씬 더 강력합니다.

1283
00:44:24,988 --> 00:44:27,711


1284
00:44:25,252 --> 00:44:28,071


1285
00:44:27,311 --> 00:44:29,015
다시 이 분야로 돌아가 보자면,

1286
00:44:27,711 --> 00:44:29,415


1287
00:44:29,015 --> 00:44:33,647
아직도 우리가 다뤄야 할 엄청나게 많은 도전과제와
해결하지 못한 문제가 있다고 생각합니다.

1288
00:44:29,415 --> 00:44:31,612


1289
00:44:30,040 --> 00:44:36,273


1290
00:44:31,612 --> 00:44:34,047


1291
00:44:33,647 --> 00:44:39,820
그리고 우리는 더 나은 일을 하고, 더 야심찬 문제에 도전할 수 있도록
알고리즘을 계속해서 개발해 나갈 필요가 있습니다.

1292
00:44:34,047 --> 00:44:36,630


1293
00:44:35,026 --> 00:44:38,214


1294
00:44:36,630 --> 00:44:40,220


1295
00:44:38,214 --> 00:44:39,974


1296
00:44:39,820 --> 00:44:43,643
몇가지 예를 들어보자면, 사실은 오래 전부터 있던 아이디어 이기는 합니다만

1297
00:44:40,220 --> 00:44:42,964


1298
00:44:42,180 --> 00:44:44,765


1299
00:44:43,643 --> 00:44:46,523
Semantic Segmentation, 즉
 Perceptual Grouping 같은 것들이죠

1300
00:44:44,043 --> 00:44:46,923


1301
00:44:44,765 --> 00:44:47,178


1302
00:44:46,523 --> 00:44:48,892
여기에서는 한장의 이미지 전체에
레이블링을 하는 것이 아니라

1303
00:44:46,923 --> 00:44:49,292


1304
00:44:47,178 --> 00:44:50,082


1305
00:44:48,892 --> 00:44:51,569
이미지 내의 모든 픽셀 하나 하나를
이해하는 것입니다.

1306
00:44:49,292 --> 00:44:51,969


1307
00:44:50,082 --> 00:44:53,499


1308
00:44:51,569 --> 00:44:53,466
뭘 하고있는지, 뭘 의미하는지를 말이죠

1309
00:44:51,969 --> 00:44:53,866


1310
00:44:53,466 --> 00:44:56,446
이건 좀 더 뒤에 다시 다루도록 하겠습니다.

1311
00:44:53,866 --> 00:44:55,661


1312
00:44:54,291 --> 00:44:58,494


1313
00:44:56,446 --> 00:44:59,734
실제 세계를 재 구성하는것에 관한 3D 이해에 관한 아이디어로
거슬러 올라가 보자면,

1314
00:44:56,846 --> 00:44:58,453


1315
00:44:58,453 --> 00:45:00,134


1316
00:44:59,734 --> 00:45:05,727
제 생각에는 여전히 풀지못한 문제입니다.

1317
00:45:00,134 --> 00:45:02,377


1318
00:45:02,377 --> 00:45:06,127


1319
00:45:03,664 --> 00:45:09,653


1320
00:45:05,389 --> 00:45:09,518


1321
00:45:07,098 --> 00:45:09,778
여러분이 상상할 수 있는
엄청나게 많은 과제들이 있습니다.

1322
00:45:07,498 --> 00:45:09,010


1323
00:45:09,778 --> 00:45:11,417
예를들어 행동인식이 있겠네요,

1324
00:45:10,178 --> 00:45:11,817


1325
00:45:11,417 --> 00:45:16,325
만약 여러분에게 어떤 사람이 무언가를 하고있는 비디오가 있다고 했을때,
그 활동을 인식할 수 있는 최고의 방법이 과연 무엇일까요?

1326
00:45:11,817 --> 00:45:13,438


1327
00:45:13,438 --> 00:45:15,212


1328
00:45:13,893 --> 00:45:16,232


1329
00:45:15,212 --> 00:45:16,725


1330
00:45:16,325 --> 00:45:19,069
그것은 꽤 도전적인 문제 이기도 합니다.

1331
00:45:16,725 --> 00:45:19,469


1332
00:45:17,948 --> 00:45:19,664


1333
00:45:19,069 --> 00:45:22,874
그리고 나서 우리가 증강현실, 가상현실로 뻗어나가고

1334
00:45:19,469 --> 00:45:21,286


1335
00:45:21,286 --> 00:45:23,274


1336
00:45:22,874 --> 00:45:27,178
새로운 종류의 센서들과 마주하게 된다면,

1337
00:45:23,274 --> 00:45:25,332


1338
00:45:23,646 --> 00:45:25,157


1339
00:45:25,332 --> 00:45:27,578


1340
00:45:27,178 --> 00:45:32,055
제 생각에, 우리는 한 분야로 다룰 수 있을만큼
새롭고 흥미롭고, 어렵고 아주 도전적인 문제들을 또 만나게 될 것입니다.

1341
00:45:27,578 --> 00:45:29,955


1342
00:45:29,955 --> 00:45:32,455


1343
00:45:31,540 --> 00:45:34,957


1344
00:45:33,516 --> 00:45:41,828
지금부터 보여드릴 예는 제가 비전연구실에서 하고있는 일중에 일부인데,
Visual Genome 이라는 데이터셋입니다.

1345
00:45:33,916 --> 00:45:37,924


1346
00:45:36,617 --> 00:45:40,284


1347
00:45:37,924 --> 00:45:42,228


1348
00:45:41,828 --> 00:45:47,074
여기에서 주된 아이디어는 바로 복잡한 실제 세상에서 일부를
포착해 내는 것입니다.

1349
00:45:42,228 --> 00:45:45,426


1350
00:45:43,359 --> 00:45:46,352


1351
00:45:44,060 --> 00:45:53,036


1352
00:45:45,426 --> 00:45:47,474


1353
00:45:47,074 --> 00:45:51,908
박스만 치는 것으로는 부족하고 이미지를

1354
00:45:47,474 --> 00:45:49,793


1355
00:45:49,793 --> 00:45:52,308


1356
00:45:51,908 --> 00:45:57,125
하나의 커다란 의미론적인 그래프로 표현하는 것입니다.
이 그래프는, 객체를 식별하는것 뿐만 아니라

1357
00:45:52,308 --> 00:45:55,056


1358
00:45:53,036 --> 00:45:55,171


1359
00:45:55,056 --> 00:45:57,525


1360
00:45:57,125 --> 00:46:02,190
그 장면에 나타난 객체의 관계, 객체의 성격, 행동 등을
나타낼 수 있습니다.

1361
00:45:57,525 --> 00:46:00,451


1362
00:45:59,273 --> 00:46:00,953


1363
00:46:00,451 --> 00:46:02,590


1364
00:46:00,953 --> 00:46:04,703


1365
00:46:02,190 --> 00:46:09,127
그리고 이런 방식의 표현방법을 통해서 어쩌면 실제 세계를
일부 만이라도 포착할 수 있지 않을까 예상합니다.

1366
00:46:02,590 --> 00:46:06,971


1367
00:46:06,971 --> 00:46:09,527


1368
00:46:07,411 --> 00:46:12,931


1369
00:46:09,127 --> 00:46:12,489
그리고 그것들은 우리가 단순한 분류만 하고 있을때
활용하지 못했던 것들이죠

1370
00:46:09,527 --> 00:46:11,225


1371
00:46:11,225 --> 00:46:12,889


1372
00:46:12,489 --> 00:46:14,870
이것이 현 시점에서 표준 접근법 이라는 말은 아니지만,

1373
00:46:12,889 --> 00:46:15,270


1374
00:46:14,870 --> 00:46:19,235
우리 인간의 시각 체계라는 것이 단순한 이미지 분류 알고리즘으로는
포착해 낼 수 없는

1375
00:46:15,270 --> 00:46:17,330


1376
00:46:17,330 --> 00:46:19,635


1377
00:46:19,235 --> 00:46:24,440
훨씬 더 많은 것을 할 수 있다는 것을 여러분들이 깨달게
해 주는 것 만으로도 충분합니다.

1378
00:46:19,635 --> 00:46:22,590


1379
00:46:22,590 --> 00:46:24,840


1380
00:46:25,588 --> 00:46:29,187


1381
00:46:27,603 --> 00:46:31,192
그런 관점에서 봤을때, 정말 재밌는 연구가 하나 있는데

1382
00:46:28,003 --> 00:46:29,744


1383
00:46:29,744 --> 00:46:31,592


1384
00:46:31,192 --> 00:46:33,745
Fei-Fei 교수님의 학부시절의 연구입니다.

1385
00:46:31,592 --> 00:46:34,145


1386
00:46:33,745 --> 00:46:38,552
그 당시 그녀는 지도 교수님과 Cal Tech에서 박사과정을 진행하고
있었습니다.

1387
00:46:34,145 --> 00:46:36,843


1388
00:46:35,486 --> 00:46:36,663


1389
00:46:36,843 --> 00:46:38,952


1390
00:46:38,552 --> 00:46:41,292
이 연구에서는, 사람들을 붙잡아서

1391
00:46:38,952 --> 00:46:41,692


1392
00:46:41,292 --> 00:46:44,204
사람들에게 이 사진을 아주 잠시 동안만 보여줬습니다.

1393
00:46:41,692 --> 00:46:44,604


1394
00:46:42,256 --> 00:46:44,790


1395
00:46:42,784 --> 00:46:46,446


1396
00:46:44,204 --> 00:46:47,496
그들에게 아무 짧은 시간만 이 이미지를 보여준 것이죠,

1397
00:46:44,604 --> 00:46:46,302


1398
00:46:46,302 --> 00:46:47,896


1399
00:46:47,496 --> 00:46:51,708
이미지를 본 시간이 아무 짧음에도 불구하고, 사람들은

1400
00:46:47,896 --> 00:46:50,169


1401
00:46:48,885 --> 00:46:52,364


1402
00:46:50,169 --> 00:46:52,108


1403
00:46:51,708 --> 00:46:56,073
위와 같이 그 이미지에 관한 아주 긴 문장을 쓸 수 있었습니다.

1404
00:46:52,108 --> 00:46:54,033


1405
00:46:52,364 --> 00:46:54,814


1406
00:46:54,033 --> 00:46:56,473


1407
00:46:54,814 --> 00:46:57,719


1408
00:46:56,073 --> 00:47:03,292
그리고 이것은 아주 주목할만한 것입니다.
이미지를 아무 잠깐만 본 후에도

1409
00:46:56,473 --> 00:47:00,284


1410
00:46:57,719 --> 00:46:59,780


1411
00:46:58,010 --> 00:47:04,111


1412
00:47:00,284 --> 00:47:03,692


1413
00:47:02,066 --> 00:47:06,233


1414
00:47:03,292 --> 00:47:05,160
인간은 이미지에 대해 말할 수 있었습니다.

1415
00:47:03,692 --> 00:47:05,560


1416
00:47:04,111 --> 00:47:11,911


1417
00:47:05,160 --> 00:47:09,975
일종의 게임, 또는 싸움을 하고 있고, 두 무리의 남자기 있고, 왼쪽에
있는 남자는 뭘 던지고 있고,

1418
00:47:05,560 --> 00:47:08,481


1419
00:47:08,481 --> 00:47:10,375


1420
00:47:09,975 --> 00:47:14,176
이곳이 밖이고, 잔디와 같은 느낌이 들어서, 등등

1421
00:47:10,375 --> 00:47:13,134


1422
00:47:13,134 --> 00:47:14,576


1423
00:47:14,176 --> 00:47:17,217
그리고 아마 사람이 이 이미지를 좀더 오래 보게 된다면
어떨지 상상할 수 있을 것입니다.

1424
00:47:14,576 --> 00:47:16,016


1425
00:47:16,016 --> 00:47:17,617


1426
00:47:17,217 --> 00:47:18,769
아마도, 그들이 누구이고

1427
00:47:17,617 --> 00:47:19,169


1428
00:47:18,769 --> 00:47:21,907
왜 그들이 저기에서 게임을 하고있는지에 대해서
소설 한편을 쓸지도 모르겠습니다.

1429
00:47:19,169 --> 00:47:20,942


1430
00:47:21,907 --> 00:47:23,285
아마 끝도없이 계속 할 수도 있을 것입니다.

1431
00:47:23,285 --> 00:47:26,787
외부의 지식과, 선행 경험을 통해서 말이죠

1432
00:47:23,685 --> 00:47:25,613


1433
00:47:25,613 --> 00:47:27,187


1434
00:47:26,787 --> 00:47:29,897
이는 어찌보면 컴퓨터 비전의 성배라고 할 수 있습니다.

1435
00:47:27,187 --> 00:47:30,297


1436
00:47:28,775 --> 00:47:31,679


1437
00:47:29,897 --> 00:47:34,263
이미지의 스토리를 아주 풍부하고 깊은 방법으로
이해 한다는 면에서 말이죠

1438
00:47:30,297 --> 00:47:32,659


1439
00:47:32,659 --> 00:47:34,663


1440
00:47:34,263 --> 00:47:39,306
그리고 제 생각에는, 지난 컴퓨터비전이라는 분야의
수년간의 큰 진보에서 불구하고

1441
00:47:34,663 --> 00:47:36,932


1442
00:47:36,932 --> 00:47:39,706


1443
00:47:39,306 --> 00:47:44,060
성배를 얻기위한 길은 아직도 멀고도 험난합니다.

1444
00:47:39,706 --> 00:47:44,460


1445
00:47:41,866 --> 00:47:48,503


1446
00:47:44,060 --> 00:47:50,072
이것에 대해 예를 들고싶은 이미지가 하나 더 있습니다.
Andrej Karpathy의 블로그에 있는 이미지입니다.

1447
00:47:44,460 --> 00:47:46,563


1448
00:47:46,563 --> 00:47:50,472


1449
00:47:48,503 --> 00:47:52,460


1450
00:47:50,072 --> 00:47:52,490
아주 놀라운 것이죠

1451
00:47:50,472 --> 00:47:52,890


1452
00:47:52,490 --> 00:47:53,991
많은 사람들이 웃었습니다.

1453
00:47:52,890 --> 00:47:54,391


1454
00:47:53,991 --> 00:47:55,812
제생각에 이 이미지는 상당히 재밌다고 생각합니다.

1455
00:47:54,391 --> 00:47:56,212


1456
00:47:55,812 --> 00:47:57,296
왜 이게 웃기죠?

1457
00:47:56,212 --> 00:47:57,696


1458
00:47:57,296 --> 00:48:01,207
한 남자가 체중계에 서 있습니다. 우리는 보통 사람들이 가끔씩

1459
00:47:57,696 --> 00:47:59,895


1460
00:47:58,534 --> 00:48:01,289


1461
00:47:59,895 --> 00:48:01,607


1462
00:48:01,207 --> 00:48:03,980
자신의 체중을 알아보기 위해 체중계를 사용한다는 것을 알고 있습니다.

1463
00:48:01,607 --> 00:48:04,380


1464
00:48:02,806 --> 00:48:07,704


1465
00:48:03,980 --> 00:48:08,391
그리고 우린 뒤에서 체중계를 밟고 있는 다른 한 사람을 볼 수 있습니다.

1466
00:48:04,380 --> 00:48:06,899


1467
00:48:04,968 --> 00:48:08,779


1468
00:48:06,899 --> 00:48:08,791


1469
00:48:08,391 --> 00:48:10,500
그리고 우리는 체중계가 어떻게 동작할 지 짐작할 수 있고,

1470
00:48:08,791 --> 00:48:10,900


1471
00:48:10,500 --> 00:48:13,467
저 사람이 보게될 부풀려진 체중의 이유를 알고 있습니다.

1472
00:48:10,900 --> 00:48:12,958


1473
00:48:11,927 --> 00:48:15,004


1474
00:48:13,467 --> 00:48:14,495
그러나 더 많은 것이 있습니다.

1475
00:48:14,495 --> 00:48:16,419
우리는 저 사람이 평범한 사람이 아니란 것을 알고 있습니다.

1476
00:48:14,895 --> 00:48:16,819


1477
00:48:16,419 --> 00:48:20,505
저 사람은 당의 미국 대통령 Barack Obama 입니다.

1478
00:48:16,819 --> 00:48:19,500


1479
00:48:17,862 --> 00:48:18,924


1480
00:48:19,500 --> 00:48:20,905


1481
00:48:20,505 --> 00:48:24,341
그리고 우리는 미국 대통령은 존경받는 정치인이
되어야 한다고 알 고 있습니다.

1482
00:48:20,905 --> 00:48:22,541


1483
00:48:22,541 --> 00:48:24,741


1484
00:48:22,797 --> 00:48:28,523


1485
00:48:24,341 --> 00:48:26,645
[웃음]

1486
00:48:24,741 --> 00:48:27,045


1487
00:48:26,645 --> 00:48:30,904
아마도 이런식으로 동료에게 장난을 치지 않아야 하겠죠

1488
00:48:27,045 --> 00:48:29,154


1489
00:48:29,154 --> 00:48:31,304


1490
00:48:29,797 --> 00:48:31,270


1491
00:48:30,904 --> 00:48:34,164
우리는 뒤 쪽의 사람들이 웃고 있다는 것을 알 수 있습니다.

1492
00:48:31,304 --> 00:48:32,713


1493
00:48:32,713 --> 00:48:34,564


1494
00:48:34,164 --> 00:48:37,512
우리는 뒤쪽의 사람들이 이 장면을 어떻게
이해하는지를 알 수도 있습니다.

1495
00:48:34,564 --> 00:48:36,066


1496
00:48:36,066 --> 00:48:37,912


1497
00:48:36,504 --> 00:48:39,769


1498
00:48:37,512 --> 00:48:42,466
그들도 우리처럼 오바마대통령이 존경받는 사람이라는 것을 알고 있다는
것을 이해할 수 있습니다.

1499
00:48:37,912 --> 00:48:39,597


1500
00:48:39,597 --> 00:48:41,575


1501
00:48:42,466 --> 00:48:43,367
이건 정말 놀라운 것입니다.

1502
00:48:43,367 --> 00:48:45,430
이 이미지에는 많은 것이 있습니다.

1503
00:48:43,767 --> 00:48:45,830


1504
00:48:45,430 --> 00:48:47,767
그리고 우리의 컴퓨터 비전 알고리즘은

1505
00:48:45,830 --> 00:48:48,167


1506
00:48:47,767 --> 00:48:52,602
이미지에 대한 이런 진정한 깊은 이해를 하기까지는
아직 갈 길이 멀다고 생각합니다.

1507
00:48:48,167 --> 00:48:51,108


1508
00:48:48,409 --> 00:48:54,607


1509
00:48:51,108 --> 00:48:53,002


1510
00:48:52,602 --> 00:48:58,377
저는 이 분야의 큰 진보에도 불구하고,
아직 갈이 멀다고 생각합니다.

1511
00:48:53,002 --> 00:48:56,032


1512
00:48:54,607 --> 00:49:01,635


1513
00:48:56,032 --> 00:48:58,777


1514
00:48:56,411 --> 00:48:59,231


1515
00:48:58,377 --> 00:49:00,985
저에게 이것은 연구자로서 정말 흥분되는 것입니다.

1516
00:48:58,777 --> 00:49:01,385


1517
00:48:59,231 --> 00:49:00,832


1518
00:49:00,985 --> 00:49:06,294
왜냐하면 앞으로 나가갈 수 있는 정말 흥미진진하고
재미있는 문제들이 우리에게 아직 많이 남아있기 때문입니다.

1519
00:49:01,385 --> 00:49:02,630


1520
00:49:02,630 --> 00:49:04,611


1521
00:49:03,242 --> 00:49:07,409


1522
00:49:04,611 --> 00:49:06,694


1523
00:49:06,149 --> 00:49:14,186


1524
00:49:07,513 --> 00:49:12,654
그래서 저는 컴퓨터비전이 정말 재미있다는 것을
여러분들에게 알리고 싶습니다.

1525
00:49:07,913 --> 00:49:10,202


1526
00:49:10,202 --> 00:49:13,054


1527
00:49:12,654 --> 00:49:13,808
정말 재밌습니다.

1528
00:49:13,808 --> 00:49:15,929
그리고 매우 유용합니다.

1529
00:49:14,208 --> 00:49:16,329


1530
00:49:15,929 --> 00:49:19,643
그리고 나아 가서 다양한 방법으로
이 세상을 좋은 곳으로 만들어 줄 수 있습니다.

1531
00:49:16,329 --> 00:49:18,315


1532
00:49:18,315 --> 00:49:20,043


1533
00:49:19,643 --> 00:49:27,734
컴퓨터비전은 의학진단이나 자율주행 자동차, 로보틱스 등
어느 곳이든 적용할 수 있습니다.

1534
00:49:20,043 --> 00:49:21,591


1535
00:49:20,581 --> 00:49:23,748


1536
00:49:21,591 --> 00:49:24,559


1537
00:49:22,230 --> 00:49:26,829


1538
00:49:24,559 --> 00:49:28,134


1539
00:49:27,734 --> 00:49:32,720
게다가 인간의 지능을 이해하기 위한 여러가지 핵심 아이디어를
서로 묶어주는 일존의 매듭이 될 수도 있습니다.

1540
00:49:28,134 --> 00:49:30,713


1541
00:49:28,778 --> 00:49:30,490


1542
00:49:30,713 --> 00:49:33,120


1543
00:49:32,720 --> 00:49:36,741
제 생각에는 컴퓨터비전은 정말 기상천외하고 재밌는 분야입니다.

1544
00:49:33,120 --> 00:49:34,849


1545
00:49:34,849 --> 00:49:37,141


1546
00:49:36,741 --> 00:49:40,075
그리고 여러분들과 이 수업을 통해서 오늘날 알고리즘들이
실제로 어떻게 동작하는지에 대해서

1547
00:49:37,141 --> 00:49:38,775


1548
00:49:38,775 --> 00:49:40,475


1549
00:49:40,075 --> 00:49:45,834
여러분들과 심도깊은 이야기를 할수 있게 되어서 정말 좋습니다.

1550
00:49:40,475 --> 00:49:42,337


1551
00:49:42,337 --> 00:49:46,234


1552
00:49:44,682 --> 00:49:46,276


1553
00:49:45,834 --> 00:49:50,273
여기까지는 컴퓨터비전에 대한 개인적인 견해와
컴퓨터 비전의 역사에 대해서 였습니다.

1554
00:49:46,234 --> 00:49:48,949


1555
00:49:48,949 --> 00:49:50,673


1556
00:49:50,273 --> 00:49:52,966
혹시 궁금한 점이 있으신가요?

1557
00:49:50,673 --> 00:49:52,283


1558
00:49:52,283 --> 00:49:53,366


1559
00:49:55,307 --> 00:49:56,655
좋습니다.

1560
00:49:56,655 --> 00:50:02,008
그러면 이제 앞으로의 수업 계획에 대해 말해보죠

1561
00:49:57,055 --> 00:49:58,345


1562
00:49:58,345 --> 00:50:00,408


1563
00:50:00,408 --> 00:50:02,408


1564
00:50:00,715 --> 00:50:07,423


1565
00:50:02,008 --> 00:50:03,982
어쩌면 여러분은 우리가 누구냐고 물으실 수도 있습니다.

1566
00:50:02,408 --> 00:50:04,382


1567
00:50:03,982 --> 00:50:06,504
이 수업은 Fei-Fei Li 교수님께서 가르치십니다.

1568
00:50:04,382 --> 00:50:06,904


1569
00:50:06,504 --> 00:50:10,871
이곳 Stanford의 컴퓨터 과학 교수님이십니다.

1570
00:50:06,904 --> 00:50:11,271


1571
00:50:07,957 --> 00:50:11,063


1572
00:50:09,123 --> 00:50:11,112


1573
00:50:10,871 --> 00:50:14,116
그리고 제 지도 교수님이시기도 하고
Stanford Vision Lab의 교수님이십니다.

1574
00:50:11,271 --> 00:50:14,516


1575
00:50:14,116 --> 00:50:16,452
Stanford AI Lab에 계시기도 하죠

1576
00:50:14,516 --> 00:50:16,852


1577
00:50:16,452 --> 00:50:22,119
그리고 다른 두명, 저 Justin Tohnson과 Serena
Yeung, 여기 앞에 서있습니다.

1578
00:50:16,852 --> 00:50:20,081


1579
00:50:17,645 --> 00:50:19,317


1580
00:50:20,081 --> 00:50:22,519


1581
00:50:22,119 --> 00:50:26,979
우리 둘은 Fei-Fei 교수님의 지도 하에
다양한 컴퓨터 비전 과제를 수행하고 있는 PHD 학생입니다.

1582
00:50:22,519 --> 00:50:25,219


1583
00:50:24,073 --> 00:50:26,238


1584
00:50:25,219 --> 00:50:27,379


1585
00:50:26,979 --> 00:50:31,520
우리에게 18명의 훌륭한 조교가 있습니다.

1586
00:50:27,379 --> 00:50:29,996


1587
00:50:28,645 --> 00:50:30,486


1588
00:50:29,996 --> 00:50:31,920


1589
00:50:30,486 --> 00:50:33,140


1590
00:50:31,520 --> 00:50:33,779
대부분은 여기 앞에 앉아 있습니다.

1591
00:50:31,920 --> 00:50:34,179


1592
00:50:33,779 --> 00:50:39,920
우리가 수업을 잘 진행하고, 모든것이 잘 돌아갈 수 있도록
도와주는 얼굴없는 영웅들 입니다.

1593
00:50:34,179 --> 00:50:35,921


1594
00:50:35,921 --> 00:50:38,527


1595
00:50:38,527 --> 00:50:40,320


1596
00:50:38,902 --> 00:50:40,343


1597
00:50:39,920 --> 00:50:41,965
그러니 그들에게 잘해주세요.

1598
00:50:40,320 --> 00:50:42,365


1599
00:50:41,965 --> 00:50:43,796
[웃음]

1600
00:50:42,365 --> 00:50:44,196


1601
00:50:43,796 --> 00:50:48,816
말씀 드려야 할 점이 있다면, 이 강의는 세 번째 열리는 강의이지만

1602
00:50:44,196 --> 00:50:47,153


1603
00:50:47,153 --> 00:50:49,216


1604
00:50:48,816 --> 00:50:52,650
Andrej Karpathy가 강의를 하지 않는 첫 번째 강의이기도 합니다.

1605
00:50:49,216 --> 00:50:51,652


1606
00:50:52,650 --> 00:50:55,792
그는 저와 아주 친한 친구입니다.

1607
00:50:53,050 --> 00:50:56,192


1608
00:50:55,792 --> 00:50:56,693
그는 아직 살아 있습니다.

1609
00:50:56,693 --> 00:50:57,953
그는 괜찮습니다. 걱정하지 마세요.

1610
00:50:57,953 --> 00:50:59,212
[웃음]

1611
00:50:59,212 --> 00:51:02,380
그는 졸업을 했고 사실 여기에 있습니다.

1612
00:50:59,612 --> 00:51:02,780


1613
00:50:59,896 --> 00:51:01,404


1614
00:51:02,380 --> 00:51:05,324
강당 어딘가에 있겠죠

1615
00:51:02,780 --> 00:51:05,724


1616
00:51:03,512 --> 00:51:08,034


1617
00:51:05,324 --> 00:51:11,217
이 수업의 발전과 역사의 대부분은 수년동안 저와 함께 일해준
그의 덕분 이었습니다.

1618
00:51:05,724 --> 00:51:07,662


1619
00:51:06,303 --> 00:51:08,675


1620
00:51:07,662 --> 00:51:09,570


1621
00:51:09,570 --> 00:51:11,617


1622
00:51:11,217 --> 00:51:14,998
그 사실은 여러분도 알고 계셨으면 좋겠습니다.

1623
00:51:11,617 --> 00:51:15,398


1624
00:51:12,604 --> 00:51:17,564


1625
00:51:14,998 --> 00:51:21,809
강의에 대해 말해보자면, 조교들과 연락할 수 있는 가장
좋은 방법은 Piazza를 이용하는 것입니다.

1626
00:51:15,398 --> 00:51:18,194


1627
00:51:18,194 --> 00:51:20,904


1628
00:51:20,472 --> 00:51:22,518


1629
00:51:21,809 --> 00:51:24,812
당장 가서 가입하세요

1630
00:51:22,209 --> 00:51:25,212


1631
00:51:22,518 --> 00:51:24,863


1632
00:51:24,812 --> 00:51:29,953
Piazza는 이 수업에 대한 의사소통을 할 수 있는
우리가 가장 선호하는 방법입니다.

1633
00:51:25,212 --> 00:51:27,597


1634
00:51:26,397 --> 00:51:30,619


1635
00:51:27,597 --> 00:51:30,353


1636
00:51:29,953 --> 00:51:33,913
만약 친구들 앞에서 질문하는 것이 꺼려진다면,

1637
00:51:30,353 --> 00:51:32,621


1638
00:51:30,628 --> 00:51:34,795


1639
00:51:32,621 --> 00:51:34,313


1640
00:51:33,913 --> 00:51:40,172
Piazza에 가서 익명으로 질문을 하세요 private
질문을 올릴수도 있습니다. 교직원에게 직접 연락하십시오.

1641
00:51:34,313 --> 00:51:36,067


1642
00:51:36,067 --> 00:51:38,602


1643
00:51:36,770 --> 00:51:44,093


1644
00:51:38,602 --> 00:51:40,572


1645
00:51:40,172 --> 00:51:44,052
기본적으로 여러분이 필요한것은 그저 Piazza를 경험하는 것입니다.

1646
00:51:40,572 --> 00:51:42,269


1647
00:51:41,051 --> 00:51:44,218


1648
00:51:42,269 --> 00:51:44,452


1649
00:51:44,052 --> 00:51:48,022
조교들의 메일링 리스트가 있긴 하지만

1650
00:51:44,452 --> 00:51:46,445


1651
00:51:45,142 --> 00:51:49,309


1652
00:51:46,445 --> 00:51:48,422


1653
00:51:48,022 --> 00:51:53,117
Piazza에 올리기 껄끄러운 개인적이거나 비공개적인 것들을 위해서만 쓰고

1654
00:51:48,422 --> 00:51:51,302


1655
00:51:50,260 --> 00:51:53,814


1656
00:51:51,302 --> 00:51:53,517


1657
00:51:53,117 --> 00:52:01,725
혹시나 정말 중요한 말못할 사항이 있다면, 저나, Serena, Fei-Fei
교수님께 직접 메일을 주셔도 되겠습니다.

1658
00:51:53,517 --> 00:51:55,773


1659
00:51:53,814 --> 00:51:56,637


1660
00:51:55,773 --> 00:51:58,365


1661
00:51:56,637 --> 00:51:59,787


1662
00:51:58,365 --> 00:52:02,125


1663
00:51:59,787 --> 00:52:03,346


1664
00:52:01,725 --> 00:52:05,696
하지만 그 외의 조교와의 커뮤니케이션은 Piazza을
통해서여만 합니다.

1665
00:52:02,125 --> 00:52:03,900


1666
00:52:03,900 --> 00:52:06,096


1667
00:52:05,696 --> 00:52:08,260
올해는 부교재도 있습니다.

1668
00:52:06,096 --> 00:52:08,660


1669
00:52:08,260 --> 00:52:10,001
필수는 아닙니다.

1670
00:52:08,660 --> 00:52:10,401


1671
00:52:10,001 --> 00:52:12,216
이 책없이도 이 강의를 들을 수 있습니다.

1672
00:52:10,401 --> 00:52:12,616


1673
00:52:10,955 --> 00:52:13,372


1674
00:52:12,216 --> 00:52:13,972
모든걸 스스로 챙겨야 할 것입니다.

1675
00:52:12,616 --> 00:52:14,372


1676
00:52:13,972 --> 00:52:19,386
정말 흥분되는 것은, 이 책이 아마 딥 러닝에 관해서 처음 출간된
교과서 라는 것 떄문입니다.

1677
00:52:14,372 --> 00:52:17,770


1678
00:52:14,877 --> 00:52:16,604


1679
00:52:16,604 --> 00:52:19,937


1680
00:52:17,770 --> 00:52:19,786


1681
00:52:19,386 --> 00:52:23,678
올해 초에 출간된 E.N. Goodfellow, U
oshua Bengio, Aaron Courville이 쓴 책 입니다.

1682
00:52:19,786 --> 00:52:21,889


1683
00:52:21,889 --> 00:52:24,078


1684
00:52:23,678 --> 00:52:26,284
슬라이드에 아마존 링크를 주가했습니다.

1685
00:52:24,078 --> 00:52:26,684


1686
00:52:26,284 --> 00:52:27,797
원한다면 구입하도록 하세요

1687
00:52:26,684 --> 00:52:28,197


1688
00:52:27,797 --> 00:52:31,407
하지만 온라인에 무료 컨텐츠도 있기 떄문에,
반드시 살 필요는 없습니다.

1689
00:52:28,197 --> 00:52:30,079


1690
00:52:30,079 --> 00:52:31,807


1691
00:52:31,407 --> 00:52:32,543
사고 싶지 않다면 말이죠

1692
00:52:32,543 --> 00:52:33,861
다시 한번 말하지만 이것은 완전히 선택 사항입니다.

1693
00:52:33,861 --> 00:52:40,214
하지만 아마도 학기동안 이 책의 일부를 읽으라고 공지할 수도 있습니다.
이 책은 여러분에게 추가적인 관점을 얻는데 도움을 줄 것입니다.

1694
00:52:34,261 --> 00:52:35,778


1695
00:52:35,778 --> 00:52:37,614


1696
00:52:37,614 --> 00:52:40,614


1697
00:52:40,059 --> 00:52:42,308


1698
00:52:41,297 --> 00:52:48,394
이 수업의 철학은 여러분이 딥러닝에 관한 모든 알고리즘을 정말로
이해해야 한다는 것입니다.

1699
00:52:41,697 --> 00:52:43,259


1700
00:52:43,259 --> 00:52:47,035


1701
00:52:44,319 --> 00:52:47,831


1702
00:52:47,035 --> 00:52:48,794


1703
00:52:48,394 --> 00:52:50,271
아주 깊은 수준에서 이해해야 합니다.

1704
00:52:48,794 --> 00:52:50,671


1705
00:52:50,271 --> 00:52:52,317
이 알고리듬이 정확히 어떻게 작동하는지

1706
00:52:50,671 --> 00:52:52,717


1707
00:52:51,314 --> 00:52:53,448


1708
00:52:52,317 --> 00:52:55,697
여러분이 뉴럴 네트워크들을 연결했을때 정확이 무슨 일이 일어나는지,

1709
00:52:52,717 --> 00:52:54,295


1710
00:52:54,295 --> 00:52:56,097


1711
00:52:55,697 --> 00:53:01,914
그런 아키텍쳐의 선택이 어떤 영향을 미치는, 네트워크가 어떻게
학습되고 테스팅 되는지 와 같은 것들입니다.

1712
00:52:56,097 --> 00:52:58,128


1713
00:52:58,128 --> 00:53:00,144


1714
00:53:00,144 --> 00:53:02,314


1715
00:53:01,914 --> 00:53:04,811
그리고 과제를 통해 코스 전반에 걸쳐셔

1716
00:53:02,314 --> 00:53:05,211


1717
00:53:04,811 --> 00:53:08,357
여러분은 아마 여러분만의 CNN을 파이썬을 이용해서
밑바닥부터 구현할 것입니다.

1718
00:53:05,211 --> 00:53:07,163


1719
00:53:07,163 --> 00:53:08,757


1720
00:53:08,357 --> 00:53:12,860
여러분은 전체 foward, backward passes을 구현할 것입니다.

1721
00:53:08,757 --> 00:53:11,560


1722
00:53:09,059 --> 00:53:09,999


1723
00:53:09,999 --> 00:53:13,499


1724
00:53:11,560 --> 00:53:13,260


1725
00:53:12,860 --> 00:53:15,920
결국, 여러분은 전체 CNN을 완벽히 구현하게 될 것입니다.

1726
00:53:13,260 --> 00:53:15,106


1727
00:53:14,580 --> 00:53:18,413


1728
00:53:15,920 --> 00:53:17,920
저는 이게 멋지다고 생각합니다.

1729
00:53:16,320 --> 00:53:18,320


1730
00:53:17,920 --> 00:53:23,120
하지만 실용적인 측면에서, 아마 대부분의 사람들이
이런 것들을 밑바닥부터 하지는 않을 것이라는 것을 알고 있습니다.

1731
00:53:18,320 --> 00:53:20,569


1732
00:53:19,562 --> 00:53:22,383


1733
00:53:20,569 --> 00:53:23,520


1734
00:53:23,120 --> 00:53:30,926
떄문에, 여러분에이 실용적으로 쓸 수 있는 일부
최신의 소프트웨어 툴을 소개해 드릴 것입니다.

1735
00:53:23,520 --> 00:53:25,613


1736
00:53:25,613 --> 00:53:27,769


1737
00:53:27,769 --> 00:53:31,326


1738
00:53:30,926 --> 00:53:37,263
Tensor Flow, Torch, PyTorch 와 같은 최신 소프트웨어에
대해서도 이야기할 것입니다.

1739
00:53:31,326 --> 00:53:33,373


1740
00:53:31,790 --> 00:53:33,098


1741
00:53:33,373 --> 00:53:36,392


1742
00:53:34,205 --> 00:53:35,763


1743
00:53:35,763 --> 00:53:39,930


1744
00:53:37,263 --> 00:53:44,128
아마 그럴 툴들을 이 강의의 과제나 프로젝트를
통해서 접할 수 있을 것입니다.

1745
00:53:37,663 --> 00:53:39,890


1746
00:53:39,890 --> 00:53:42,636


1747
00:53:42,636 --> 00:53:44,528


1748
00:53:44,128 --> 00:53:47,420
또 한 가지 말씀드릴 것은, 이 강의는
매우 state-of-the-art 하다는 것입니다.

1749
00:53:44,528 --> 00:53:46,303


1750
00:53:46,303 --> 00:53:47,820


1751
00:53:47,420 --> 00:53:48,722
저는 이점이 매우 흥분됩니다.

1752
00:53:47,637 --> 00:53:50,818


1753
00:53:48,722 --> 00:53:50,315
이 분야는 매우 빠르게 변하는 분야입니다.

1754
00:53:49,122 --> 00:53:50,715


1755
00:53:50,315 --> 00:53:55,211
여러분도 ImageNet Challenge의 그래프에서 보았듯이
2012년 이래로 엄청난 변화가 있었습니다.

1756
00:53:50,715 --> 00:53:53,337


1757
00:53:53,337 --> 00:53:55,611


1758
00:53:55,211 --> 00:54:00,138
제가 대학원에 있는 동안, 이 분야는 일년 내내 변했습니다.

1759
00:53:55,611 --> 00:53:58,840


1760
00:53:58,840 --> 00:54:00,538


1761
00:54:00,138 --> 00:54:03,349
그리고, 그것은 매우 흥분되고 매우 유망하다는 것입니다.

1762
00:54:00,538 --> 00:54:03,749


1763
00:54:03,349 --> 00:54:08,732
어쨌든, 말하고 싶었던 것은 어쩌면 우리가 저번 해에 다뤘던 내용이

1764
00:54:03,749 --> 00:54:07,177


1765
00:54:07,177 --> 00:54:09,132


1766
00:54:07,460 --> 00:54:10,605


1767
00:54:08,732 --> 00:54:12,493
올해에는 없을 수도 있다는 것을 의미합니다.

1768
00:54:09,132 --> 00:54:12,893


1769
00:54:10,605 --> 00:54:12,854


1770
00:54:12,493 --> 00:54:16,229
그것은 매우 흥미로운 부분이고, 제가 이 과목을 가르칠때
가장 좋아하는 부분 중 하나입니다.

1771
00:54:12,893 --> 00:54:14,417


1772
00:54:14,417 --> 00:54:16,629


1773
00:54:16,229 --> 00:54:23,641
이 분야는 모든 과학적인 새로운 것들을 모조리 빨아드릴 수 있고
저는 여러분들에게 이것을 알려줄 수 있다는 것입니다.

1774
00:54:16,629 --> 00:54:18,826


1775
00:54:18,826 --> 00:54:21,041


1776
00:54:21,041 --> 00:54:24,041


1777
00:54:21,481 --> 00:54:23,771


1778
00:54:22,387 --> 00:54:28,457


1779
00:54:23,641 --> 00:54:25,671
재밌는 것들도 있습니다.

1780
00:54:24,041 --> 00:54:26,071


1781
00:54:25,671 --> 00:54:30,053
심각하지 않은 재미있는 주제에 관해서도 다룰 것입니다.

1782
00:54:26,071 --> 00:54:27,770


1783
00:54:27,770 --> 00:54:30,453


1784
00:54:28,457 --> 00:54:34,459


1785
00:54:30,053 --> 00:54:32,722
이미지 캡셔닝과 같은 것인데, 매우 재밌습니다.

1786
00:54:30,453 --> 00:54:33,122


1787
00:54:32,722 --> 00:54:34,949
이미지 캡셔닝은 이미지에 관해 기술하는 것입니다.

1788
00:54:33,122 --> 00:54:35,349


1789
00:54:33,648 --> 00:54:36,341


1790
00:54:34,949 --> 00:54:39,496
그리고 여기 왼쪽에 보이는 DeepDream과 같은
좀 더 예술적인 것들에 관해서는 다룰 것입니다.

1791
00:54:35,349 --> 00:54:37,177


1792
00:54:37,177 --> 00:54:39,896


1793
00:54:39,496 --> 00:54:43,877
이것은 우리가 Neural Network를 통해
이런 사이키델릭한 이미지를 만들게도 해줍니다.

1794
00:54:39,896 --> 00:54:42,261


1795
00:54:40,551 --> 00:54:44,160


1796
00:54:42,261 --> 00:54:44,277


1797
00:54:43,877 --> 00:54:46,477
그리고 코스가 끝날 쯤이면, 어떻게 동작하는지 알 수 있을 겁니다.

1798
00:54:44,277 --> 00:54:45,975


1799
00:54:45,469 --> 00:54:46,699


1800
00:54:46,477 --> 00:54:54,940
오른쪽 그림의, style tranfer라는 아이디어는 우리에게 이미지가
있을때, 이를 피카소나 반 고흐와 같은 유명화가의 풍으로 바꿔줍니다.

1801
00:54:46,877 --> 00:54:48,900


1802
00:54:47,461 --> 00:54:54,073


1803
00:54:48,900 --> 00:54:50,628


1804
00:54:50,628 --> 00:54:54,507


1805
00:54:51,654 --> 00:54:53,248


1806
00:54:53,248 --> 00:54:54,357


1807
00:54:54,940 --> 00:54:56,254
그리고 다시 이 수업을 마치면

1808
00:54:56,254 --> 00:54:59,254
여러분은 어떻게 동작하는지 알게 될 것입니다.

1809
00:54:56,654 --> 00:54:59,654


1810
00:54:59,254 --> 00:55:03,394
여러분에게 수업동안 세가지 문제를 던져줄 것입니다.

1811
00:54:59,654 --> 00:55:02,519


1812
00:55:02,287 --> 00:55:04,751


1813
00:55:03,394 --> 00:55:07,852
첫 번째 문제는 잘하면 일주일 내로 끝날 수도 있습니다.

1814
00:55:03,794 --> 00:55:07,039


1815
00:55:04,751 --> 00:55:08,251


1816
00:55:05,251 --> 00:55:11,528


1817
00:55:07,852 --> 00:55:10,306
그리고 중간고사가 있습니다.

1818
00:55:08,252 --> 00:55:10,706


1819
00:55:10,306 --> 00:55:17,007
그리고 여러분의 학점에서 가장 큰 비율을 차지하는 것이 바로
최종 코스 프로젝트인데, 3인 1조로 진행할 것이며,

1820
00:55:10,706 --> 00:55:12,511


1821
00:55:12,511 --> 00:55:15,056


1822
00:55:15,056 --> 00:55:17,407


1823
00:55:17,007 --> 00:55:20,114
여러분들은 모든 사람들의 마음을 날려버릴만큼
놀라운 프로젝트를 만들 것입니다.

1824
00:55:17,407 --> 00:55:20,514


1825
00:55:18,137 --> 00:55:23,353


1826
00:55:20,114 --> 00:55:25,980
제출기한에 대한 정책도 있습니다. 도합 7일정도는 늦을 수
있고, 여러분들의 과제 수행 중 자유롭게 분배할 수 있습니다.

1827
00:55:20,514 --> 00:55:23,871


1828
00:55:20,955 --> 00:55:23,599


1829
00:55:23,871 --> 00:55:26,380


1830
00:55:25,980 --> 00:55:33,804
몸이 조금 아프거나, 여행을 가거나, 컨퍼런스에 참가하거나 할때
쓸 수 있을 것입니다.

1831
00:55:26,380 --> 00:55:29,549


1832
00:55:26,869 --> 00:55:29,619


1833
00:55:27,132 --> 00:55:32,152


1834
00:55:29,549 --> 00:55:34,204


1835
00:55:31,462 --> 00:55:35,273


1836
00:55:32,152 --> 00:55:37,058


1837
00:55:33,804 --> 00:55:39,571
하지만, 갑자기 학기 말에 와서는
"이번에 컨퍼런스에서 발표를 해야만 해요" 라고 말한다면

1838
00:55:34,204 --> 00:55:36,188


1839
00:55:36,188 --> 00:55:38,757


1840
00:55:37,058 --> 00:55:40,630


1841
00:55:39,571 --> 00:55:40,480
아마 좋지 않을것입니다.

1842
00:55:40,480 --> 00:55:42,224
이것이 바로 late days가 의미하는 것입니다.

1843
00:55:40,880 --> 00:55:42,624


1844
00:55:42,224 --> 00:55:46,243
그렇긴 해도, 만약 여러분이 정상참작할만한
이유가 있었다면

1845
00:55:42,624 --> 00:55:44,111


1846
00:55:44,111 --> 00:55:46,643


1847
00:55:46,243 --> 00:55:49,895
언제든지 조교들에게 이메일을 보내주시길 바랍니다.
피지못할 사정이 있었다면 말이죠.

1848
00:55:46,643 --> 00:55:48,705


1849
00:55:48,705 --> 00:55:50,295


1850
00:55:49,895 --> 00:55:53,777
또 한가지 알려드릴 점은
협업 정책입니다.

1851
00:55:50,295 --> 00:55:52,404


1852
00:55:50,609 --> 00:55:55,181


1853
00:55:52,404 --> 00:55:54,177


1854
00:55:53,777 --> 00:56:03,209
Stanford 학생으로서, 여러분은 항상 규율에 대해 알고 있어야 합니다.
이것은 아주 중요합니다.

1855
00:55:54,177 --> 00:55:55,921


1856
00:55:55,921 --> 00:55:58,389


1857
00:55:58,389 --> 00:56:00,785


1858
00:55:59,557 --> 00:56:02,947


1859
00:56:00,785 --> 00:56:03,609


1860
00:56:03,209 --> 00:56:07,220
우리는 여러분이 어떻게 협력하고 있는지에 대해, 그리고 그것을

1861
00:56:03,609 --> 00:56:05,635


1862
00:56:05,635 --> 00:56:07,620


1863
00:56:07,220 --> 00:56:10,637
규율의 테두리 안에 있도록 하는 것에 대해 아주
조심스럽게 생각하는 것을 장려합니다.

1864
00:56:07,620 --> 00:56:11,037


1865
00:56:09,097 --> 00:56:14,246


1866
00:56:10,690 --> 00:56:13,718


1867
00:56:11,904 --> 00:56:17,092
Pre-requisites에 대해서라면, 가장 중요한 것은
아마도 얼마나 Python에 익숙한지 일 것입니다.

1868
00:56:12,304 --> 00:56:14,378


1869
00:56:14,378 --> 00:56:17,492


1870
00:56:17,092 --> 00:56:21,939
모든 프로그래밍 과제는 Python
으로 진행 될 것이기 때문입니다.

1871
00:56:17,492 --> 00:56:20,081


1872
00:56:20,081 --> 00:56:22,339


1873
00:56:21,939 --> 00:56:25,666
C나 C++에 익숙한 것도
어느정도는 유용할 것입니다.

1874
00:56:22,339 --> 00:56:26,066


1875
00:56:23,157 --> 00:56:24,795


1876
00:56:25,666 --> 00:56:31,305
이번 코스에서 C나 C++을 쓰진 않을 거지만,
아마 과제를 하다 보면

1877
00:56:26,066 --> 00:56:29,354


1878
00:56:27,092 --> 00:56:30,168


1879
00:56:29,354 --> 00:56:31,705


1880
00:56:30,168 --> 00:56:31,764


1881
00:56:31,305 --> 00:56:39,479
여러 소프트웨어 패키지의 코드를 살펴볼 것이고, C++ 코드는
패키지들이 어떻게 동작하는지 이해하는데 아주 도움이 될 것입니다.

1882
00:56:31,705 --> 00:56:33,676


1883
00:56:33,676 --> 00:56:35,922


1884
00:56:35,922 --> 00:56:39,879


1885
00:56:37,573 --> 00:56:39,662


1886
00:56:39,479 --> 00:56:42,039
이 코스에서는 여러분이 미분에 대해 한다고
가정하고 수업을 진행할 것입니다.

1887
00:56:39,879 --> 00:56:42,439


1888
00:56:42,039 --> 00:56:44,571
여러분이 모든 종류의 미분을 할 줄 안다고도 가정할 것입니다

1889
00:56:42,439 --> 00:56:44,971


1890
00:56:43,509 --> 00:56:45,594


1891
00:56:44,571 --> 00:56:46,133
또한 일부 선형대수도 안다고 가정할 것입니다.

1892
00:56:44,971 --> 00:56:46,533


1893
00:56:46,133 --> 00:56:47,479
매트릭스가 뭔지 알고,

1894
00:56:47,479 --> 00:56:51,672
어떻게 곱하고 하는것들을 미리 알아야 합니다.

1895
00:56:47,879 --> 00:56:52,072


1896
00:56:49,816 --> 00:56:55,214


1897
00:56:51,672 --> 00:56:55,291
우리가 도함수를 계산하는 방법같은 것을
전부 다 가르칠 순 없습니다.

1898
00:56:52,072 --> 00:56:53,660


1899
00:56:53,660 --> 00:56:55,691


1900
00:56:55,291 --> 00:57:00,838
또한 우리는 CS131 또는 231a 정도 수준의 컴퓨터 비전
지식을 어느정도 알 고 있다고 가정할 것입니다.

1901
00:56:55,691 --> 00:56:57,321


1902
00:56:57,321 --> 00:56:59,821


1903
00:56:59,821 --> 00:57:01,238


1904
00:57:01,967 --> 00:57:04,720
이 과목들을 수강한 적이 있는 분들은
괜찮을 것입니다.

1905
00:57:02,367 --> 00:57:03,923


1906
00:57:03,069 --> 00:57:06,105


1907
00:57:04,720 --> 00:57:09,453
그렇지 않다 해도, 수업을 듣는데는 지장이 없겠지만,
따라 잡으려면 좀 더 노력해야 할 것입니다.

1908
00:57:05,120 --> 00:57:07,347


1909
00:57:06,105 --> 00:57:08,317


1910
00:57:07,347 --> 00:57:09,853


1911
00:57:08,317 --> 00:57:09,620


1912
00:57:09,453 --> 00:57:11,150
그래도 아마 큰 문제는 없으이라 봅니다.

1913
00:57:09,853 --> 00:57:11,550


1914
00:57:11,150 --> 00:57:13,304
완전 완전 필수인 prerequisites은 없습니다.

1915
00:57:11,550 --> 00:57:13,704


1916
00:57:13,304 --> 00:57:20,140
우리는 또한 CS229 정도 수준의 기계학습에
어느정도의 배경지식이 있다고 가정합니다.

1917
00:57:13,704 --> 00:57:16,964


1918
00:57:16,964 --> 00:57:20,540


1919
00:57:20,140 --> 00:57:25,323
하지만, 기계학습에서 정말 중요하고
핵심적인 개념에 대해서는 아마 제가 다시 설명해 드릴 것입니다.

1920
00:57:20,540 --> 00:57:23,556


1921
00:57:23,556 --> 00:57:25,723


1922
00:57:25,323 --> 00:57:27,355
수업 중 그 개념이 나오고, 그것이 아주 중요할때 말이죠

1923
00:57:25,723 --> 00:57:27,755


1924
00:57:27,355 --> 00:57:32,016
뭐 그렇긴 해도, 미리 익숙해 지는 것이 수업 진도를
따라가는 데 더 도움일 될 것입니다.

1925
00:57:27,755 --> 00:57:29,916


1926
00:57:28,771 --> 00:57:31,115


1927
00:57:29,916 --> 00:57:32,416


1928
00:57:31,115 --> 00:57:39,810


1929
00:57:34,374 --> 00:57:35,646
우리는 강의 홈페이지를 가지고 있습니다.

1930
00:57:35,646 --> 00:57:36,550
가서 확인해 보세요

1931
00:57:36,550 --> 00:57:39,342
많은 정보나 링크, 교수과목 등 많은 것들이 있습니다.

1932
00:57:36,950 --> 00:57:38,303


1933
00:57:38,303 --> 00:57:39,742


1934
00:57:39,342 --> 00:57:43,256
그 모든 것들이 제가 이번 수업에서
정말로 다루고 싶은 것들 입니다.

1935
00:57:39,742 --> 00:57:43,656


1936
00:57:43,256 --> 00:57:48,757
그리고 이번 주 목요일에, 우리는 첫번째
학습 알고리즘부터 시작할 것이고, 세부사항을 알아 볼 것입니다.

1937
00:57:43,656 --> 00:57:46,157


1938
00:57:46,157 --> 00:57:48,733


1939
00:57:48,733 --> 00:00:00,000

