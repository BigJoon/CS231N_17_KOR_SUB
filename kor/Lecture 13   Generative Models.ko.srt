1
00:00:11,077 --> 00:00:14,258
오늘은 정말 배울게 많습니다.
시작하도록 하겠습니다!

2
00:00:14,258 --> 00:00:17,454
오늘은 생성 모델(Generative Models)
에 대해서 배워보도록 하겠습니다.

3
00:00:17,454 --> 00:00:20,484
수업에 앞서 공지사항을 전달하도록 하겠습니다.

4
00:00:20,484 --> 00:00:23,522
중간 고사 채점 결과는
Gradescope를 통해 이번주에 공개될 예정입니다.

5
00:00:23,522 --> 00:00:27,730
그리고 과제 3은 다음주 금요일 (5월 26)
까지임을 명심하도록 하세요

6
00:00:27,730 --> 00:00:32,709
추가 크레딧을 받기 위한 HyperQuest 기한은
5월 21일 일요일 까지 입니다.

7
00:00:33,632 --> 00:00:37,799
그리고 포스터 세션은
6월 6일 12시부터 3시 까지 진행됩니다.

8
00:00:40,812 --> 00:00:47,759
오늘을 주제를 조금 바꿔서
비지도 학습(unsupervised leraning)에 대해 배울 것입니다.

9
00:00:47,759 --> 00:00:54,103
특히 비지도학습의 일종인
생성 모델(Generative models)에 대해서 배워보겠습니다.

10
00:00:54,103 --> 00:00:57,112
세가지 종류의 생성모델을 다룰 것입니다.

11
00:00:57,112 --> 00:01:01,174
pixelRNN 과 pixelCNN,
variational autoencoders(VAE)

12
00:01:01,174 --> 00:01:04,174
그리고 Generative Adversarial networks(GAN)
입니다.

13
00:01:05,571 --> 00:01:11,168
지금까지 CS231n 수업에서는 다양한
지도학습(supervised learning) 문제를 다뤄왔습니다.

14
00:01:11,168 --> 00:01:16,078
지도 학습에서는 데이터 X, 레이블 Y가 있었습니다.

15
00:01:16,078 --> 00:01:21,417
지도 학습의 목적은 데이터 X를 레이블 Y에
매핑시키는 함수를 배우는 것입니다.

16
00:01:21,417 --> 00:01:26,237
레이블은 다양한 형태를 띄고 있었습니다.

17
00:01:26,237 --> 00:01:34,934
가령 분류(classification) 문제의 예를 들어보자면
이미지가 입력이고, 출력은 클래스 레이블 Y 입니다. 카테고리죠

18
00:01:34,934 --> 00:01:44,093
Object Detection 문제에서는 입력은 이미지로 동일하지만
출력은 각 객체들의 bounding box 입니다.

19
00:01:46,138 --> 00:01:51,986
Semantic segmentation 에서는 모든 픽셀 마다, 각
픽셀이 속하는 카테고리를 결정해야 했습니다.

20
00:01:53,572 --> 00:01:58,961
Image captioning에 대해서도 배워보았습니다.
레이블이 한 문장이었습니다.

21
00:01:58,961 --> 00:02:02,961
문장은 자연어(natural language)의
형태를 띄고 있었습니다.

22
00:02:03,998 --> 00:02:15,661
비지도 학습에서는 레이블이 없는 학습 데이터만 가지고
데이터에 숨어있는 기본적인 구조를 학습시켜야 합니다.

23
00:02:15,661 --> 00:02:20,370
비지도 학습의 예로는 군집화(clustering)이 있습니다.
군집화에 대해서 이미 아시는 분들도 계실 것입니다.

24
00:02:20,370 --> 00:02:25,029
군집화의 목표는 일정 metric을 가지고 유사한
데이터들끼리 묶어(group)주는 것입니다.

25
00:02:25,029 --> 00:02:27,187
가령 K-means clustering이 있습니다.

26
00:02:27,187 --> 00:02:32,871
비지도 학습의 또다른 예는
차원 축소(dimensionality reduction) 입니다.

27
00:02:33,777 --> 00:02:38,939
차원 축소 문제에서는 학습 데이터가 가장 많이
퍼져있는 축을 찾아내는 것입니다.

28
00:02:38,939 --> 00:02:43,537
그렇게 찾아낸 축은 데이터에 숨어있는 구조의
일부분이라고 할 수 있습니다.

29
00:02:43,537 --> 00:02:51,095
이 방법은 데이터의 차원을 감소시키는데 사용할 수 있습니다.
데이터는 축소된 차원에서도 중요한 정보들을 잘 보존해야 합니다.

30
00:02:51,095 --> 00:02:57,842
가령 여기 3차원 데이터가 있습니다.
이 데이터의 두 개의 축을 찾아낼 것입니다.

31
00:02:57,842 --> 00:03:01,259
2차원으로 차원을 축소시키기 위해서죠 (projection)

32
00:03:04,205 --> 00:03:09,964
비지도 학습의 또 다른 예는 데이터의
feature representation을 학습하는 것입니다.

33
00:03:11,006 --> 00:03:17,209
우리는 앞서 분류문제와 같은 supervised loss를 이용한
feature representation을 배웠습니다.

34
00:03:17,209 --> 00:03:21,617
여기에는 분류를 위한 레이블(개, 고양이)가 있고
Softmax loss 등을 사용합니다.

35
00:03:21,617 --> 00:03:29,869
그렇게 네트워크를 학습시켜서 , FC7 레이어의 특징을
데이터의 feature representation으로 사용할 수 있습니다.

36
00:03:29,869 --> 00:03:35,742
비지도 학습의 경우에는, 잠시 후에 더 자세히 다룰
Autoencoders가 있습니다.

37
00:03:35,742 --> 00:03:46,872
AE의 Loss는 입력 데이터를 얼마나 잘 재구성했는지 인데,
이를 이용해서도 특징들을 학습시킬 수 있습니다.

38
00:03:46,872 --> 00:03:52,245
AE를 사용하면 추가적인 레이블 없이도
 feature representation을 학습시킬 수 있는 것입니다.

39
00:03:53,471 --> 00:03:59,585
그리고 마지막으로 비지도 학습의 예에는
분포 추정(density estimation) 이 있습니다.

40
00:03:59,585 --> 00:04:02,884
이는 데이터가 가진 기본적인(underlyting)
분포를 추정하는 방법입니다.

41
00:04:02,884 --> 00:04:10,811
가령 오른쪽 맨 위의 1차원 점들이 있습니다. 그리고 이
점들의 분포를 가우시안(Gaussian)으로 추정합니다.

42
00:04:10,811 --> 00:04:16,605
그리고 하단의 예제의 경우에는 2차원 데이터입니다.
이번에는 2차원 데이터의 분포를 추정합니다.

43
00:04:16,605 --> 00:04:24,239
점들이 더 많이 밀집되어 있는 곳의 분포가
더 크도록 이들의 분포를 적절히 모델링할 수 있습니다.

44
00:04:26,100 --> 00:04:35,990
교사/비교사 학습의 차이점을 요약해보면, 교사학습의 경우에는
레이블을 통해 X에서 Y로 가능 함수 매핑을 학습합니다.

45
00:04:35,990 --> 00:04:44,124
비교사 학습의 경우에는 레이블이 없고 대신에 데이터의
숨겨진 구조를 학습합니다. 군집화(grouping),

46
00:04:44,124 --> 00:04:48,291
변화의 중심 축(axis of variation), 혹은
데이터의 밀도추정 등이 있습니다.

47
00:04:49,662 --> 00:04:54,113
비교사 학습은 아주 광범하고 흥미있는 분야입니다.

48
00:04:54,113 --> 00:05:04,339
인기있는 이유 중 하나는, 데이터에 대한 비용이 아주 적기 때문
입니다. 레이블이 없기 때문에 데이터를 아주 많이 모을 수 있습니다.

49
00:05:04,339 --> 00:05:09,977
레이블이 있는 데이터보다 데이터를 수직하기 훨씬 수월합니다.

50
00:05:09,977 --> 00:05:17,823
하지만 비교사 학습은 여전히 (비교적) 많은 연구가 이루어진
분야는 아닙니다. 여전히 풀어야 할 문제가 많죠

51
00:05:17,823 --> 00:05:24,669
하지만 여러분이 데이터에 숨겨진 구조들을
성공적으로 잘 학습할 수만 있다면

52
00:05:24,669 --> 00:05:32,729
시각 세계(visual world.)의 구조를 이해할 수 있는
아주 좋은 발판을 마련할 수 있는 좋은 기회일 수 있습니다.

53
00:05:35,026 --> 00:05:40,432
지금까지 비교사 학습에 관한 개괄이었습니다.

54
00:05:40,432 --> 00:05:44,155
오늘은 비교사 학습 중에서도
생성 모델을 집중적으로 다룰 예정입니다.

55
00:05:44,155 --> 00:05:52,933
생성 모델은 비교사 학습의 일종으로, 생성 모델의 목적은
동일한 분포에서 새로운 샘플들을 생성해 내는 것입니다.

56
00:05:52,933 --> 00:05:57,686
자 여기 학습 데이터가 있습니다. 이 데이터는
분포 P_data로부터 나온 데이터들입니다.

57
00:05:57,686 --> 00:06:04,955
우리가 하고자 하는 것은 p_model을 학습시키는 것입니다.
p_model이 p_data와 같은 데이터를 생성하도록 하는 것이죠

58
00:06:04,955 --> 00:06:09,854
이를 위해선 p_model 과 p_data가 유사하게 만들어야만 합니다.

59
00:06:09,854 --> 00:06:12,636
생성 모델에서는 "분포 추정"을 다뤄야 합니다.

60
00:06:12,636 --> 00:06:22,180
앞서 말씀드렸듯이, 학습 데이터의 근본이 되는 분포를
추정해야 합니다. 이는 비교사 학습의 핵심 문제이기도 합니다.

61
00:06:22,180 --> 00:06:25,190
분포 추정에는 몇 가지 전략이 있을 수 있습니다.

62
00:06:25,190 --> 00:06:33,353
하나는, 생성 모델 P_model의 분포가 어떨지를
명시적(explicitly) 으로 정의해 주는 경우입니다.

63
00:06:35,045 --> 00:06:37,610
혹은(다른 하나는), 간접적(implicit)인 방법도 있습니다.

64
00:06:37,610 --> 00:06:45,035
모델이 p_model에서 샘플을 만들어내도록 학습시키는 것은
동일하지만, 이번에는 p_model의 분포를 정의하지 않습니다.

65
00:06:47,700 --> 00:06:54,096
그렇다면 생성 모델이 왜 중요할까요? 왜 생성 모델이
비교사 학습에서 중요한 문제인 것일까요?

66
00:06:54,096 --> 00:06:57,451
생성 모델을 가지고 할 수 있는 것들은 정말 많습니다.

67
00:06:57,451 --> 00:07:04,659
데이터 분포로부터, 아주 사실적인(realistic) 샘플들을 생성해
낼 수만 있다면 이를 이용하여 아주 많은 것들을 할 수 있습니다.

68
00:07:04,659 --> 00:07:14,568
다음 이미지들은 생성 모델에 의해 생성된 샘플들입니다.

69
00:07:14,568 --> 00:07:21,042
생성 모델을 이미지에 적용하면 super resolution이나
colorization과 같은 테스크에 적용할 수 있습니다.

70
00:07:21,042 --> 00:07:32,145
colorization의 예를 보면, 지갑의 밑그림만 그려 놓으면 생성 모델이
색을 채워줘서 지갑이 실제로 어떻게 생겼을지 알 수 있습니다.

71
00:07:32,145 --> 00:07:41,619
생성 모델은 강화 학습을 이용한 시뮬레이션이나 플래닝
(planning)을 위한 시계열 데이터 생성에도 이용될 수 있습니다.

72
00:07:41,619 --> 00:07:45,089
강화학습(reinforcement learning)은 다음 시간에
저 자세히 다뤄볼 예정입니다.

73
00:07:45,089 --> 00:07:50,261
생성 모델을 학습하면 latent representations을
추정해 볼 수도 있습니다.

74
00:07:50,261 --> 00:07:57,435
데이터의 잠재적인 특징들(latent features)을 잘 학습시켜
놓으면 추후 다른 테스크에도 아주 유용하게 쓰일 수 있습니다.

75
00:07:59,059 --> 00:08:05,688
생성 모델의 종류를 살펴보겠습니다. 생성 모델은 다음과
같은 taxonomy로 분류를 해 볼 수 있습니다.

76
00:08:05,688 --> 00:08:13,180
앞서 명시적(explicit)/간접적(implicit) 분포 모델에
대해서는 말씀드렸습니다.

77
00:08:13,180 --> 00:08:19,062
그리고 그 밑으로 다양한 서브 카테고리로
더 많이 쪼갤 수도 있습니다.

78
00:08:19,062 --> 00:08:27,814
이 taxonomy는 Ian Goodfellow의 GAN 튜토리얼에 있습니다.

79
00:08:27,814 --> 00:08:36,861
여러분이 생성 모델의 다양한 갈래를 알고싶다면
이 taxonomy를 참고하시면 아주 유용할 것입니다.

80
00:08:36,861 --> 00:08:45,645
오늘은 생성모델 중에서도, 오늘날 연구가 아주 활발하게
이루어지고 있는 세가지 모델만 배울 것입니다.

81
00:08:45,645 --> 00:08:49,475
우선, pixelRNN/CNN에 대해서 간단히 설명드릴 것입니다(1).

82
00:08:49,475 --> 00:08:52,162
그 다음은 variational autoencoders(VAE) 입니다(2).

83
00:08:52,162 --> 00:08:55,661
이 두가지 모델은 명시적 분포 모델에 속합니다.

84
00:08:55,661 --> 00:08:57,494
PixelRNN/CNN은 "계산이 가능한 확률모델 사용"
(Tractable density)에 속하고

85
00:08:57,494 --> 00:09:01,312
VAE는  "근사적 밀도추정(Approximate density)"
에 속합니다.

86
00:09:01,312 --> 00:09:05,614
그리고 마지막으로 generative adversarial networks
(GAN)에 대해서 배워볼 것입니다(3).

87
00:09:05,614 --> 00:09:09,781
GANs은 "간접적인 분포 추정(implicit density)"의
한 유형입니다.

88
00:09:12,152 --> 00:09:16,304
자 그럼 pixelRNN/CNN 부터 시작해봅시다.

89
00:09:16,304 --> 00:09:20,015
 pixelRNN/CNN은 fully visible brief networks
의 일종입니다.

90
00:09:20,015 --> 00:09:22,432
여기에서는 밀도를 명시적으로 정의하고 모델링합니다.

91
00:09:22,432 --> 00:09:34,941
자 이제 이미지 데이터 X가 있습니다. 그리고 이미지 x에 대한
우도(likelihood)인 p(x)를 모델링할 것입니다. 이 모델의 경우에는

92
00:09:34,941 --> 00:09:40,384
체인룰(chain rule)로 우도(likelihood) p(x)를 1차원
분포들간의 곱의 형태로 분해(decompose)합니다.

93
00:09:40,384 --> 00:09:43,493
이렇게 분해하면, 픽셀 x_i에 대해서 각각
p(x_i │conditions) 를 정의할 수 있습니다.

94
00:09:43,493 --> 00:09:47,871
conditions은 이전의 모든 픽셀
x1부터 x_(i-1) 이 붙게 됩니다.

95
00:09:47,871 --> 00:09:58,073
이미지 내의 모든 픽셀에 대한 joint likelihood는
모든 픽셀의 likelihoods의 곱의 형태가 됩니다.

96
00:09:58,073 --> 00:10:08,938
우도(likelihood) p(x) 를 정의했으니 이제 모델을 학습시키려면
학습 데이터의 우도를 최대화시키면 됩니다.

97
00:10:10,980 --> 00:10:20,833
픽셀 값에 대한 분포를 보면 p(x_i given 이전의 모든 픽셀) 입니다.
이는 분포가 아주 복잡합니다.

98
00:10:20,833 --> 00:10:22,700
어떻게 모델링하면 좋을까요?

99
00:10:22,700 --> 00:10:29,042
우리는 앞서, 복잡한 변환(transformation)을 수행하길
원한다면 Neural Networks를 사용했습니다.

100
00:10:29,042 --> 00:10:32,828
Neural networks가 이러한 복잡한 변환들을
표현하기에는 제격입니다.

101
00:10:32,828 --> 00:10:42,300
이제는 이 복잡한 함수를 표현하기 위해서
신경망을 이용할 것입니다.

102
00:10:43,235 --> 00:10:44,796
이 문제에서 여러분이 알아두셔야 할 점은

103
00:10:44,796 --> 00:10:51,212
nerural network를 쓰는 것 까진 좋지만 한가지 문제가 있습니다.
픽셀들의 순서를 어떻게 다뤄야 할까요?

104
00:10:51,212 --> 00:10:58,886
우리의 분포 p(현재 픽셀 given 모든 이전 픽셀) 에서
도대체 "모든 이전 픽셀"이 의미하는 바가 무엇일까요?

105
00:10:58,886 --> 00:11:01,303
지금부터 그것을 살펴볼 것입니다.

106
00:11:03,336 --> 00:11:06,669
PixelRNN은 2016에 제안된 논문입니다.

107
00:11:07,595 --> 00:11:17,657
PixelRNN은 기본적으로 이 문제를 풀기 위해 고안된 방법입니다.
이 모델이 어떻게 동작하는지 살펴보면

108
00:11:17,657 --> 00:11:21,187
우선 이미지의 좌상단 코너에 있는 픽셀부터
생성을 시작해보도록 합니다.

109
00:11:21,187 --> 00:11:31,050
여기 보이시는 그리드가 이미지의 픽셀들이라고 보시면 됩니다.
이제 좌상단 코너부터 시작해 보도록 하겠습니다.

110
00:11:31,050 --> 00:11:37,195
이 모델은 여기보이시는 화살표 방향으로의 연결성을 기반으로
순차적으로 픽셀을 생성해냅니다.

111
00:11:37,195 --> 00:11:44,332
그리고 이러한 방향성을 기반으로한 픽셀들간의 종속성을
RNN을 이용하여 모델링합니다.

112
00:11:44,332 --> 00:11:48,092
RNN 모델 중에서도 우리가 앞서 다룬 LSTM 모델을 이용합니다.

113
00:11:48,092 --> 00:11:55,242
이런 방식으로 대각선 아래 방향으로 계속 내려가면서
픽셀들을 생성해 냅니다.

114
00:11:55,242 --> 00:12:01,244
이들의 종속성은 연결성을 기반으로 한 채 말이죠

115
00:12:01,244 --> 00:12:08,736
이 방법은 정말 잘 동작하긴 하지만 한가지 단점이 있습니다.
바로 순차적인 생성 방식이기 때문에 아주 느리다는 점이죠

116
00:12:08,736 --> 00:12:15,061
가령 새로운 이미지를 생성하고자 한다면 여러번의
feed forward를 거쳐야 합니다.

117
00:12:15,061 --> 00:12:20,952
모든 픽셀이 생성될 때 까지 반복적으로
네트워크를 수행해야 합니다.

118
00:12:24,044 --> 00:12:30,575
pixelRNN 조금 뒤에 pixelCNN이라는 또
다른 모델이 제안되었습니다.

119
00:12:30,575 --> 00:12:34,570
pixelCNN의 기본적인 문제 세팅 자체는
pixelRNN과 동일합니다.

120
00:12:34,570 --> 00:12:43,074
왼쪽 코너에서부터 새로운 이미지를 생성할 것입니다.
pixelCNN과의 차이점이 있다면

121
00:12:43,074 --> 00:12:47,752
모든 종속성을 고려하여 모델링하는 RNN 대신에
pixelCNN은 CNN으로 모델링한다는 점입니다.

122
00:12:47,752 --> 00:12:52,179
이제 우리는 컨텍스트 영역에서 CNN을 사용할 것입니다.

123
00:12:52,179 --> 00:12:56,384
이제는 픽셀을 생성할때 특정 픽셀만을 고려합니다.

124
00:12:56,384 --> 00:13:09,313
그림의 회색 지역이 이미 생성된 픽셀들인데, 이들 중에서도
특정 영역만을 사용하여 다른 픽셀 값을 생성합니다.

125
00:13:11,041 --> 00:13:18,055
자 PixelCNN에서는 각 픽셀에서 CNN을 수행합니다.

126
00:13:18,055 --> 00:13:22,967
CNN에서는 출력 값을 가지고 softmax loss
를 계산할 수 있습니다.

127
00:13:22,967 --> 00:13:31,193
여기에서는 레이블이 0-255 가 될 것입니다. 우리는 학습 데이터로
 likelihood가 최대화하도록 학습시킬 수 있습니다.

128
00:13:31,193 --> 00:13:43,482
이렇게 픽셀을 생성하는 과정에서
각 픽셀 값은 정답 값(ground truth)를 가지고 있을 것입니다.

129
00:13:43,482 --> 00:13:53,976
이 정답값은 0-255 사이의 분류(classification) 문제를
풀기 위한 레이블 이라고 볼 수 있습니다.

130
00:13:53,976 --> 00:13:56,723
따라서 softmax loss로 학습시킬 수 있는 것입니다.

131
00:13:56,723 --> 00:14:05,597
그리고 이런 학습 과정은 기본적으로
likelihood를 최대화하는 것과 같습니다.

132
00:14:05,597 --> 00:14:08,413
질문 있나요?

133
00:14:08,413 --> 00:14:12,159
[학생이 질문]

134
00:14:12,159 --> 00:14:18,675
질문은 "우리는 지금 비지도 학습을 다루고 있는데
왜 여기에는 classification label이 들어가는지" 입니다.

135
00:14:18,675 --> 00:14:24,970
우리가 Loss를 계산할때 쓰는 레이블은
입력 학습 데이터를 사용할 뿐입니다.

136
00:14:24,970 --> 00:14:26,983
추가적인 레이블은 필요가 없습니다.

137
00:14:26,983 --> 00:14:38,533
우리가 레이블을 추가적으로 만들어낸 것이 아니고
입력 데이터 그 자체를 사용했을 뿐입니다.

138
00:14:41,199 --> 00:14:45,366
[학생이 질문]

139
00:14:47,998 --> 00:14:50,746
질문은 "이 방법이 bag of words같은 방법인지" 입니다.

140
00:14:50,746 --> 00:14:53,109
 bag of words하고는 거리가 멉니다.

141
00:14:53,109 --> 00:15:01,466
이 방법은 이미지 내의 각 픽셀들의 분포를 알고싶은 것입니다.

142
00:15:01,466 --> 00:15:10,442
이를 위해 likelihood를 최대화하도록 잘 학습을 시켜서
입력인 학습 데이터를 잘 생성하도록 하는 것이죠

143
00:15:10,442 --> 00:15:15,761
이를 위해서 입력 데이터를 Loss로 사용하는 것입니다.

144
00:15:21,006 --> 00:15:24,904
pixelCNN을 사용하면 pixelRNN보다 학습이 더 빠릅니다.

145
00:15:24,904 --> 00:15:34,301
왜냐하면 Train time에서는 (모든 픽셀들에 대해서) 학습 데이터의
likelihood를 최대화하는 것이기 때문입니다.

146
00:15:34,301 --> 00:15:40,739
학습 데이터는 이미 우리가 알고있는 값이기 때문에
학습 과정을 병렬화시킬 수 있습니다.

147
00:15:40,739 --> 00:15:47,296
하지만 새로운 이미지를 생성해야 하는 test time에서는
여전히 코너에서부터 시작해야 하고

148
00:15:47,296 --> 00:15:59,197
이 생성 방법에 대한 새로운 제안은 없었기 때문에 여전히
현재 픽셀을 생성하려면 이전 픽셀부터 순차적으로 처리해야 합니다.

149
00:15:59,197 --> 00:16:03,025
따라서 학습은 더 빠를지 몰라도
이미지를 생성하는데 걸리는 시간은 여전히 느립니다.

150
00:16:03,025 --> 00:16:04,204
질문 있나요?

151
00:16:04,204 --> 00:16:08,365
[학생이 질문]

152
00:16:08,365 --> 00:16:14,077
질문은 "이 방법은 첫 픽셀(의 분포)을 어떤 값으로
정하는냐에 민감해지지 않은지" 입니다.

153
00:16:14,077 --> 00:16:21,208
예 맞습니다. 처음 픽셀의 분포는 이후 모든 분포에
영향을 미치기 때문에 중요합니다.

154
00:16:23,203 --> 00:16:32,171
초기 픽셀의 분포를 선택하는 방법은, Training
time에는 학습 데이터의 픽셀 값을 가져오면 됩니다.

155
00:16:32,171 --> 00:16:38,368
Test time(생성) 에는 uniform distribuion을 사용할
수도 있고, 첫 픽셀만 학습 데이터에서 가져올 수도 있습니다.

156
00:16:38,368 --> 00:16:42,553
초기 값만 설정하면 나머지 값들은
알고리즘을 수행하면 됩니다.

157
00:16:42,553 --> 00:16:43,912
질문 있나요?

158
00:16:43,912 --> 00:16:48,079
[학생이 질문]

159
00:17:07,415 --> 00:17:14,146
질문은 "한번에 모든 픽셀을 예측하는 대신에 Chain rule
방식으로 이를 정의하는 방법은 없는지" 입니다. (#issue_8)

160
00:17:14,146 --> 00:17:17,884
앞으로 이와 관련된 모델을 보게 될 테지만

161
00:17:17,884 --> 00:17:27,868
chain rule은 계산 가능한(tractable) 확률모델을 기반으로
likelihood를 직접 최적화시킬 수 있도록 도와줍니다.

162
00:17:31,864 --> 00:17:39,606
자 여기 이미지가 pixelCNN으로 생성한 이미지들입니다.

163
00:17:39,606 --> 00:17:48,846
왼쪽은 CIFAR-10을 생성한 결과입니다. 결과를 보면
자연 이미지의 분포를 잘 포착해낸 것 같아 보입니다.

164
00:17:48,846 --> 00:17:56,848
자연 이미지에서 나올법한 이미지들을 잘 생성해 냈습니다.

165
00:17:56,848 --> 00:18:02,768
그리고 오른쪽은 ImageNet으로 학습시킨 결과입니다.
이 결과 또한 자연스러워 보이기는 합니다.

166
00:18:05,060 --> 00:18:09,966
하지만 여전히 개선의 여지는 많습니다.

167
00:18:09,966 --> 00:18:17,059
원래의 학습 이미지와 분명히 차이점이 존재하고.
실제 의미론적인 부분이 명확하지 않음을 알 수 있습니다.

168
00:18:19,371 --> 00:18:27,020
요약하자면, pixelRNN/CNN은
likelihood p(x)를 명시적으로 계산하는 방법입니다.

169
00:18:27,020 --> 00:18:29,297
우리가 최적화시킬 수 있는
분포(밀도)를 명시적으로 정의합니다.

170
00:18:29,297 --> 00:18:34,043
이렇게 분포를 명시적으로 정의하는 경우의 추가적인
장점이 있다면 "evaludation metic"이 존재한다는 것입니다.

171
00:18:34,043 --> 00:18:40,958
우리가 데이터를 통해 계산할 수 있는 likelihood를 이용하면
생성된 샘플이 얼마나 잘 만들어졌는지를 평가할 수 있습니다.

172
00:18:40,958 --> 00:18:47,043
그리고 꽤 좋은 샘플 이미지들을 생성하기는 하지만
여전히 아주 활발히 연구되고 있는 분야입니다.

173
00:18:47,043 --> 00:18:53,760
이 방법의 가장 큰 단점은 생성 과정이 순차적이기 때문에
상당히 느리다는 점입니다.

174
00:18:53,760 --> 00:18:59,324
그리고 pixelRNN/CNN은 가령,
음성생성 (audio generation) 에도 사용될 수 있습니다.

175
00:18:59,324 --> 00:19:08,170
음성생성에 관련 예제를 온라인에서 쉽게 찾아보실 수 있습니다.
다만, 음성생성의 경우에도 아주 느리다는 단점은 여전합니다.

176
00:19:08,170 --> 00:19:14,565
그리고 pixelCNN의 성능을 개선시기키 위한
아주 많은 연구들이 진행되어 오고 있습니다.

177
00:19:14,565 --> 00:19:22,346
아키텍쳐 혹은 Loss 함수를 새롭게 설계한다던가
학습 과정의 다양한 트릭을 적용하는 등 여러 시도가 있었습니다.

178
00:19:22,346 --> 00:19:29,495
PixelCNN에 더 관심이 있으신 분들은
PixelCNN 논문을 참고하시기 바랍니다.

179
00:19:29,495 --> 00:19:35,115
또한 2017년도에 나온 PixelCNN++ 와 같은  더 향상된 버전의
논문들도 많으니 참고해 주시기 바랍니다.

180
00:19:37,455 --> 00:19:44,321
자 이제부터는 다른 종류의 생성모델인
variational autoencoders(VAE)에 대해서 배워보겠습니다.

181
00:19:44,321 --> 00:19:52,204
우리가 지금까지 살펴본 pixelCNN은 여기 있는 정의처럼
"계산이 가능한 확률모델"을 기반으로 합니다.

182
00:19:52,204 --> 00:19:58,365
이를 기반으로 학습 데이터의 likelihood를 직접 최적화시킵니다.

183
00:19:59,419 --> 00:20:04,195
VAE의 경우에는 직접 계산이 불가능한(intractable)
확률 모델을 정의합니다.

184
00:20:04,195 --> 00:20:10,769
우리는 이제 추가적인 잠재 변수(latent vatiable)
z를 모델링할 것입니다. 이에 대해 더 자세히 알아봅시다.

185
00:20:10,769 --> 00:20:17,886
VAE에서는 data likelihood p(x)가
적분의 형태를 띄고 있습니다.

186
00:20:17,886 --> 00:20:21,422
가능한 모든 z값에 대한 기댓값을 구하는 방식입니다.

187
00:20:21,422 --> 00:20:26,909
하지만 이는 문제가 됩니다. 이 식을
직접 최적화시킬 수는 없습니다.

188
00:20:26,909 --> 00:20:33,706
대신에 이 likelihood(p(x))의 하안(lower bound)
를 구해서(detrive) 최적화시켜야만 합니다.

189
00:20:33,706 --> 00:20:34,956
질문 있나요?

190
00:20:35,864 --> 00:20:37,592
질문은 "z가 무엇인지" 입니다.

191
00:20:37,592 --> 00:20:42,862
z는 잠재 변수(latent variable) 입니다.
앞으로 더 자세히 다룰 내용입니다.

192
00:20:44,479 --> 00:20:48,538
자 그럼 우선 VAE의 배경을 먼저 살펴보겠습니다.

193
00:20:48,538 --> 00:20:54,733
VAE는 autoencoders(AEs) 라는
비교사 학습 모델과 관련이 있습니다.

194
00:20:54,733 --> 00:21:00,965
그러니 우선은 autoencoders에 대해서 설명을 드리고 나서

195
00:21:00,965 --> 00:21:05,851
VAE가 AE와 어떤 연관이 있고, 이를 통해 어떻게
데이터를 생성할 수 있는지를 알아보겠습니다.

196
00:21:05,851 --> 00:21:09,168
우선 autoencoders는 데이터 생성이 목적이 아닙니다.

197
00:21:09,168 --> 00:21:15,719
AE는 레이블되지 않은 학습 데이터로부터 저차원의
feature representation을 학습하기 위한 비교사 방법입니다.

198
00:21:15,719 --> 00:21:21,550
여기 보시는 바와 같이 입력 데이터 x가 있습니다.
우리는 어떤 특징 "z"를 학습하길 원하는 것입니다.

199
00:21:22,541 --> 00:21:29,605
여기에서 encoder는 입력 데이터 x를 특징 z로 변환하는
매핑 함수의 역할을 합니다.

200
00:21:30,911 --> 00:21:33,905
Encoder는 다양한 방법으로 설계할 수 있습니다.

201
00:21:33,905 --> 00:21:41,239
일반적으로는 Neural network를 사용합니다.
하지만 autoencoder는 아주 오래전부터 존재했던 모델입니다.

202
00:21:41,239 --> 00:21:45,803
2000대에는 Linear + nonlinearity를 이용한 모델을
주로 사용했으며

203
00:21:45,803 --> 00:21:54,389
그 이후로는 FC-layer를 사용한 더 깊은 네트워크가,  그리고
더 나아가 CNN을 사용하기에 까지 이르렀습니다.

204
00:21:55,385 --> 00:22:01,351
입력 데이터 x가 있고, x를 특징 z로 매핑시킬 것입니다.

205
00:22:01,351 --> 00:22:11,817
일반적으로 z는 x보다 작읍니다. 이로 인해 기본적으로
AE를 통해 차원 축소의 효과를 기대할 수 있습니다.

206
00:22:11,817 --> 00:22:17,729
그렇다면 질문입니다.
"우리는 왜 차원 축소를 하고싶은 것일까요?"

207
00:22:17,729 --> 00:22:20,896
왜 z가 x보다 작아지길 원하는 걸까요?

208
00:22:22,114 --> 00:22:25,497
[학생이 답변]

209
00:22:25,497 --> 00:22:31,657
답변은 "z가 데이터 x의 가장 중요한 특징들을 잘 담고
있어야 하기 때문" 이라고 했습니다. 예 맞습니다.

210
00:22:32,634 --> 00:22:41,758
우리는 z가 데이터 x의 중요한 요소들이 담겨있는
특징들을 학습하길 원합니다.

211
00:22:42,833 --> 00:22:46,717
그렇다면 "우리가 어떻게
feature representation을 학습할 수 있는 걸까요?"

212
00:22:46,717 --> 00:22:55,944
AE은 원본을 다시 복원(reconstruct)하는데
사용될 수 있는 특징들을 학습하는 방식을 취합니다.

213
00:22:55,944 --> 00:23:03,730
AE의 과정을 살펴보면, 입력 데이터 x 가 있습니다.
encoder는 x를 더 낮은 차원의 z로 매핑시킵니다.

214
00:23:05,320 --> 00:23:06,926
z가 바로 encoder 네트워크의 출력입니다.

215
00:23:06,926 --> 00:23:16,554
입력 데이터로부터 만들어진 특징 z는 두 번째 네트워크인
decoder에 사용됩니다. decoder의 출력은

216
00:23:16,554 --> 00:23:24,865
입력 X과 동일한 차원이고, X과 유사해야 합니다. 즉 우리는
원본 데이터를 복원(reconstruct)하고 싶은 것입니다.

217
00:23:26,387 --> 00:23:38,583
그리고 decoder는 기본적으로 encoder와 동일한 구조를 지닙니다.
즉 이 둘이 대칭적이여야 하는데. 이는 대게 CNN으로 구성합니다.

218
00:23:41,675 --> 00:23:48,720
전체 과정을 다시한번 살펴봅시다. 우선 입력 데이터가 있습니다.
입력 데이터를 endoer에 통과시킵니다.(step 1)

219
00:23:48,720 --> 00:23:53,996
encoder는 가령 4-layers CNN이 될 수 있습니다.
이렇게 encoder는 거쳐서 특징(z)을 얻으면,

220
00:23:53,996 --> 00:24:04,196
z를 decoder에 통과시킵니다. (step 2) decoder는 가령
upconv 네트워크일 수 있습니다. 데이터를 다시 복원하는 단계이죠

221
00:24:04,196 --> 00:24:14,409
CNN모델로 AE를 설계했을 때 encoder는 conv net으로
decoder는 upconv net으로 설계하는 이유는, encoder는

222
00:24:14,409 --> 00:24:25,893
고차원 입력(x)을 받아 저차원 특징(z)으로 변환해야 하는 반면
decoder는 저차원 특징(z)을 고차원으로 복원해야 하기 때문입니다.

223
00:24:28,906 --> 00:24:39,071
지금까지 말씀드렸던것 처럼 입력을 다시 복원하기 위해서는
L2 같은 loss 함수를 이용합니다.

224
00:24:39,071 --> 00:24:49,306
L2 loss는 "복원된 이미지의 픽셀 값과 입력 이미지의 픽셀 값이
서로 같았으면 좋겠다" 라는 의미를 담고 있습니다.

225
00:24:51,078 --> 00:24:58,599
여기에서 중요한점은, 앞서 질문내용에도 있었지만
AE에서 loss 함수를 사용하기는 하지만

226
00:24:58,599 --> 00:25:02,515
AE의 학습과정에서 추가적인 레이블을
필요하지 않다는 것입니다.

227
00:25:02,515 --> 00:25:10,861
우리가 가진것 이라고는 (레이블이 없는) 학습 데이터뿐이며,
학습 데이터 x만으로 네트워크도 통과시키고 Loss도 계산합니다.

228
00:25:13,346 --> 00:25:19,021
AE에서는 학습을 끝마치면 decoder는 버립니다.

229
00:25:19,021 --> 00:25:26,108
decoder는 training time에 입력을 복원해서
loss 함수를 계산하는 용도로만 쓰입니다.

230
00:25:26,108 --> 00:25:34,819
결국 encoder만 가져다 쓰는데, encoder가 학습한
특징 매핑을 교사학습 모델의 초기값으로 사용할 수 있습니다.

231
00:25:34,819 --> 00:25:45,773
encoder가 입력(x)을 특징공간(z)에 매핑시키고나면
그 위로 추가적인 분류기를 붙힙니다.

232
00:25:45,773 --> 00:25:55,601
클래스 레이블을 출력해야 하는 분류 문제로 바뀌는 것이고,
이 경우 Loss함수는 Softmax이고,  추가적인 레이블도 필요합니다.

233
00:25:55,601 --> 00:26:04,449
AE는 많은 레이블링되지 않은 데이터로부터 양질의 general
 feature representation을 학습할 수 있는 장점이 있습니다.

234
00:26:04,449 --> 00:26:12,363
이렇게 학습시킨 feature representation을 데이터가 부족한
교사학습 모델의 초기 가중치로 이용할 수 있는 것입니다.

235
00:26:12,363 --> 00:26:19,697
여러분이 지난 강의와 과제에서 접했겠지만,
소량의 데이터로는 학습하기 힘들었습니다.

236
00:26:19,697 --> 00:26:22,563
과적합(overfitting) 과 같은 다양한 문제가 있었죠

237
00:26:22,563 --> 00:26:27,540
이 경우 AE는 교사학습 모델이 더 좋은 특징으로
초기화될 수 있도록 도와줍니다.

238
00:26:31,371 --> 00:26:42,329
정리해보면 AE는 입력을 복원하는 과정에서 특징을 잘 학습했고
학습된 특징은 교사학습 모델의 초기화에 이용할 수 있었습니다.

239
00:26:42,329 --> 00:26:50,133
우리는 이러한 AE의 특징을 살펴보며 AE가 학습 데이터의
vatiation를  잘 포착해낼 수 있다는 직관을 가질 수 있었습니다.

240
00:26:50,133 --> 00:26:58,941
즉 잠재 변수인 벡터 z가 학습 데이터의
variation을 잘 가지고있는 것입니다.

241
00:26:58,941 --> 00:27:04,957
그러면 자연스럽게 이런 질문이 따라옵니다.
"유사한 방식으로 새로운 이미지를 생성해 낼 수는 없을까?"

242
00:27:06,922 --> 00:27:09,502
자 이제부터는 variational autoencoders에
대해서 다뤄보겠습니다.

243
00:27:09,502 --> 00:27:15,987
AE와는 관점이 조금 다릅니다. 이제는 새로운 데이터를 생성할
것이고, 이를 위해 모델로부터 데이터를 샘플링할 것입니다.

244
00:27:15,987 --> 00:27:19,404
우선, 혹시 autoencoder에 대해서 질문 있으신가요?

245
00:27:20,796 --> 00:27:22,828
그럼 variational autoencoders 시작하겠습니다.

246
00:27:22,828 --> 00:27:28,914
VAE에서는 학습 데이터 xi가 있습니다. i = 1 ~ N 까지 있죠

247
00:27:30,255 --> 00:27:34,812
이 학습데이터가 우리가 관측할 수 없는 어떤 잠재 변수 z
(latent representation Z)에 의해 생성된다고 가정합니다.

248
00:27:34,812 --> 00:27:38,357
여기서의 직관은 z는 어떤 벡터입니다.

249
00:27:38,357 --> 00:27:47,069
이 벡터 z의 각 요소들은 데이터의 변동 요소들을
(some factor of variation) 잘 포착해내고 있는 것입니다.

250
00:27:48,491 --> 00:27:54,811
즉 벡터z가 다양한 종류의 속성들을 담고 있는 것인데
가령 얼굴을 생성할때의 특성이라고 하면

251
00:27:54,811 --> 00:28:02,608
생성된 얼굴이 얼마나 웃고있는지, 눈썹의 위치,  머리의 방향
등이 될 수 있습니다.

252
00:28:02,608 --> 00:28:08,772
이러한 속성들이 모두 학습될 수 있는
잠재된 요소라고 할 수 있습니다.

253
00:28:08,772 --> 00:28:13,901
생성 과정에서는 z에 대한 prior로부터 샘플링을 수행할 것입니다.

254
00:28:13,901 --> 00:28:25,014
얼마나 웃고있는지와 같은 속성을 담기 위해서는 이러한 속성들이
어떤 distribution을 따르는지에 대한 prior를 정의해야 합니다.

255
00:28:25,014 --> 00:28:31,571
가령 z에 대한 prior로
gaussian distribution을 선택할 수도 있습니다.

256
00:28:31,571 --> 00:28:40,140
그리고 conditional distribution, P(x given z)
로부터 샘플링하여 데이터 X를 생성해냅니다.

257
00:28:40,140 --> 00:28:48,862
이를 위해서는 우선 z를 먼저 샘플링하고
z를 이용해서 이미지 X를 샘플링합니다.

258
00:28:51,409 --> 00:28:57,667
이 생성 모델의 true parameters는
theta star 입니다.

259
00:28:57,667 --> 00:29:03,158
prior와 conditional distributions에 대한
parameter가 있습니다.

260
00:29:03,158 --> 00:29:11,727
자 이제 생성모델이 새로은 데이터를 잘 생성하게 하러면
true parameter를 잘 추정해야 합니다.

261
00:29:14,790 --> 00:29:17,611
자 그러면 이 모델을 어떻게 설계하면 좋을까요?

262
00:29:20,282 --> 00:29:27,317
이제 생성 과정을 잘 모델링 할 차례인데 앞서 우리는
prior인 P(z)는 단순한 모델을 선택하기도 했습니다.

263
00:29:27,317 --> 00:29:32,713
가령 Gaussian 처럼 말이죠. 잠재적인 속성들을 위한
prior로 Gaussian을 선택하는 것은 합리적입니다.

264
00:29:35,696 --> 00:29:40,840
하지만 conditional distribution, P(x given z)
는 조금 더 복잡합니다.

265
00:29:40,840 --> 00:29:43,410
왜냐하면 우리는 p(x given z)를 가지고
이미지를 생성해야 하기 때문입니다.

266
00:29:43,410 --> 00:29:53,062
우리가 앞서 했던것 처럼, P(x given z)와 같은 복잡한
함수는 neural network로 모델링하면 됩니다.

267
00:29:53,062 --> 00:29:58,259
P(x given z)와 같은 복잡한 모델에는
neural network가 제격입니다.

268
00:30:00,308 --> 00:30:02,345
자 이제 이렇게 설계된 네트워크를
decoder network라고 하겠습니다.

269
00:30:02,345 --> 00:30:10,167
decoder는 어떤 잠재 변수(z)를 받아서
이미지로 디코딩하는 역할을 합니다.

270
00:30:10,167 --> 00:30:13,765
이 모델을 어떻게 학습시킬 수 있을까요?

271
00:30:13,765 --> 00:30:19,419
모델들의 파라미터들을 추정하기 위해서는
모델을 학습시킬 수 있어야겠죠

272
00:30:19,419 --> 00:30:26,668
자 다시 fully visible networks인 pixelRNN/CNN
에서의 전략을 떠올려봅시다.

273
00:30:28,577 --> 00:30:35,498
가장 쉬운 방법은 모델 파라미터가 학습 데이터의
likelihood를 최대화하도록 학습시키는 것입니다.

274
00:30:35,498 --> 00:30:39,346
VAE의 경우에는 잠재 변수 z가 있었습니다.

275
00:30:39,346 --> 00:30:49,884
P(x)는 모든 z에 대한 기댓값으로 나타냈습니다.
여기 있는 것 처럼 말이죠. 잠재변수 z가 있습니다.

276
00:30:49,884 --> 00:30:55,759
자 그럼 이 likelihood p(x)를 최대화시키려고 할 때
무엇이 문제일까요?

277
00:30:55,759 --> 00:31:01,372
지금까지 했던 것 처럼 그레디언트를 계산하고  
likelihood를 최대화시키면 되는 것 아닐까요?

278
00:31:01,372 --> 00:31:04,358
[학생이 답변]

279
00:31:04,358 --> 00:31:08,524
네 맞습니다. 위 적분식은 계산을 할 수 없습니다.
(intractable)

280
00:31:10,199 --> 00:31:12,547
이제 조금 더 자세히 살펴보도록 하겠습니다.

281
00:31:12,547 --> 00:31:18,772
자 여기 데이터에 대한 likelihood가 있습니다.
첫 번째 항은 p(z)입니다.

282
00:31:18,772 --> 00:31:24,847
앞서  p(z)의 prior는 gaussian prior로
정했습니다. 여기까지는 문제 없습니다.

283
00:31:24,847 --> 00:31:29,031
P(x given z)는 우리가 정의한
decoder neural network입니다.

284
00:31:29,031 --> 00:31:32,774
따라서 z가 주어지기만 한다면
모든 p(x given z)을 얻어낼 수 있습니다.

285
00:31:32,774 --> 00:31:35,721
p(x given z)는
 neural network의 출력입니다.

286
00:31:35,721 --> 00:31:38,147
그렇다면 문제가 어디에서 발생하는 것일까요?

287
00:31:38,147 --> 00:31:48,435
저 캐릭터가 원래 저렇게 생기진 않았는데 변환이 잘못됐는지
울고있는 검은 유령 모양이 되었네요 :(

288
00:31:49,298 --> 00:31:58,591
우리는 "모든 z"에 대해서 p(x given z)를 계산하고 싶지만, 
계산할 수 없다는 것입니다(intractable).

289
00:31:59,519 --> 00:32:02,186
우리는 이 적분식을 계산할 수 할 수 없습니다.

290
00:32:04,794 --> 00:32:06,591
따라서 data likelihood을 계산할 수 없습니다.
(intractable)

291
00:32:06,591 --> 00:32:19,639
posterior density로 나타내보면
p(z gien x) = p(x given z) *  p(z) / p(x)

292
00:32:19,639 --> 00:32:23,712
와 같이 베이즈 룰로 나타낼 수 있습니다.

293
00:32:23,712 --> 00:32:25,740
하지만 이 경우 또한 계산하기 어렵습니다.

294
00:32:25,740 --> 00:32:35,143
P(x given z) 나 p(z)는 괜찮지만 p(x)에
들어가는 적분이 계산이 힘듭니다.

295
00:32:36,027 --> 00:32:37,993
따라서 우리는 여러모로 p(x)를 직접 최적화하기는 힘듭니다.

296
00:32:37,993 --> 00:32:45,230
이 모델을 학습시키기 위한 해결책으로는

297
00:32:45,230 --> 00:32:54,824
decoder network이 p(x given z) 말도고 
추가적인 encoder network를 정의하는 것입니다.

298
00:32:54,824 --> 00:33:06,652
encoder는 q(z given x) 입니다. encodr를 이용해서 
입력 x를 z로 인코딩할 것입니다.

299
00:33:06,652 --> 00:33:10,329
이 encoder네트워크를(q) 통해서
p(z given x)를 근사시키는 것입니다.

300
00:33:12,388 --> 00:33:15,688
이렇게 정의한 posterior density 항은
계산이 가능합니다.

301
00:33:15,688 --> 00:33:22,866
이렇게 p(z given x)를 근사시키는
추가적인 네트워크(q)를 사용하면

302
00:33:22,866 --> 00:33:27,486
data likelihood의 하안(lower bound)을 구할 수 있고,
이는 계산이 가능하므로 최적화로 풀 수 있게됩니다.

303
00:33:29,308 --> 00:33:35,396
자 우선 encoder/decoder 네트워크에 대해서
조금 더 구체적으로 설명해 드리도록 하겠습니다.

304
00:33:36,579 --> 00:33:40,695
VAE에서 우리가 하고싶은 것은 데이터의 확률론적 생성
(probabilistic generation)모델을 만들고싶은 것입니다.

305
00:33:40,695 --> 00:33:51,530
앞서 다뤘던 autoencoder에서는 endoer에서 입력 x를
받아 z를 만들고 decoder에서 z를 받아 다시 이미지를 생성했습니다.

306
00:33:53,294 --> 00:33:58,907
VAE도 기본적으로 encoder/decoder 구조입니다.
그리고 여기에 확률론적인 의미가 가미됩니다.

307
00:33:58,907 --> 00:34:06,134
아 우선 파라미터 phi를 가진 encoder network
q(z given x)를 살펴보겠습니다. encoder의 출력은

308
00:34:06,134 --> 00:34:09,467
평균과 (대각) 공분산 입니다.
(mean & diagonal covatiance of z given x)

309
00:34:11,411 --> 00:34:14,795
이 값들이 encoder network의 출력입니다.(왼쪽 초록색 박스 두개)
이와 동일하게 -

310
00:34:14,795 --> 00:34:23,109
이제 decoder network를 살펴보면 z부터 시작해서
평균과 (대각)공분산을 출력으로 합니다.

311
00:34:23,109 --> 00:34:26,725
( p(x given z) 에서 x의 차원은 입력 x와 동일합니다. )

312
00:34:26,725 --> 00:34:29,478
decoder에는 파라미터인 theta가 있습니다.
(encoder와 다른 파라미터임)

313
00:34:31,136 --> 00:34:42,058
그렇다면, 실제로 "z given x" 와 "x given z"를 얻으려면
이들의 분포로부터 샘플링해야만 합니다.

314
00:34:42,058 --> 00:34:49,072
따라서 encoder/decoder network는 각각
z와 x에 대한 분포를 생성해야 하며

315
00:34:49,072 --> 00:34:52,409
실제 값을 뽑으려면 이 분포로부터 샘플링을 해야 합니다.

316
00:34:52,409 --> 00:34:59,630
여기 그림을 보시면 이런 구조로 어떻게 새로운 데이터를
샘플링하고 생성해 낼 수 있는지 알 수 있습니다.

317
00:34:59,630 --> 00:35:05,041
그리고  encoder/decoder networks를
다른 용어로 부르기도 합니다.

318
00:35:05,041 --> 00:35:09,138
encoder network의 경우에는
"recognition"/"inference" network 부르기도 합니다.

319
00:35:09,138 --> 00:35:15,913
왜냐하면 encoder는 (z given x) 라는 잠재 변수를
"추론하는 (inference)" 네트워크이기 때문입니다.

320
00:35:15,913 --> 00:35:18,826
그리고 decoder는 "생성(generation)"
네트워크 라고 하기도 합니다.

321
00:35:18,826 --> 00:35:22,993
generation network 라는 용어를 보실수도 있습니다.

322
00:35:24,410 --> 00:35:31,899
자 이제 encoder/decoder networks를 준비해 놨으니
다시 data likelihood 문제로 돌아가봅시다.

323
00:35:31,899 --> 00:35:35,117
우선 data likelihood인 p(x)에  log를 취할 것입니다.
( log p(x) )

324
00:35:35,117 --> 00:35:38,833
자 이제 log p(x)가 있습니다.

325
00:35:38,833 --> 00:35:44,988
그리고 p(x)에다가 z에 대한 기댓값(expectation)을 취합니다.

326
00:35:44,988 --> 00:35:51,053
z는 encoder network로 모델링한 q(z given x) 
분포로부터 샘플링한 값입니다.

327
00:35:52,606 --> 00:35:58,254
log p(x)에 Expectation을 취할 수 있는 이유는 
p(x)가 z에 독립적이기 때문입니다.

328
00:35:58,254 --> 00:36:04,794
자 여기 z에 대한 기댓값(expectation)에 대한 부분은
잠시 후에 다시 살펴보도록 하겠습니다.

329
00:36:06,255 --> 00:36:20,564
자 이제 이 식을 확장해서 베이즈 룰을 적용해봅시다. 
log[p(x given z) p(z) / p(z given x)]

330
00:36:20,564 --> 00:36:24,996
자 여기에 어떤 상수를 곱해줄 것입니다.
(Multiply by constant)

331
00:36:24,996 --> 00:36:30,874
q(z given x) / q(z given x) 를 곱해줍니다.
어짜피 1을 곱해주는 것이죠

332
00:36:30,874 --> 00:36:33,847
1을 곱해주므로 바뀌는 건 없지만 
나중에 도움이 될 것입니다.

333
00:36:33,847 --> 00:36:39,444
그리고 이제 식을 세 개의 항으로 나눠줍니다.

334
00:36:39,444 --> 00:36:44,703
여러분들께서 나중에 직접 유도해보시면 좋겠습니다. 
기본적인 로그 공식으로 유도할 수 있습니다.

335
00:36:44,703 --> 00:36:54,728
이렇게 나눠주면 각 세개의 항을 각기 다르게 해석할 수 있습니다. 
(nice meanings)

336
00:36:56,431 --> 00:37:02,754
자 그럼 나눠진 세 개의 항을 살펴보자면 
첫 번째 항은 E[log p(x given z)] 입니다.

337
00:37:02,754 --> 00:37:07,210
그리고 KL 항이 두 개 있습니다.

338
00:37:07,210 --> 00:37:14,400
간단히 설명드리면 KL divergence는 
두 분포가 얼마나 가까운지를 알려줍니다.

339
00:37:14,400 --> 00:37:18,567
여기에서는(첫 번째 KL) q(z given x)와 p(z)가
얼마나 가까운지를 알려줍니다.

340
00:37:19,489 --> 00:37:24,287
KL의 수식은 바로 위의 Expectation과 동일합니다.

341
00:37:24,287 --> 00:37:28,454
KL divergence는 분포간의 거리를 측정하는 척도라고 할 수 있습니다.

342
00:37:30,908 --> 00:37:36,183
자 이렇게 해서 KL 항들도 한번 살펴보았습니다.

343
00:37:36,183 --> 00:37:39,290
자 그럼 이 세 가지 항을 다시 한번 살펴보겠습니다.

344
00:37:39,290 --> 00:37:45,819
p(x given z)는 decoder network 입니다.

345
00:37:45,819 --> 00:37:52,042
이 첫 번째 항은 샘플링을 통해서 계산할 수 있습니다.

346
00:37:52,042 --> 00:37:56,099
이런 샘플링 과정에서 미분이 가능하도록 하는
"re-parametrization trick" 이라는 기법이 있습니다.

347
00:37:56,099 --> 00:37:59,920
더 관심 있으신 분들은 논문을 살펴보시기 바랍니다.

348
00:37:59,920 --> 00:38:02,479
어쨋든 우리는 첫 번째 항은 계산할 수 있습니다.

349
00:38:02,479 --> 00:38:08,600
자 그리고 두 번째 항을 살펴봅시다. 두 번째 항은 
두 가우시안 분포 간의 KL divergence 입니다.

350
00:38:08,600 --> 00:38:16,079
우선 q(z given x)는 encoder에서 발생하는 분포로
평균/공분산을 가지는 가우시안 분포입니다.

351
00:38:16,079 --> 00:38:19,892
그리고 prior p(z) 또한 가우시안입니다.

352
00:38:19,892 --> 00:38:25,628
참고로 KL divergence 에서 두 개의 분포가 모두 가우시안이면
closed form solution으로 풀 수 있습니다.

353
00:38:25,628 --> 00:38:31,324
자 그리고 마지막으로 세 번째 항을 보겠습니다.
q(z given x)와 p(z given x)간의 KL 입니다.

354
00:38:32,303 --> 00:38:36,766
앞서  p(z given x)는 계산할 수 없는 항
이라고 했습니다. (untractable)

355
00:38:36,766 --> 00:38:41,794
p(z given x)를 계산할 수 없었기 때문에 q로 근사시킨 것이죠
(variational inference가 이 부분에서 들어감)

356
00:38:41,794 --> 00:38:44,625
따라서 이 항은 여전히 문제가 됩니다.

357
00:38:44,625 --> 00:38:54,776
하지만 우리에게 단서가 하나 있는데, KL divergence는 두 분포간의
거리를 나타내므로, 정의로 보면 항상 0보다 크다는 사실입니다.

358
00:38:57,060 --> 00:39:03,396
따라서 앞의 두 항만 가지고 잘 해보자는 관점으로 본다면

359
00:39:03,396 --> 00:39:10,023
앞의 두 항은, 그레디언트를 이용해 최적화시켜서
실질적으로 계산할 수 있는 하안(lower bound)가 된다는 점입니다.

360
00:39:10,023 --> 00:39:16,652
p(x given z)는 미분가능하고 (1),  두번째 KL 항도
close form solution 으로 미분가능합니다(2).

361
00:39:16,652 --> 00:39:24,168
이 값이 "Tractable lower bound"인 이유는, 맨 오른쪽 
세 번째 항이 0보다 크거나 같이 때문입니다.

362
00:39:24,168 --> 00:39:26,251
자 이렇게 lower bound를 구했습니다.

363
00:39:27,273 --> 00:39:37,699
자 이제 VAE를 학습시키기 위해서는, 앞서 구한 
lower bound가 최대화되도록 최적화시키면 됩니다.

364
00:39:37,699 --> 00:39:42,251
다시 말해, data likehood의 lower bound를
최적화시키는 것입니다.

365
00:39:42,251 --> 00:39:49,940
이는 data likelihood가 적어도 우리가 최대화시킨(최적화시킨)
lower bound 보다는 항상 높을 것임을 의미합니다.

366
00:39:49,940 --> 00:39:58,941
자 이제 lower bound를 최대화시키기 위해서는
파라미터 theta와 phi를 구해야 합니다.

367
00:40:03,169 --> 00:40:06,412
그리고 나서이 하한에 대한 직감의 마지막 종류

368
00:40:06,412 --> 00:40:09,132
우리가 가진 첫 번째 임기는

369
00:40:09,132 --> 00:40:12,796
Z의 모든 샘플에 대한 기대치이다.

370
00:40:12,796 --> 00:40:16,963
인코더 네트워크를 통해 우리 X를
통과하는 것으로부터 샘플링 됨

371
00:40:18,267 --> 00:40:21,836
이 모든 샘플에 대해 기대를 모은 샘플링 Z

372
00:40:21,836 --> 00:40:24,003
주어진 Z의 확률

373
00:40:24,963 --> 00:40:26,854
그래서 이것은 재건입니다, 맞죠?

374
00:40:26,854 --> 00:40:29,196
이것은 기본적으로 말하고 있습니다.

375
00:40:29,196 --> 00:40:33,300
나는 Z가 높은 것으로 주어진이 X의 가능성
(likelihood) P를 원한다.

376
00:40:33,300 --> 00:40:36,168
그래서 좋은 일을하려고하는 것과 같습니다.

377
00:40:36,168 --> 00:40:37,756
데이터를 재구성하는 것.

378
00:40:37,756 --> 00:40:40,528
이전에 autoencoder에서 얻은 것과 비슷합니다.

379
00:40:40,528 --> 00:40:44,695
그러나 두 번째 용어는이 KL을
작게 만드는 것을 말합니다.

380
00:40:46,161 --> 00:40:48,832
근사 사후 분포를 닫습니다.

381
00:40:48,832 --> 00:40:51,283
우리의 이전 배포판에.

382
00:40:51,283 --> 00:40:55,450
그리고 이것은 기본적으로 우리가

383
00:40:56,633 --> 00:40:59,883
잠복 변수 Z는 이것 다음에,

384
00:41:01,980 --> 00:41:05,338
이 분포 유형, 분포 모양을 갖는다.

385
00:41:05,338 --> 00:41:07,838
우리가 가지고 있기를 바란다.

386
00:41:08,974 --> 00:41:12,058
이것에 대한 질문이 있으십니까?

387
00:41:12,058 --> 00:41:14,486
나는 이것이 수학의 많은 부분이라고 생각한다.

388
00:41:14,486 --> 00:41:17,440
관심을 가지고 돌아 가야하고 일을해야합니다.

389
00:41:17,440 --> 00:41:19,128
모든 파생물들.

390
00:41:19,128 --> 00:41:19,961
네.

391
00:41:20,883 --> 00:41:23,669
[학생의 말은 마이크가 없어서 가려졌습니다.]

392
00:41:23,669 --> 00:41:26,928
그래서 질문은 왜 우리가 이전에

393
00:41:26,928 --> 00:41:29,373
잠재 변수는 가우스?

394
00:41:29,373 --> 00:41:31,523
그리고 그 이유는 우리가

395
00:41:31,523 --> 00:41:33,512
일종의 생성 적 프로세스 권리,

396
00:41:33,512 --> 00:41:35,930
먼저 Z를 샘플링 한 다음 X를 먼저 샘플링하십시오.

397
00:41:35,930 --> 00:41:39,444
가우스로 정의하는 것은 합리적인 유형입니다.

398
00:41:39,444 --> 00:41:43,611
우리는 이러한 유형에 대해

399
00:41:44,668 --> 00:41:47,619
에 따라 분포 될 잠재적 속성

400
00:41:47,619 --> 00:41:51,724
일종의 가우시안 (Gaussian)에 가면, 이제 우리에게

401
00:41:51,724 --> 00:41:53,307
우리 모델을 최적화하십시오.

402
00:41:55,988 --> 00:42:00,211
좋아, 그럼 우리가 어떻게이 하한선을
비웃을 수 있는지 이야기 했어.

403
00:42:00,211 --> 00:42:03,725
이제이 모든 것을 합치고 걸어 나가자.

404
00:42:03,725 --> 00:42:06,053
AE의 훈련 과정.

405
00:42:06,053 --> 00:42:08,802
바로 여기에 우리가 최적화하고 싶은 경계가 있습니다.

406
00:42:08,802 --> 00:42:10,008
극대화하십시오.

407
00:42:10,008 --> 00:42:12,057
그리고 앞으로 전달합니다.

408
00:42:12,057 --> 00:42:14,864
우리는 다음과 같은 방식으로 진행할 것입니다.

409
00:42:14,864 --> 00:42:18,134
입력 데이터 X가 있으므로 미니 배치

410
00:42:18,134 --> 00:42:19,301
입력 데이터의

411
00:42:20,845 --> 00:42:24,211
그런 다음 엔코더 네트워크를 통해 전달합니다.

412
00:42:24,211 --> 00:42:26,544
그래서 우리는 주어진 X의 Q를 얻을 것입니다.

413
00:42:28,439 --> 00:42:33,384
그리고이 Z부터 주어진 X의 X에서,
이것은 조건이 될 것입니다.

414
00:42:33,384 --> 00:42:35,805
KL 용어를 계산할 때 사용합니다.

415
00:42:35,805 --> 00:42:40,606
그리고 나서 여기에서 우리는이
분포에서 Z를 샘플링 할 것입니다.

416
00:42:40,606 --> 00:42:44,773
우리는 잠정적 인 요소의 샘플을
가지고 있으므로 주어진 X의 X

417
00:42:46,120 --> 00:42:48,203
우리는 X에서 추론 할 수 있습니다.

418
00:42:50,721 --> 00:42:52,543
그리고 나서 여기에서 우리는 Z를 통과시킬 것입니다.

419
00:42:52,543 --> 00:42:54,889
또 다른, 우리의 두 번째 디코더 네트워크.

420
00:42:54,889 --> 00:42:56,999
그리고 디코더 네트워크에서 우리는이 출력을 얻을 것입니다.

421
00:42:56,999 --> 00:43:00,150
에 대한 우리의 분포에 대한 평균과 분산

422
00:43:00,150 --> 00:43:03,817
X가 Z로 주어지면 마침내 지금 샘플링 할 수 있습니다.

423
00:43:04,821 --> 00:43:07,686
이 분포에서 우리의 X 주어진 Z

424
00:43:07,686 --> 00:43:12,155
여기에 몇 가지 샘플 출력이 생성됩니다.

425
00:43:12,155 --> 00:43:13,676
우리가 훈련 할 때 우리는 이것을 취할 것입니다.

426
00:43:13,676 --> 00:43:16,500
우리의 손실 기간은

427
00:43:16,500 --> 00:43:20,417
주어진 Z의 트레이닝 이미지 픽셀 값의 로그.

428
00:43:23,612 --> 00:43:26,517
그래서 우리의 손실 함수는

429
00:43:26,517 --> 00:43:30,684
원래 입력이 재구성 될 가능성.

430
00:43:32,020 --> 00:43:34,086
이제 모든 미니 배치에 대해

431
00:43:34,086 --> 00:43:35,919
우리는이 전달 경로를 계산할 것입니다.

432
00:43:35,919 --> 00:43:37,770
우리가 필요로하는 모든 용어를 얻으십시오.

433
00:43:37,770 --> 00:43:40,290
그리고 나서 이것은 모두 차별화 될 수 있습니다.

434
00:43:40,290 --> 00:43:43,837
이 모든 것을 뒷받침하고 그라데이션을 얻으십시오.

435
00:43:43,837 --> 00:43:47,194
우리는 우리 모델을 업데이트하고
이것을 계속해서 사용합니다.

436
00:43:47,194 --> 00:43:50,763
매개 변수, 생성기 및 디코더 업데이트

437
00:43:50,763 --> 00:43:54,123
네트워크 매개 변수 theta 및 phi를 최대화하기 위해

438
00:43:54,123 --> 00:43:57,040
훈련 된 데이터의 가능성.

439
00:43:58,408 --> 00:44:01,084
우리 VAE를 훈련하면

440
00:44:01,084 --> 00:44:03,508
데이터를 생성하기 위해 할 수있는 일은 다음과 같습니다.

441
00:44:03,508 --> 00:44:05,547
디코더 네트워크 만 사용하십시오.

442
00:44:05,547 --> 00:44:07,919
좋아요. 여기에서 우리는 지금
Z를 샘플링 할 수 있습니다.

443
00:44:07,919 --> 00:44:10,947
우리가 가진이 후부에서 Z를 샘플링하는 대신에

444
00:44:10,947 --> 00:44:13,805
훈련 도중, 우리는 세대 동안 우리는 샘플

445
00:44:13,805 --> 00:44:15,504
우리의 진정한 생성 과정에서.

446
00:44:15,504 --> 00:44:18,673
그래서 우리는 이전에 우리가 지정한 것을 샘플링합니다.

447
00:44:18,673 --> 00:44:22,840
그런 다음 여기에서 데이터 X를 샘플링합니다.

448
00:44:25,281 --> 00:44:27,606
그리고 우리는 이것이 이것이 생산할 수
있음을 보게 될 것입니다,이 경우,

449
00:44:27,606 --> 00:44:32,465
MNIST에서 기차, 이들은 생성 된 자릿수 샘플입니다.

450
00:44:32,465 --> 00:44:34,798
MNIST에서 훈련 된 VAE에서.

451
00:44:36,058 --> 00:44:38,842
그리고 당신도 알다시피, 우리는이
아이디어에 대해 이야기했습니다.

452
00:44:38,842 --> 00:44:43,796
우리가 할 수있는 잠재 요인을 나타내는 Z의

453
00:44:43,796 --> 00:44:46,440
서로 다른 표본에 따라 Z를 묻어 라.

454
00:44:46,440 --> 00:44:50,464
우리 이전의 부분들과 다른 종류의

455
00:44:50,464 --> 00:44:52,625
해석의 의미는 여기에서.

456
00:44:52,625 --> 00:44:54,207
그래서 여기에서 우리는 이것이

457
00:44:54,207 --> 00:44:57,142
2 차원 Z에 대한 데이터 매니 폴드.

458
00:44:57,142 --> 00:44:59,718
그래서 우리는 2 차원 Z를 가지고 Z를 취하고합시다.

459
00:44:59,718 --> 00:45:04,110
다른 백분위 수에서 알 수있는 범위를 말하십시오.

460
00:45:04,110 --> 00:45:08,568
우리는 Z1을 변화시키고 우리는 Z2를 변화시키고,

461
00:45:08,568 --> 00:45:13,038
그러면 이미지가 어떻게 생성되는지를 볼 수 있습니다.

462
00:45:13,038 --> 00:45:16,300
우리가 여기에 가지고있는 Z1과 Z2의 조합,

463
00:45:16,300 --> 00:45:19,587
당신은 그것이 전체적으로 원활하게
전환하고 있음을 볼 수 있습니다.

464
00:45:19,587 --> 00:45:22,087
이러한 다양한 변형의

465
00:45:24,051 --> 00:45:27,808
그리고 우리는 이전에 Z가 있었고, 대각선이었으며,

466
00:45:27,808 --> 00:45:30,387
그래서 우리는 이것을 장려하기 위해 이것을 선택했습니다.

467
00:45:30,387 --> 00:45:34,568
독립적 인 잠재 변수는

468
00:45:34,568 --> 00:45:37,372
변이의 해석 가능한 요인.

469
00:45:37,372 --> 00:45:39,731
이제 이것 때문에 우리는 다른 차원을 가질 것입니다.

470
00:45:39,731 --> 00:45:41,923
다른 해석 가능한 요소들을 인코딩하는 Z의

471
00:45:41,923 --> 00:45:43,006
변화의.

472
00:45:44,477 --> 00:45:47,674
이제 Faces에있는이 예제 기차에서,

473
00:45:47,674 --> 00:45:52,020
우리는 Z1을 변화시키면서 위아래로 가고,

474
00:45:52,020 --> 00:45:54,771
미소가 바뀌는 것을 볼 수 있습니다.

475
00:45:54,771 --> 00:45:56,892
그래서 위의 찡그림에서 큰 웃음까지.

476
00:45:56,892 --> 00:46:00,225
바닥에서 그리고 우리가 갈 때 Z2,

477
00:46:01,997 --> 00:46:04,192
왼쪽에서 오른쪽으로, 머리 포즈가
바뀌는 것을 볼 수 있습니다.

478
00:46:04,192 --> 00:46:07,859
한 방향에서 다른 방향으로.

479
00:46:09,883 --> 00:46:12,020
그리고 내가 지적하고 싶은 한가지 추가 사항

480
00:46:12,020 --> 00:46:13,964
이 일의 결과로,

481
00:46:13,964 --> 00:46:17,214
이 Z 변수도 좋은 기능입니다.

482
00:46:18,198 --> 00:46:19,510
표현.

483
00:46:19,510 --> 00:46:23,355
왜냐하면 그들은 서로 다른

484
00:46:23,355 --> 00:46:26,376
우리가 가진이 해석 할 수있는 다른 의미들.

485
00:46:26,376 --> 00:46:29,466
그래서 주어진 X의 Q를 사용할 수 있습니다.

486
00:46:29,466 --> 00:46:32,296
우리가 배운 인코더와 입력

487
00:46:32,296 --> 00:46:36,213
이미지 X, 이것을 Z에 매핑하고 Z를
다음과 같이 사용할 수 있습니다.

488
00:46:38,121 --> 00:46:40,198
다운 스트림 작업에 사용할 수있는 기능

489
00:46:40,198 --> 00:46:43,157
감독과 같은 또는 분류 또는

490
00:46:43,157 --> 00:46:44,157
다른 작업.

491
00:46:47,348 --> 00:46:49,947
그래, 데이터의 또 다른 몇 가지 예가 있습니다.

492
00:46:49,947 --> 00:46:51,434
VAEs에서 생성됩니다.

493
00:46:51,434 --> 00:46:55,694
여기 왼쪽에는 CIFAR-10에서
생성 된 데이터가 있습니다.

494
00:46:55,694 --> 00:46:58,729
CIFAR-10 교육을받은 다음 오른쪽에

495
00:46:58,729 --> 00:47:02,231
Faces에서 훈련되고 생성 된 데이터.

496
00:47:02,231 --> 00:47:05,043
그리고 우리는 VAEs에서 볼 수있는 것을 볼 것입니다.

497
00:47:05,043 --> 00:47:08,737
인식 할 수있는 데이터를 생성 할 수 있습니다.

498
00:47:08,737 --> 00:47:11,796
VAE의 가장 큰 단점 중 하나는

499
00:47:11,796 --> 00:47:15,493
여전히 그들에게는 약간 모호한면이 있습니다.

500
00:47:15,493 --> 00:47:18,270
당신은 얼굴에서 이것을 볼 수 있습니다.
그래서 이것은 여전히 있습니다.

501
00:47:18,270 --> 00:47:20,520
연구의 활발한 영역.

502
00:47:22,008 --> 00:47:24,944
VAEs를 요약하기 위해,

503
00:47:24,944 --> 00:47:28,030
그들은 전통적인 자동 인코딩 장치에서
확률 론적으로 변화하고 있습니다.

504
00:47:28,030 --> 00:47:31,895
따라서 결정적으로 입력 X를받는 대신

505
00:47:31,895 --> 00:47:36,077
Z로 이동하고, Z를 피한 다음 X를 재구성하고,

506
00:47:36,077 --> 00:47:40,585
이제 배포판과 샘플링에 대한 아이디어가 있습니다.

507
00:47:40,585 --> 00:47:43,023
우리가 데이터를 생성 할 수있게하는 관련.

508
00:47:43,023 --> 00:47:46,928
그리고이를 훈련시키기 위해 VAE는

509
00:47:46,928 --> 00:47:48,435
다루기 힘든 밀도.

510
00:47:48,435 --> 00:47:51,101
그래서 우리는 하한을 도출하고 최적화 할 수 있습니다.

511
00:47:51,101 --> 00:47:55,938
변하기 쉬운 하한, 그래서 변하기
쉬운 것은 기본적으로 의미한다.

512
00:47:55,938 --> 00:47:58,621
근사치를 사용하여 이러한 유형의 다루기 힘든

513
00:47:58,621 --> 00:47:59,718
표현.

514
00:47:59,718 --> 00:48:03,577
그래서 이것을 왜 variational
autoencoder라고 부릅니다.

515
00:48:03,577 --> 00:48:07,188
따라서이 접근법의 장점 중 일부는

516
00:48:07,188 --> 00:48:10,249
VAE가 있다는 것, 그들은 원칙적인 접근 방식입니다.

517
00:48:10,249 --> 00:48:14,230
생성 모델에 전달하고이 추론을 허용합니다.

518
00:48:14,230 --> 00:48:17,628
질의가 주어 지므로 주어진 Q의 Z와
같은 것들을 추론 할 수 있습니다.

519
00:48:17,628 --> 00:48:20,221
우리가 말한 것은 유용한 특징 표현 일 수 있습니다.

520
00:48:20,221 --> 00:48:21,554
다른 작업.

521
00:48:23,101 --> 00:48:27,081
VAE의 단점은 우리가 최대화하는 동안

522
00:48:27,081 --> 00:48:29,548
우도의 하한은 괜찮습니다.

523
00:48:29,548 --> 00:48:32,303
당신이 일반적으로 알고있는 것처럼 이것은 여전히 우리를

524
00:48:32,303 --> 00:48:33,967
올바른 방향으로

525
00:48:33,967 --> 00:48:37,782
이것에 대한 다른 이론적 분석.

526
00:48:37,782 --> 00:48:41,700
알다시피, 괜찮아요,하지만 아직은 아니에요.

527
00:48:41,700 --> 00:48:46,042
픽셀로서의 최적화 및 평가를 지시한다.

528
00:48:46,042 --> 00:48:48,378
이전에 본 RNN과 CNN,

529
00:48:48,378 --> 00:48:50,378
그러나,

530
00:48:51,857 --> 00:48:55,431
또한 VAE 샘플은 약간의 경향이 있습니다.

531
00:48:55,431 --> 00:48:59,235
최첨단에 비해 흐림 및 낮은 품질

532
00:48:59,235 --> 00:49:01,967
다른 생성 모델에서 볼 수있는 샘플

533
00:49:01,967 --> 00:49:04,827
우리가 다음에 이야기 할 GAN과 같은

534
00:49:04,827 --> 00:49:07,230
VAE는 지금도 여전히 활동적입니다.

535
00:49:07,230 --> 00:49:08,647
연구 분야.

536
00:49:11,044 --> 00:49:13,447
사람들은보다 유연한 근사치를
만들기 위해 노력하고 있습니다.

537
00:49:13,447 --> 00:49:15,565
이렇게 더 부유 한 대략 posteriors,

538
00:49:15,565 --> 00:49:19,611
그래서 대각선 가우시안 대신에 더 풍부한

539
00:49:19,611 --> 00:49:20,881
이것에 대한 함수.

540
00:49:20,881 --> 00:49:23,977
그리고 나서 사람들이 일하고있는 또 다른 영역

541
00:49:23,977 --> 00:49:26,159
이 잠재성에 더 많은 구조가 통합되어 있습니다.

542
00:49:26,159 --> 00:49:26,992
변수.

543
00:49:26,992 --> 00:49:31,282
이제 우리는이 모든 독립 잠복 변수를 가졌습니다.

544
00:49:31,282 --> 00:49:34,327
그러나 사람들은 모델링 구조를 가지고 작업하고있다.

545
00:49:34,327 --> 00:49:38,077
여기서 그룹화, 다른 유형의 구조.

546
00:49:41,106 --> 00:49:43,106
좋아, 그럼 네.

547
00:49:44,404 --> 00:49:47,529
[학생의 말은 마이크가 없어서 가려졌습니다.]

548
00:49:47,529 --> 00:49:49,810
그래, 문제는 우리가 차원을 결정하는 것이다.

549
00:49:49,810 --> 00:49:51,394
잠복 변수의

550
00:49:51,394 --> 00:49:54,727
네, 그건 당신이 지정하는 것입니다.

551
00:49:55,874 --> 00:50:00,041
좋아, 이제까지 우리는 pixelCNN과
VAE에 대해 이야기 해왔다.

552
00:50:01,082 --> 00:50:05,439
이제 우리는 세 번째와 매우
인기있는 것을 살펴볼 것입니다.

553
00:50:05,439 --> 00:50:08,522
GANs라고 불리는 생성 모델의 유형.

554
00:50:10,019 --> 00:50:13,378
지금까지 우리가 본 모델, pixelCNN과 RNN

555
00:50:13,378 --> 00:50:15,713
다루기 쉬운 밀도 함수를 정의하십시오.

556
00:50:15,713 --> 00:50:19,752
그리고 훈련 된 데이터의 가능성을 최적화합니다.

557
00:50:19,752 --> 00:50:24,174
그리고 VAE는 이제 이와는 대조적으로

558
00:50:24,174 --> 00:50:26,675
생성 변수에서 정의하는 잠재 변수 Z

559
00:50:26,675 --> 00:50:27,752
방법.

560
00:50:27,752 --> 00:50:31,206
그래서 Z는 좋은 속성을 많이 가지고 있습니다.

561
00:50:31,206 --> 00:50:34,242
우리가 이야기 한 것이지만, 그들은 또한 우리에게

562
00:50:34,242 --> 00:50:36,858
우리가 할 수없는이 다루기 힘든 밀도 함수

563
00:50:36,858 --> 00:50:39,813
직접 최적화하고 그래서 우리는 파생하고 최적화합니다.

564
00:50:39,813 --> 00:50:43,934
우도에 대한 하한값.

565
00:50:43,934 --> 00:50:46,405
그리고 지금 우리가 단지 명시 적으로 포기하면

566
00:50:46,405 --> 00:50:48,486
이 밀도를 전혀 모델링하지 않습니까?

567
00:50:48,486 --> 00:50:51,100
우리가 원하는 것은 우리가 원하는 것이 바로 능력입니다.

568
00:50:51,100 --> 00:50:55,267
샘플을 보내고 우리의 배포판에서 좋은 샘플을 얻으십시오.

569
00:50:56,501 --> 00:50:59,175
이것이 GAN이 취하는 접근법입니다.

570
00:50:59,175 --> 00:51:02,637
그래서 GANs에서는 명시적인
밀도 함수로 작업하지 않습니다.

571
00:51:02,637 --> 00:51:05,642
대신에 우리는 게임 이론적 접근법을 취할 것입니다.

572
00:51:05,642 --> 00:51:08,018
우리는 우리의 훈련에서 생성하는 법을 배울 것입니다.

573
00:51:08,018 --> 00:51:10,422
두 선수 게임의 설정을 통해 배포,

574
00:51:10,422 --> 00:51:13,839
이에 대해 더 자세히 설명하겠습니다.

575
00:51:15,255 --> 00:51:18,654
그래서 GAN이 우리가 말하고있는 것을 설정합니다. 좋아,

576
00:51:18,654 --> 00:51:21,354
우리가 관심을 갖는 것은 우리가 표본
추출이 가능하기를 원한다는 것이다.

577
00:51:21,354 --> 00:51:24,681
복잡한 고차원 교육 배포.

578
00:51:24,681 --> 00:51:27,339
그래서 우리가 잘 생각해 보면 샘플을 만들고 싶습니다.

579
00:51:27,339 --> 00:51:29,885
이 배포판에는 직접적인 방법이 없습니다.

580
00:51:29,885 --> 00:51:31,170
우리가이 일을 할 수 있다고.

581
00:51:31,170 --> 00:51:32,560
우리는 매우 복잡한 분포를 가지고 있습니다.

582
00:51:32,560 --> 00:51:35,078
여기에서 샘플을 가져올 수는 없습니다.

583
00:51:35,078 --> 00:51:38,956
그래서 우리가 취할 해결책은 우리가 할 수있는 것입니다,

584
00:51:38,956 --> 00:51:42,895
그러나 더 간단한 배포판에서 샘플을 얻을 수 있습니다.

585
00:51:42,895 --> 00:51:44,687
예를 들어 무작위 노이즈예요?

586
00:51:44,687 --> 00:51:46,875
가우시안들은 우리가 샘플링 할 수있는 것들입니다.

587
00:51:46,875 --> 00:51:49,414
그래서 우리가 할 일은 우리가 배우려고하는 것입니다.

588
00:51:49,414 --> 00:51:52,622
이 단순한 분포들로부터의 변형

589
00:51:52,622 --> 00:51:56,789
우리가 원하는 교육 배포판에 직접 연결됩니다.

590
00:51:58,790 --> 00:52:03,221
그래서 질문, 우리는이 복합체를 표현하기
위해 무엇을 사용할 수 있습니까?

591
00:52:03,221 --> 00:52:04,304
분포?

592
00:52:06,120 --> 00:52:07,718
신경망, 나는 그 대답을 들었다.

593
00:52:07,718 --> 00:52:10,362
그래서 우리가 일종의 복잡한 함수를 모델링하고 싶을 때

594
00:52:10,362 --> 00:52:14,373
또는 변환 우리는 신경 네트워크를 사용합니다.

595
00:52:14,373 --> 00:52:17,478
좋아, 그럼 우리가 할 일은

596
00:52:17,478 --> 00:52:19,702
GAN에서 우리는 몇 가지 정보를 얻을 것입니다.

597
00:52:19,702 --> 00:52:23,297
우리가 지정하는 차원의 벡터입니다.

598
00:52:23,297 --> 00:52:26,060
무작위 잡음을 제거한 다음이를 통과시킵니다.

599
00:52:26,060 --> 00:52:29,015
발전기 네트워크, 그리고 우리는
결과물을 얻게 될 것입니다.

600
00:52:29,015 --> 00:52:33,628
직접 훈련 배포판의 샘플.

601
00:52:33,628 --> 00:52:36,821
그래서 우리가 원하는 무작위 잡음의 모든 입력

602
00:52:36,821 --> 00:52:40,154
훈련 배급의 샘플.

603
00:52:41,278 --> 00:52:44,763
그리하여 우리는이 네트워크를 훈련하고 배울 것입니다.

604
00:52:44,763 --> 00:52:48,737
우리는 이것을 두 사람의 게임으로 보게 될 것입니다.

605
00:52:48,737 --> 00:52:50,721
그래서 두 명의 플레이어, 발전기 네트워크가 있습니다.

606
00:52:50,721 --> 00:52:54,595
내가 다음에 보여줄 추가적인 판별 자 네트워크로서.

607
00:52:54,595 --> 00:52:59,080
그리고 우리의 발전기 네트워크는 플레이어 하나로서,

608
00:52:59,080 --> 00:53:02,584
그것은 차별자를 속이려고 노력할 것입니다.

609
00:53:02,584 --> 00:53:04,320
진짜 보는 이미지.

610
00:53:04,320 --> 00:53:07,089
그리고 두 번째 플레이어, 우리의 판별 자 네트워크

611
00:53:07,089 --> 00:53:11,629
진짜와 가짜를 구별하려고합니다.

612
00:53:11,629 --> 00:53:12,462
이미지.

613
00:53:12,462 --> 00:53:16,950
그래서 가능한 한 좋은 일을하고 싶다.

614
00:53:16,950 --> 00:53:19,740
이 이미지들 중 어느 것이 위조인지 판단하는

615
00:53:19,740 --> 00:53:23,323
또는이 생성자에 의해 생성 된 가짜 이미지.

616
00:53:25,425 --> 00:53:27,324
좋아, 이렇게 생겼어.

617
00:53:27,324 --> 00:53:31,203
우리는 우리의 랜덤 노이즈가
우리의 발전기 네트워크로 간다.

618
00:53:31,203 --> 00:53:33,678
발전기 네트워크에서 이러한 이미지를 생성합니다.

619
00:53:33,678 --> 00:53:36,121
전화 할거야, 그들은 우리 발전기에서 가짜 야.

620
00:53:36,121 --> 00:53:38,738
그리고 나서 우리는 또한 실제 이미지를 갖게 될 것입니다.

621
00:53:38,738 --> 00:53:42,439
우리의 훈련 세트에서 가져온 다음 우리는

622
00:53:42,439 --> 00:53:46,356
판별자를 구별 할 수있다.

623
00:53:48,358 --> 00:53:50,881
진짜와 가짜 이미지.

624
00:53:50,881 --> 00:53:52,849
각 이미지에 대해 실제와 가짜를 출력합니다.

625
00:53:52,849 --> 00:53:55,779
그래서 아이디어는 우리가 아주
좋은 것을 가질 수 있다면입니다.

626
00:53:55,779 --> 00:53:57,910
우리는 훌륭한 discriminator를
훈련시키고 자하며,

627
00:53:57,910 --> 00:54:01,638
그것이 진짜 대 가짜를 차별하는
훌륭한 일을 할 수 있다면,

628
00:54:01,638 --> 00:54:05,760
그리고 우리의 발전기 네트워크가 생성 할 수 있다면,

629
00:54:05,760 --> 00:54:08,227
그것이 잘하고 가짜 이미지를 생성 할 수 있다면

630
00:54:08,227 --> 00:54:11,140
이 discriminator를
성공적으로 바보짓을 할 수있는,

631
00:54:11,140 --> 00:54:13,135
우리는 훌륭한 생성 모델을 가지고 있습니다.

632
00:54:13,135 --> 00:54:16,348
우리는 이미지와 같이 보이는 이미지를

633
00:54:16,348 --> 00:54:17,431
훈련 세트.

634
00:54:19,482 --> 00:54:22,421
좋아, 그래서 우리는이 두 선수가 있고 그래서 우리는

635
00:54:22,421 --> 00:54:25,548
미니 맥스 게임 공식에서 이것을 공동으로 훈련하십시오.

636
00:54:25,548 --> 00:54:28,941
그래서이 미니 맥스 목적 함수는
우리가 여기서 가지고있는 것입니다.

637
00:54:28,941 --> 00:54:33,108
우리는 취할 것입니다, 그것은
세타 G 이상 최소가 될 것입니다

638
00:54:34,791 --> 00:54:37,399
발전기 네트워크 G의 매개 변수,

639
00:54:37,399 --> 00:54:41,431
Discriminator 네트워크의
최대 매개 변수 Zeta

640
00:54:41,431 --> 00:54:44,848
D,이 목적의 권리,이 기간.

641
00:54:47,177 --> 00:54:49,624
그래서 우리가이 용어들을 보면,
이것이 말하고있는 것입니다.

642
00:54:49,624 --> 00:54:53,243
이 첫 번째 일, 데이터에 대한 기대

643
00:54:53,243 --> 00:54:54,910
주어진 X의 로그의

644
00:54:56,094 --> 00:54:59,496
X의 D의 로그는 판별 자 출력입니다.

645
00:54:59,496 --> 00:55:01,151
실제 데이터 X.

646
00:55:01,151 --> 00:55:05,318
이것은 실제 데이터가 실제가 될 가능성이 있습니다.

647
00:55:06,978 --> 00:55:09,309
데이터 분포 P 데이터로부터.

648
00:55:09,309 --> 00:55:12,963
그리고 나서 두 번째 용어 인 Z의 기대

649
00:55:12,963 --> 00:55:16,882
Z의 P에서 나온 Z는 P의
P에서 가져온 것을 의미합니다.

650
00:55:16,882 --> 00:55:21,049
우리의 발전기 네트워크와 G의이 용어 D는 Z의

651
00:55:22,581 --> 00:55:25,875
우리는 여기에 우리의
discriminator의 결과가 있습니다.

652
00:55:25,875 --> 00:55:29,109
우리를 위해 생성 된 가짜 데이터는

653
00:55:29,109 --> 00:55:32,602
Z의 G의 판별 자 출력은 무엇입니까?

654
00:55:32,602 --> 00:55:33,769
우리의 가짜 데이터.

655
00:55:36,311 --> 00:55:39,678
그래서 우리가 이것에 대해 생각한다면,

656
00:55:39,678 --> 00:55:43,105
우리의 판별자는이 목표를 극대화하기를 원합니다.

657
00:55:43,105 --> 00:55:47,272
X의 D가 1에 가깝도록 theta D의 최대 값입니다.

658
00:55:49,271 --> 00:55:53,278
그것은 실제에 가깝고 실제 데이터에 대해서는 높습니다.

659
00:55:53,278 --> 00:55:57,445
그리고 X의 G의 D, 가짜 데이터의 생각

660
00:55:58,696 --> 00:56:02,679
여기 왼쪽에있는 작은 숫자는 0에 가까워 야합니다.

661
00:56:02,679 --> 00:56:06,341
그래서 우리가 이것을 극대화 할 수
있다면 이것은 판별자를 의미합니다.

662
00:56:06,341 --> 00:56:09,237
실제와 제로를 구별하는 훌륭한 일을하고 있습니다.

663
00:56:09,237 --> 00:56:13,449
기본적으로 실제 데이터와 가짜 데이터를 분류합니다.

664
00:56:13,449 --> 00:56:17,092
그리고 나서 우리 발전기, 여기서 우리는 발전기를

665
00:56:17,092 --> 00:56:21,542
Z의 G의 D가 가깝도록이 목적을 최소화한다.

666
00:56:21,542 --> 00:56:22,375
하나에.

667
00:56:22,375 --> 00:56:26,329
Z의 G의 D가 여기에 가까운 경우,

668
00:56:26,329 --> 00:56:31,319
마이너스 쪽은 작고 근본적으로 우리는 원합니다.

669
00:56:31,319 --> 00:56:35,236
이 용어를 최소화하면

670
00:56:36,768 --> 00:56:39,175
discreiminator는 우리의 가짜
데이터가 실제로 진짜라고 생각합니다.

671
00:56:39,175 --> 00:56:44,087
그래서 우리 발전기가 실제 샘플을
생산하고 있음을 의미합니다.

672
00:56:44,087 --> 00:56:46,893
좋아요, 이것이 GAN의 중요한 목표입니다.

673
00:56:46,893 --> 00:56:51,139
시도하고 이해하기에 이것에 대해 질문이 있습니까?

674
00:56:51,139 --> 00:56:55,306
[학생의 말은 마이크가 없어서 가려졌습니다.]

675
00:57:02,342 --> 00:57:04,229
나는 당신의 질문을 이해할 수 있는지 확신하지 못합니다,

676
00:57:04,229 --> 00:57:08,396
[학생의 말은 마이크가 없어서 가려졌습니다.]

677
00:57:12,334 --> 00:57:15,377
그래, 문제는 이것이 기본적으로 시도하는 것이다.

678
00:57:15,377 --> 00:57:19,544
첫 번째 네트워크에서 실제로 보이는
이미지를 생성하게하는 방법

679
00:57:20,761 --> 00:57:22,617
우리의 두 번째 네트워크,
discriminator 수 없습니다

680
00:57:22,617 --> 00:57:24,284
구별하다.

681
00:57:30,474 --> 00:57:34,174
그래, 문제는 우리가 실제로 어떻게
데이터에 라벨을 붙이 느냐이다.

682
00:57:34,174 --> 00:57:36,809
또는 이러한 네트워크에 대한 교육을 수행하십시오.

683
00:57:36,809 --> 00:57:39,364
우리는 다음에 네트워크를 훈련시키는 방법을 보게 될 것입니다.

684
00:57:39,364 --> 00:57:43,530
그러나 기본적으로 데이터 라벨이 무엇인지에 관해서는,

685
00:57:43,530 --> 00:57:46,180
이것은 감독되지 않으므로 데이터 레이블이 없습니다.

686
00:57:46,180 --> 00:57:49,541
그러나 발전기 네트워크에서 생성 된 데이터,

687
00:57:49,541 --> 00:57:52,805
가짜 이미지에는 기본적으로 0
또는 가짜라는 레이블이 있습니다.

688
00:57:52,805 --> 00:57:56,913
그리고 실제 이미지 인 훈련 이미지를 얻을 수 있습니다.

689
00:57:56,913 --> 00:58:00,344
그리고 이것은 기본적으로 하나 또는
진짜의 라벨을 가지고 있습니다.

690
00:58:00,344 --> 00:58:03,692
그래서 우리의 discriminator에 대한 손실 함수

691
00:58:03,692 --> 00:58:04,866
이것을 사용하고 있습니다.

692
00:58:04,866 --> 00:58:08,157
생성기 이미지에 0을 출력하려고합니다.

693
00:58:08,157 --> 00:58:09,819
그리고 실제 이미지를위한 것.

694
00:58:09,819 --> 00:58:12,048
따라서 외부 레이블이 없습니다.

695
00:58:12,048 --> 00:58:15,136
[학생의 말은 마이크가 없어서 가려졌습니다.]

696
00:58:15,136 --> 00:58:17,554
따라서 문제는 발전기 네트워크의 라벨입니다.

697
00:58:17,554 --> 00:58:22,119
판별 자 네트워크의 출력이됩니다.

698
00:58:22,119 --> 00:58:25,534
발전기는 실제로하지 않습니다.

699
00:58:25,534 --> 00:58:29,321
실제로 분류를 실제로하고있는 것은 아닙니다.

700
00:58:29,321 --> 00:58:32,744
그것이 객관적인 것은 여기에 있습니다, G의 Z of Z,

701
00:58:32,744 --> 00:58:35,536
이게 최고라고 원합니다.

702
00:58:35,536 --> 00:58:40,228
그래서 고정 된 discriminator
주어진, 그것을 배우고 싶어

703
00:58:40,228 --> 00:58:42,487
발전기 매개 변수가 높습니다.

704
00:58:42,487 --> 00:58:46,169
그래서 우리는 고정 된 판별 자 출력을
취해 그것을 사용할 것입니다.

705
00:58:46,169 --> 00:58:47,752
그 배경을 이루기 위해서.

706
00:58:51,447 --> 00:58:54,219
좋아, 이것을 훈련시키기 위해서,
우리는 무엇을 할 것인가?

707
00:58:54,219 --> 00:58:57,714
그래디언트 상승 사이를 번갈아 가며

708
00:58:57,714 --> 00:59:02,401
우리의 discriminator에, 그래서 우리는
theta 베타를 배우려고 노력하고 있습니다.

709
00:59:02,401 --> 00:59:05,222
이 목표를 극대화 할 수 있습니다.

710
00:59:05,222 --> 00:59:08,059
그리고 생성기에 그라디언트 디센트.

711
00:59:08,059 --> 00:59:12,247
따라서이 매개 변수에 대한 기울기
상승을 사용하여 theta G

712
00:59:12,247 --> 00:59:15,698
우리는이 목표와 목적을 최소화하고 있습니다.

713
00:59:15,698 --> 00:59:18,413
그리고 여기에 우리는이 부분을 여기로 가져갈 것입니다.

714
00:59:18,413 --> 00:59:22,165
그것은 그 부분에 의존하는 유일한 부분이기 때문에

715
00:59:22,165 --> 00:59:23,748
theta G 매개 변수.

716
00:59:26,574 --> 00:59:30,603
좋아요, 그래서 이것이 우리가이 GAN을 훈련 할 수있는 방법입니다.

717
00:59:30,603 --> 00:59:32,527
우리는 우리의 판별자를 훈련시키는 것과

718
00:59:32,527 --> 00:59:35,716
그리고이 게임에서 우리의 발전기, 각 바보하려고

719
00:59:35,716 --> 00:59:40,561
판별자를 바보로 만들려고 노력하는 다른 또는 발전기.

720
00:59:40,561 --> 00:59:44,027
그러나 주목할 중요한 사실 중 하나는 실제로

721
00:59:44,027 --> 00:59:48,802
우리가 방금 정의한이 생성기 목표

722
00:59:48,802 --> 00:59:50,478
잘 작동하지 않습니다.

723
00:59:50,478 --> 00:59:54,169
그리고 이것에 대한 이유는 우리가
손실을보아야한다는 것입니다.

724
00:59:54,169 --> 00:59:55,309
경치.

725
00:59:55,309 --> 01:00:00,059
우리가 여기있는 손실의 조망을 보면

726
01:00:00,059 --> 01:00:01,059
D의 X of G,

727
01:00:02,858 --> 01:00:06,279
여기에 X의 G의 1을 뺀 D를 적용하면

728
01:00:06,279 --> 01:00:08,737
그것은 우리가 발전기를 최소화하기를 원하는 것입니다.

729
01:00:08,737 --> 01:00:10,654
여기에는이 모양이 있습니다.

730
01:00:12,748 --> 01:00:16,406
그래서 우리는 이것을 최소화하기를 원합니다.

731
01:00:16,406 --> 01:00:21,119
이 손실 중 실제로 오른쪽으로 갈 것입니다.

732
01:00:21,119 --> 01:00:24,369
G의 D가 1에 가까울 때 높습니다.

733
01:00:26,915 --> 01:00:31,082
그래서 우리 발전기가 좋은 일을 할 때

734
01:00:31,082 --> 01:00:33,409
discriminator를 속일 때, 우리는

735
01:00:33,409 --> 01:00:36,837
높은 그래디언트, 더 높은 그래디언트 용어.

736
01:00:36,837 --> 01:00:39,636
그리고 다른 한편으로 우리가 나쁜 샘플을 가지고있을 때,

737
01:00:39,636 --> 01:00:43,068
우리 발전기는 아직 좋은 직업을 배우지 못했지만,

738
01:00:43,068 --> 01:00:44,794
그것은 아직 생성에 좋지 않다,

739
01:00:44,794 --> 01:00:47,992
다음은 판별자가 쉽게 알 수있는 때입니다

740
01:00:47,992 --> 01:00:52,159
이제는 X 축의이 제로 영역에 더 가깝습니다.

741
01:00:53,002 --> 01:00:55,482
그런 다음 그라디언트가 상대적으로 평평합니다.

742
01:00:55,482 --> 01:00:59,065
그리고 이것이 실제로 의미하는 바는

743
01:01:00,288 --> 01:01:03,185
우리의 그라데이션 신호는

744
01:01:03,185 --> 01:01:05,200
샘플은 이미 꽤 좋다.

745
01:01:05,200 --> 01:01:08,011
반면에 우리가 실제로 많은 것을 배우기를 원하는 반면에

746
01:01:08,011 --> 01:01:08,927
나쁘다, 그렇지?

747
01:01:08,927 --> 01:01:12,624
이것은 우리가 배우고 자하는 훈련 샘플입니다.

748
01:01:12,624 --> 01:01:17,570
그래서 이렇게하면 기본적으로 어렵게됩니다.

749
01:01:17,570 --> 01:01:21,664
배우고 그래서 학습을 향상시키기 위해,

750
01:01:21,664 --> 01:01:23,767
우리가하려고하는 것은 다른 것을 정의하는 것입니다.

751
01:01:23,767 --> 01:01:26,320
그라디언트에 약간 다른 목적 함수.

752
01:01:26,320 --> 01:01:30,145
이제 우리는 그라디언트 상승을 대신 할 것입니다.

753
01:01:30,145 --> 01:01:32,229
그래서 우리의 가능성을 최소화하는 대신

754
01:01:32,229 --> 01:01:35,748
discriminator가 올바른지,
우리가 이전에 가지고 있었던 것,

755
01:01:35,748 --> 01:01:38,147
이제 우리는 그것을 뒤집어서 극대화 하자고 말할 것입니다.

756
01:01:38,147 --> 01:01:40,908
우리의 discriminator의 틀린 가능성.

757
01:01:40,908 --> 01:01:45,075
그래서 이것은 여기에 목표를 최대화하고,

758
01:01:47,220 --> 01:01:49,720
X의 G의 D의 로그를 최대화합니다.

759
01:01:50,767 --> 01:01:52,517
그리고 이제는 기본적으로

760
01:01:56,575 --> 01:01:58,327
우리가 원한다면 음수가 있어야한다.

761
01:01:58,327 --> 01:01:59,160
여기에 서명하십시오.

762
01:01:59,160 --> 01:02:03,327
하지만 기본적으로 우리는 이제
플립 목적을 극대화하고자합니다.

763
01:02:04,492 --> 01:02:08,659
대신에이 함수를 플롯하면 이것이
현재 무엇을하는지 알 수 있습니다.

764
01:02:10,118 --> 01:02:13,263
오른쪽에 여기에 높은 그라디언트 신호가 있습니다.

765
01:02:13,263 --> 01:02:16,149
우리가 나쁜 샘플을 가지고있는이 지역에서,

766
01:02:16,149 --> 01:02:20,316
이제는 더 평평한 지역이 오른쪽에 있습니다.

767
01:02:21,566 --> 01:02:23,242
좋은 샘플을 얻을 수 있습니다.

768
01:02:23,242 --> 01:02:25,582
이제 우리는 지역에서 더 많은 것을 배우겠습니다.

769
01:02:25,582 --> 01:02:26,571
나쁜 샘플들.

770
01:02:26,571 --> 01:02:29,059
그래서 이것은 속이는 것과 같은 목적을 가지고 있습니다.

771
01:02:29,059 --> 01:02:31,995
discriminator하지만
실제로는 훨씬 더 잘 작동합니다.

772
01:02:31,995 --> 01:02:35,990
실제로 그리고 GAN에 관한 많은 연구를 위해

773
01:02:35,990 --> 01:02:38,742
이러한 종류의 바닐라 GAN 제제를 사용하여

774
01:02:38,742 --> 01:02:41,492
실제로이 목적을 사용하고 있습니다.

775
01:02:44,220 --> 01:02:48,387
좋습니다. 그렇습니다.

776
01:02:49,444 --> 01:02:53,964
이 두 네트워크는 도전적이고 불안정 할 수 있습니다.

777
01:02:53,964 --> 01:02:56,222
우리가 여기에서 보았 듯이, 우리는

778
01:02:56,222 --> 01:02:59,079
discriminator 훈련 및 발전기 훈련.

779
01:02:59,079 --> 01:03:03,246
이런 유형의 교대는 기본적으로 배우기 어렵다.

780
01:03:04,418 --> 01:03:08,398
한 번에 두 개의 네트워크가 있으며이 문제도 있습니다.

781
01:03:08,398 --> 01:03:11,131
우리의 손실 조경이 보는 것에 따라,

782
01:03:11,131 --> 01:03:13,815
우리의 훈련 역학에 영향을 줄 수 있습니다.

783
01:03:13,815 --> 01:03:17,735
따라서 연구 활동이 활발한 이유는 어떻게 우리가

784
01:03:17,735 --> 01:03:20,592
도움이 될 수있는 더 나은 손실 경관을 가진 목표

785
01:03:20,592 --> 01:03:23,342
훈련을하고 더 안정하게 만드나요?

786
01:03:26,516 --> 01:03:29,257
좋아, 이제이 모든 것을 정리하고

787
01:03:29,257 --> 01:03:31,152
전체 GAN 교육 알고리즘.

788
01:03:31,152 --> 01:03:34,366
그래서 우리가하려고하는 것은 각 반복 훈련을위한 것입니다.

789
01:03:34,366 --> 01:03:37,674
우리는 먼저 세대를 훈련시킬 것입니다,

790
01:03:37,674 --> 01:03:39,145
판별 자 네트워크를 조금 훈련시키다.

791
01:03:39,145 --> 01:03:41,078
발전기 네트워크를 훈련시킬 수 있습니다.

792
01:03:41,078 --> 01:03:43,959
따라서 discriminator
네트워크를 훈련하는 k 단계

793
01:03:43,959 --> 01:03:47,861
우리는 우리의

794
01:03:47,861 --> 01:03:52,442
Z 이전의 노이즈를 제거한 다음 미니 배치를 샘플링합니다.

795
01:03:52,442 --> 01:03:55,859
우리의 훈련 데이터 X의 실제 샘플 수

796
01:03:57,366 --> 01:04:01,410
그래서 우리가 할 일은 우리가 우리를
통해 소음을 전달할 것입니다.

797
01:04:01,410 --> 01:04:04,519
발전기를 사용하면 가짜 이미지가 출력됩니다.

798
01:04:04,519 --> 01:04:07,019
그래서 우리는 가짜 이미지와 미니
배치의 미니 배치를 가지고 있습니다.

799
01:04:07,019 --> 01:04:08,052
실제 이미지의

800
01:04:08,052 --> 01:04:11,554
그리고 나서 우리는 discriminator에
그라데이션 단계를 선택합니다.

801
01:04:11,554 --> 01:04:15,041
이 미니 배치를 사용하여 가짜 이미지와 실제 이미지

802
01:04:15,041 --> 01:04:17,891
우리의 discriminator
매개 변수를 업데이트하십시오.

803
01:04:17,891 --> 01:04:21,318
그리고 이것을 사용하고 반복 횟수만큼 반복하십시오.

804
01:04:21,318 --> 01:04:24,313
기본적으로 판별자를 훈련시키는 것.

805
01:04:24,313 --> 01:04:26,452
그리고 나서 우리는 우리의 두 번째 단계로갑니다.

806
01:04:26,452 --> 01:04:28,803
발전기를 훈련시키는 것입니다.

807
01:04:28,803 --> 01:04:32,544
여기에서는 노이즈 샘플의 작은 배치를 샘플링합니다.

808
01:04:32,544 --> 01:04:36,205
우리는 이것을 발전기를 통해 전달할 것이고, 이제 우리는

809
01:04:36,205 --> 01:04:40,288
근본적으로 우리를 최적화하기 위해
이것에 백도핑을하고 싶습니다.

810
01:04:42,264 --> 01:04:45,078
우리가 전에 보았던 발전기 목표.

811
01:04:45,078 --> 01:04:48,038
그래서 우리는 우리의 생성기를 우리의
판별 자로 속이기를 원합니다.

812
01:04:48,038 --> 01:04:49,705
가능한 한 많이.

813
01:04:50,773 --> 01:04:54,940
그래서 우리는이 두 단계를 번갈아 가려고합니다.

814
01:04:56,041 --> 01:04:58,410
우리의 discriminator에
대한 그라디언트 단계를 복용의

815
01:04:58,410 --> 01:04:59,996
발전기 용.

816
01:04:59,996 --> 01:05:02,579
그리고 여기 k 단계를 위해 말했습니다.

817
01:05:03,474 --> 01:05:06,306
discriminator 훈련을
위해 그리고 이것은 친절하다.

818
01:05:06,306 --> 01:05:08,604
논쟁 주제의

819
01:05:08,604 --> 01:05:11,612
어떤 사람들은 판별자를 한 번 반복한다고 생각합니다.

820
01:05:11,612 --> 01:05:15,391
한 종류의 판별 기, 한 종류의 발전기가 가장 좋습니다.

821
01:05:15,391 --> 01:05:18,259
어떤 사람들은 판별자를 양성하는
것이 더 바람직하다고 생각합니다.

822
01:05:18,259 --> 01:05:20,744
발전기로 전환하기 전에 좀 더 길게.

823
01:05:20,744 --> 01:05:24,771
진짜 확실한 규칙은 없으며

824
01:05:24,771 --> 01:05:28,552
사람들은 더 잘 작동하기 위해 다른 일을 발견했습니다.

825
01:05:28,552 --> 01:05:30,732
문제에 따라.

826
01:05:30,732 --> 01:05:33,693
제가 지적하고자하는 한 가지는

827
01:05:33,693 --> 01:05:37,838
이 문제를 완화시키는 많은 최근 연구

828
01:05:37,838 --> 01:05:41,580
당신이 그렇게 많은 노력을 할 필요가 없도록 만듭니다.

829
01:05:41,580 --> 01:05:45,028
이 두 네트워크의 교육 방법을 균형있게 조정하려고합니다.

830
01:05:45,028 --> 01:05:47,880
보다 안정적인 교육을 받고 더
나은 결과를 얻을 수 있습니다.

831
01:05:47,880 --> 01:05:51,822
그래서 Wasserstein GAN은 논문의 한 예입니다.

832
01:05:51,822 --> 01:05:55,655
그것은 이것을하기위한 중요한 작업이었습니다.

833
01:06:00,313 --> 01:06:04,417
좋아, 이제 우리가 훈련 한 전체 그림을보고,

834
01:06:04,417 --> 01:06:06,548
우리는 우리의 네트워크 설정을 가지고 있으며 우리는

835
01:06:06,548 --> 01:06:09,767
발전기 네트워크와 판별 자 네트워크

836
01:06:09,767 --> 01:06:11,785
그리고 지금 세대를위한 훈련 후에,

837
01:06:11,785 --> 01:06:15,009
우리는 단지 우리의 발전기 네트워크를
가지고 이것을 사용할 수 있습니다.

838
01:06:15,009 --> 01:06:16,899
새로운 이미지를 생성합니다.

839
01:06:16,899 --> 01:06:19,687
그래서 우리는 단지 잡음 Z를 취해
이것을 통과시키고 생성합니다.

840
01:06:19,687 --> 01:06:21,520
여기에서 가짜 이미지.

841
01:06:23,636 --> 01:06:27,352
이제 생성 된 샘플을 살펴 보겠습니다.

842
01:06:27,352 --> 01:06:28,351
이 GAN들로부터.

843
01:06:28,351 --> 01:06:31,093
그럼 여기에 MNIST에서 훈련받은 예가 있습니다.

844
01:06:31,093 --> 01:06:33,099
그리고 Faces의 오른쪽에서.

845
01:06:33,099 --> 01:06:36,195
그리고 이들 각각에 대해서도 볼 수 있습니다.

846
01:06:36,195 --> 01:06:39,765
시각화를 위해 가장 가까운, 오른쪽,

847
01:06:39,765 --> 01:06:42,349
훈련 세트에서 가장 가까운 이웃

848
01:06:42,349 --> 01:06:43,849
바로 옆에.

849
01:06:43,849 --> 01:06:45,426
그래서 우리는 우리가 생성 할 수
있다는 것을 알 수 있습니다.

850
01:06:45,426 --> 01:06:47,810
매우 현실적인 샘플이며 직접 기억하지 못합니다.

851
01:06:47,810 --> 01:06:49,227
훈련 세트.

852
01:06:51,264 --> 01:06:54,003
그리고 원래 GAN 논문의 몇 가지 예가 있습니다.

853
01:06:54,003 --> 01:06:56,061
CIFAR 이미지.

854
01:06:56,061 --> 01:06:59,960
그리고 이것들은 여전히 공정하고 좋은 품질은 아닙니다.

855
01:06:59,960 --> 01:07:03,200
이들은 원래 작품은 2014 년,

856
01:07:03,200 --> 01:07:07,374
그래서 이들은 더 오래되고 간단한 네트워크입니다.

857
01:07:07,374 --> 01:07:11,541
그리고 이들은 단순하고 완벽하게 연결된
네트워크를 사용하고있었습니다.

858
01:07:12,550 --> 01:07:14,518
그리고 그 이후로 많은 일들이있었습니다.

859
01:07:14,518 --> 01:07:16,018
GANs 개선에.

860
01:07:18,120 --> 01:07:20,905
실제로 큰 걸음을 내디뎠던 작품의 한 예

861
01:07:20,905 --> 01:07:24,645
샘플의 품질 향상을 향한 노력

862
01:07:24,645 --> 01:07:29,555
ICLR 2016의 알렉스 래드 포드 (Alex
Radford)에서 길쌈 (convolutional) 추가

863
01:07:29,555 --> 01:07:31,388
GANs에 아키텍처.

864
01:07:33,806 --> 01:07:37,663
이 신문에는 일련의 지침이있었습니다

865
01:07:37,663 --> 01:07:41,926
GAN이 더 잘 생산할 수 있도록 도와주는 아키텍처

866
01:07:41,926 --> 01:07:42,958
견본.

867
01:07:42,958 --> 01:07:46,517
그래서 당신은 이것에 대한 자세한 내용을 볼 수 있습니다.

868
01:07:46,517 --> 01:07:49,217
이것은 길쌈 아키텍처의 예입니다.

869
01:07:49,217 --> 01:07:52,669
그들이 사용하고있는 것이 우리의
입력 Z에서 나온 것입니다.

870
01:07:52,669 --> 01:07:55,944
노이즈 벡터 Z와이 모든 변형

871
01:07:55,944 --> 01:07:57,694
출력 샘플로.

872
01:08:00,527 --> 01:08:03,437
이제는이 커다란 콘볼 루션 아키텍처

873
01:08:03,437 --> 01:08:06,446
이 모델의 샘플은 실제로

874
01:08:06,446 --> 01:08:08,251
아주 좋아 보이기 시작했다.

875
01:08:08,251 --> 01:08:11,408
그래서 이것은 침실의 데이터 세트에 대해 훈련되었습니다.

876
01:08:11,408 --> 01:08:15,575
우리는 모든 종류의 매우 현실적인 공상을 볼 수 있습니다.

877
01:08:16,783 --> 01:08:20,950
창문과 야간 스탠드 및 기타 가구가있는 침실

878
01:08:22,926 --> 01:08:26,063
그 주위에는 정말 예쁜 샘플들이 있습니다.

879
01:08:26,064 --> 01:08:29,828
그리고 우리는 또한 무엇을 시도하고 해석 할 수 있습니다.

880
01:08:29,828 --> 01:08:32,346
이 GAN은하고 있습니다.

881
01:08:32,346 --> 01:08:36,151
그래서이 예제에서 우리가 할 수있는
것은 우리가 취할 수있는 것입니다.

882
01:08:36,152 --> 01:08:40,038
두 점 Z, 두 개의 다른 랜덤 잡음 벡터

883
01:08:40,038 --> 01:08:42,817
그리고이 점들 사이를 보간하자.

884
01:08:42,818 --> 01:08:45,245
여기에있는 각 행은

885
01:08:45,245 --> 01:08:50,142
하나의 랜덤 잡음 Z로부터 다른 랜덤 잡음 벡터 Z로

886
01:08:50,142 --> 01:08:53,207
당신은 그것이 변화하고 있음을 볼 수 있습니다,

887
01:08:53,207 --> 01:08:55,655
이미지를 부드럽게 보간하고 있습니다.

888
01:08:55,656 --> 01:08:57,073
끝까지.

889
01:08:59,286 --> 01:09:02,067
그래서 우리가 할 수있는 다른 일은
우리가 그것을 볼 수 있다는 것입니다,

890
01:09:02,067 --> 01:09:06,584
자,이 벡터 Z가 무엇인지 더 자세히 분석해 봅시다.

891
01:09:06,584 --> 01:09:10,313
의미, 그래서 우리는 여기서 벡터
수학을 시도하고 할 수 있습니다.

892
01:09:10,313 --> 01:09:13,563
이 실험이하는 것은

893
01:09:14,888 --> 01:09:17,828
알았어. 미소 짓는 모습을 찍자.

894
01:09:17,828 --> 01:09:22,099
미소 짓는 여성 이미지의 샘플을 가져 와서

895
01:09:22,100 --> 01:09:25,379
중립 여성의 표본 및 일부 표본

896
01:09:25,379 --> 01:09:26,629
중립적 인 사람들의

897
01:09:28,341 --> 01:09:32,049
그래서 Z 벡터의 평균을 취해 봅시다.

898
01:09:32,050 --> 01:09:34,920
이 샘플들 각각을 생산했고 우리가

899
01:09:34,920 --> 01:09:38,184
우리가 이것을 가져 가라, 미소
짓는 여자들을위한 평균적인 벡터,

900
01:09:38,184 --> 01:09:40,783
중성 여성을위한 평균 벡터를 뺀다.

901
01:09:40,783 --> 01:09:43,786
중립적 인 인간에 대한 평균 벡터를 더하고,

902
01:09:43,787 --> 01:09:45,037
우리는 무엇을 얻습니까?

903
01:09:46,651 --> 01:09:49,884
그리고 우리는 웃는 남자의 표본을 얻습니다.

904
01:09:49,884 --> 01:09:52,200
그래서 우리는 거기에서 생성 된
Z 벡터를 취할 수 있습니다.

905
01:09:52,200 --> 01:09:56,200
샘플을 생성하고 웃는 남자의 샘플을 얻으십시오.

906
01:09:57,190 --> 01:09:59,712
그리고 우리는 이것의 또 다른 예를 가질 수 있습니다.

907
01:09:59,712 --> 01:10:03,879
안경 남자 마이너스 안경 남자와 플러스 안경 여자.

908
01:10:05,918 --> 01:10:08,763
그리고 안경을 쓰고 여자를 구하십시오.

909
01:10:08,763 --> 01:10:12,483
그래서 여기 당신은 기본적으로 Z가이
타입을 가지고 있음을 볼 수 있습니다.

910
01:10:12,483 --> 01:10:16,191
당신이 생성하기 위해 이것을 사용할 수있는 해석 가능성

911
01:10:16,191 --> 01:10:18,358
아주 멋진 예제들.

912
01:10:20,026 --> 01:10:22,300
올해는 2017 년이되었습니다.

913
01:10:22,300 --> 01:10:23,967
GAN의 해.

914
01:10:24,842 --> 01:10:28,309
GAN에 대한 많은 작업이있었습니다.

915
01:10:28,309 --> 01:10:31,737
그리고 그것은 정말로 종류의 폭발과 정말로 줬다

916
01:10:31,737 --> 01:10:33,261
멋진 결과.

917
01:10:33,261 --> 01:10:37,017
왼쪽의 여기에서 작업하는 사람들을 볼 수 있습니다.

918
01:10:37,017 --> 01:10:38,680
더 나은 훈련과 세대.

919
01:10:38,680 --> 01:10:41,454
그래서 우리는 손실 기능 개선에 관해 이야기했습니다.

920
01:10:41,454 --> 01:10:45,621
더 안정적인 교육 및 이것은 정말 좋은 얻을 수있었습니다.

921
01:10:47,216 --> 01:10:50,173
다양한 아키텍처 유형의 세대

922
01:10:50,173 --> 01:10:54,326
아래쪽은 정말 선명한 고해상도의 얼굴입니다.

923
01:10:54,326 --> 01:10:58,918
GAN을 사용하면 다음과 같은 모델도 있습니다.

924
01:10:58,918 --> 01:11:01,742
소스를 사용하여 도메인 전송 및
조건부 GAN을 시도합니다.

925
01:11:01,742 --> 01:11:04,394
그리고 여기에서, 이것은 시도하려고하는 소스의 예입니다.

926
01:11:04,394 --> 01:11:08,363
예를 들어 상단 부분에서 도메인 전송을 얻습니다.

927
01:11:08,363 --> 01:11:12,540
여기에서 우리는 말의 근원 영역에서 가려고 노력하고있다.

928
01:11:12,540 --> 01:11:14,703
얼룩말의 출력 영역으로

929
01:11:14,703 --> 01:11:18,692
그래서 우리는 말의 이미지를 찍고
GAN을 훈련시킬 수 있습니다.

930
01:11:18,692 --> 01:11:21,646
출력이 같은 것이 될 것입니다.

931
01:11:21,646 --> 01:11:25,813
그러나 지금 말과 같은 이미지 설정에서 얼룩말

932
01:11:28,408 --> 01:11:29,915
다른 방향으로 가십시오.

933
01:11:29,915 --> 01:11:33,124
우리는 사과를 오렌지로 변형시킬 수 있습니다.

934
01:11:33,124 --> 01:11:35,128
그리고 또 다른 방법.

935
01:11:35,128 --> 01:11:38,608
우리는 이것을 사용하여 사진을 향상시킬 수도 있습니다.

936
01:11:38,608 --> 01:11:41,676
그래서 이것을 제작하고, 표준 사진을 찍습니다.

937
01:11:41,676 --> 01:11:46,218
네가 가진 것처럼 정말 멋지게 만들려고 노력하는거야.

938
01:11:46,218 --> 01:11:48,717
당신은 정말 좋은 비싼 카메라를 가지고있는 척.

939
01:11:48,717 --> 01:11:52,379
멋진 흐림 효과를 얻을 수 있습니다.

940
01:11:52,379 --> 01:11:55,987
아래쪽에는 장면이 바뀌고,

941
01:11:55,987 --> 01:11:59,733
요세미티의 이미지를 이미지에서 변형시키는 것

942
01:11:59,733 --> 01:12:03,750
여름 시간에는 겨울 시간에 이미지로.

943
01:12:03,750 --> 01:12:05,753
그리고 실제로 많은 응용 프로그램이 있습니다.

944
01:12:05,753 --> 01:12:08,430
여기 오른쪽에는 더 많은 것이 있습니다.

945
01:12:08,430 --> 01:12:11,930
텍스트 설명에서 나옵니다.

946
01:12:13,900 --> 01:12:15,839
이 텍스트를 조건으로하는 GAN

947
01:12:15,839 --> 01:12:18,343
설명 및 이미지 제작.

948
01:12:18,343 --> 01:12:21,572
여기에 작은 새에 관한 뭔가가 있습니다.

949
01:12:21,572 --> 01:12:25,094
분홍색 유방과 크라운을 가지고 지금 우리는

950
01:12:25,094 --> 01:12:26,421
이 이미지들.

951
01:12:26,421 --> 01:12:30,588
그리고 여기에 가장자리를 채우는 예제도 있습니다.

952
01:12:31,808 --> 01:12:34,436
우리가 가지고있는 스케치에 주어진 조건들,

953
01:12:34,436 --> 01:12:38,603
우리는 이것이 어떻게 생겼는지에 대한
컬러 버전을 채울 수 있습니까?

954
01:12:40,848 --> 01:12:45,015
Google,지도 그리드를 사용하여
무언가를 넣을 수 있습니까?

955
01:12:47,127 --> 01:12:49,033
Google 어스처럼 보이지만,

956
01:12:49,033 --> 01:12:52,528
Google 어스와 같은 모양으로 변환하십시오.

957
01:12:52,528 --> 01:12:55,492
들어가서이 모든 건물과 나무를 환각 시키십시오.

958
01:12:55,492 --> 01:12:56,767
등등.

959
01:12:56,767 --> 01:12:59,825
그래서 이것에 대한 정말 멋진 예제가 많이 있습니다.

960
01:12:59,825 --> 01:13:03,575
그리고 pics to pics를위한이 웹 사이트도있다.

961
01:13:04,591 --> 01:13:06,869
이러한 종류의 조건부 GAN 유형을 많이 수행했습니다.

962
01:13:06,869 --> 01:13:08,077
예.

963
01:13:08,077 --> 01:13:12,244
좀 더 재미있게 볼 것을 권합니다.

964
01:13:13,450 --> 01:13:17,549
사람들이 GAN으로 수행 한 애플리케이션

965
01:13:17,549 --> 01:13:20,473
연구 논문의 관점에서 볼 때

966
01:13:20,473 --> 01:13:24,640
올해 GAN에 관한 수많은 논문이 있습니다.

967
01:13:26,047 --> 01:13:29,528
GAN 동물원이라는 웹 사이트가 있습니다.

968
01:13:29,528 --> 01:13:31,365
이것들의 전체 목록을 컴파일하려고합니다.

969
01:13:31,365 --> 01:13:35,036
그리고 여기 이것은 단지 나를 통해 A에서 C 걸렸습니다.

970
01:13:35,036 --> 01:13:37,690
왼쪽의 오른쪽과 같은 L을 통해.

971
01:13:37,690 --> 01:13:40,076
따라서 슬라이드에는 맞지 않습니다.

972
01:13:40,076 --> 01:13:42,446
당신이 볼 수있는 수많은 종이가 있습니다.

973
01:13:42,446 --> 01:13:44,794
당신이 관심이 있다면.

974
01:13:44,794 --> 01:13:48,961
그리고 마지막 포인터 하나가 팁과 트릭을위한 것입니다.

975
01:13:49,927 --> 01:13:53,348
GAN 교육을 위해 여기에 멋진
작은 웹 사이트가 있습니다.

976
01:13:53,348 --> 01:13:57,259
이 GAN을 훈련 시키려고한다면 포인터가 있습니다.

977
01:13:57,259 --> 01:13:58,342
실제로.

978
01:14:01,313 --> 01:14:03,396
좋아, GAN의 요약.

979
01:14:04,336 --> 01:14:06,915
GAN은 명시 적 밀도 함수로 작동하지 않습니다.

980
01:14:06,915 --> 01:14:10,036
대신 우리는 이것을 암묵적으로 표현하려고합니다.

981
01:14:10,036 --> 01:14:13,989
샘플을 사용하여 교육에 대한 게임
이론 접근 방식을 취합니다.

982
01:14:13,989 --> 01:14:16,092
그래서 우리는 우리의 훈련에서
생성하는 법을 배울 것입니다.

983
01:14:16,092 --> 01:14:18,973
두 플레이어 게임 설정을 통한 배포.

984
01:14:18,973 --> 01:14:21,947
그리고 GAN의 프로들은 그들이 정말로

985
01:14:21,947 --> 01:14:24,934
예술 샘플의 화려한 상태와 당신은 많이 할 수 있습니다.

986
01:14:24,934 --> 01:14:26,212
이것들과.

987
01:14:26,212 --> 01:14:29,580
단점은 그들이 더 까다 롭고 불안정하다는 것입니다.

988
01:14:29,580 --> 01:14:33,247
훈련을 위해, 우리는 단지 직접 최적화하지 않습니다.

989
01:14:36,499 --> 01:14:40,054
우리가 바로 할 수있는 하나의 목적 함수

990
01:14:40,054 --> 01:14:41,830
쉽게 훈련 할 수 있습니다.

991
01:14:41,830 --> 01:14:44,648
대신 우리는 우리가 시도하고있는이 두
가지 네트워크를 가지고 있습니다.

992
01:14:44,648 --> 01:14:47,710
훈련과 균형을 맞추기 위해 좀 더 불안정 할 수 있습니다.

993
01:14:47,710 --> 01:14:50,979
그리고 우리는 할 수 없다는 것을 잊을 수 있습니다.

994
01:14:50,979 --> 01:14:54,915
어떤 추론 질의들, X의 P, 주어진 Z의 P

995
01:14:54,915 --> 01:14:57,629
VAE에서 예를 들어 보았습니다.

996
01:14:57,629 --> 01:15:00,051
그리고 GAN은 여전히 활발한 연구 분야이며,

997
01:15:00,051 --> 01:15:04,427
이것은 우리가 시작하고있는 비교적
새로운 유형의 모델입니다.

998
01:15:04,427 --> 01:15:07,040
많은 것을보기 위해 당신은 훨씬 더 많이 볼 것입니다.

999
01:15:07,040 --> 01:15:11,556
그래서 사람들은 더 나은 손실 기능을
위해 지금 일하고 있습니다.

1000
01:15:11,556 --> 01:15:14,994
보다 안정적인 교육, 그래서 Wasserstein GAN

1001
01:15:14,994 --> 01:15:18,994
관심있는 사람들은 기본적으로

1002
01:15:20,585 --> 01:15:22,224
이 방향의 개선.

1003
01:15:22,224 --> 01:15:25,099
이제는 많은 사람들이 모델을 사용하고 기초하고 있습니다.

1004
01:15:25,099 --> 01:15:26,387
떨어져.

1005
01:15:26,387 --> 01:15:29,759
LSGAN, Least Square의 GAN,

1006
01:15:29,759 --> 01:15:31,489
최소한 Square의 GAN 및 기타.

1007
01:15:31,489 --> 01:15:32,871
그래서 당신은 이것을 더 자세히 볼 수 있습니다.

1008
01:15:32,871 --> 01:15:35,285
그리고이 새로운 모델을위한 많은 시간

1009
01:15:35,285 --> 01:15:37,108
실제로이를 구현하는 측면에서,

1010
01:15:37,108 --> 01:15:39,307
반드시 큰 변화는 아닙니다.

1011
01:15:39,307 --> 01:15:41,622
그들은 당신이 바꿀 수있는 다른 손실 함수입니다.

1012
01:15:41,622 --> 01:15:43,407
조금이라도 큰 개선이되다.

1013
01:15:43,407 --> 01:15:44,279
훈련 중.

1014
01:15:44,279 --> 01:15:47,159
그래서 이것들 중 일부는 다음을 조사 할 가치가 있습니다.

1015
01:15:47,159 --> 01:15:50,115
숙제에 대한 연습을하게됩니다.

1016
01:15:50,115 --> 01:15:51,500
할당.

1017
01:15:51,500 --> 01:15:54,410
또한 여러 유형의 작업에 많은 작업이 있습니다.

1018
01:15:54,410 --> 01:15:57,279
조건부 GAN 및 GAN은 모든 종류의 다른

1019
01:15:57,279 --> 01:15:59,946
문제 설정 및 응용 프로그램.

1020
01:16:01,648 --> 01:16:03,507
좋아, 오늘의 정리.

1021
01:16:03,507 --> 01:16:05,807
우리는 생성 모델에 대해 이야기했습니다.

1022
01:16:05,807 --> 01:16:08,538
우리는 가장 일반적인 세대의 3
가지 유형에 대해 이야기했습니다.

1023
01:16:08,538 --> 01:16:12,329
사람들이 사용하고 있고 연구를하고있는 모델.

1024
01:16:12,329 --> 01:16:15,098
그래서 우리는 먼저 pixelRNN과
pixelCNN에 대해 이야기했습니다.

1025
01:16:15,098 --> 01:16:17,588
이것은 명시적인 밀도 모델이다.

1026
01:16:17,588 --> 01:16:20,710
정확한 확률을 최적화하고 좋은 결과를 산출합니다.

1027
01:16:20,710 --> 01:16:24,607
샘플을 사용하지만 꽤 비효율적입니다.

1028
01:16:24,607 --> 01:16:26,981
순차 생성.

1029
01:16:26,981 --> 01:16:29,902
VAE를 살펴보면,

1030
01:16:29,902 --> 01:16:32,696
가능성에 묶여 있고 이것은 또한

1031
01:16:32,696 --> 01:16:35,090
유용한 잠재 표현.

1032
01:16:35,090 --> 01:16:36,890
추론 쿼리를 할 수 있습니다.

1033
01:16:36,890 --> 01:16:40,305
그러나 예제의 품질은 여전히 최고가 아닙니다.

1034
01:16:40,305 --> 01:16:42,715
약속이 많아도 여전히 그렇습니다.

1035
01:16:42,715 --> 01:16:46,583
매우 활발한 연구 분야이며 많은 것을 가지고있다.

1036
01:16:46,583 --> 01:16:47,657
열린 문제.

1037
01:16:47,657 --> 01:16:51,654
그리고 나서 우리가 이야기 한 GAN은 게임 이론적

1038
01:16:51,654 --> 01:16:55,089
훈련을위한 접근법이며 현재 달성되는 것입니다.

1039
01:16:55,089 --> 01:16:57,375
최고의 예술적 사례.

1040
01:16:57,375 --> 01:17:00,253
그러나 훈련이 까다 롭고 불안정 할 수도 있습니다.

1041
01:17:00,253 --> 01:17:05,047
추측 쿼리에서 약간의 손실이 발생합니다.

1042
01:17:05,047 --> 01:17:08,108
그래서 여러분도 볼 수있는 것은 많은 최근 연구입니다.

1043
01:17:08,108 --> 01:17:10,239
이러한 종류의 모델의 조합.

1044
01:17:10,239 --> 01:17:12,733
그래서 예를 들어 adversarial autoencoders입니다.

1045
01:17:12,733 --> 01:17:14,865
추가로 훈련 된 VAE와 같은 것

1046
01:17:14,865 --> 01:17:18,478
샘플 품질을 향상시키는 상단의 적자 손실.

1047
01:17:18,478 --> 01:17:21,517
pixelVAE와 같은 것들도 있습니다.

1048
01:17:21,517 --> 01:17:23,848
pixelCNN과 VAE의 조합이 많아서

1049
01:17:23,848 --> 01:17:28,015
기본적으로 모든 세계를 최대한 활용하려고 노력합니다.

1050
01:17:29,808 --> 01:17:32,444
함께 모아라.

1051
01:17:32,444 --> 01:17:35,000
좋아, 오늘 우리는 생성 모델에 대해 이야기했다.

1052
01:17:35,000 --> 01:17:38,449
다음에 우리는 강화 학습에 관해 이야기 할 것입니다.

1053
01:17:38,449 --> 01:17:40,449
감사.

