1
00:00:11,077 --> 00:00:14,258
- 알았어. 오늘은 많이 다루려고 시작하자.

2
00:00:14,258 --> 00:00:17,454
오늘 우리는 Generative
Models에 대해 이야기 할 것입니다.

3
00:00:17,454 --> 00:00:20,484
그리고 우리가 시작하기 전에, 몇 가지 관리 세부 사항.

4
00:00:20,484 --> 00:00:23,522
그래서 중급 성적은 이번 주
Gradescope에서 발표 될 예정입니다.

5
00:00:23,522 --> 00:00:27,730
A3가 다음 주 금요일 5 월 26
일에 만기 연장 될 예정입니다.

6
00:00:27,730 --> 00:00:30,376
HyperQuest가 추가 크레딧을
제출하면이 작업을 수행 할 수 있습니다.

7
00:00:30,376 --> 00:00:32,709
여전히 5 월 21 일 일요일까지.

8
00:00:33,632 --> 00:00:37,799
포스터 세션은 6 월 6 일 오후 12
시부 터 오후 3 시까 지 진행됩니다.

9
00:00:40,812 --> 00:00:43,095
오늘 우리가 이야기 할 내용에 대한 개요

10
00:00:43,095 --> 00:00:44,646
우리는 기어를 조금 바꿀 것입니다.

11
00:00:44,646 --> 00:00:47,759
오늘 자율 학습을 살펴보십시오.

12
00:00:47,759 --> 00:00:50,686
그리고 특히 우리는 생성에 대해 이야기 할 것입니다.

13
00:00:50,686 --> 00:00:54,103
무 감독 학습의 한 유형 인 모델.

14
00:00:54,103 --> 00:00:57,112
그리고 세 가지 유형의 생성 모델을 살펴 보겠습니다.

15
00:00:57,112 --> 00:01:01,174
그래서 pixelRNNs와 pixelCNNs
variational autoencoders

16
00:01:01,174 --> 00:01:04,174
및 Generative Adversarial networks를 포함한다.

17
00:01:05,571 --> 00:01:07,847
지금까지이 수업에서 우리는 감독자에
대해 많이 이야기했습니다.

18
00:01:07,847 --> 00:01:09,672
학습과 다른 종류

19
00:01:09,672 --> 00:01:11,168
감독 학습 문제.

20
00:01:11,168 --> 00:01:14,247
따라서 감독 학습 설정에서 데이터 X와

21
00:01:14,247 --> 00:01:16,078
Y라는 레이블이 있습니다.

22
00:01:16,078 --> 00:01:19,063
그리고 우리의 목표는 매핑하는 함수를 배우는 것입니다.

23
00:01:19,063 --> 00:01:21,417
우리의 데이터 X에서 우리의 레이블 Y로

24
00:01:21,417 --> 00:01:26,237
그리고이 라벨은 다양한 형태의 형태를 취할 수 있습니다.

25
00:01:26,237 --> 00:01:28,390
예를 들어 분류에 대해 살펴 보았습니다.

26
00:01:28,390 --> 00:01:30,303
우리의 입력은 이미지입니다.

27
00:01:30,303 --> 00:01:34,934
우리는 카테고리에 대한 클래스
레이블 인 Y를 출력하려고합니다.

28
00:01:34,934 --> 00:01:37,214
우리는 물체 감지에 대해 이야기했습니다.

29
00:01:37,214 --> 00:01:39,926
여전히 이미지이지만 여기에

30
00:01:39,926 --> 00:01:44,093
여러 개 또는 고양이까지의 인스턴스 경계 상자.

31
00:01:46,138 --> 00:01:48,532
우리는 여기서 의미 론적 세분화에 대해 이야기했습니다.

32
00:01:48,532 --> 00:01:51,069
모든 픽셀에 대한 레이블.

33
00:01:51,069 --> 00:01:51,986
에 속한다.

34
00:01:53,572 --> 00:01:55,298
그리고 이미지 캡션에 대해서도 이야기했습니다.

35
00:01:55,298 --> 00:01:58,961
여기서 우리의 레이블은 이제 문장입니다.

36
00:01:58,961 --> 00:02:02,961
그래서 그것은 자연 언어의 형태로되었습니다.

37
00:02:03,998 --> 00:02:06,534
그래서이 설정에서 무 감독 학습,

38
00:02:06,534 --> 00:02:08,095
그것은 여기에 우리가 가지고있는 학습의 한 유형입니다.

39
00:02:08,095 --> 00:02:11,520
레이블이없는 교육 데이터 및 우리의
목표는 이제 일부를 배우는 것입니다.

40
00:02:11,520 --> 00:02:15,661
데이터의 숨겨진 기본 구조.

41
00:02:15,661 --> 00:02:17,439
맞아, 이것의 예는 다음과 같다.

42
00:02:17,439 --> 00:02:20,370
네가 전에 보았을지도 모르는 클러스터링

43
00:02:20,370 --> 00:02:22,534
여기서 목표는 데이터 내의 그룹을 찾는 것입니다.

44
00:02:22,534 --> 00:02:25,029
이는 어떤 유형의 측정 항목을 통해 유사합니다.

45
00:02:25,029 --> 00:02:27,187
예를 들어, K는 클러스터링을 의미합니다.

46
00:02:27,187 --> 00:02:30,371
감독되지 않은 학습 과제의 또 다른 예

47
00:02:30,371 --> 00:02:32,871
차원 감소입니다.

48
00:02:33,777 --> 00:02:36,634
그래서이 문제에서 축을 발견하고 싶습니다.

49
00:02:36,634 --> 00:02:38,939
우리의 훈련 데이터가 가장 다양합니다.

50
00:02:38,939 --> 00:02:42,298
그래서이 축은 밑에있는 구조물의 일부입니다.

51
00:02:42,298 --> 00:02:43,537
데이터의

52
00:02:43,537 --> 00:02:45,685
그런 다음이를 사용하여 차원을 줄입니다.

53
00:02:45,685 --> 00:02:48,918
데이터가 중요한 변화를 갖도록 데이터의

54
00:02:48,918 --> 00:02:51,095
나머지 각 측정 기준 사이에

55
00:02:51,095 --> 00:02:52,938
맞아, 여기이 예제는 데이터로 시작합니다.

56
00:02:52,938 --> 00:02:56,014
3 차원에서 우리는 두 가지를 찾을 것입니다.

57
00:02:56,014 --> 00:02:57,842
이 경우의 변화의 축

58
00:02:57,842 --> 00:03:01,259
우리의 데이터를 2D로 축소 할 수 있습니다.

59
00:03:04,205 --> 00:03:06,214
감독되지 않은 학습의 또 다른 예

60
00:03:06,214 --> 00:03:09,964
데이터에 대한 피쳐 표현을 학습하고 있습니다.

61
00:03:11,006 --> 00:03:14,137
우리는 이전에 감독 방식으로이 작업을
수행하는 방법을 보았습니다.

62
00:03:14,137 --> 00:03:15,645
감독 된 손실을 사용했던 곳에,

63
00:03:15,645 --> 00:03:17,209
예를 들어 분류.

64
00:03:17,209 --> 00:03:19,743
분류 라벨이있는 곳.

65
00:03:19,743 --> 00:03:21,617
Softmax 손실과 같은 것이 있습니다.

66
00:03:21,617 --> 00:03:23,671
그리고 우리는 신경망을 훈련시킬 수 있습니다.

67
00:03:23,671 --> 00:03:25,635
예를 들어 활성화를 해석 할 수 있습니다.

68
00:03:25,635 --> 00:03:27,723
미래의 일종으로 우리의 FC7 레이어

69
00:03:27,723 --> 00:03:29,869
데이터에 대한 표현.

70
00:03:29,869 --> 00:03:31,791
그리고 감독되지 않은 환경에서,

71
00:03:31,791 --> 00:03:34,492
예를 들어 여기서는 자동 인코딩을 사용합니다.

72
00:03:34,492 --> 00:03:35,742
나중에 더 많은 정보

73
00:03:35,742 --> 00:03:38,349
이 경우 우리의 손실은 이제

74
00:03:38,349 --> 00:03:41,962
기본적으로 입력 데이터를 재구성하고,

75
00:03:41,962 --> 00:03:44,685
우리는 입력 데이터를 잘 재구성했다.

76
00:03:44,685 --> 00:03:46,872
기능을 배우기 위해 이것을 사용하십시오.

77
00:03:46,872 --> 00:03:49,162
그래서 우리는 다음과 같은 특징 표현을 배우고 있습니다.

78
00:03:49,162 --> 00:03:52,245
추가 외부 레이블을 사용합니다.

79
00:03:53,471 --> 00:03:56,411
마지막으로 감독되지 않은 학습의 또 다른 사례

80
00:03:56,411 --> 00:03:59,585
이 경우에 우리는 밀도 추정입니다.

81
00:03:59,585 --> 00:04:02,884
데이터의 기본 분포를 추정합니다.

82
00:04:02,884 --> 00:04:05,581
예를 들어 여기에있는이 사례에서,

83
00:04:05,581 --> 00:04:08,432
우리는 1-d의 점수를 얻었고 시도 할 수 있습니다.

84
00:04:08,432 --> 00:04:10,811
이 밀도에 가우스를 맞추십시오.

85
00:04:10,811 --> 00:04:13,757
이 하단의 예제에서는 2D 데이터입니다.

86
00:04:13,757 --> 00:04:16,605
여기에서 우리는 밀도와 밀도를

87
00:04:16,605 --> 00:04:18,750
우리는이 밀도를 모델링 할 수 있습니다.

88
00:04:18,750 --> 00:04:20,988
우리는 밀도가 더 높도록 모델을 맞추기를 원합니다.

89
00:04:20,988 --> 00:04:24,239
더 많은 포인트가 집중되어 있습니다.

90
00:04:26,100 --> 00:04:29,377
그리고 감독받지 않은 사람들의 차이점을 요약하면

91
00:04:29,377 --> 00:04:32,069
우리가 지금까지 많이 보았던 학습,

92
00:04:32,069 --> 00:04:33,657
우리는 라벨 데이터를 사용하여 학습하고자합니다.

93
00:04:33,657 --> 00:04:35,990
X에서 Y 로의 함수 매핑

94
00:04:35,990 --> 00:04:38,515
우리가 라벨을 사용하지 않고 감독없이 학습하는 경우

95
00:04:38,515 --> 00:04:40,716
대신에 숨겨진 숨겨진 어떤 것을 배우려고 노력합니다.

96
00:04:40,716 --> 00:04:44,124
데이터의 구조, 그룹화 여부,

97
00:04:44,124 --> 00:04:48,291
변형 또는 기본 밀도 추정으로 작용합니다.

98
00:04:49,662 --> 00:04:51,855
그리고 자율 학습은 거대한 것입니다.

99
00:04:51,855 --> 00:04:54,113
그리고 정말 흥미 진진한 연구 및

100
00:04:54,113 --> 00:04:57,074
그리고 몇 가지 이유는 훈련 데이터가 실제로

101
00:04:57,074 --> 00:04:59,898
싸구려 레이블을 사용하지 않기 때문에 배울 수 있습니다.

102
00:04:59,898 --> 00:05:04,339
한 번에 많은 양의 데이터를 사용하고
기본적으로 많이 활용합니다.

103
00:05:04,339 --> 00:05:07,672
주석달라고하는 것보다 더 많은 데이터

104
00:05:07,672 --> 00:05:09,977
또는 데이터에 대한 레이블을 찾는 것.

105
00:05:09,977 --> 00:05:13,345
그리고 자율 학습은 여전히 상대적으로

106
00:05:13,345 --> 00:05:15,758
비교하여 미해결 된 연구 영역.

107
00:05:15,758 --> 00:05:17,823
이것에는 많은 열린 문제가 있습니다.

108
00:05:17,823 --> 00:05:20,483
그러나 그것 또한 잠재력을 지니고 있습니다.

109
00:05:20,483 --> 00:05:22,029
당신이 성공적으로 학습 할 수 있다면

110
00:05:22,029 --> 00:05:24,669
기본 구조를 많이 나타냅니다.

111
00:05:24,669 --> 00:05:26,434
데이터에서 이것은 또한 당신에게

112
00:05:26,434 --> 00:05:30,229
성배를 향해 먼 길을 이해하려고 애쓰다.

113
00:05:30,229 --> 00:05:32,729
시각적 세계의 구조.

114
00:05:35,026 --> 00:05:38,222
그래서 조금 높은 수준의 큰 그림입니다.

115
00:05:38,222 --> 00:05:40,432
무 감독 학습의 견해.

116
00:05:40,432 --> 00:05:44,155
그리고 오늘은 생성 모델에 좀더 집중할 것입니다.

117
00:05:44,155 --> 00:05:46,996
자율 학습을위한 모델의 클래스입니다

118
00:05:46,996 --> 00:05:50,369
우리의 목표가 시도하고 훈련 데이터가 주어진 곳에서 학습

119
00:05:50,369 --> 00:05:52,933
동일한 분포에서 새로운 샘플을 생성한다.

120
00:05:52,933 --> 00:05:55,441
맞아요, 그래서 여기에 훈련 데이터가 있습니다.

121
00:05:55,441 --> 00:05:57,686
일부 배포 P 데이터에서

122
00:05:57,686 --> 00:06:00,769
우리는 모델, P 모델을 배우고 싶다.

123
00:06:01,872 --> 00:06:04,955
같은 분포에서 샘플 생성하기

124
00:06:04,955 --> 00:06:09,854
우리는 P 모형과 유사한 P 모형을 배우기를 원합니다.

125
00:06:09,854 --> 00:06:12,636
생성 모델은 밀도 추정을 처리합니다.

126
00:06:12,636 --> 00:06:14,551
그래서 우리가 이전에 시도한이 문제는

127
00:06:14,551 --> 00:06:18,217
귀하의 기본 분포를

128
00:06:18,217 --> 00:06:20,093
핵심적인 문제인 훈련 자료

129
00:06:20,093 --> 00:06:22,180
무 감독 학습에서.

130
00:06:22,180 --> 00:06:25,190
그리고 이것의 몇 가지 맛이 있음을 알 수 있습니다.

131
00:06:25,190 --> 00:06:28,461
명시적인 밀도를 만들기 위해 생성
모델을 사용할 수 있습니다.

132
00:06:28,461 --> 00:06:31,270
우리가 명시 적으로 정의 할 추정

133
00:06:31,270 --> 00:06:33,353
우리의 P 모형을 풀어 라.

134
00:06:35,045 --> 00:06:37,610
또는 암시 적 밀도 추정을 할 수도 있습니다.

135
00:06:37,610 --> 00:06:40,868
이 경우 우리는 다음과 같은 모델을 배울 것입니다.

136
00:06:40,868 --> 00:06:45,035
명시 적으로 정의하지 않고 P
모델로부터 샘플을 생성합니다.

137
00:06:47,700 --> 00:06:50,016
그렇다면 왜 우리는 생성 모델에 관심이 있습니까?

138
00:06:50,016 --> 00:06:52,584
왜 이것이 정말 흥미로운 핵심 문제입니까?

139
00:06:52,584 --> 00:06:54,096
무 감독 학습에서?

140
00:06:54,096 --> 00:06:55,868
우리가 할 수있는 많은 것들이 있습니다.

141
00:06:55,868 --> 00:06:57,451
생성 모델.

142
00:06:57,451 --> 00:07:01,243
데이터로 현실적인 샘플을 만들 수 있다면

143
00:07:01,243 --> 00:07:03,826
우리가 정말 멋진 일을 할 수있는 배포판

144
00:07:03,826 --> 00:07:04,659
이걸로, 그렇지?

145
00:07:04,659 --> 00:07:07,143
시작할 때 아름다운 샘플을 생성 할 수 있습니다.

146
00:07:07,143 --> 00:07:11,334
왼쪽에는 완전히 새로운 샘플을 볼 수 있습니다.

147
00:07:11,334 --> 00:07:14,568
이 생성 모델에 의해 생성 된 것입니다.

148
00:07:14,568 --> 00:07:17,387
또한 센터의 여기에 생성 된 샘플

149
00:07:17,387 --> 00:07:21,042
이미지 우리는 또한 슈퍼 해상도,

150
00:07:21,042 --> 00:07:25,232
착색 때문에 이러한 경계가 환각되거나 채워진다.

151
00:07:25,232 --> 00:07:27,732
생성 된 색상 아이디어

152
00:07:30,078 --> 00:07:32,145
지갑이 어떻게 생겼는지.

153
00:07:32,145 --> 00:07:36,022
또한 시계열 데이터의 생성 모델을 사용할 수 있습니다.

154
00:07:36,022 --> 00:07:39,147
시뮬레이션 및 계획에 유용합니다.

155
00:07:39,147 --> 00:07:41,619
강화 학습 응용 프로그램

156
00:07:41,619 --> 00:07:43,558
우리는 보강 학습에 대해 더 이야기 할 것입니다.

157
00:07:43,558 --> 00:07:45,089
나중에 강의합니다.

158
00:07:45,089 --> 00:07:48,190
또한 생성 모델을 교육하면

159
00:07:48,190 --> 00:07:50,261
잠재 표현에 대한 추론.

160
00:07:50,261 --> 00:07:54,018
유용 할 수있는 잠복 기능 학습

161
00:07:54,018 --> 00:07:57,435
다운 스트림 작업을위한 일반적인 기능으로

162
00:07:59,059 --> 00:08:02,188
따라서 생성 모델의 유형을 살펴보면

163
00:08:02,188 --> 00:08:05,688
이것들은 여기의 택 소노 미로 조직 될 수있다.

164
00:08:05,688 --> 00:08:08,789
우리가 이야기 한이 두 가지 주요한 부분이있는 곳에,

165
00:08:08,789 --> 00:08:13,180
명시 적 밀도 모델 및 암시 적 밀도 모델.

166
00:08:13,180 --> 00:08:16,202
그리고 나서 우리는 또한 많은 사람들로 나눌 수 있습니다.

167
00:08:16,202 --> 00:08:19,062
이러한 다른 하위 범주 중

168
00:08:19,062 --> 00:08:23,423
그리고 우리는이 그림이 적용된 것을 참조 할 수 있습니다.

169
00:08:23,423 --> 00:08:27,814
Ian Goodfellow의 GAN에 대한 자습서에서

170
00:08:27,814 --> 00:08:29,713
그래서 당신이 어떤 것에 관심이 있다면

171
00:08:29,713 --> 00:08:32,501
이 분류법과 분류의

172
00:08:32,501 --> 00:08:35,749
생성 모델이 당신이 취할 수있는 좋은 자원입니다

173
00:08:35,749 --> 00:08:36,861
봐.

174
00:08:36,861 --> 00:08:39,052
그러나 오늘 우리는 가장 세 가지

175
00:08:39,052 --> 00:08:43,259
사용중인 생성 모델의 대중적인 유형

176
00:08:43,259 --> 00:08:45,645
그리고 오늘 연구에.

177
00:08:45,645 --> 00:08:49,475
그래서 우리는 먼저 pixelRNNs와
CNNs에 대해 간단히 이야기 할 것입니다.

178
00:08:49,475 --> 00:08:52,162
그리고 나서 우리는 변화하는 자동 인코딩
장치에 대해서 이야기 할 것입니다.

179
00:08:52,162 --> 00:08:55,661
이들은 모두 명시 적 밀도 모델 유형입니다.

180
00:08:55,661 --> 00:08:57,494
다루기 쉬운 밀도를 사용하는 사람

181
00:08:57,494 --> 00:09:01,312
근사 밀도를 사용하는 다른

182
00:09:01,312 --> 00:09:05,614
그리고 우리는 생성 적 적자 네트워크에
대해 이야기 할 것입니다.

183
00:09:05,614 --> 00:09:09,781
암시 적 밀도 추정의 한 유형 인 GAN.

184
00:09:12,152 --> 00:09:16,304
먼저 pixelRNN과 CNN에 대해 이야기 해 봅시다.

185
00:09:16,304 --> 00:09:20,015
그래서 이들은 완전히 가시적 인
믿음 네트워크의 한 유형입니다.

186
00:09:20,015 --> 00:09:22,432
명시 적으로 밀도를 모델링하는

187
00:09:22,432 --> 00:09:25,966
그래서이 경우 그들이하는 일은 우리가 가지고있는 것입니다.

188
00:09:25,966 --> 00:09:28,958
우리가 가지고 있고 우리가
모델링하고 싶은 이미지 데이터 X

189
00:09:28,958 --> 00:09:32,236
X의이 이미지 P의 확률 또는 가능성.

190
00:09:32,236 --> 00:09:34,941
이 경우 모델의 이러한 종류의 경우,

191
00:09:34,941 --> 00:09:37,646
이 우도를 분해하기 위해 체인 규칙을 사용합니다.

192
00:09:37,646 --> 00:09:40,384
1 차원 분포의 산물

193
00:09:40,384 --> 00:09:43,493
따라서 각 픽셀의 확률 X I

194
00:09:43,493 --> 00:09:47,871
이전의 모든 픽셀들 X1 내지 XI-1에 컨디셔닝된다.

195
00:09:47,871 --> 00:09:50,495
그리고 너의 가능성, 너의 공동 확률

196
00:09:50,495 --> 00:09:53,416
귀하의 이미지에있는 모든 픽셀의 제품이 될 것입니다

197
00:09:53,416 --> 00:09:55,474
이 모든 픽셀을 함께

198
00:09:55,474 --> 00:09:58,073
이 모든 가능성을 함께.

199
00:09:58,073 --> 00:10:00,690
그리고 나서 우리가이 우도를 정의하면,

200
00:10:00,690 --> 00:10:04,428
이 모델을 훈련시키기 위해서 우리는
단지 최대화 할 수 있습니다.

201
00:10:04,428 --> 00:10:06,688
우리의 훈련 데이터의 가능성

202
00:10:06,688 --> 00:10:08,938
이 정의 된 밀도 하에서.

203
00:10:10,980 --> 00:10:14,334
그래서 이것을 픽셀 값에 대한이 분포를 보면

204
00:10:14,334 --> 00:10:17,319
맞아,이 XI의 P는 이전의

205
00:10:17,319 --> 00:10:20,833
픽셀 값, 이것은 매우 복잡한 분포입니다.

206
00:10:20,833 --> 00:10:22,700
그럼 어떻게 모델링 할 수 있을까요?

207
00:10:22,700 --> 00:10:25,478
우리가 복잡해지기를 원한다면 그 전에 보았습니다.

208
00:10:25,478 --> 00:10:29,042
변환은 신경망을 사용하여 수행 할 수 있습니다.

209
00:10:29,042 --> 00:10:31,766
신경 네트워크는 복잡한 표현을위한 좋은 방법입니다.

210
00:10:31,766 --> 00:10:32,828
변형.

211
00:10:32,828 --> 00:10:36,189
그래서 우리가 할 일은 신경망을 사용하는 것입니다.

212
00:10:36,189 --> 00:10:40,633
우리가 가지고있는이 복잡한 기능을 표현하기 위해

213
00:10:40,633 --> 00:10:42,300
분포의.

214
00:10:43,235 --> 00:10:44,796
그리고 여러분이 여기에서 볼 수있는 한 가지는,

215
00:10:44,796 --> 00:10:47,379
우리가 이것을 위해 신경망을 사용할지라도

216
00:10:47,379 --> 00:10:50,379
우리가 돌봐야 할 또 다른 일은 우리가
어떻게 주문해야 하는가입니다.

217
00:10:50,379 --> 00:10:51,212
픽셀.

218
00:10:51,212 --> 00:10:54,009
맞아, 나는 여기에 우리가 배포판을 가지고 있다고 말했다.

219
00:10:54,009 --> 00:10:56,577
이전의 모든 픽셀이 주어진 XI의 P에 대해

220
00:10:56,577 --> 00:10:58,886
이전의 모든 픽셀은 무엇을 의미합니까?

221
00:10:58,886 --> 00:11:01,303
그래서 우리는 그것을 살펴볼 것입니다.

222
00:11:03,336 --> 00:11:06,669
그래서 PixelRNN은 2016 년에 제안 된 모델이었습니다.

223
00:11:07,595 --> 00:11:11,762
기본적으로 설정 및 최적화 방법을 정의합니다.

224
00:11:14,949 --> 00:11:17,657
이 문제와이 모델의 작동 방식은 다음과 같습니다.

225
00:11:17,657 --> 00:11:19,479
시작 픽셀을 생성하려고합니다.

226
00:11:19,479 --> 00:11:21,187
이미지의 구석에.

227
00:11:21,187 --> 00:11:25,767
그래서 우리는이 그리드를 기본적으로
픽셀로 볼 수 있습니다.

228
00:11:25,767 --> 00:11:28,039
우리가 할 일은 시작이다.

229
00:11:28,039 --> 00:11:31,050
왼쪽 상단의 픽셀에서

230
00:11:31,050 --> 00:11:34,548
그런 다음 픽셀을 기반으로 순차적으로 픽셀을 생성합니다.

231
00:11:34,548 --> 00:11:36,131
이 연결에서 화살

232
00:11:36,131 --> 00:11:37,195
여기에서 볼 수 있습니다.

233
00:11:37,195 --> 00:11:39,962
이전 픽셀의 각 종속성

234
00:11:39,962 --> 00:11:44,332
이 순서는 RNN을 사용하여 모델링됩니다.

235
00:11:44,332 --> 00:11:47,114
또는 더 구체적으로는 이전에 본 LSTM

236
00:11:47,114 --> 00:11:48,092
강의에서.

237
00:11:48,092 --> 00:11:51,385
이걸 사용하면 기본적으로 계속 움직일 수 있습니다.

238
00:11:51,385 --> 00:11:55,242
앞으로 내려가는 길은 대각선이다.

239
00:11:55,242 --> 00:11:57,860
이들 모든 픽셀 값을 생성하는 단계

240
00:11:57,860 --> 00:12:01,244
그들이 연결된 픽셀에.

241
00:12:01,244 --> 00:12:03,925
그리고 이것은 정말로 잘 작동하지만
여기에 단점이 있습니다.

242
00:12:03,925 --> 00:12:05,908
이 순차적 세대가, 바로,

243
00:12:05,908 --> 00:12:08,736
그래서 실제로 이렇게하는 것이 아주 느립니다.

244
00:12:08,736 --> 00:12:10,869
당신은 당신이 새로운 것을 생성하려고하는지
안다는 것을 상상할 수 있습니다.

245
00:12:10,869 --> 00:12:13,334
이러한 모든 피드 포워드 네트워크 대신

246
00:12:13,334 --> 00:12:15,061
CNN과 함께 보았습니다.

247
00:12:15,061 --> 00:12:16,952
여기서 우리는 반복적으로 진행해야 할 것입니다.

248
00:12:16,952 --> 00:12:20,952
이 모든 모든 픽셀을 생성합니다.

249
00:12:24,044 --> 00:12:27,499
조금 나중에, pixelRNN 다음에,

250
00:12:27,499 --> 00:12:30,575
pixelCNN이라는 또 다른 모델이 소개되었습니다.

251
00:12:30,575 --> 00:12:34,570
그리고 이것은 pixelCNN과 매우
비슷한 설정을 가지고 있습니다.

252
00:12:34,570 --> 00:12:36,887
우리는 여전히이 이미지 생성을 할 것입니다.

253
00:12:36,887 --> 00:12:39,801
이미지의 모서리에서 시작하여 확대

254
00:12:39,801 --> 00:12:43,074
바깥쪽에 있지만 차이점은 이제

255
00:12:43,074 --> 00:12:45,480
이러한 모든 종속성을 모델링하는 RNN

256
00:12:45,480 --> 00:12:47,752
우리는 대신 CNN을 사용할 것입니다.

257
00:12:47,752 --> 00:12:52,179
이제 우리는 컨텍스트 영역에서 CNN을 사용할 것입니다.

258
00:12:52,179 --> 00:12:54,761
특정 픽셀에서 주변을 볼 수 있습니다.

259
00:12:54,761 --> 00:12:56,384
우리가 지금 생성 할 것입니다.

260
00:12:56,384 --> 00:12:58,127
맞아요. 그래서 우리는 그것 주위에 픽셀을 가지고 있습니다.

261
00:12:58,127 --> 00:13:02,843
이미이 지역의이 회색 지역

262
00:13:02,843 --> 00:13:05,480
생성 된 다음 CNN을 통해 전달할 수 있습니다.

263
00:13:05,480 --> 00:13:09,313
이것을 사용하여 다음 픽셀 값을 생성하십시오.

264
00:13:11,041 --> 00:13:14,466
그리고 이것은 이것이 줄 것이 무엇이 줄 것인가입니다.

265
00:13:14,466 --> 00:13:18,055
CNN은 각 픽셀 위치의 신경망입니다.

266
00:13:18,055 --> 00:13:20,176
맞아요. 그리고 이것의 출력은 부드러워 질 것입니다.

267
00:13:20,176 --> 00:13:22,967
여기 픽셀 값의 최대 손실

268
00:13:22,967 --> 00:13:27,443
이 경우 우리는 0에서 255까지의 값을
가지며이 값을 훈련 할 수 있습니다.

269
00:13:27,443 --> 00:13:31,193
교육 이미지의 가능성을 극대화함으로써

270
00:13:31,193 --> 00:13:35,810
맞아요. 근본적으로 우리는 훈련을 원합니다.

271
00:13:35,810 --> 00:13:38,659
우리가이 생성 과정을 수행 할 이미지

272
00:13:38,659 --> 00:13:43,482
각 픽셀 위치에서 우리는 지상 진리를가집니다.

273
00:13:43,482 --> 00:13:45,742
우리가 여기있는 훈련 데이터 이미지 값

274
00:13:45,742 --> 00:13:48,541
기본적으로 빠른 라벨입니다.

275
00:13:48,541 --> 00:13:51,384
또는 우리가 원하는 분류 표

276
00:13:51,384 --> 00:13:53,976
우리의 픽셀은이 255 개의 값 중 어느 것인가?

277
00:13:53,976 --> 00:13:56,723
우리는 Softmax 손실을 사용하여
이것을 훈련시킬 수 있습니다.

278
00:13:56,723 --> 00:13:59,155
맞아요. 근본적으로 이렇게하는 것의 효과.

279
00:13:59,155 --> 00:14:01,285
우린 가능성을 극대화하려고합니다.

280
00:14:01,285 --> 00:14:05,597
우리의 훈련 데이터 픽셀이 생성됩니다.

281
00:14:05,597 --> 00:14:06,981
이것에 대해 질문이 있으십니까?

282
00:14:06,981 --> 00:14:08,413
예.

283
00:14:08,413 --> 00:14:12,159
[학생의 말은 마이크가 없어서 가려졌습니다.]

284
00:14:12,159 --> 00:14:14,117
그래, 문제는 우리가 말하고있는 줄 알았는데

285
00:14:14,117 --> 00:14:16,606
자율 학습에 대해서, 왜 우리는 기본적으로

286
00:14:16,606 --> 00:14:18,675
분류 레이블은 여기에 있니?

287
00:14:18,675 --> 00:14:22,833
그 이유는이 손실, 우리가 가진이 결과

288
00:14:22,833 --> 00:14:24,970
는 입력 된 학습 데이터의 값입니다.

289
00:14:24,970 --> 00:14:26,983
외부 레이블이 없으니까요?

290
00:14:26,983 --> 00:14:31,645
우리는 가서 레이블을 수동으로 수집해야했습니다.

291
00:14:31,645 --> 00:14:34,366
이를 위해 우리는 입력 데이터를 취하고 있습니다.

292
00:14:34,366 --> 00:14:38,533
이것이 우리가 마지막 기능을 위해
사용한 것이라고 말했습니다.

293
00:14:41,199 --> 00:14:45,366
[학생의 말은 마이크가 없어서 가려졌습니다.]

294
00:14:47,998 --> 00:14:50,746
문제는 이것이 단어의 가방과 같은가요?

295
00:14:50,746 --> 00:14:53,109
나는 그것이 정말로 단어의 가방이 아니다라고 말할 것이다.

296
00:14:53,109 --> 00:14:55,784
우리가 어디에서 출력하고 싶은지를 말하는 것이 더 낫다.

297
00:14:55,784 --> 00:14:58,724
각 위치의 픽셀 값에 대한 분포

298
00:14:58,724 --> 00:15:01,466
우리 이미지의 권리와 우리가하고 싶은 일

299
00:15:01,466 --> 00:15:06,444
우리는 입력의 가능성을 극대화하기를 원하며,

300
00:15:06,444 --> 00:15:10,442
우리의 훈련 데이터가 생성되고 생성됩니다.

301
00:15:10,442 --> 00:15:13,761
맞습니다. 그런 의미에서 이것이
우리의 의견을 사용하는 이유입니다.

302
00:15:13,761 --> 00:15:15,761
우리의 손실을 만들기위한 데이터.

303
00:15:21,006 --> 00:15:24,904
따라서 pixelCNN 교육을 사용하는
것이 pixelRNN보다 빠릅니다.

304
00:15:24,904 --> 00:15:28,275
왜냐하면 모든 픽셀 위치에서 바로 여기에 있기 때문입니다.

305
00:15:28,275 --> 00:15:31,249
우리는 우리의 가치를 극대화하기를 원합니다.

306
00:15:31,249 --> 00:15:34,301
우리는 우리의 훈련 데이터의 가능성을 극대화하고자합니다.

307
00:15:34,301 --> 00:15:38,035
보여 주므로 우리는 이미이 모든
가치를 이미 가지고 있습니다.

308
00:15:38,035 --> 00:15:40,739
우리의 훈련 데이터에서 나온 것입니다.

309
00:15:40,739 --> 00:15:44,340
우리가 원할 때 테스트 시간을위한 생성 시간은 빠르지 만

310
00:15:44,340 --> 00:15:47,296
완전히 새로운 이미지를 생성합니다. 바로 시작합니다.

311
00:15:47,296 --> 00:15:50,545
모퉁이와 우리는 아니며, 우리는
어떤 유형을하려고하지 않습니다.

312
00:15:50,545 --> 00:15:52,572
그래서 우리는 여전히 세대 시간에 학습

313
00:15:52,572 --> 00:15:56,609
이 픽셀 위치들 각각을 생성해야한다.

314
00:15:56,609 --> 00:15:59,197
다음 위치를 생성 할 수 있습니다.

315
00:15:59,197 --> 00:16:01,695
그리고 여기 세대 시간은 여전히 느립니다.

316
00:16:01,695 --> 00:16:03,025
교육 시간이 더 빠릅니다.

317
00:16:03,025 --> 00:16:04,204
문제.

318
00:16:04,204 --> 00:16:08,365
[학생의 말은 마이크가 없어서 가려졌습니다.]

319
00:16:08,365 --> 00:16:10,517
문제는이 교육이 민감한 것인가하는 것입니다.

320
00:16:10,517 --> 00:16:14,077
첫 번째 픽셀을 선택하는 데 배포?

321
00:16:14,077 --> 00:16:17,376
예, 당신이 처음에 가지고있는 것에 달려 있습니다.

322
00:16:17,376 --> 00:16:20,041
픽셀 분포 및 모든 조건부

323
00:16:20,041 --> 00:16:21,208
그걸 바탕으로

324
00:16:23,203 --> 00:16:26,667
다시 한번,이 배포판을 어떻게 선택합니까?

325
00:16:26,667 --> 00:16:29,428
그래서 훈련 시간에 당신은이 배포판을 가지고 있습니다.

326
00:16:29,428 --> 00:16:32,171
귀하의 교육 데이터에서 다음 생성 시간에

327
00:16:32,171 --> 00:16:35,305
유니폼으로 초기화 할 수 있습니다.

328
00:16:35,305 --> 00:16:38,368
또는 당신이 원하지만 당신의 훈련
데이터로부터 얻을 수 있습니다.

329
00:16:38,368 --> 00:16:40,612
그리고 나서 일단 다른 것들은 준비가되어 있습니다.

330
00:16:40,612 --> 00:16:42,553
그걸 바탕으로

331
00:16:42,553 --> 00:16:43,912
문제.

332
00:16:43,912 --> 00:16:48,079
[학생의 말은 마이크가 없어서 가려졌습니다.]

333
00:17:07,415 --> 00:17:09,761
그래, 질문은 우리가 정의하는 방법이있는 것입니다.

334
00:17:09,761 --> 00:17:12,469
예측하는 대신이 연쇄 규칙 방식으로

335
00:17:12,469 --> 00:17:14,146
한 번에 모든 픽셀?

336
00:17:14,146 --> 00:17:17,884
그리고 우리는 나중에 모델을 보게 될 것입니다.

337
00:17:17,884 --> 00:17:20,164
체인 규칙으로 우리가 할 수있는 것은 우리에게

338
00:17:20,164 --> 00:17:23,701
우리가 할 수있는 매우 조밀 한 밀도를 찾아야합니다.

339
00:17:23,701 --> 00:17:27,868
기본적으로 최적화하고 직접 가능성을 직접 최적화합니다.

340
00:17:31,864 --> 00:17:34,982
좋습니다. 이것들은 몇 세대의 예입니다.

341
00:17:34,982 --> 00:17:39,606
이 모델과 왼쪽에서 볼 수 있습니다.

342
00:17:39,606 --> 00:17:42,742
교육 자료가 CIFAR-10 인 세대,

343
00:17:42,742 --> 00:17:43,995
CIFAR-10 데이터 세트.

344
00:17:43,995 --> 00:17:46,115
그래서 당신은 일반적으로 그들이
시작하고 있음을 볼 수 있습니다.

345
00:17:46,115 --> 00:17:48,846
자연스러운 이미지의 통계를 캡처합니다.

346
00:17:48,846 --> 00:17:51,931
일반적인 유형의 얼룩을 볼 수 있습니다.

347
00:17:51,931 --> 00:17:55,879
자연스러운 이미지의 일부처럼 보입니다.

348
00:17:55,879 --> 00:17:56,848
나왔다.

349
00:17:56,848 --> 00:17:59,647
바로 여기 ImageNet입니다.
샘플을 다시 볼 수 있습니다.

350
00:17:59,647 --> 00:18:00,730
여기에서

351
00:18:03,022 --> 00:18:05,060
자연의 이미지처럼 보이기 시작합니다.

352
00:18:05,060 --> 00:18:09,966
그러나 그들은 여전히 개선의 여지가 남아 있습니다.

353
00:18:09,966 --> 00:18:12,634
분명히 차이가 있음을 아직도 볼 수 있습니다.

354
00:18:12,634 --> 00:18:15,226
지역 교육 이미지와 일부 의미론

355
00:18:15,226 --> 00:18:17,059
여기서 분명하지 않습니다.

356
00:18:19,371 --> 00:18:23,508
따라서이를 요약하기 위해
pixelRNN과 CNN을 사용하면

357
00:18:23,508 --> 00:18:27,020
X의 우도 P를 명시 적으로 계산할 수 있습니다.

358
00:18:27,020 --> 00:18:29,297
우리가 최적화 할 수있는 명시 밀도입니다.

359
00:18:29,297 --> 00:18:31,585
그리고 이것을 할 수 있다는
것도 또 다른 이점이 있습니다.

360
00:18:31,585 --> 00:18:34,043
좋은 평가 척도를 제공합니다.

361
00:18:34,043 --> 00:18:36,934
샘플이 얼마나 좋은지 측정 할 수 있습니다.

362
00:18:36,934 --> 00:18:40,958
당신이 계산할 수있는 데이터의 가능성에 의해.

363
00:18:40,958 --> 00:18:44,009
그리고 꽤 좋은 샘플을 생산할 수 있습니다.

364
00:18:44,009 --> 00:18:47,043
그러나 그것은 여전히 연구의 활발한 영역이다

365
00:18:47,043 --> 00:18:50,401
이 방법의 주된 단점은

366
00:18:50,401 --> 00:18:53,760
세대가 순차적이어서 매우 느릴 수 있습니다.

367
00:18:53,760 --> 00:18:56,534
그리고 이런 종류의 방법도 사용되었습니다.

368
00:18:56,534 --> 00:18:59,324
예를 들어 오디오를 생성하기위한 것이다.

369
00:18:59,324 --> 00:19:02,724
그리고 꽤 재미있는 예제를 온라인에서 볼 수 있습니다.

370
00:19:02,724 --> 00:19:05,460
이것의, 그러나 다시 단점은 그것이
오랜 시간이 걸린다는 것이다.

371
00:19:05,460 --> 00:19:08,170
이러한 샘플을 생성합니다.

372
00:19:08,170 --> 00:19:11,856
그래서 많은 일이 있었고, 그 이후로 일해 왔습니다.

373
00:19:11,856 --> 00:19:14,565
여전히 픽셀 CNN 성능 향상에

374
00:19:14,565 --> 00:19:17,964
건축물의 변화를 아는 모든 종류의 다른 것들

375
00:19:17,964 --> 00:19:20,641
이를 다르게 공식화하는 손실 함수를 추가하십시오.

376
00:19:20,641 --> 00:19:22,346
다양한 종류의 훈련 트릭에

377
00:19:22,346 --> 00:19:25,914
그리고 만약 당신이 이것에 대해
더 많은 것을 배우고 싶다면

378
00:19:25,914 --> 00:19:29,495
당신은 PixelCNN에서이 논문들을 볼 수 있습니다.

379
00:19:29,495 --> 00:19:33,115
그런 다음 다른 pixelCNN
더하기 더 나은 개선 된 버전

380
00:19:33,115 --> 00:19:35,115
올해에 나왔습니다.

381
00:19:37,455 --> 00:19:39,748
자 이제 우리는 다른 유형에 대해서 이야기 할 것입니다.

382
00:19:39,748 --> 00:19:44,321
생성 모델은 가변 자동 인코딩을 호출합니다.

383
00:19:44,321 --> 00:19:48,263
그리고 지금까지 우리는 pixelCNN이 다루기 쉬운

384
00:19:48,263 --> 00:19:52,204
밀도 함수, 오른쪽,이 정의를 사용하여

385
00:19:52,204 --> 00:19:55,365
이를 토대로 우리는 직접 최적화를 최적화 할 수 있습니다.

386
00:19:55,365 --> 00:19:58,365
훈련 데이터의 가능성.

387
00:19:59,419 --> 00:20:02,409
이제는 가변적 인 자동 인코딩을 사용하여

388
00:20:02,409 --> 00:20:04,195
다루기 힘든 밀도 함수.

389
00:20:04,195 --> 00:20:06,833
우리는 이제 이것을 잠정적 인
추가 모델로 모델링 할 것입니다.

390
00:20:06,833 --> 00:20:09,492
변수 Z와 더 자세히 얘기하겠습니다.

391
00:20:09,492 --> 00:20:10,769
어떻게 보이는지.

392
00:20:10,769 --> 00:20:14,936
그래서 우리의 데이터 가능성은 기본적으로 X의 P입니다.

393
00:20:16,257 --> 00:20:17,886
이 중요한 권리가 있어야합니다.

394
00:20:17,886 --> 00:20:21,422
가능한 모든 Z 값에 대한 기대치를 취한다.

395
00:20:21,422 --> 00:20:24,016
그래서 지금이 문제가 될 것입니다.

396
00:20:24,016 --> 00:20:26,909
우리는 이것을 직접 최적화 할
수 없음을 알게 될 것입니다.

397
00:20:26,909 --> 00:20:29,349
그래서 우리가해야 할 일은 우리가 파생해야한다는 것입니다.

398
00:20:29,349 --> 00:20:33,706
우도에 대한 하한을 대신 최적화 할 수 있습니다.

399
00:20:33,706 --> 00:20:34,956
그래, 질문.

400
00:20:35,864 --> 00:20:37,592
질문은 Z가 무엇인가하는 것입니다.

401
00:20:37,592 --> 00:20:41,195
Z는 잠재 변수이고 나는 이것을 통과 할 것입니다.

402
00:20:41,195 --> 00:20:42,862
훨씬 더 자세하게.

403
00:20:44,479 --> 00:20:48,538
먼저 배경에 대해 이야기 해 봅시다.

404
00:20:48,538 --> 00:20:52,071
변형 자동 인코딩은 유형과 관련이 있습니다.

405
00:20:52,071 --> 00:20:54,733
autoencoders라고 불리는 자율 학습 모델.

406
00:20:54,733 --> 00:20:58,267
자 이제 자동 인코딩 장치에
대해 조금 더 이야기하겠습니다.

407
00:20:58,267 --> 00:21:00,965
그리고 그들이 무엇인지 그리고 나는 어떻게 변이

408
00:21:00,965 --> 00:21:04,332
autoencoders는 관련이 있고 이것으로 만듭니다

409
00:21:04,332 --> 00:21:05,851
데이터를 생성 할 수 있습니다.

410
00:21:05,851 --> 00:21:09,168
따라서 자동 인코딩을 사용하면 데이터를
생성하는 데이 방법을 사용하지 않습니다.

411
00:21:09,168 --> 00:21:12,132
그러나 더 낮은 것을 배우기를위한 감독되지 않는 접근이다

412
00:21:12,132 --> 00:21:13,769
차원 특징 표현

413
00:21:13,769 --> 00:21:15,719
레이블이없는 교육 데이터로부터.

414
00:21:15,719 --> 00:21:18,399
좋습니다.이 경우 우리는 입력 데이터 X를가집니다.

415
00:21:18,399 --> 00:21:20,300
우리는 몇 가지 기능을 배우기를 원할 것입니다.

416
00:21:20,300 --> 00:21:21,550
우리는 Z라고 부릅니다.

417
00:21:22,541 --> 00:21:25,708
그리고 우리는 매핑이 될 인코더를 갖게 될 것입니다.

418
00:21:25,708 --> 00:21:28,188
이 입력 데이터로부터 함수 매핑

419
00:21:28,188 --> 00:21:29,605
우리의 특징 Z에.

420
00:21:30,911 --> 00:21:33,905
그리고이 엔코더는 여러 가지
다른 형태를 가질 수 있습니다.

421
00:21:33,905 --> 00:21:37,070
그들은 일반적으로 원래 신경망을 사용할 것입니다.

422
00:21:37,070 --> 00:21:38,981
이 모델들은 주변에 있었고, 자동 인코딩 장치들은

423
00:21:38,981 --> 00:21:41,239
오랫동안 주위에.

424
00:21:41,239 --> 00:21:45,803
그래서 2000 년대에는 비선형
성의 선형 레이어를 사용했습니다.

425
00:21:45,803 --> 00:21:49,650
나중에 우리는 더 깊은 네트워크를 완전히 연결했습니다.

426
00:21:49,650 --> 00:21:53,556
그 다음에는 CNN을 사용하여

427
00:21:53,556 --> 00:21:54,389
인코더.

428
00:21:55,385 --> 00:21:59,995
그래서 우리는 입력 데이터 X를
취한 다음 이것을 매핑합니다.

429
00:21:59,995 --> 00:22:01,351
어떤 특징 Z에.

430
00:22:01,351 --> 00:22:05,249
그리고 Z는 대개 다음과 같습니다.
우리는 일반적으로 이것을 지정합니다.

431
00:22:05,249 --> 00:22:09,138
X보다 작고 기본적으로 차원을 수행합니다.

432
00:22:09,138 --> 00:22:11,817
감소 때문입니다.

433
00:22:11,817 --> 00:22:16,189
그래서 우리가 왜하고 싶은지에 대한 생각을 가진 사람

434
00:22:16,189 --> 00:22:17,729
여기의 차원 감소?

435
00:22:17,729 --> 00:22:20,896
왜 우리는 Z가 X보다 작기를 원합니까?

436
00:22:22,114 --> 00:22:23,415
네.

437
00:22:23,415 --> 00:22:25,497
[학생의 말은 마이크가 없어서 가려졌습니다.]

438
00:22:25,497 --> 00:22:28,074
그래서 내가 들었던 대답은 Z가
가장 대표적인 것이 었습니다.

439
00:22:28,074 --> 00:22:31,657
X의 중요한 기능은 정확합니다.

440
00:22:32,634 --> 00:22:36,517
따라서 Z가 캡처 할 수있는 기능을
학습 할 수 있기를 바랍니다.

441
00:22:36,517 --> 00:22:38,758
의미있는 데이터 변동 요인

442
00:22:38,758 --> 00:22:41,758
맞아요.이게 그들에게 좋은 특징이됩니다.

443
00:22:42,833 --> 00:22:46,717
그렇다면이 피쳐 표현을 어떻게 배울 수 있습니까?

444
00:22:46,717 --> 00:22:50,570
자, 자동 엔코더가하는 일은 우리가 훈련하는 것입니다.

445
00:22:50,570 --> 00:22:54,513
모델은 그러한 특징들이 재구성하는데 사용될 수있다.

446
00:22:54,513 --> 00:22:55,944
우리의 원래 데이터.

447
00:22:55,944 --> 00:22:59,563
우리가 원하는 것은 입력 데이터를 사용하는 것입니다.

448
00:22:59,563 --> 00:23:03,730
그것을 일부 저 차원 피처 Z에 매핑하는 인코더.

449
00:23:05,320 --> 00:23:06,926
이것은 인코더 네트워크의 출력이며,

450
00:23:06,926 --> 00:23:09,178
우리는 이러한 기능을 사용할 수 있기를 원합니다.

451
00:23:09,178 --> 00:23:13,125
이 입력 데이터를 기반으로 생성
된 다음 디코더를 사용합니다.

452
00:23:13,125 --> 00:23:16,554
두 번째 네트워크와 지금 뭔가를 출력 할 수 있습니다.

453
00:23:16,554 --> 00:23:21,466
X와 동일한 크기 차원의

454
00:23:21,466 --> 00:23:24,032
X 오른쪽으로 이동하여 원본을
재구성 할 수 있기를 바랍니다.

455
00:23:24,032 --> 00:23:24,865
데이터.

456
00:23:26,387 --> 00:23:31,228
그리고 디코더에 대해서는 기본적으로
동일한 유형을 사용합니다.

457
00:23:31,228 --> 00:23:33,375
인코더로서의 네트워크는 일반적으로 조금 있습니다.

458
00:23:33,375 --> 00:23:37,083
대칭형이어서 이제 CNN 네트워크를 사용할 수 있습니다.

459
00:23:37,083 --> 00:23:38,583
이들 대부분의 경우.

460
00:23:41,675 --> 00:23:44,145
좋아, 그 과정은 우리가 취할 것입니다.

461
00:23:44,145 --> 00:23:48,720
입력 데이터를 인코더를 통해 먼저 전달

462
00:23:48,720 --> 00:23:51,045
예를 들어 4 층과 같은 무언가가 될 것입니다.

463
00:23:51,045 --> 00:23:53,996
컨볼 루션 네트워크 (convolutional network)를
만들고 나서 우리는 그것을 통과시킬 것입니다.

464
00:23:53,996 --> 00:23:56,698
이러한 기능을 얻은 다음이를 통과 시키십시오.

465
00:23:56,698 --> 00:24:00,323
예를 들어, 상층 컨벌루션 인 4 개의 계층 인 디코더

466
00:24:00,323 --> 00:24:03,314
네트워크에 연결 한 다음 마지막에
재구성 된 데이터를 가져옵니다.

467
00:24:03,314 --> 00:24:04,196
이의.

468
00:24:04,196 --> 00:24:07,447
우리가 왜곡 된 네트워크를 가지고있는 바로 그 이유로

469
00:24:07,447 --> 00:24:09,659
인코더 및 상 컨버전
(upconvolutional) 네트워크

470
00:24:09,659 --> 00:24:14,409
왜냐하면 인코더에서 우리는 기본적으로

471
00:24:14,409 --> 00:24:16,890
이 높은 차원의 입력에서이 낮은 차원으로 가져 가라.

472
00:24:16,890 --> 00:24:20,394
우리는 다른 차원으로 가고 싶다.

473
00:24:20,394 --> 00:24:22,810
우리의 낮은 차원의 기능에서 우리의

474
00:24:22,810 --> 00:24:25,893
고 차원 재구성 입력.

475
00:24:28,906 --> 00:24:33,248
그래서 우리가 원했던 효과를 얻기 위해서

476
00:24:33,248 --> 00:24:36,602
입력 데이터를 재구성 할 수 있기 전에

477
00:24:36,602 --> 00:24:39,071
우리는 L2 손실 기능과 같은 것을 사용할 것입니다.

478
00:24:39,071 --> 00:24:42,220
기본적으로 내 픽셀을 만들어 보겠습니다.

479
00:24:42,220 --> 00:24:44,764
내 입력 데이터의 크기가 my,

480
00:24:44,764 --> 00:24:46,723
내 재구성 된 데이터의 내 픽셀이 동일해야합니다.

481
00:24:46,723 --> 00:24:49,306
내 입력 데이터의 픽셀로

482
00:24:51,078 --> 00:24:53,032
여기서 주목해야 할 중요한 점은,

483
00:24:53,032 --> 00:24:55,147
이것은 우리가 전에 가지고 있었던 질문으로 돌아갑니다.

484
00:24:55,147 --> 00:24:58,599
비록 우리가이 손실 함수를 가지고 있다고해도,

485
00:24:58,599 --> 00:25:01,431
사용할 수있는 외부 라벨이 없습니다.

486
00:25:01,431 --> 00:25:02,515
이 훈련에.

487
00:25:02,515 --> 00:25:06,337
우리가 가지고있는 것은 훈련 데이터입니다.

488
00:25:06,337 --> 00:25:09,361
둘 다 네트워크를 통과하고 컴퓨팅 할 수 있어야합니다.

489
00:25:09,361 --> 00:25:10,861
우리의 손실 함수.

490
00:25:13,346 --> 00:25:17,082
그래서 우리는이 모델을 훈련 한
후에 이것을 가지고 있습니다.

491
00:25:17,082 --> 00:25:19,021
우리가 할 수있는 일은이 디코더를
버릴 수 있다는 것입니다.

492
00:25:19,021 --> 00:25:22,627
이 모든 것은 우리를 생산할 수있을만큼
너무 많이 사용되었습니다.

493
00:25:22,627 --> 00:25:24,937
재건 입력과 우리의 손실을 계산할 수 있어야한다.

494
00:25:24,937 --> 00:25:26,108
기능.

495
00:25:26,108 --> 00:25:29,526
그리고 우리가 만든 엔코더를 사용할 수 있습니다.

496
00:25:29,526 --> 00:25:32,960
기능 매핑을 사용하여이를 초기화 할 수 있습니다.

497
00:25:32,960 --> 00:25:34,819
감독 된 모델.

498
00:25:34,819 --> 00:25:37,647
맞습니다. 예를 들어 이제이 입력으로부터 갈 수 있습니다.

499
00:25:37,647 --> 00:25:42,447
우리의 기능에 추가 분류기를 추가하십시오.

500
00:25:42,447 --> 00:25:45,773
우리가 출력에 사용할 수있는 네트워크

501
00:25:45,773 --> 00:25:49,901
분류 문제 예를 들어 클래스 레이블

502
00:25:49,901 --> 00:25:52,808
우리는 여기에서 외부 레이블을 가질 수 있습니다.

503
00:25:52,808 --> 00:25:55,601
Softmax와 같은 표준 손실 기능을 사용하십시오.

504
00:25:55,601 --> 00:25:58,157
그리고 이것의 가치는 우리가 기본적으로
할 수 있었다는 것입니다.

505
00:25:58,157 --> 00:26:01,046
시도하고 배우기 위해 레이블이없는
많은 훈련 데이터를 사용하는 것

506
00:26:01,046 --> 00:26:04,449
좋은 일반적인 특징 표현.

507
00:26:04,449 --> 00:26:08,107
좋습니다, 이제 우리는 이것을 사용하여
감독자를 초기화 할 수 있습니다.

508
00:26:08,107 --> 00:26:10,834
때로는 너무 많은 데이터가없는 학습 문제

509
00:26:10,834 --> 00:26:12,363
우리는 단지 작은 데이터만을 가지고 있습니다.

510
00:26:12,363 --> 00:26:16,363
우리는 이전의 숙제와 수업에서 보았습니다.

511
00:26:17,336 --> 00:26:19,697
작은 데이터로는 모델을 배우기가 어렵습니다. 맞습니까?

512
00:26:19,697 --> 00:26:22,563
너는 피팅과 모든 종류의 문제를 가질 수있다.

513
00:26:22,563 --> 00:26:25,790
따라서 모델을 먼저 초기화 할 수 있습니다.

514
00:26:25,790 --> 00:26:27,540
더 나은 기능.

515
00:26:31,371 --> 00:26:34,489
자, 오토 엔코더가 재구성 할 수있는 것을 보았습니다.

516
00:26:34,489 --> 00:26:38,518
데이터를 저장하고 결과적으로 기능을 학습 할 수 있습니다.

517
00:26:38,518 --> 00:26:41,243
초기화하려면 감독자를 초기화하는 데 사용할 수 있습니다.

518
00:26:41,243 --> 00:26:42,329
모델.

519
00:26:42,329 --> 00:26:44,453
그리고 우리가 배운 이러한 기능들을 보았습니다.

520
00:26:44,453 --> 00:26:47,474
요인을 포착 할 수있는 직감을 가졌다.

521
00:26:47,474 --> 00:26:50,133
훈련 데이터의 변화.

522
00:26:50,133 --> 00:26:53,262
알았어 이런 직관에 기초해서

523
00:26:53,262 --> 00:26:56,953
우리는이 잠재 된이 벡터 Z를 가질 수 있습니다.

524
00:26:56,953 --> 00:26:58,941
교육 자료의 변동 요인

525
00:26:58,941 --> 00:27:02,290
이제 자연스러운 질문은 우리가 비슷한
유형을 사용할 수 있을까요?

526
00:27:02,290 --> 00:27:04,957
새 이미지를 생성하는 설치 프로그램?

527
00:27:06,922 --> 00:27:09,502
이제는 변화하는 자동 인코딩 장치에
대해 이야기 할 것입니다.

528
00:27:09,502 --> 00:27:11,828
autoencoders에서
probabillstic 스핀을 사용하면

529
00:27:11,828 --> 00:27:15,987
새 데이터를 생성하기 위해 모델에서 샘플을 추출합니다.

530
00:27:15,987 --> 00:27:19,404
autoencoders에 대한 질문이 있으십니까?

531
00:27:20,796 --> 00:27:22,828
좋아, 그래서 변화하는 자동 인코딩 장치.

532
00:27:22,828 --> 00:27:26,414
좋아, 여기 우리는 우리의 훈련 데이터

533
00:27:26,414 --> 00:27:28,914
우리는 1부터 N까지 X I를 가졌다.

534
00:27:30,255 --> 00:27:32,751
일부 근본적인, 관찰되지 않은

535
00:27:32,751 --> 00:27:34,812
잠재 표현 Z.

536
00:27:34,812 --> 00:27:38,357
맞아, 그래서 Z가 어떤 직관 이니.

537
00:27:38,357 --> 00:27:41,891
Z의 어느 요소가 얼마나 작은 것을 포착하고 있는지

538
00:27:41,891 --> 00:27:45,319
또는 우리가 가지고있는 변동 요인의 정도

539
00:27:45,319 --> 00:27:47,069
우리의 훈련 데이터에서.

540
00:27:48,491 --> 00:27:51,118
맞아 직감이 그렇게 될지도 몰라.

541
00:27:51,118 --> 00:27:52,971
다른 종류의 속성과 같아야합니다.

542
00:27:52,971 --> 00:27:54,811
우리가 얼굴을 생성하려고한다고 가정 해 보겠습니다.

543
00:27:54,811 --> 00:27:57,791
얼마나 많은 미소가 얼굴에있을 수 있습니다,

544
00:27:57,791 --> 00:28:00,236
그것은 눈썹 머리카락의 위치 수 있습니다.

545
00:28:00,236 --> 00:28:02,608
머리의 방향.

546
00:28:02,608 --> 00:28:07,270
이것들은 잠재적 인 잠재 요인들 전부입니다

547
00:28:07,270 --> 00:28:08,772
그것은 배울 수 있습니다.

548
00:28:08,772 --> 00:28:11,282
맞습니다. 그래서 우리 세대의 과정은 우리가

549
00:28:11,282 --> 00:28:13,901
이전의 Z부터의 샘플.

550
00:28:13,901 --> 00:28:17,299
이러한 속성들 각각에 대해 예를 들어,

551
00:28:17,299 --> 00:28:19,202
있잖아, 얼마나 웃고 있니?

552
00:28:19,202 --> 00:28:22,172
우리는 어떤 종류의 분포

553
00:28:22,172 --> 00:28:25,014
우리는 이것이 그렇게해야한다고 생각합니다.

554
00:28:25,014 --> 00:28:28,035
가우스는 자연적인 이전의 어떤 것입니다

555
00:28:28,035 --> 00:28:31,571
Z의 각 요소에 대해 사용할 수있는

556
00:28:31,571 --> 00:28:34,345
그리고 우리는 우리의 데이터 X를 생성하려고합니다.

557
00:28:34,345 --> 00:28:38,416
조건부, 조건부 분포로부터 샘플링함으로써

558
00:28:38,416 --> 00:28:40,140
주어진 Z의 P

559
00:28:40,140 --> 00:28:43,019
그래서 우리는 먼저 Z를 샘플링하고,
이들 각각에 대한 값을 샘플링합니다

560
00:28:43,019 --> 00:28:46,112
잠복 한 요소들을

561
00:28:46,112 --> 00:28:48,862
여기에서 우리의 이미지 X를 샘플링하십시오.

562
00:28:51,409 --> 00:28:54,665
그리고이 생성 과정의 진정한 매개 변수들

563
00:28:54,665 --> 00:28:57,667
theta, theta star right입니까?

564
00:28:57,667 --> 00:28:59,961
그래서 우리는 이전의 매개 변수를 가지고 있습니다.

565
00:28:59,961 --> 00:29:03,158
우리의 조건부 분포

566
00:29:03,158 --> 00:29:06,102
우리가하고 싶은 일은 생식력을 가지기 위해서입니다.

567
00:29:06,102 --> 00:29:07,560
모델은 새로운 데이터를 생성 할 수 있어야한다.

568
00:29:07,560 --> 00:29:11,727
우리는 우리의 실제 매개 변수에 대한
이러한 매개 변수를 추정하려고합니다.

569
00:29:14,790 --> 00:29:16,694
자, 이제 우리가 어떻게 대처해야하는지에
대해 먼저 이야기 해 봅시다.

570
00:29:16,694 --> 00:29:17,611
이 모델.

571
00:29:20,282 --> 00:29:22,252
좋아요, 그래서 우리가이 발전기에 대한 모델을 가지면

572
00:29:22,252 --> 00:29:25,021
프로세스, 잘 우리는 전에 우리가 선택할 수 있다고 말했다

573
00:29:25,021 --> 00:29:27,317
우리의 이전 P는 단순한 것입니다.

574
00:29:27,317 --> 00:29:28,919
가우스처럼 뭔가?

575
00:29:28,919 --> 00:29:30,880
그리고 이것은 합리적인 선택입니다.

576
00:29:30,880 --> 00:29:32,713
잠복 속성.

577
00:29:35,696 --> 00:29:39,260
이제 우리의 조건부 분포 P에 대해 주어진 X의 P

578
00:29:39,260 --> 00:29:40,840
이것은 훨씬 더 복잡합니다.

579
00:29:40,840 --> 00:29:43,410
왜냐하면 이미지를 생성하기 위해
이것을 사용해야하기 때문입니다.

580
00:29:43,410 --> 00:29:46,918
그래서 주어진 Z의 P에 대해서,
이전에 우리가 보았던 것처럼,

581
00:29:46,918 --> 00:29:49,395
우리가 원하는 복잡한 기능이있을 때

582
00:29:49,395 --> 00:29:53,062
표현하기 위해 우리는 이것을
신경망으로 나타낼 수 있습니다.

583
00:29:53,062 --> 00:29:55,176
그래서 그것은 시도하고 모델을
시도하는 자연스러운 선택입니다.

584
00:29:55,176 --> 00:29:58,259
신경망으로 주어진 Z의 P.

585
00:30:00,308 --> 00:30:02,345
그리고 우리는 이것을 디코더 네트워크라고 부를 것입니다.

586
00:30:02,345 --> 00:30:04,756
맞아요, 그래서 우리는 잠복 할 생각을하려고합니다.

587
00:30:04,756 --> 00:30:08,327
표현과 이미지로 디코딩하려고

588
00:30:08,327 --> 00:30:10,167
그것은 지정하고있다.

589
00:30:10,167 --> 00:30:13,765
이제 우리는이 모델을 어떻게 훈련시킬 수 있습니까?

590
00:30:13,765 --> 00:30:15,699
우리는이 모델을 훈련 할 수 있기를 바랍니다.

591
00:30:15,699 --> 00:30:19,419
이 매개 변수의 추정치를 배웁니다.

592
00:30:19,419 --> 00:30:21,985
따라서 우리가 생성적인 훈련으로부터
우리의 전략을 기억한다면

593
00:30:21,985 --> 00:30:24,668
모델은 완전히 가시적 인 믿음 네트워크이며,

594
00:30:24,668 --> 00:30:26,668
우리의 pixelRNNs와 CNNs,

595
00:30:28,577 --> 00:30:30,492
간단하고 자연스러운 전략은

596
00:30:30,492 --> 00:30:33,809
극대화하기 위해 이러한 모델 매개 변수를 배우십시오.

597
00:30:33,809 --> 00:30:35,498
훈련 데이터의 가능성.

598
00:30:35,498 --> 00:30:36,850
맞아, 우리는 이전에이 경우에,

599
00:30:36,850 --> 00:30:39,346
잠정적 변수 Z를 사용하면

600
00:30:39,346 --> 00:30:42,771
가능한 모든 것에 기대를 걸고 X의 P를 써라.

601
00:30:42,771 --> 00:30:45,311
Z의 값은 연속적이므로 우리는 이것을 얻습니다.

602
00:30:45,311 --> 00:30:46,886
여기 표현.

603
00:30:46,886 --> 00:30:49,884
바로 지금 우리는이 잠복 된 Z

604
00:30:49,884 --> 00:30:53,658
그리고 지금 우리가 가려고한다면,
당신이 시도하고 최대화하고 싶다면

605
00:30:53,658 --> 00:30:55,759
그 가능성, 그럼 뭐가 문제 야?

606
00:30:55,759 --> 00:30:59,301
우리는 이것을 가지고 그라디언트를
취하고 최대화 할 수 있습니까?

607
00:30:59,301 --> 00:31:01,372
이 가능성?

608
00:31:01,372 --> 00:31:04,358
[학생의 말은 마이크가 없어서 가려졌습니다.]

609
00:31:04,358 --> 00:31:07,274
맞습니다. 그래서이 통합은 다루기가 쉽지 않을 것입니다.

610
00:31:07,274 --> 00:31:08,524
맞아요.

611
00:31:10,199 --> 00:31:12,547
이제 좀 더 자세하게 살펴 보겠습니다.

612
00:31:12,547 --> 00:31:15,911
맞아, 여기에 우리의 데이터 우도 용어가 있습니다.

613
00:31:15,911 --> 00:31:18,772
그리고 처음으로 Z of P입니다.

614
00:31:18,772 --> 00:31:20,921
그리고 우리는 앞서 이미 말했고,
우리는 이것을 선택할 수 있습니다.

615
00:31:20,921 --> 00:31:24,847
이전의 간단한 Gaussian이기 때문에 괜찮습니다.

616
00:31:24,847 --> 00:31:26,532
주어진 Z의 P, 우리는 우리가 가고 있다고 말했습니다.

617
00:31:26,532 --> 00:31:29,031
디코더 신경망을 지정합니다.

618
00:31:29,031 --> 00:31:32,774
어떤 Z가 주어지면 여기에서 Z를
주어진 X의 P를 얻을 수 있습니다.

619
00:31:32,774 --> 00:31:35,721
그것은 우리 신경 네트워크의 출력입니다.

620
00:31:35,721 --> 00:31:38,147
그렇다면 여기에 어떤 문제가 있습니까?

621
00:31:38,147 --> 00:31:42,450
좋아, 이건 다른 불행한 얼굴 인거야.

622
00:31:42,450 --> 00:31:44,495
하지만 어떻게 든 나는 무슨 일이 일어 났는지 모르겠다.

623
00:31:44,495 --> 00:31:45,518
번역 과정에서,

624
00:31:45,518 --> 00:31:48,435
그것은 우는 검은 유령으로 변했다.

625
00:31:49,298 --> 00:31:53,465
그러나 이것이 상징하는 것은 기본적으로 우리가 원한다면

626
00:31:54,393 --> 00:31:55,855
주어진 Z의 P를 계산하는

627
00:31:55,855 --> 00:31:59,519
모든 Z에 대해 이것은 이제 다루기가 어렵습니다.

628
00:31:59,519 --> 00:32:02,186
우리는이 적분을 계산할 수 없습니다.

629
00:32:04,794 --> 00:32:06,591
따라서 데이터 가능성은 다루기가 어렵습니다.

630
00:32:06,591 --> 00:32:10,486
다른 용어를 보면

631
00:32:10,486 --> 00:32:12,901
이 모델에서 우리의 후부 밀도를 보면,

632
00:32:12,901 --> 00:32:15,818
그래서 주어진 X의 후부의 P는 X,

633
00:32:16,921 --> 00:32:19,639
그러면 이것은 주어진 Z의 P가 될 것입니다.

634
00:32:19,639 --> 00:32:23,712
베이 즈 규칙에 의한 X의 P에 대한 Z의 P 배

635
00:32:23,712 --> 00:32:25,740
그리고 이것은 또한 다루기 어려울 것입니다.

636
00:32:25,740 --> 00:32:28,230
주어진 X의 P는 Z이고, Z의 P는 괜찮습니다.

637
00:32:28,230 --> 00:32:31,476
그러나 우리는이 X의 가능성을 가지고 있습니다.

638
00:32:31,476 --> 00:32:35,143
그것은 통합 성을 가지고 있으며 다루기가 어렵다.

639
00:32:36,027 --> 00:32:37,993
그래서 우리는 이것을 직접 최적화 할 수 없습니다.

640
00:32:37,993 --> 00:32:40,493
그러나 우리는 그 해결책을 볼 것입니다,

641
00:32:42,463 --> 00:32:45,230
이 모델을 배울 수있는 솔루션

642
00:32:45,230 --> 00:32:48,153
디코더 네트워크를 사용하는 것 외에

643
00:32:48,153 --> 00:32:50,997
Z를 주어진 X의 P를 모델링하기
위해이 신경망을 정의한다.

644
00:32:50,997 --> 00:32:54,824
이제 추가 인코더 네트워크를 정의하면

645
00:32:54,824 --> 00:32:57,887
주어진 X의 Q, 우리는 이것을 엔코더라고 부릅니다.

646
00:32:57,887 --> 00:33:01,776
왜냐하면 우리는 입력 X를로 변환하기를 원하기 때문에,

647
00:33:01,776 --> 00:33:04,414
주어진 X의 확률을 X,

648
00:33:04,414 --> 00:33:06,652
이것을 Z로 인코딩 할 것입니다.

649
00:33:06,652 --> 00:33:08,746
그리고이 네트워크를 대략적으로 정의했습니다.

650
00:33:08,746 --> 00:33:10,329
주어진 X의 P.

651
00:33:12,388 --> 00:33:14,517
오른쪽 이것은 나중에 밀도 용어였습니다.

652
00:33:14,517 --> 00:33:15,688
다루기 힘든.

653
00:33:15,688 --> 00:33:20,396
우리가이 추가 네트워크를 사용하여 이것을 근사하면

654
00:33:20,396 --> 00:33:22,866
그러면 이것이 실제로 우리가 파생시킬
수 있음을 알게 될 것입니다.

655
00:33:22,866 --> 00:33:25,319
다루기 쉬운 데이터 우도에 대한 하한

656
00:33:25,319 --> 00:33:27,486
우리는 최적화 할 수 있습니다.

657
00:33:29,308 --> 00:33:31,229
좋아, 우선 조금 더 구체적으로 설명하자.

658
00:33:31,229 --> 00:33:35,396
내가 지정한 이러한 인코더 및 디코더 네트워크,

659
00:33:36,579 --> 00:33:39,156
우리는 확률론적인 모델을 원하는 가변 자동 엔코더에서

660
00:33:39,156 --> 00:33:40,695
데이터 생성.

661
00:33:40,695 --> 00:33:42,334
따라서 자동 인코딩에서 우리는 이미 이야기했습니다.

662
00:33:42,334 --> 00:33:45,647
인코더가 입력 X에서 시작하는 개념에 대해

663
00:33:45,647 --> 00:33:49,447
일부 기능 Z 및 Z에서 디코더 네트워크로 이동

664
00:33:49,447 --> 00:33:51,530
일부 이미지 X로 되돌아갑니다.

665
00:33:53,294 --> 00:33:55,927
여기 엔 엔코더 네트워크가 있습니다.

666
00:33:55,927 --> 00:33:57,462
디코더 네트워크가 있지만 우리는 가고있다.

667
00:33:57,462 --> 00:33:58,907
이를 확률 론적으로 만든다.

668
00:33:58,907 --> 00:34:02,433
이제 Z의 X의 엔코더 네트워크 Q는 다음과 같습니다.

669
00:34:02,433 --> 00:34:06,134
매개 변수 phi는 평균을 출력합니다.

670
00:34:06,134 --> 00:34:09,467
대각선 공분산과 여기에서,

671
00:34:11,411 --> 00:34:13,433
이것은 인코더의 직접 출력입니다.

672
00:34:13,434 --> 00:34:14,795
네트워크 및 우리와 동일한

673
00:34:14,795 --> 00:34:17,637
Z에서 시작할 디코더 네트워크

674
00:34:17,637 --> 00:34:19,600
이제 평균을 출력 할 것입니다.

675
00:34:19,600 --> 00:34:23,109
일부 X의 대각 공분산,

676
00:34:23,109 --> 00:34:26,725
주어진 입력과 동일한 차원

677
00:34:26,725 --> 00:34:28,645
그런 다음이 디코더 네트워크에는 다른 매개 변수가 있습니다

678
00:34:28,645 --> 00:34:29,478
세타.

679
00:34:31,136 --> 00:34:35,053
그리고 지금 우리 Z와 우리를 실제로 얻으려면,

680
00:34:36,494 --> 00:34:40,436
이것은 주어진 Z이며, 주어진 Z는 X와 X이다.

681
00:34:40,436 --> 00:34:42,058
우리는이 배포판에서 샘플을 제공 할 것입니다.

682
00:34:42,058 --> 00:34:44,387
이제 인코더와 디코더 네트워크

683
00:34:44,387 --> 00:34:49,072
Z와 X 각각에 대한 분포를 생성하고있다.

684
00:34:49,072 --> 00:34:50,706
이 분포에서 샘플을 얻습니다.

685
00:34:50,706 --> 00:34:52,409
여기에서 가치를 얻으려면

686
00:34:52,409 --> 00:34:54,641
그래서 당신은 이것이 우리를 방향으로
어떻게 이끌고 있는지를 알 수 있습니다.

687
00:34:54,641 --> 00:34:59,630
새로운 데이터를 샘플링하고 생성 할 수있게되었습니다.

688
00:34:59,630 --> 00:35:00,983
그리고 주목할 사실 중 하나는

689
00:35:00,983 --> 00:35:02,855
이들 인코더 및 디코더 네트워크,

690
00:35:02,855 --> 00:35:05,041
당신은 또한 그들에 대한 다른 용어를 듣게됩니다.

691
00:35:05,041 --> 00:35:07,944
엔코더 네트워크는 인식의 종류가 될 수도 있습니다

692
00:35:07,944 --> 00:35:09,138
또는 추론 네트워크

693
00:35:09,138 --> 00:35:12,888
우리는이 잠정적 추론을 형성하려고 노력하고있다.

694
00:35:12,888 --> 00:35:15,913
주어진 X의 표현과 디코더의 표현

695
00:35:15,913 --> 00:35:18,826
네트워크, 이것은 우리가 세대를
수행하는 데 사용하는 것입니다.

696
00:35:18,826 --> 00:35:22,993
그렇기 때문에 세대 네트워크가 사용되고 있음을 듣게됩니다.

697
00:35:24,410 --> 00:35:28,186
이제 우리의 인코더 및 디코더 네트워크를 갖추고 있으므로,

698
00:35:28,186 --> 00:35:31,899
데이터 우도를 다시 시도해 봅시다.

699
00:35:31,899 --> 00:35:35,117
데이터 우도 로그를 사용합니다.

700
00:35:35,117 --> 00:35:38,833
그래서 우리는 X의 P의 로그를 원한다면

701
00:35:38,833 --> 00:35:40,957
우리는 X의 P처럼 이것을 쓸 수 있습니다.

702
00:35:40,957 --> 00:35:44,988
Z와 관련하여 기대하다.

703
00:35:44,988 --> 00:35:46,738
그래서 우리의 Z 샘플

704
00:35:48,291 --> 00:35:50,801
우리가 지금 정의한 Z 주어진 X의 Q의 분포

705
00:35:50,801 --> 00:35:52,606
인코더 네트워크를 사용합니다.

706
00:35:52,606 --> 00:35:55,477
그리고 우리는 X의 P가 Z에 의존하지
않기 때문에 이것을 할 수 있습니다.

707
00:35:55,477 --> 00:35:58,254
Z는 그 부분이 아닙니다.

708
00:35:58,254 --> 00:36:01,461
그래서 우리는 존경심으로 기대를하는
것을 보게 될 것입니다.

709
00:36:01,461 --> 00:36:04,794
나중에 Z는 나중에 편리하게 들어올 것입니다.

710
00:36:06,255 --> 00:36:10,350
좋아, 이제이 원래 표현에서 우리는 할 수있다.

711
00:36:10,350 --> 00:36:14,332
이제 Z를 주어진 X의 P의 로그가되도록 확장합니다.

712
00:36:14,332 --> 00:36:17,576
베이 즈 규칙을 사용하여 주어진 X의 P에 대한 Z의 P.

713
00:36:17,576 --> 00:36:20,564
그래서 이것은 이것을 직접 작성하는 것입니다.

714
00:36:20,564 --> 00:36:23,763
그리고 이것을 취하면 우리는
또한 그것을 곱할 수 있습니다.

715
00:36:23,763 --> 00:36:24,996
상수로.

716
00:36:24,996 --> 00:36:28,937
맞습니다. 그래서 Z의 Q는 X의
주어진 Q에 대해 주어진 것입니다.

717
00:36:28,937 --> 00:36:30,874
이것이 우리가 할 수있는 일입니다.

718
00:36:30,874 --> 00:36:33,847
그것은 변경되지 않지만 나중에 도움이 될 것입니다.

719
00:36:33,847 --> 00:36:36,899
그래서 우리가 할 일은 우리가 그것을 쓸 것입니다.

720
00:36:36,899 --> 00:36:39,444
이 3 가지 별도 용어로

721
00:36:39,444 --> 00:36:41,567
그리고 나중에이 수학을 스스로 해결할 수 있습니다.

722
00:36:41,567 --> 00:36:44,703
본질적으로 대수 규칙 만 사용합니다.

723
00:36:44,703 --> 00:36:47,449
우리가 가지고 있던

724
00:36:47,449 --> 00:36:50,561
위의 줄과 그냥 그것을 밖으로 분리

725
00:36:50,561 --> 00:36:54,728
좋은 의미를 지닌이 세 가지 용어.

726
00:36:56,431 --> 00:36:58,758
맞습니다. 우리가 이것을 보면,
우리가 얻는 첫 번째 용어입니다.

727
00:36:58,758 --> 00:37:02,754
분리 된 로그는 P 주어진 X의 로그이고 기대

728
00:37:02,754 --> 00:37:05,560
주어진 X의 로그를 구한 다음 우리는

729
00:37:05,560 --> 00:37:07,210
KL 용어 두 개, 맞아.

730
00:37:07,210 --> 00:37:10,210
이것은 기본적으로 KL 분기 (divergence) 기간입니다.

731
00:37:11,619 --> 00:37:14,400
to say 얼마나 가까운 이러한 두 배포판을 말할 수 있습니다.

732
00:37:14,400 --> 00:37:18,567
Z와 Z의 분포 Q는 얼마나 가깝습니다.

733
00:37:19,489 --> 00:37:24,287
따라서 그것은 바로 위의 기대 기간입니다.

734
00:37:24,287 --> 00:37:28,454
그리고 이것은 배포판에 대한 거리 척도 일뿐입니다.

735
00:37:30,908 --> 00:37:33,332
그리고 우리는 그것을 볼 것입니다, 맞습니다.

736
00:37:33,332 --> 00:37:36,183
우리가 쓸 수있는 멋진 KL 용어.

737
00:37:36,183 --> 00:37:39,290
그리고 지금 우리가이 세 용어를 보게되면,

738
00:37:39,290 --> 00:37:43,806
첫 번째 항은 주어진 Z의 P이다.

739
00:37:43,806 --> 00:37:45,819
우리의 디코더 네트워크에 의해.

740
00:37:45,819 --> 00:37:48,873
그리고 우리는이 용어의 추정치를 계산할 수 있습니다.

741
00:37:48,873 --> 00:37:52,042
샘플링을 통해 우리는

742
00:37:52,042 --> 00:37:54,160
어떤 것을 통해 구별 할 수있는 샘플링을해라.

743
00:37:54,160 --> 00:37:56,099
re-parametrization 트릭을 호출합니다.

744
00:37:56,099 --> 00:37:58,932
당신이이 종이를 볼 수있는 세부 사항

745
00:37:58,932 --> 00:37:59,920
관심.

746
00:37:59,920 --> 00:38:02,479
그러나 기본적으로 우리는 이제이
용어를 계산할 수 있습니다.

747
00:38:02,479 --> 00:38:06,398
그런 다음이 KL 용어, 두 번째 KL 용어

748
00:38:06,398 --> 00:38:08,600
두 가우시안 사이의 KL,

749
00:38:08,600 --> 00:38:11,964
Z 주어진 X의 Q는 우리의
엔코더가 생성 된 것을 기억합니다.

750
00:38:11,964 --> 00:38:14,608
이 분포는 평균과 공분산을 가지고 있었고,

751
00:38:14,608 --> 00:38:16,079
좋은 가우시안이었다.

752
00:38:16,079 --> 00:38:19,892
그리고 또한 가우스 인 Z의 이전 P도.

753
00:38:19,892 --> 00:38:22,058
그래서 이것은 KL을 가질 때 좋았습니다.

754
00:38:22,058 --> 00:38:24,513
두 개의 가우시안 중 멋진 닫힌 폼 솔루션이 있습니다.

755
00:38:24,513 --> 00:38:25,628
네가 가질 수있는 것.

756
00:38:25,628 --> 00:38:27,324
그리고 지금이 세 번째 KL 용어는,

757
00:38:27,324 --> 00:38:31,324
이것은 주어진 Q의 KL이고 주어진 X의 P는 X이다.

758
00:38:32,303 --> 00:38:35,311
그러나 우리는 주어진 X의 P가이
다루기 힘든 것을 알고 있습니다.

759
00:38:35,311 --> 00:38:36,766
우리가 더 일찍 본 후방?

760
00:38:36,766 --> 00:38:38,922
우리가 계산하기를 원하지 않는 이유는

761
00:38:38,922 --> 00:38:41,794
이 근사값은 Q를 사용합니다.

762
00:38:41,794 --> 00:38:44,625
그래서이 용어는 여전히 문제입니다.

763
00:38:44,625 --> 00:38:47,102
그러나 우리가이 용어에 대해 알고있는 한 가지는 KL

764
00:38:47,102 --> 00:38:50,609
발산, 두 분포 사이의 거리

765
00:38:50,609 --> 00:38:54,776
정의에 따라 항상 0보다 크거나 같습니다.

766
00:38:57,060 --> 00:38:59,058
그래서 우리가 이것으로 할 수있는 것은,

767
00:38:59,058 --> 00:39:01,257
우리가 여기서 가지고있는 것,
우리가 일할 수있는 두 가지 용어

768
00:39:01,257 --> 00:39:03,396
멋지게, 이것은,

769
00:39:03,396 --> 00:39:06,935
이것은 우리가 실제로 할 수있는 다루기 쉬운 하한이다.

770
00:39:06,935 --> 00:39:10,023
그라디언트를 취하여 최적화하십시오.

771
00:39:10,023 --> 00:39:12,781
주어진 Z의 P는 미분 가능하고 KL 항

772
00:39:12,781 --> 00:39:16,652
또한, 가까운 형태의 솔루션도 차별화 될 수 있습니다.

773
00:39:16,652 --> 00:39:19,213
그리고 이것은 우리가 KL

774
00:39:19,213 --> 00:39:22,686
오른쪽에있는 용어는 못생긴 것보다 큽니다.

775
00:39:22,686 --> 00:39:24,168
또는 0과 같습니다.

776
00:39:24,168 --> 00:39:26,251
그래서 우리는 낮은 경계를가집니다.

777
00:39:27,273 --> 00:39:32,224
그래서 우리는 variational autoencoder를
훈련시키기 위해 무엇을 할 것인가?

778
00:39:32,224 --> 00:39:35,155
우리가이 하한값을 대신 사용한다는 것입니다.

779
00:39:35,155 --> 00:39:37,699
이 하한을 최적화하고 최대화하십시오.

780
00:39:37,699 --> 00:39:40,777
그래서 우도에 대한 하한을 최적화합니다.

781
00:39:40,777 --> 00:39:42,251
우리 데이터의

782
00:39:42,251 --> 00:39:45,031
즉, 우리의 데이터는 항상

783
00:39:45,031 --> 00:39:47,554
적어도 이보다 낮은 우도

784
00:39:47,554 --> 00:39:49,940
우리가 극대화하고있는 경계.

785
00:39:49,940 --> 00:39:53,607
그래서 우리는 세타 매개 변수를 찾고 싶습니다.

786
00:39:54,875 --> 00:39:59,042
추정 매개 변수 인 theta와 phi를 사용하면

787
00:40:00,162 --> 00:40:01,329
이것을 극대화하십시오.

788
00:40:03,169 --> 00:40:06,412
그리고 나서이 하한에 대한 직감의 마지막 종류

789
00:40:06,412 --> 00:40:09,132
우리가 가진 첫 번째 임기는

790
00:40:09,132 --> 00:40:12,796
Z의 모든 샘플에 대한 기대치이다.

791
00:40:12,796 --> 00:40:16,963
인코더 네트워크를 통해 우리 X를
통과하는 것으로부터 샘플링 됨

792
00:40:18,267 --> 00:40:21,836
이 모든 샘플에 대해 기대를 모은 샘플링 Z

793
00:40:21,836 --> 00:40:24,003
주어진 Z의 확률

794
00:40:24,963 --> 00:40:26,854
그래서 이것은 재건입니다, 맞죠?

795
00:40:26,854 --> 00:40:29,196
이것은 기본적으로 말하고 있습니다.

796
00:40:29,196 --> 00:40:33,300
나는 Z가 높은 것으로 주어진이 X의 가능성
(likelihood) P를 원한다.

797
00:40:33,300 --> 00:40:36,168
그래서 좋은 일을하려고하는 것과 같습니다.

798
00:40:36,168 --> 00:40:37,756
데이터를 재구성하는 것.

799
00:40:37,756 --> 00:40:40,528
이전에 autoencoder에서 얻은 것과 비슷합니다.

800
00:40:40,528 --> 00:40:44,695
그러나 두 번째 용어는이 KL을
작게 만드는 것을 말합니다.

801
00:40:46,161 --> 00:40:48,832
근사 사후 분포를 닫습니다.

802
00:40:48,832 --> 00:40:51,283
우리의 이전 배포판에.

803
00:40:51,283 --> 00:40:55,450
그리고 이것은 기본적으로 우리가

804
00:40:56,633 --> 00:40:59,883
잠복 변수 Z는 이것 다음에,

805
00:41:01,980 --> 00:41:05,338
이 분포 유형, 분포 모양을 갖는다.

806
00:41:05,338 --> 00:41:07,838
우리가 가지고 있기를 바란다.

807
00:41:08,974 --> 00:41:12,058
이것에 대한 질문이 있으십니까?

808
00:41:12,058 --> 00:41:14,486
나는 이것이 수학의 많은 부분이라고 생각한다.

809
00:41:14,486 --> 00:41:17,440
관심을 가지고 돌아 가야하고 일을해야합니다.

810
00:41:17,440 --> 00:41:19,128
모든 파생물들.

811
00:41:19,128 --> 00:41:19,961
네.

812
00:41:20,883 --> 00:41:23,669
[학생의 말은 마이크가 없어서 가려졌습니다.]

813
00:41:23,669 --> 00:41:26,928
그래서 질문은 왜 우리가 이전에

814
00:41:26,928 --> 00:41:29,373
잠재 변수는 가우스?

815
00:41:29,373 --> 00:41:31,523
그리고 그 이유는 우리가

816
00:41:31,523 --> 00:41:33,512
일종의 생성 적 프로세스 권리,

817
00:41:33,512 --> 00:41:35,930
먼저 Z를 샘플링 한 다음 X를 먼저 샘플링하십시오.

818
00:41:35,930 --> 00:41:39,444
가우스로 정의하는 것은 합리적인 유형입니다.

819
00:41:39,444 --> 00:41:43,611
우리는 이러한 유형에 대해

820
00:41:44,668 --> 00:41:47,619
에 따라 분포 될 잠재적 속성

821
00:41:47,619 --> 00:41:51,724
일종의 가우시안 (Gaussian)에 가면, 이제 우리에게

822
00:41:51,724 --> 00:41:53,307
우리 모델을 최적화하십시오.

823
00:41:55,988 --> 00:42:00,211
좋아, 그럼 우리가 어떻게이 하한선을
비웃을 수 있는지 이야기 했어.

824
00:42:00,211 --> 00:42:03,725
이제이 모든 것을 합치고 걸어 나가자.

825
00:42:03,725 --> 00:42:06,053
AE의 훈련 과정.

826
00:42:06,053 --> 00:42:08,802
바로 여기에 우리가 최적화하고 싶은 경계가 있습니다.

827
00:42:08,802 --> 00:42:10,008
극대화하십시오.

828
00:42:10,008 --> 00:42:12,057
그리고 앞으로 전달합니다.

829
00:42:12,057 --> 00:42:14,864
우리는 다음과 같은 방식으로 진행할 것입니다.

830
00:42:14,864 --> 00:42:18,134
입력 데이터 X가 있으므로 미니 배치

831
00:42:18,134 --> 00:42:19,301
입력 데이터의

832
00:42:20,845 --> 00:42:24,211
그런 다음 엔코더 네트워크를 통해 전달합니다.

833
00:42:24,211 --> 00:42:26,544
그래서 우리는 주어진 X의 Q를 얻을 것입니다.

834
00:42:28,439 --> 00:42:33,384
그리고이 Z부터 주어진 X의 X에서,
이것은 조건이 될 것입니다.

835
00:42:33,384 --> 00:42:35,805
KL 용어를 계산할 때 사용합니다.

836
00:42:35,805 --> 00:42:40,606
그리고 나서 여기에서 우리는이
분포에서 Z를 샘플링 할 것입니다.

837
00:42:40,606 --> 00:42:44,773
우리는 잠정적 인 요소의 샘플을
가지고 있으므로 주어진 X의 X

838
00:42:46,120 --> 00:42:48,203
우리는 X에서 추론 할 수 있습니다.

839
00:42:50,721 --> 00:42:52,543
그리고 나서 여기에서 우리는 Z를 통과시킬 것입니다.

840
00:42:52,543 --> 00:42:54,889
또 다른, 우리의 두 번째 디코더 네트워크.

841
00:42:54,889 --> 00:42:56,999
그리고 디코더 네트워크에서 우리는이 출력을 얻을 것입니다.

842
00:42:56,999 --> 00:43:00,150
에 대한 우리의 분포에 대한 평균과 분산

843
00:43:00,150 --> 00:43:03,817
X가 Z로 주어지면 마침내 지금 샘플링 할 수 있습니다.

844
00:43:04,821 --> 00:43:07,686
이 분포에서 우리의 X 주어진 Z

845
00:43:07,686 --> 00:43:12,155
여기에 몇 가지 샘플 출력이 생성됩니다.

846
00:43:12,155 --> 00:43:13,676
우리가 훈련 할 때 우리는 이것을 취할 것입니다.

847
00:43:13,676 --> 00:43:16,500
우리의 손실 기간은

848
00:43:16,500 --> 00:43:20,417
주어진 Z의 트레이닝 이미지 픽셀 값의 로그.

849
00:43:23,612 --> 00:43:26,517
그래서 우리의 손실 함수는

850
00:43:26,517 --> 00:43:30,684
원래 입력이 재구성 될 가능성.

851
00:43:32,020 --> 00:43:34,086
이제 모든 미니 배치에 대해

852
00:43:34,086 --> 00:43:35,919
우리는이 전달 경로를 계산할 것입니다.

853
00:43:35,919 --> 00:43:37,770
우리가 필요로하는 모든 용어를 얻으십시오.

854
00:43:37,770 --> 00:43:40,290
그리고 나서 이것은 모두 차별화 될 수 있습니다.

855
00:43:40,290 --> 00:43:43,837
이 모든 것을 뒷받침하고 그라데이션을 얻으십시오.

856
00:43:43,837 --> 00:43:47,194
우리는 우리 모델을 업데이트하고
이것을 계속해서 사용합니다.

857
00:43:47,194 --> 00:43:50,763
매개 변수, 생성기 및 디코더 업데이트

858
00:43:50,763 --> 00:43:54,123
네트워크 매개 변수 theta 및 phi를 최대화하기 위해

859
00:43:54,123 --> 00:43:57,040
훈련 된 데이터의 가능성.

860
00:43:58,408 --> 00:44:01,084
우리 VAE를 훈련하면

861
00:44:01,084 --> 00:44:03,508
데이터를 생성하기 위해 할 수있는 일은 다음과 같습니다.

862
00:44:03,508 --> 00:44:05,547
디코더 네트워크 만 사용하십시오.

863
00:44:05,547 --> 00:44:07,919
좋아요. 여기에서 우리는 지금
Z를 샘플링 할 수 있습니다.

864
00:44:07,919 --> 00:44:10,947
우리가 가진이 후부에서 Z를 샘플링하는 대신에

865
00:44:10,947 --> 00:44:13,805
훈련 도중, 우리는 세대 동안 우리는 샘플

866
00:44:13,805 --> 00:44:15,504
우리의 진정한 생성 과정에서.

867
00:44:15,504 --> 00:44:18,673
그래서 우리는 이전에 우리가 지정한 것을 샘플링합니다.

868
00:44:18,673 --> 00:44:22,840
그런 다음 여기에서 데이터 X를 샘플링합니다.

869
00:44:25,281 --> 00:44:27,606
그리고 우리는 이것이 이것이 생산할 수
있음을 보게 될 것입니다,이 경우,

870
00:44:27,606 --> 00:44:32,465
MNIST에서 기차, 이들은 생성 된 자릿수 샘플입니다.

871
00:44:32,465 --> 00:44:34,798
MNIST에서 훈련 된 VAE에서.

872
00:44:36,058 --> 00:44:38,842
그리고 당신도 알다시피, 우리는이
아이디어에 대해 이야기했습니다.

873
00:44:38,842 --> 00:44:43,796
우리가 할 수있는 잠재 요인을 나타내는 Z의

874
00:44:43,796 --> 00:44:46,440
서로 다른 표본에 따라 Z를 묻어 라.

875
00:44:46,440 --> 00:44:50,464
우리 이전의 부분들과 다른 종류의

876
00:44:50,464 --> 00:44:52,625
해석의 의미는 여기에서.

877
00:44:52,625 --> 00:44:54,207
그래서 여기에서 우리는 이것이

878
00:44:54,207 --> 00:44:57,142
2 차원 Z에 대한 데이터 매니 폴드.

879
00:44:57,142 --> 00:44:59,718
그래서 우리는 2 차원 Z를 가지고 Z를 취하고합시다.

880
00:44:59,718 --> 00:45:04,110
다른 백분위 수에서 알 수있는 범위를 말하십시오.

881
00:45:04,110 --> 00:45:08,568
우리는 Z1을 변화시키고 우리는 Z2를 변화시키고,

882
00:45:08,568 --> 00:45:13,038
그러면 이미지가 어떻게 생성되는지를 볼 수 있습니다.

883
00:45:13,038 --> 00:45:16,300
우리가 여기에 가지고있는 Z1과 Z2의 조합,

884
00:45:16,300 --> 00:45:19,587
당신은 그것이 전체적으로 원활하게
전환하고 있음을 볼 수 있습니다.

885
00:45:19,587 --> 00:45:22,087
이러한 다양한 변형의

886
00:45:24,051 --> 00:45:27,808
그리고 우리는 이전에 Z가 있었고, 대각선이었으며,

887
00:45:27,808 --> 00:45:30,387
그래서 우리는 이것을 장려하기 위해 이것을 선택했습니다.

888
00:45:30,387 --> 00:45:34,568
독립적 인 잠재 변수는

889
00:45:34,568 --> 00:45:37,372
변이의 해석 가능한 요인.

890
00:45:37,372 --> 00:45:39,731
이제 이것 때문에 우리는 다른 차원을 가질 것입니다.

891
00:45:39,731 --> 00:45:41,923
다른 해석 가능한 요소들을 인코딩하는 Z의

892
00:45:41,923 --> 00:45:43,006
변화의.

893
00:45:44,477 --> 00:45:47,674
이제 Faces에있는이 예제 기차에서,

894
00:45:47,674 --> 00:45:52,020
우리는 Z1을 변화시키면서 위아래로 가고,

895
00:45:52,020 --> 00:45:54,771
미소가 바뀌는 것을 볼 수 있습니다.

896
00:45:54,771 --> 00:45:56,892
그래서 위의 찡그림에서 큰 웃음까지.

897
00:45:56,892 --> 00:46:00,225
바닥에서 그리고 우리가 갈 때 Z2,

898
00:46:01,997 --> 00:46:04,192
왼쪽에서 오른쪽으로, 머리 포즈가
바뀌는 것을 볼 수 있습니다.

899
00:46:04,192 --> 00:46:07,859
한 방향에서 다른 방향으로.

900
00:46:09,883 --> 00:46:12,020
그리고 내가 지적하고 싶은 한가지 추가 사항

901
00:46:12,020 --> 00:46:13,964
이 일의 결과로,

902
00:46:13,964 --> 00:46:17,214
이 Z 변수도 좋은 기능입니다.

903
00:46:18,198 --> 00:46:19,510
표현.

904
00:46:19,510 --> 00:46:23,355
왜냐하면 그들은 서로 다른

905
00:46:23,355 --> 00:46:26,376
우리가 가진이 해석 할 수있는 다른 의미들.

906
00:46:26,376 --> 00:46:29,466
그래서 주어진 X의 Q를 사용할 수 있습니다.

907
00:46:29,466 --> 00:46:32,296
우리가 배운 인코더와 입력

908
00:46:32,296 --> 00:46:36,213
이미지 X, 이것을 Z에 매핑하고 Z를
다음과 같이 사용할 수 있습니다.

909
00:46:38,121 --> 00:46:40,198
다운 스트림 작업에 사용할 수있는 기능

910
00:46:40,198 --> 00:46:43,157
감독과 같은 또는 분류 또는

911
00:46:43,157 --> 00:46:44,157
다른 작업.

912
00:46:47,348 --> 00:46:49,947
그래, 데이터의 또 다른 몇 가지 예가 있습니다.

913
00:46:49,947 --> 00:46:51,434
VAEs에서 생성됩니다.

914
00:46:51,434 --> 00:46:55,694
여기 왼쪽에는 CIFAR-10에서
생성 된 데이터가 있습니다.

915
00:46:55,694 --> 00:46:58,729
CIFAR-10 교육을받은 다음 오른쪽에

916
00:46:58,729 --> 00:47:02,231
Faces에서 훈련되고 생성 된 데이터.

917
00:47:02,231 --> 00:47:05,043
그리고 우리는 VAEs에서 볼 수있는 것을 볼 것입니다.

918
00:47:05,043 --> 00:47:08,737
인식 할 수있는 데이터를 생성 할 수 있습니다.

919
00:47:08,737 --> 00:47:11,796
VAE의 가장 큰 단점 중 하나는

920
00:47:11,796 --> 00:47:15,493
여전히 그들에게는 약간 모호한면이 있습니다.

921
00:47:15,493 --> 00:47:18,270
당신은 얼굴에서 이것을 볼 수 있습니다.
그래서 이것은 여전히 있습니다.

922
00:47:18,270 --> 00:47:20,520
연구의 활발한 영역.

923
00:47:22,008 --> 00:47:24,944
VAEs를 요약하기 위해,

924
00:47:24,944 --> 00:47:28,030
그들은 전통적인 자동 인코딩 장치에서
확률 론적으로 변화하고 있습니다.

925
00:47:28,030 --> 00:47:31,895
따라서 결정적으로 입력 X를받는 대신

926
00:47:31,895 --> 00:47:36,077
Z로 이동하고, Z를 피한 다음 X를 재구성하고,

927
00:47:36,077 --> 00:47:40,585
이제 배포판과 샘플링에 대한 아이디어가 있습니다.

928
00:47:40,585 --> 00:47:43,023
우리가 데이터를 생성 할 수있게하는 관련.

929
00:47:43,023 --> 00:47:46,928
그리고이를 훈련시키기 위해 VAE는

930
00:47:46,928 --> 00:47:48,435
다루기 힘든 밀도.

931
00:47:48,435 --> 00:47:51,101
그래서 우리는 하한을 도출하고 최적화 할 수 있습니다.

932
00:47:51,101 --> 00:47:55,938
변하기 쉬운 하한, 그래서 변하기
쉬운 것은 기본적으로 의미한다.

933
00:47:55,938 --> 00:47:58,621
근사치를 사용하여 이러한 유형의 다루기 힘든

934
00:47:58,621 --> 00:47:59,718
표현.

935
00:47:59,718 --> 00:48:03,577
그래서 이것을 왜 variational
autoencoder라고 부릅니다.

936
00:48:03,577 --> 00:48:07,188
따라서이 접근법의 장점 중 일부는

937
00:48:07,188 --> 00:48:10,249
VAE가 있다는 것, 그들은 원칙적인 접근 방식입니다.

938
00:48:10,249 --> 00:48:14,230
생성 모델에 전달하고이 추론을 허용합니다.

939
00:48:14,230 --> 00:48:17,628
질의가 주어 지므로 주어진 Q의 Z와
같은 것들을 추론 할 수 있습니다.

940
00:48:17,628 --> 00:48:20,221
우리가 말한 것은 유용한 특징 표현 일 수 있습니다.

941
00:48:20,221 --> 00:48:21,554
다른 작업.

942
00:48:23,101 --> 00:48:27,081
VAE의 단점은 우리가 최대화하는 동안

943
00:48:27,081 --> 00:48:29,548
우도의 하한은 괜찮습니다.

944
00:48:29,548 --> 00:48:32,303
당신이 일반적으로 알고있는 것처럼 이것은 여전히 우리를

945
00:48:32,303 --> 00:48:33,967
올바른 방향으로

946
00:48:33,967 --> 00:48:37,782
이것에 대한 다른 이론적 분석.

947
00:48:37,782 --> 00:48:41,700
알다시피, 괜찮아요,하지만 아직은 아니에요.

948
00:48:41,700 --> 00:48:46,042
픽셀로서의 최적화 및 평가를 지시한다.

949
00:48:46,042 --> 00:48:48,378
이전에 본 RNN과 CNN,

950
00:48:48,378 --> 00:48:50,378
그러나,

951
00:48:51,857 --> 00:48:55,431
또한 VAE 샘플은 약간의 경향이 있습니다.

952
00:48:55,431 --> 00:48:59,235
최첨단에 비해 흐림 및 낮은 품질

953
00:48:59,235 --> 00:49:01,967
다른 생성 모델에서 볼 수있는 샘플

954
00:49:01,967 --> 00:49:04,827
우리가 다음에 이야기 할 GAN과 같은

955
00:49:04,827 --> 00:49:07,230
VAE는 지금도 여전히 활동적입니다.

956
00:49:07,230 --> 00:49:08,647
연구 분야.

957
00:49:11,044 --> 00:49:13,447
사람들은보다 유연한 근사치를
만들기 위해 노력하고 있습니다.

958
00:49:13,447 --> 00:49:15,565
이렇게 더 부유 한 대략 posteriors,

959
00:49:15,565 --> 00:49:19,611
그래서 대각선 가우시안 대신에 더 풍부한

960
00:49:19,611 --> 00:49:20,881
이것에 대한 함수.

961
00:49:20,881 --> 00:49:23,977
그리고 나서 사람들이 일하고있는 또 다른 영역

962
00:49:23,977 --> 00:49:26,159
이 잠재성에 더 많은 구조가 통합되어 있습니다.

963
00:49:26,159 --> 00:49:26,992
변수.

964
00:49:26,992 --> 00:49:31,282
이제 우리는이 모든 독립 잠복 변수를 가졌습니다.

965
00:49:31,282 --> 00:49:34,327
그러나 사람들은 모델링 구조를 가지고 작업하고있다.

966
00:49:34,327 --> 00:49:38,077
여기서 그룹화, 다른 유형의 구조.

967
00:49:41,106 --> 00:49:43,106
좋아, 그럼 네.

968
00:49:44,404 --> 00:49:47,529
[학생의 말은 마이크가 없어서 가려졌습니다.]

969
00:49:47,529 --> 00:49:49,810
그래, 문제는 우리가 차원을 결정하는 것이다.

970
00:49:49,810 --> 00:49:51,394
잠복 변수의

971
00:49:51,394 --> 00:49:54,727
네, 그건 당신이 지정하는 것입니다.

972
00:49:55,874 --> 00:50:00,041
좋아, 이제까지 우리는 pixelCNN과
VAE에 대해 이야기 해왔다.

973
00:50:01,082 --> 00:50:05,439
이제 우리는 세 번째와 매우
인기있는 것을 살펴볼 것입니다.

974
00:50:05,439 --> 00:50:08,522
GANs라고 불리는 생성 모델의 유형.

975
00:50:10,019 --> 00:50:13,378
지금까지 우리가 본 모델, pixelCNN과 RNN

976
00:50:13,378 --> 00:50:15,713
다루기 쉬운 밀도 함수를 정의하십시오.

977
00:50:15,713 --> 00:50:19,752
그리고 훈련 된 데이터의 가능성을 최적화합니다.

978
00:50:19,752 --> 00:50:24,174
그리고 VAE는 이제 이와는 대조적으로

979
00:50:24,174 --> 00:50:26,675
생성 변수에서 정의하는 잠재 변수 Z

980
00:50:26,675 --> 00:50:27,752
방법.

981
00:50:27,752 --> 00:50:31,206
그래서 Z는 좋은 속성을 많이 가지고 있습니다.

982
00:50:31,206 --> 00:50:34,242
우리가 이야기 한 것이지만, 그들은 또한 우리에게

983
00:50:34,242 --> 00:50:36,858
우리가 할 수없는이 다루기 힘든 밀도 함수

984
00:50:36,858 --> 00:50:39,813
직접 최적화하고 그래서 우리는 파생하고 최적화합니다.

985
00:50:39,813 --> 00:50:43,934
우도에 대한 하한값.

986
00:50:43,934 --> 00:50:46,405
그리고 지금 우리가 단지 명시 적으로 포기하면

987
00:50:46,405 --> 00:50:48,486
이 밀도를 전혀 모델링하지 않습니까?

988
00:50:48,486 --> 00:50:51,100
우리가 원하는 것은 우리가 원하는 것이 바로 능력입니다.

989
00:50:51,100 --> 00:50:55,267
샘플을 보내고 우리의 배포판에서 좋은 샘플을 얻으십시오.

990
00:50:56,501 --> 00:50:59,175
이것이 GAN이 취하는 접근법입니다.

991
00:50:59,175 --> 00:51:02,637
그래서 GANs에서는 명시적인
밀도 함수로 작업하지 않습니다.

992
00:51:02,637 --> 00:51:05,642
대신에 우리는 게임 이론적 접근법을 취할 것입니다.

993
00:51:05,642 --> 00:51:08,018
우리는 우리의 훈련에서 생성하는 법을 배울 것입니다.

994
00:51:08,018 --> 00:51:10,422
두 선수 게임의 설정을 통해 배포,

995
00:51:10,422 --> 00:51:13,839
이에 대해 더 자세히 설명하겠습니다.

996
00:51:15,255 --> 00:51:18,654
그래서 GAN이 우리가 말하고있는 것을 설정합니다. 좋아,

997
00:51:18,654 --> 00:51:21,354
우리가 관심을 갖는 것은 우리가 표본
추출이 가능하기를 원한다는 것이다.

998
00:51:21,354 --> 00:51:24,681
복잡한 고차원 교육 배포.

999
00:51:24,681 --> 00:51:27,339
그래서 우리가 잘 생각해 보면 샘플을 만들고 싶습니다.

1000
00:51:27,339 --> 00:51:29,885
이 배포판에는 직접적인 방법이 없습니다.

1001
00:51:29,885 --> 00:51:31,170
우리가이 일을 할 수 있다고.

1002
00:51:31,170 --> 00:51:32,560
우리는 매우 복잡한 분포를 가지고 있습니다.

1003
00:51:32,560 --> 00:51:35,078
여기에서 샘플을 가져올 수는 없습니다.

1004
00:51:35,078 --> 00:51:38,956
그래서 우리가 취할 해결책은 우리가 할 수있는 것입니다,

1005
00:51:38,956 --> 00:51:42,895
그러나 더 간단한 배포판에서 샘플을 얻을 수 있습니다.

1006
00:51:42,895 --> 00:51:44,687
예를 들어 무작위 노이즈예요?

1007
00:51:44,687 --> 00:51:46,875
가우시안들은 우리가 샘플링 할 수있는 것들입니다.

1008
00:51:46,875 --> 00:51:49,414
그래서 우리가 할 일은 우리가 배우려고하는 것입니다.

1009
00:51:49,414 --> 00:51:52,622
이 단순한 분포들로부터의 변형

1010
00:51:52,622 --> 00:51:56,789
우리가 원하는 교육 배포판에 직접 연결됩니다.

1011
00:51:58,790 --> 00:52:03,221
그래서 질문, 우리는이 복합체를 표현하기
위해 무엇을 사용할 수 있습니까?

1012
00:52:03,221 --> 00:52:04,304
분포?

1013
00:52:06,120 --> 00:52:07,718
신경망, 나는 그 대답을 들었다.

1014
00:52:07,718 --> 00:52:10,362
그래서 우리가 일종의 복잡한 함수를 모델링하고 싶을 때

1015
00:52:10,362 --> 00:52:14,373
또는 변환 우리는 신경 네트워크를 사용합니다.

1016
00:52:14,373 --> 00:52:17,478
좋아, 그럼 우리가 할 일은

1017
00:52:17,478 --> 00:52:19,702
GAN에서 우리는 몇 가지 정보를 얻을 것입니다.

1018
00:52:19,702 --> 00:52:23,297
우리가 지정하는 차원의 벡터입니다.

1019
00:52:23,297 --> 00:52:26,060
무작위 잡음을 제거한 다음이를 통과시킵니다.

1020
00:52:26,060 --> 00:52:29,015
발전기 네트워크, 그리고 우리는
결과물을 얻게 될 것입니다.

1021
00:52:29,015 --> 00:52:33,628
직접 훈련 배포판의 샘플.

1022
00:52:33,628 --> 00:52:36,821
그래서 우리가 원하는 무작위 잡음의 모든 입력

1023
00:52:36,821 --> 00:52:40,154
훈련 배급의 샘플.

1024
00:52:41,278 --> 00:52:44,763
그리하여 우리는이 네트워크를 훈련하고 배울 것입니다.

1025
00:52:44,763 --> 00:52:48,737
우리는 이것을 두 사람의 게임으로 보게 될 것입니다.

1026
00:52:48,737 --> 00:52:50,721
그래서 두 명의 플레이어, 발전기 네트워크가 있습니다.

1027
00:52:50,721 --> 00:52:54,595
내가 다음에 보여줄 추가적인 판별 자 네트워크로서.

1028
00:52:54,595 --> 00:52:59,080
그리고 우리의 발전기 네트워크는 플레이어 하나로서,

1029
00:52:59,080 --> 00:53:02,584
그것은 차별자를 속이려고 노력할 것입니다.

1030
00:53:02,584 --> 00:53:04,320
진짜 보는 이미지.

1031
00:53:04,320 --> 00:53:07,089
그리고 두 번째 플레이어, 우리의 판별 자 네트워크

1032
00:53:07,089 --> 00:53:11,629
진짜와 가짜를 구별하려고합니다.

1033
00:53:11,629 --> 00:53:12,462
이미지.

1034
00:53:12,462 --> 00:53:16,950
그래서 가능한 한 좋은 일을하고 싶다.

1035
00:53:16,950 --> 00:53:19,740
이 이미지들 중 어느 것이 위조인지 판단하는

1036
00:53:19,740 --> 00:53:23,323
또는이 생성자에 의해 생성 된 가짜 이미지.

1037
00:53:25,425 --> 00:53:27,324
좋아, 이렇게 생겼어.

1038
00:53:27,324 --> 00:53:31,203
우리는 우리의 랜덤 노이즈가
우리의 발전기 네트워크로 간다.

1039
00:53:31,203 --> 00:53:33,678
발전기 네트워크에서 이러한 이미지를 생성합니다.

1040
00:53:33,678 --> 00:53:36,121
전화 할거야, 그들은 우리 발전기에서 가짜 야.

1041
00:53:36,121 --> 00:53:38,738
그리고 나서 우리는 또한 실제 이미지를 갖게 될 것입니다.

1042
00:53:38,738 --> 00:53:42,439
우리의 훈련 세트에서 가져온 다음 우리는

1043
00:53:42,439 --> 00:53:46,356
판별자를 구별 할 수있다.

1044
00:53:48,358 --> 00:53:50,881
진짜와 가짜 이미지.

1045
00:53:50,881 --> 00:53:52,849
각 이미지에 대해 실제와 가짜를 출력합니다.

1046
00:53:52,849 --> 00:53:55,779
그래서 아이디어는 우리가 아주
좋은 것을 가질 수 있다면입니다.

1047
00:53:55,779 --> 00:53:57,910
우리는 훌륭한 discriminator를
훈련시키고 자하며,

1048
00:53:57,910 --> 00:54:01,638
그것이 진짜 대 가짜를 차별하는
훌륭한 일을 할 수 있다면,

1049
00:54:01,638 --> 00:54:05,760
그리고 우리의 발전기 네트워크가 생성 할 수 있다면,

1050
00:54:05,760 --> 00:54:08,227
그것이 잘하고 가짜 이미지를 생성 할 수 있다면

1051
00:54:08,227 --> 00:54:11,140
이 discriminator를
성공적으로 바보짓을 할 수있는,

1052
00:54:11,140 --> 00:54:13,135
우리는 훌륭한 생성 모델을 가지고 있습니다.

1053
00:54:13,135 --> 00:54:16,348
우리는 이미지와 같이 보이는 이미지를

1054
00:54:16,348 --> 00:54:17,431
훈련 세트.

1055
00:54:19,482 --> 00:54:22,421
좋아, 그래서 우리는이 두 선수가 있고 그래서 우리는

1056
00:54:22,421 --> 00:54:25,548
미니 맥스 게임 공식에서 이것을 공동으로 훈련하십시오.

1057
00:54:25,548 --> 00:54:28,941
그래서이 미니 맥스 목적 함수는
우리가 여기서 가지고있는 것입니다.

1058
00:54:28,941 --> 00:54:33,108
우리는 취할 것입니다, 그것은
세타 G 이상 최소가 될 것입니다

1059
00:54:34,791 --> 00:54:37,399
발전기 네트워크 G의 매개 변수,

1060
00:54:37,399 --> 00:54:41,431
Discriminator 네트워크의
최대 매개 변수 Zeta

1061
00:54:41,431 --> 00:54:44,848
D,이 목적의 권리,이 기간.

1062
00:54:47,177 --> 00:54:49,624
그래서 우리가이 용어들을 보면,
이것이 말하고있는 것입니다.

1063
00:54:49,624 --> 00:54:53,243
이 첫 번째 일, 데이터에 대한 기대

1064
00:54:53,243 --> 00:54:54,910
주어진 X의 로그의

1065
00:54:56,094 --> 00:54:59,496
X의 D의 로그는 판별 자 출력입니다.

1066
00:54:59,496 --> 00:55:01,151
실제 데이터 X.

1067
00:55:01,151 --> 00:55:05,318
이것은 실제 데이터가 실제가 될 가능성이 있습니다.

1068
00:55:06,978 --> 00:55:09,309
데이터 분포 P 데이터로부터.

1069
00:55:09,309 --> 00:55:12,963
그리고 나서 두 번째 용어 인 Z의 기대

1070
00:55:12,963 --> 00:55:16,882
Z의 P에서 나온 Z는 P의
P에서 가져온 것을 의미합니다.

1071
00:55:16,882 --> 00:55:21,049
우리의 발전기 네트워크와 G의이 용어 D는 Z의

1072
00:55:22,581 --> 00:55:25,875
우리는 여기에 우리의
discriminator의 결과가 있습니다.

1073
00:55:25,875 --> 00:55:29,109
우리를 위해 생성 된 가짜 데이터는

1074
00:55:29,109 --> 00:55:32,602
Z의 G의 판별 자 출력은 무엇입니까?

1075
00:55:32,602 --> 00:55:33,769
우리의 가짜 데이터.

1076
00:55:36,311 --> 00:55:39,678
그래서 우리가 이것에 대해 생각한다면,

1077
00:55:39,678 --> 00:55:43,105
우리의 판별자는이 목표를 극대화하기를 원합니다.

1078
00:55:43,105 --> 00:55:47,272
X의 D가 1에 가깝도록 theta D의 최대 값입니다.

1079
00:55:49,271 --> 00:55:53,278
그것은 실제에 가깝고 실제 데이터에 대해서는 높습니다.

1080
00:55:53,278 --> 00:55:57,445
그리고 X의 G의 D, 가짜 데이터의 생각

1081
00:55:58,696 --> 00:56:02,679
여기 왼쪽에있는 작은 숫자는 0에 가까워 야합니다.

1082
00:56:02,679 --> 00:56:06,341
그래서 우리가 이것을 극대화 할 수
있다면 이것은 판별자를 의미합니다.

1083
00:56:06,341 --> 00:56:09,237
실제와 제로를 구별하는 훌륭한 일을하고 있습니다.

1084
00:56:09,237 --> 00:56:13,449
기본적으로 실제 데이터와 가짜 데이터를 분류합니다.

1085
00:56:13,449 --> 00:56:17,092
그리고 나서 우리 발전기, 여기서 우리는 발전기를

1086
00:56:17,092 --> 00:56:21,542
Z의 G의 D가 가깝도록이 목적을 최소화한다.

1087
00:56:21,542 --> 00:56:22,375
하나에.

1088
00:56:22,375 --> 00:56:26,329
Z의 G의 D가 여기에 가까운 경우,

1089
00:56:26,329 --> 00:56:31,319
마이너스 쪽은 작고 근본적으로 우리는 원합니다.

1090
00:56:31,319 --> 00:56:35,236
이 용어를 최소화하면

1091
00:56:36,768 --> 00:56:39,175
discreiminator는 우리의 가짜
데이터가 실제로 진짜라고 생각합니다.

1092
00:56:39,175 --> 00:56:44,087
그래서 우리 발전기가 실제 샘플을
생산하고 있음을 의미합니다.

1093
00:56:44,087 --> 00:56:46,893
좋아요, 이것이 GAN의 중요한 목표입니다.

1094
00:56:46,893 --> 00:56:51,139
시도하고 이해하기에 이것에 대해 질문이 있습니까?

1095
00:56:51,139 --> 00:56:55,306
[학생의 말은 마이크가 없어서 가려졌습니다.]

1096
00:57:02,342 --> 00:57:04,229
나는 당신의 질문을 이해할 수 있는지 확신하지 못합니다,

1097
00:57:04,229 --> 00:57:08,396
[학생의 말은 마이크가 없어서 가려졌습니다.]

1098
00:57:12,334 --> 00:57:15,377
그래, 문제는 이것이 기본적으로 시도하는 것이다.

1099
00:57:15,377 --> 00:57:19,544
첫 번째 네트워크에서 실제로 보이는
이미지를 생성하게하는 방법

1100
00:57:20,761 --> 00:57:22,617
우리의 두 번째 네트워크,
discriminator 수 없습니다

1101
00:57:22,617 --> 00:57:24,284
구별하다.

1102
00:57:30,474 --> 00:57:34,174
그래, 문제는 우리가 실제로 어떻게
데이터에 라벨을 붙이 느냐이다.

1103
00:57:34,174 --> 00:57:36,809
또는 이러한 네트워크에 대한 교육을 수행하십시오.

1104
00:57:36,809 --> 00:57:39,364
우리는 다음에 네트워크를 훈련시키는 방법을 보게 될 것입니다.

1105
00:57:39,364 --> 00:57:43,530
그러나 기본적으로 데이터 라벨이 무엇인지에 관해서는,

1106
00:57:43,530 --> 00:57:46,180
이것은 감독되지 않으므로 데이터 레이블이 없습니다.

1107
00:57:46,180 --> 00:57:49,541
그러나 발전기 네트워크에서 생성 된 데이터,

1108
00:57:49,541 --> 00:57:52,805
가짜 이미지에는 기본적으로 0
또는 가짜라는 레이블이 있습니다.

1109
00:57:52,805 --> 00:57:56,913
그리고 실제 이미지 인 훈련 이미지를 얻을 수 있습니다.

1110
00:57:56,913 --> 00:58:00,344
그리고 이것은 기본적으로 하나 또는
진짜의 라벨을 가지고 있습니다.

1111
00:58:00,344 --> 00:58:03,692
그래서 우리의 discriminator에 대한 손실 함수

1112
00:58:03,692 --> 00:58:04,866
이것을 사용하고 있습니다.

1113
00:58:04,866 --> 00:58:08,157
생성기 이미지에 0을 출력하려고합니다.

1114
00:58:08,157 --> 00:58:09,819
그리고 실제 이미지를위한 것.

1115
00:58:09,819 --> 00:58:12,048
따라서 외부 레이블이 없습니다.

1116
00:58:12,048 --> 00:58:15,136
[학생의 말은 마이크가 없어서 가려졌습니다.]

1117
00:58:15,136 --> 00:58:17,554
따라서 문제는 발전기 네트워크의 라벨입니다.

1118
00:58:17,554 --> 00:58:22,119
판별 자 네트워크의 출력이됩니다.

1119
00:58:22,119 --> 00:58:25,534
발전기는 실제로하지 않습니다.

1120
00:58:25,534 --> 00:58:29,321
실제로 분류를 실제로하고있는 것은 아닙니다.

1121
00:58:29,321 --> 00:58:32,744
그것이 객관적인 것은 여기에 있습니다, G의 Z of Z,

1122
00:58:32,744 --> 00:58:35,536
이게 최고라고 원합니다.

1123
00:58:35,536 --> 00:58:40,228
그래서 고정 된 discriminator
주어진, 그것을 배우고 싶어

1124
00:58:40,228 --> 00:58:42,487
발전기 매개 변수가 높습니다.

1125
00:58:42,487 --> 00:58:46,169
그래서 우리는 고정 된 판별 자 출력을
취해 그것을 사용할 것입니다.

1126
00:58:46,169 --> 00:58:47,752
그 배경을 이루기 위해서.

1127
00:58:51,447 --> 00:58:54,219
좋아, 이것을 훈련시키기 위해서,
우리는 무엇을 할 것인가?

1128
00:58:54,219 --> 00:58:57,714
그래디언트 상승 사이를 번갈아 가며

1129
00:58:57,714 --> 00:59:02,401
우리의 discriminator에, 그래서 우리는
theta 베타를 배우려고 노력하고 있습니다.

1130
00:59:02,401 --> 00:59:05,222
이 목표를 극대화 할 수 있습니다.

1131
00:59:05,222 --> 00:59:08,059
그리고 생성기에 그라디언트 디센트.

1132
00:59:08,059 --> 00:59:12,247
따라서이 매개 변수에 대한 기울기
상승을 사용하여 theta G

1133
00:59:12,247 --> 00:59:15,698
우리는이 목표와 목적을 최소화하고 있습니다.

1134
00:59:15,698 --> 00:59:18,413
그리고 여기에 우리는이 부분을 여기로 가져갈 것입니다.

1135
00:59:18,413 --> 00:59:22,165
그것은 그 부분에 의존하는 유일한 부분이기 때문에

1136
00:59:22,165 --> 00:59:23,748
theta G 매개 변수.

1137
00:59:26,574 --> 00:59:30,603
좋아요, 그래서 이것이 우리가이 GAN을 훈련 할 수있는 방법입니다.

1138
00:59:30,603 --> 00:59:32,527
우리는 우리의 판별자를 훈련시키는 것과

1139
00:59:32,527 --> 00:59:35,716
그리고이 게임에서 우리의 발전기, 각 바보하려고

1140
00:59:35,716 --> 00:59:40,561
판별자를 바보로 만들려고 노력하는 다른 또는 발전기.

1141
00:59:40,561 --> 00:59:44,027
그러나 주목할 중요한 사실 중 하나는 실제로

1142
00:59:44,027 --> 00:59:48,802
우리가 방금 정의한이 생성기 목표

1143
00:59:48,802 --> 00:59:50,478
잘 작동하지 않습니다.

1144
00:59:50,478 --> 00:59:54,169
그리고 이것에 대한 이유는 우리가
손실을보아야한다는 것입니다.

1145
00:59:54,169 --> 00:59:55,309
경치.

1146
00:59:55,309 --> 01:00:00,059
우리가 여기있는 손실의 조망을 보면

1147
01:00:00,059 --> 01:00:01,059
D의 X of G,

1148
01:00:02,858 --> 01:00:06,279
여기에 X의 G의 1을 뺀 D를 적용하면

1149
01:00:06,279 --> 01:00:08,737
그것은 우리가 발전기를 최소화하기를 원하는 것입니다.

1150
01:00:08,737 --> 01:00:10,654
여기에는이 모양이 있습니다.

1151
01:00:12,748 --> 01:00:16,406
그래서 우리는 이것을 최소화하기를 원합니다.

1152
01:00:16,406 --> 01:00:21,119
이 손실 중 실제로 오른쪽으로 갈 것입니다.

1153
01:00:21,119 --> 01:00:24,369
G의 D가 1에 가까울 때 높습니다.

1154
01:00:26,915 --> 01:00:31,082
그래서 우리 발전기가 좋은 일을 할 때

1155
01:00:31,082 --> 01:00:33,409
discriminator를 속일 때, 우리는

1156
01:00:33,409 --> 01:00:36,837
높은 그래디언트, 더 높은 그래디언트 용어.

1157
01:00:36,837 --> 01:00:39,636
그리고 다른 한편으로 우리가 나쁜 샘플을 가지고있을 때,

1158
01:00:39,636 --> 01:00:43,068
우리 발전기는 아직 좋은 직업을 배우지 못했지만,

1159
01:00:43,068 --> 01:00:44,794
그것은 아직 생성에 좋지 않다,

1160
01:00:44,794 --> 01:00:47,992
다음은 판별자가 쉽게 알 수있는 때입니다

1161
01:00:47,992 --> 01:00:52,159
이제는 X 축의이 제로 영역에 더 가깝습니다.

1162
01:00:53,002 --> 01:00:55,482
그런 다음 그라디언트가 상대적으로 평평합니다.

1163
01:00:55,482 --> 01:00:59,065
그리고 이것이 실제로 의미하는 바는

1164
01:01:00,288 --> 01:01:03,185
우리의 그라데이션 신호는

1165
01:01:03,185 --> 01:01:05,200
샘플은 이미 꽤 좋다.

1166
01:01:05,200 --> 01:01:08,011
반면에 우리가 실제로 많은 것을 배우기를 원하는 반면에

1167
01:01:08,011 --> 01:01:08,927
나쁘다, 그렇지?

1168
01:01:08,927 --> 01:01:12,624
이것은 우리가 배우고 자하는 훈련 샘플입니다.

1169
01:01:12,624 --> 01:01:17,570
그래서 이렇게하면 기본적으로 어렵게됩니다.

1170
01:01:17,570 --> 01:01:21,664
배우고 그래서 학습을 향상시키기 위해,

1171
01:01:21,664 --> 01:01:23,767
우리가하려고하는 것은 다른 것을 정의하는 것입니다.

1172
01:01:23,767 --> 01:01:26,320
그라디언트에 약간 다른 목적 함수.

1173
01:01:26,320 --> 01:01:30,145
이제 우리는 그라디언트 상승을 대신 할 것입니다.

1174
01:01:30,145 --> 01:01:32,229
그래서 우리의 가능성을 최소화하는 대신

1175
01:01:32,229 --> 01:01:35,748
discriminator가 올바른지,
우리가 이전에 가지고 있었던 것,

1176
01:01:35,748 --> 01:01:38,147
이제 우리는 그것을 뒤집어서 극대화 하자고 말할 것입니다.

1177
01:01:38,147 --> 01:01:40,908
우리의 discriminator의 틀린 가능성.

1178
01:01:40,908 --> 01:01:45,075
그래서 이것은 여기에 목표를 최대화하고,

1179
01:01:47,220 --> 01:01:49,720
X의 G의 D의 로그를 최대화합니다.

1180
01:01:50,767 --> 01:01:52,517
그리고 이제는 기본적으로

1181
01:01:56,575 --> 01:01:58,327
우리가 원한다면 음수가 있어야한다.

1182
01:01:58,327 --> 01:01:59,160
여기에 서명하십시오.

1183
01:01:59,160 --> 01:02:03,327
하지만 기본적으로 우리는 이제
플립 목적을 극대화하고자합니다.

1184
01:02:04,492 --> 01:02:08,659
대신에이 함수를 플롯하면 이것이
현재 무엇을하는지 알 수 있습니다.

1185
01:02:10,118 --> 01:02:13,263
오른쪽에 여기에 높은 그라디언트 신호가 있습니다.

1186
01:02:13,263 --> 01:02:16,149
우리가 나쁜 샘플을 가지고있는이 지역에서,

1187
01:02:16,149 --> 01:02:20,316
이제는 더 평평한 지역이 오른쪽에 있습니다.

1188
01:02:21,566 --> 01:02:23,242
좋은 샘플을 얻을 수 있습니다.

1189
01:02:23,242 --> 01:02:25,582
이제 우리는 지역에서 더 많은 것을 배우겠습니다.

1190
01:02:25,582 --> 01:02:26,571
나쁜 샘플들.

1191
01:02:26,571 --> 01:02:29,059
그래서 이것은 속이는 것과 같은 목적을 가지고 있습니다.

1192
01:02:29,059 --> 01:02:31,995
discriminator하지만
실제로는 훨씬 더 잘 작동합니다.

1193
01:02:31,995 --> 01:02:35,990
실제로 그리고 GAN에 관한 많은 연구를 위해

1194
01:02:35,990 --> 01:02:38,742
이러한 종류의 바닐라 GAN 제제를 사용하여

1195
01:02:38,742 --> 01:02:41,492
실제로이 목적을 사용하고 있습니다.

1196
01:02:44,220 --> 01:02:48,387
좋습니다. 그렇습니다.

1197
01:02:49,444 --> 01:02:53,964
이 두 네트워크는 도전적이고 불안정 할 수 있습니다.

1198
01:02:53,964 --> 01:02:56,222
우리가 여기에서 보았 듯이, 우리는

1199
01:02:56,222 --> 01:02:59,079
discriminator 훈련 및 발전기 훈련.

1200
01:02:59,079 --> 01:03:03,246
이런 유형의 교대는 기본적으로 배우기 어렵다.

1201
01:03:04,418 --> 01:03:08,398
한 번에 두 개의 네트워크가 있으며이 문제도 있습니다.

1202
01:03:08,398 --> 01:03:11,131
우리의 손실 조경이 보는 것에 따라,

1203
01:03:11,131 --> 01:03:13,815
우리의 훈련 역학에 영향을 줄 수 있습니다.

1204
01:03:13,815 --> 01:03:17,735
따라서 연구 활동이 활발한 이유는 어떻게 우리가

1205
01:03:17,735 --> 01:03:20,592
도움이 될 수있는 더 나은 손실 경관을 가진 목표

1206
01:03:20,592 --> 01:03:23,342
훈련을하고 더 안정하게 만드나요?

1207
01:03:26,516 --> 01:03:29,257
좋아, 이제이 모든 것을 정리하고

1208
01:03:29,257 --> 01:03:31,152
전체 GAN 교육 알고리즘.

1209
01:03:31,152 --> 01:03:34,366
그래서 우리가하려고하는 것은 각 반복 훈련을위한 것입니다.

1210
01:03:34,366 --> 01:03:37,674
우리는 먼저 세대를 훈련시킬 것입니다,

1211
01:03:37,674 --> 01:03:39,145
판별 자 네트워크를 조금 훈련시키다.

1212
01:03:39,145 --> 01:03:41,078
발전기 네트워크를 훈련시킬 수 있습니다.

1213
01:03:41,078 --> 01:03:43,959
따라서 discriminator
네트워크를 훈련하는 k 단계

1214
01:03:43,959 --> 01:03:47,861
우리는 우리의

1215
01:03:47,861 --> 01:03:52,442
Z 이전의 노이즈를 제거한 다음 미니 배치를 샘플링합니다.

1216
01:03:52,442 --> 01:03:55,859
우리의 훈련 데이터 X의 실제 샘플 수

1217
01:03:57,366 --> 01:04:01,410
그래서 우리가 할 일은 우리가 우리를
통해 소음을 전달할 것입니다.

1218
01:04:01,410 --> 01:04:04,519
발전기를 사용하면 가짜 이미지가 출력됩니다.

1219
01:04:04,519 --> 01:04:07,019
그래서 우리는 가짜 이미지와 미니
배치의 미니 배치를 가지고 있습니다.

1220
01:04:07,019 --> 01:04:08,052
실제 이미지의

1221
01:04:08,052 --> 01:04:11,554
그리고 나서 우리는 discriminator에
그라데이션 단계를 선택합니다.

1222
01:04:11,554 --> 01:04:15,041
이 미니 배치를 사용하여 가짜 이미지와 실제 이미지

1223
01:04:15,041 --> 01:04:17,891
우리의 discriminator
매개 변수를 업데이트하십시오.

1224
01:04:17,891 --> 01:04:21,318
그리고 이것을 사용하고 반복 횟수만큼 반복하십시오.

1225
01:04:21,318 --> 01:04:24,313
기본적으로 판별자를 훈련시키는 것.

1226
01:04:24,313 --> 01:04:26,452
그리고 나서 우리는 우리의 두 번째 단계로갑니다.

1227
01:04:26,452 --> 01:04:28,803
발전기를 훈련시키는 것입니다.

1228
01:04:28,803 --> 01:04:32,544
여기에서는 노이즈 샘플의 작은 배치를 샘플링합니다.

1229
01:04:32,544 --> 01:04:36,205
우리는 이것을 발전기를 통해 전달할 것이고, 이제 우리는

1230
01:04:36,205 --> 01:04:40,288
근본적으로 우리를 최적화하기 위해
이것에 백도핑을하고 싶습니다.

1231
01:04:42,264 --> 01:04:45,078
우리가 전에 보았던 발전기 목표.

1232
01:04:45,078 --> 01:04:48,038
그래서 우리는 우리의 생성기를 우리의
판별 자로 속이기를 원합니다.

1233
01:04:48,038 --> 01:04:49,705
가능한 한 많이.

1234
01:04:50,773 --> 01:04:54,940
그래서 우리는이 두 단계를 번갈아 가려고합니다.

1235
01:04:56,041 --> 01:04:58,410
우리의 discriminator에
대한 그라디언트 단계를 복용의

1236
01:04:58,410 --> 01:04:59,996
발전기 용.

1237
01:04:59,996 --> 01:05:02,579
그리고 여기 k 단계를 위해 말했습니다.

1238
01:05:03,474 --> 01:05:06,306
discriminator 훈련을
위해 그리고 이것은 친절하다.

1239
01:05:06,306 --> 01:05:08,604
논쟁 주제의

1240
01:05:08,604 --> 01:05:11,612
어떤 사람들은 판별자를 한 번 반복한다고 생각합니다.

1241
01:05:11,612 --> 01:05:15,391
한 종류의 판별 기, 한 종류의 발전기가 가장 좋습니다.

1242
01:05:15,391 --> 01:05:18,259
어떤 사람들은 판별자를 양성하는
것이 더 바람직하다고 생각합니다.

1243
01:05:18,259 --> 01:05:20,744
발전기로 전환하기 전에 좀 더 길게.

1244
01:05:20,744 --> 01:05:24,771
진짜 확실한 규칙은 없으며

1245
01:05:24,771 --> 01:05:28,552
사람들은 더 잘 작동하기 위해 다른 일을 발견했습니다.

1246
01:05:28,552 --> 01:05:30,732
문제에 따라.

1247
01:05:30,732 --> 01:05:33,693
제가 지적하고자하는 한 가지는

1248
01:05:33,693 --> 01:05:37,838
이 문제를 완화시키는 많은 최근 연구

1249
01:05:37,838 --> 01:05:41,580
당신이 그렇게 많은 노력을 할 필요가 없도록 만듭니다.

1250
01:05:41,580 --> 01:05:45,028
이 두 네트워크의 교육 방법을 균형있게 조정하려고합니다.

1251
01:05:45,028 --> 01:05:47,880
보다 안정적인 교육을 받고 더
나은 결과를 얻을 수 있습니다.

1252
01:05:47,880 --> 01:05:51,822
그래서 Wasserstein GAN은 논문의 한 예입니다.

1253
01:05:51,822 --> 01:05:55,655
그것은 이것을하기위한 중요한 작업이었습니다.

1254
01:06:00,313 --> 01:06:04,417
좋아, 이제 우리가 훈련 한 전체 그림을보고,

1255
01:06:04,417 --> 01:06:06,548
우리는 우리의 네트워크 설정을 가지고 있으며 우리는

1256
01:06:06,548 --> 01:06:09,767
발전기 네트워크와 판별 자 네트워크

1257
01:06:09,767 --> 01:06:11,785
그리고 지금 세대를위한 훈련 후에,

1258
01:06:11,785 --> 01:06:15,009
우리는 단지 우리의 발전기 네트워크를
가지고 이것을 사용할 수 있습니다.

1259
01:06:15,009 --> 01:06:16,899
새로운 이미지를 생성합니다.

1260
01:06:16,899 --> 01:06:19,687
그래서 우리는 단지 잡음 Z를 취해
이것을 통과시키고 생성합니다.

1261
01:06:19,687 --> 01:06:21,520
여기에서 가짜 이미지.

1262
01:06:23,636 --> 01:06:27,352
이제 생성 된 샘플을 살펴 보겠습니다.

1263
01:06:27,352 --> 01:06:28,351
이 GAN들로부터.

1264
01:06:28,351 --> 01:06:31,093
그럼 여기에 MNIST에서 훈련받은 예가 있습니다.

1265
01:06:31,093 --> 01:06:33,099
그리고 Faces의 오른쪽에서.

1266
01:06:33,099 --> 01:06:36,195
그리고 이들 각각에 대해서도 볼 수 있습니다.

1267
01:06:36,195 --> 01:06:39,765
시각화를 위해 가장 가까운, 오른쪽,

1268
01:06:39,765 --> 01:06:42,349
훈련 세트에서 가장 가까운 이웃

1269
01:06:42,349 --> 01:06:43,849
바로 옆에.

1270
01:06:43,849 --> 01:06:45,426
그래서 우리는 우리가 생성 할 수
있다는 것을 알 수 있습니다.

1271
01:06:45,426 --> 01:06:47,810
매우 현실적인 샘플이며 직접 기억하지 못합니다.

1272
01:06:47,810 --> 01:06:49,227
훈련 세트.

1273
01:06:51,264 --> 01:06:54,003
그리고 원래 GAN 논문의 몇 가지 예가 있습니다.

1274
01:06:54,003 --> 01:06:56,061
CIFAR 이미지.

1275
01:06:56,061 --> 01:06:59,960
그리고 이것들은 여전히 공정하고 좋은 품질은 아닙니다.

1276
01:06:59,960 --> 01:07:03,200
이들은 원래 작품은 2014 년,

1277
01:07:03,200 --> 01:07:07,374
그래서 이들은 더 오래되고 간단한 네트워크입니다.

1278
01:07:07,374 --> 01:07:11,541
그리고 이들은 단순하고 완벽하게 연결된
네트워크를 사용하고있었습니다.

1279
01:07:12,550 --> 01:07:14,518
그리고 그 이후로 많은 일들이있었습니다.

1280
01:07:14,518 --> 01:07:16,018
GANs 개선에.

1281
01:07:18,120 --> 01:07:20,905
실제로 큰 걸음을 내디뎠던 작품의 한 예

1282
01:07:20,905 --> 01:07:24,645
샘플의 품질 향상을 향한 노력

1283
01:07:24,645 --> 01:07:29,555
ICLR 2016의 알렉스 래드 포드 (Alex
Radford)에서 길쌈 (convolutional) 추가

1284
01:07:29,555 --> 01:07:31,388
GANs에 아키텍처.

1285
01:07:33,806 --> 01:07:37,663
이 신문에는 일련의 지침이있었습니다

1286
01:07:37,663 --> 01:07:41,926
GAN이 더 잘 생산할 수 있도록 도와주는 아키텍처

1287
01:07:41,926 --> 01:07:42,958
견본.

1288
01:07:42,958 --> 01:07:46,517
그래서 당신은 이것에 대한 자세한 내용을 볼 수 있습니다.

1289
01:07:46,517 --> 01:07:49,217
이것은 길쌈 아키텍처의 예입니다.

1290
01:07:49,217 --> 01:07:52,669
그들이 사용하고있는 것이 우리의
입력 Z에서 나온 것입니다.

1291
01:07:52,669 --> 01:07:55,944
노이즈 벡터 Z와이 모든 변형

1292
01:07:55,944 --> 01:07:57,694
출력 샘플로.

1293
01:08:00,527 --> 01:08:03,437
이제는이 커다란 콘볼 루션 아키텍처

1294
01:08:03,437 --> 01:08:06,446
이 모델의 샘플은 실제로

1295
01:08:06,446 --> 01:08:08,251
아주 좋아 보이기 시작했다.

1296
01:08:08,251 --> 01:08:11,408
그래서 이것은 침실의 데이터 세트에 대해 훈련되었습니다.

1297
01:08:11,408 --> 01:08:15,575
우리는 모든 종류의 매우 현실적인 공상을 볼 수 있습니다.

1298
01:08:16,783 --> 01:08:20,950
창문과 야간 스탠드 및 기타 가구가있는 침실

1299
01:08:22,926 --> 01:08:26,063
그 주위에는 정말 예쁜 샘플들이 있습니다.

1300
01:08:26,064 --> 01:08:29,828
그리고 우리는 또한 무엇을 시도하고 해석 할 수 있습니다.

1301
01:08:29,828 --> 01:08:32,346
이 GAN은하고 있습니다.

1302
01:08:32,346 --> 01:08:36,151
그래서이 예제에서 우리가 할 수있는
것은 우리가 취할 수있는 것입니다.

1303
01:08:36,152 --> 01:08:40,038
두 점 Z, 두 개의 다른 랜덤 잡음 벡터

1304
01:08:40,038 --> 01:08:42,817
그리고이 점들 사이를 보간하자.

1305
01:08:42,818 --> 01:08:45,245
여기에있는 각 행은

1306
01:08:45,245 --> 01:08:50,142
하나의 랜덤 잡음 Z로부터 다른 랜덤 잡음 벡터 Z로

1307
01:08:50,142 --> 01:08:53,207
당신은 그것이 변화하고 있음을 볼 수 있습니다,

1308
01:08:53,207 --> 01:08:55,655
이미지를 부드럽게 보간하고 있습니다.

1309
01:08:55,656 --> 01:08:57,073
끝까지.

1310
01:08:59,286 --> 01:09:02,067
그래서 우리가 할 수있는 다른 일은
우리가 그것을 볼 수 있다는 것입니다,

1311
01:09:02,067 --> 01:09:06,584
자,이 벡터 Z가 무엇인지 더 자세히 분석해 봅시다.

1312
01:09:06,584 --> 01:09:10,313
의미, 그래서 우리는 여기서 벡터
수학을 시도하고 할 수 있습니다.

1313
01:09:10,313 --> 01:09:13,563
이 실험이하는 것은

1314
01:09:14,888 --> 01:09:17,828
알았어. 미소 짓는 모습을 찍자.

1315
01:09:17,828 --> 01:09:22,099
미소 짓는 여성 이미지의 샘플을 가져 와서

1316
01:09:22,100 --> 01:09:25,379
중립 여성의 표본 및 일부 표본

1317
01:09:25,379 --> 01:09:26,629
중립적 인 사람들의

1318
01:09:28,341 --> 01:09:32,049
그래서 Z 벡터의 평균을 취해 봅시다.

1319
01:09:32,050 --> 01:09:34,920
이 샘플들 각각을 생산했고 우리가

1320
01:09:34,920 --> 01:09:38,184
우리가 이것을 가져 가라, 미소
짓는 여자들을위한 평균적인 벡터,

1321
01:09:38,184 --> 01:09:40,783
중성 여성을위한 평균 벡터를 뺀다.

1322
01:09:40,783 --> 01:09:43,786
중립적 인 인간에 대한 평균 벡터를 더하고,

1323
01:09:43,787 --> 01:09:45,037
우리는 무엇을 얻습니까?

1324
01:09:46,651 --> 01:09:49,884
그리고 우리는 웃는 남자의 표본을 얻습니다.

1325
01:09:49,884 --> 01:09:52,200
그래서 우리는 거기에서 생성 된
Z 벡터를 취할 수 있습니다.

1326
01:09:52,200 --> 01:09:56,200
샘플을 생성하고 웃는 남자의 샘플을 얻으십시오.

1327
01:09:57,190 --> 01:09:59,712
그리고 우리는 이것의 또 다른 예를 가질 수 있습니다.

1328
01:09:59,712 --> 01:10:03,879
안경 남자 마이너스 안경 남자와 플러스 안경 여자.

1329
01:10:05,918 --> 01:10:08,763
그리고 안경을 쓰고 여자를 구하십시오.

1330
01:10:08,763 --> 01:10:12,483
그래서 여기 당신은 기본적으로 Z가이
타입을 가지고 있음을 볼 수 있습니다.

1331
01:10:12,483 --> 01:10:16,191
당신이 생성하기 위해 이것을 사용할 수있는 해석 가능성

1332
01:10:16,191 --> 01:10:18,358
아주 멋진 예제들.

1333
01:10:20,026 --> 01:10:22,300
올해는 2017 년이되었습니다.

1334
01:10:22,300 --> 01:10:23,967
GAN의 해.

1335
01:10:24,842 --> 01:10:28,309
GAN에 대한 많은 작업이있었습니다.

1336
01:10:28,309 --> 01:10:31,737
그리고 그것은 정말로 종류의 폭발과 정말로 줬다

1337
01:10:31,737 --> 01:10:33,261
멋진 결과.

1338
01:10:33,261 --> 01:10:37,017
왼쪽의 여기에서 작업하는 사람들을 볼 수 있습니다.

1339
01:10:37,017 --> 01:10:38,680
더 나은 훈련과 세대.

1340
01:10:38,680 --> 01:10:41,454
그래서 우리는 손실 기능 개선에 관해 이야기했습니다.

1341
01:10:41,454 --> 01:10:45,621
더 안정적인 교육 및 이것은 정말 좋은 얻을 수있었습니다.

1342
01:10:47,216 --> 01:10:50,173
다양한 아키텍처 유형의 세대

1343
01:10:50,173 --> 01:10:54,326
아래쪽은 정말 선명한 고해상도의 얼굴입니다.

1344
01:10:54,326 --> 01:10:58,918
GAN을 사용하면 다음과 같은 모델도 있습니다.

1345
01:10:58,918 --> 01:11:01,742
소스를 사용하여 도메인 전송 및
조건부 GAN을 시도합니다.

1346
01:11:01,742 --> 01:11:04,394
그리고 여기에서, 이것은 시도하려고하는 소스의 예입니다.

1347
01:11:04,394 --> 01:11:08,363
예를 들어 상단 부분에서 도메인 전송을 얻습니다.

1348
01:11:08,363 --> 01:11:12,540
여기에서 우리는 말의 근원 영역에서 가려고 노력하고있다.

1349
01:11:12,540 --> 01:11:14,703
얼룩말의 출력 영역으로

1350
01:11:14,703 --> 01:11:18,692
그래서 우리는 말의 이미지를 찍고
GAN을 훈련시킬 수 있습니다.

1351
01:11:18,692 --> 01:11:21,646
출력이 같은 것이 될 것입니다.

1352
01:11:21,646 --> 01:11:25,813
그러나 지금 말과 같은 이미지 설정에서 얼룩말

1353
01:11:28,408 --> 01:11:29,915
다른 방향으로 가십시오.

1354
01:11:29,915 --> 01:11:33,124
우리는 사과를 오렌지로 변형시킬 수 있습니다.

1355
01:11:33,124 --> 01:11:35,128
그리고 또 다른 방법.

1356
01:11:35,128 --> 01:11:38,608
우리는 이것을 사용하여 사진을 향상시킬 수도 있습니다.

1357
01:11:38,608 --> 01:11:41,676
그래서 이것을 제작하고, 표준 사진을 찍습니다.

1358
01:11:41,676 --> 01:11:46,218
네가 가진 것처럼 정말 멋지게 만들려고 노력하는거야.

1359
01:11:46,218 --> 01:11:48,717
당신은 정말 좋은 비싼 카메라를 가지고있는 척.

1360
01:11:48,717 --> 01:11:52,379
멋진 흐림 효과를 얻을 수 있습니다.

1361
01:11:52,379 --> 01:11:55,987
아래쪽에는 장면이 바뀌고,

1362
01:11:55,987 --> 01:11:59,733
요세미티의 이미지를 이미지에서 변형시키는 것

1363
01:11:59,733 --> 01:12:03,750
여름 시간에는 겨울 시간에 이미지로.

1364
01:12:03,750 --> 01:12:05,753
그리고 실제로 많은 응용 프로그램이 있습니다.

1365
01:12:05,753 --> 01:12:08,430
여기 오른쪽에는 더 많은 것이 있습니다.

1366
01:12:08,430 --> 01:12:11,930
텍스트 설명에서 나옵니다.

1367
01:12:13,900 --> 01:12:15,839
이 텍스트를 조건으로하는 GAN

1368
01:12:15,839 --> 01:12:18,343
설명 및 이미지 제작.

1369
01:12:18,343 --> 01:12:21,572
여기에 작은 새에 관한 뭔가가 있습니다.

1370
01:12:21,572 --> 01:12:25,094
분홍색 유방과 크라운을 가지고 지금 우리는

1371
01:12:25,094 --> 01:12:26,421
이 이미지들.

1372
01:12:26,421 --> 01:12:30,588
그리고 여기에 가장자리를 채우는 예제도 있습니다.

1373
01:12:31,808 --> 01:12:34,436
우리가 가지고있는 스케치에 주어진 조건들,

1374
01:12:34,436 --> 01:12:38,603
우리는 이것이 어떻게 생겼는지에 대한
컬러 버전을 채울 수 있습니까?

1375
01:12:40,848 --> 01:12:45,015
Google,지도 그리드를 사용하여
무언가를 넣을 수 있습니까?

1376
01:12:47,127 --> 01:12:49,033
Google 어스처럼 보이지만,

1377
01:12:49,033 --> 01:12:52,528
Google 어스와 같은 모양으로 변환하십시오.

1378
01:12:52,528 --> 01:12:55,492
들어가서이 모든 건물과 나무를 환각 시키십시오.

1379
01:12:55,492 --> 01:12:56,767
등등.

1380
01:12:56,767 --> 01:12:59,825
그래서 이것에 대한 정말 멋진 예제가 많이 있습니다.

1381
01:12:59,825 --> 01:13:03,575
그리고 pics to pics를위한이 웹 사이트도있다.

1382
01:13:04,591 --> 01:13:06,869
이러한 종류의 조건부 GAN 유형을 많이 수행했습니다.

1383
01:13:06,869 --> 01:13:08,077
예.

1384
01:13:08,077 --> 01:13:12,244
좀 더 재미있게 볼 것을 권합니다.

1385
01:13:13,450 --> 01:13:17,549
사람들이 GAN으로 수행 한 애플리케이션

1386
01:13:17,549 --> 01:13:20,473
연구 논문의 관점에서 볼 때

1387
01:13:20,473 --> 01:13:24,640
올해 GAN에 관한 수많은 논문이 있습니다.

1388
01:13:26,047 --> 01:13:29,528
GAN 동물원이라는 웹 사이트가 있습니다.

1389
01:13:29,528 --> 01:13:31,365
이것들의 전체 목록을 컴파일하려고합니다.

1390
01:13:31,365 --> 01:13:35,036
그리고 여기 이것은 단지 나를 통해 A에서 C 걸렸습니다.

1391
01:13:35,036 --> 01:13:37,690
왼쪽의 오른쪽과 같은 L을 통해.

1392
01:13:37,690 --> 01:13:40,076
따라서 슬라이드에는 맞지 않습니다.

1393
01:13:40,076 --> 01:13:42,446
당신이 볼 수있는 수많은 종이가 있습니다.

1394
01:13:42,446 --> 01:13:44,794
당신이 관심이 있다면.

1395
01:13:44,794 --> 01:13:48,961
그리고 마지막 포인터 하나가 팁과 트릭을위한 것입니다.

1396
01:13:49,927 --> 01:13:53,348
GAN 교육을 위해 여기에 멋진
작은 웹 사이트가 있습니다.

1397
01:13:53,348 --> 01:13:57,259
이 GAN을 훈련 시키려고한다면 포인터가 있습니다.

1398
01:13:57,259 --> 01:13:58,342
실제로.

1399
01:14:01,313 --> 01:14:03,396
좋아, GAN의 요약.

1400
01:14:04,336 --> 01:14:06,915
GAN은 명시 적 밀도 함수로 작동하지 않습니다.

1401
01:14:06,915 --> 01:14:10,036
대신 우리는 이것을 암묵적으로 표현하려고합니다.

1402
01:14:10,036 --> 01:14:13,989
샘플을 사용하여 교육에 대한 게임
이론 접근 방식을 취합니다.

1403
01:14:13,989 --> 01:14:16,092
그래서 우리는 우리의 훈련에서
생성하는 법을 배울 것입니다.

1404
01:14:16,092 --> 01:14:18,973
두 플레이어 게임 설정을 통한 배포.

1405
01:14:18,973 --> 01:14:21,947
그리고 GAN의 프로들은 그들이 정말로

1406
01:14:21,947 --> 01:14:24,934
예술 샘플의 화려한 상태와 당신은 많이 할 수 있습니다.

1407
01:14:24,934 --> 01:14:26,212
이것들과.

1408
01:14:26,212 --> 01:14:29,580
단점은 그들이 더 까다 롭고 불안정하다는 것입니다.

1409
01:14:29,580 --> 01:14:33,247
훈련을 위해, 우리는 단지 직접 최적화하지 않습니다.

1410
01:14:36,499 --> 01:14:40,054
우리가 바로 할 수있는 하나의 목적 함수

1411
01:14:40,054 --> 01:14:41,830
쉽게 훈련 할 수 있습니다.

1412
01:14:41,830 --> 01:14:44,648
대신 우리는 우리가 시도하고있는이 두
가지 네트워크를 가지고 있습니다.

1413
01:14:44,648 --> 01:14:47,710
훈련과 균형을 맞추기 위해 좀 더 불안정 할 수 있습니다.

1414
01:14:47,710 --> 01:14:50,979
그리고 우리는 할 수 없다는 것을 잊을 수 있습니다.

1415
01:14:50,979 --> 01:14:54,915
어떤 추론 질의들, X의 P, 주어진 Z의 P

1416
01:14:54,915 --> 01:14:57,629
VAE에서 예를 들어 보았습니다.

1417
01:14:57,629 --> 01:15:00,051
그리고 GAN은 여전히 활발한 연구 분야이며,

1418
01:15:00,051 --> 01:15:04,427
이것은 우리가 시작하고있는 비교적
새로운 유형의 모델입니다.

1419
01:15:04,427 --> 01:15:07,040
많은 것을보기 위해 당신은 훨씬 더 많이 볼 것입니다.

1420
01:15:07,040 --> 01:15:11,556
그래서 사람들은 더 나은 손실 기능을
위해 지금 일하고 있습니다.

1421
01:15:11,556 --> 01:15:14,994
보다 안정적인 교육, 그래서 Wasserstein GAN

1422
01:15:14,994 --> 01:15:18,994
관심있는 사람들은 기본적으로

1423
01:15:20,585 --> 01:15:22,224
이 방향의 개선.

1424
01:15:22,224 --> 01:15:25,099
이제는 많은 사람들이 모델을 사용하고 기초하고 있습니다.

1425
01:15:25,099 --> 01:15:26,387
떨어져.

1426
01:15:26,387 --> 01:15:29,759
LSGAN, Least Square의 GAN,

1427
01:15:29,759 --> 01:15:31,489
최소한 Square의 GAN 및 기타.

1428
01:15:31,489 --> 01:15:32,871
그래서 당신은 이것을 더 자세히 볼 수 있습니다.

1429
01:15:32,871 --> 01:15:35,285
그리고이 새로운 모델을위한 많은 시간

1430
01:15:35,285 --> 01:15:37,108
실제로이를 구현하는 측면에서,

1431
01:15:37,108 --> 01:15:39,307
반드시 큰 변화는 아닙니다.

1432
01:15:39,307 --> 01:15:41,622
그들은 당신이 바꿀 수있는 다른 손실 함수입니다.

1433
01:15:41,622 --> 01:15:43,407
조금이라도 큰 개선이되다.

1434
01:15:43,407 --> 01:15:44,279
훈련 중.

1435
01:15:44,279 --> 01:15:47,159
그래서 이것들 중 일부는 다음을 조사 할 가치가 있습니다.

1436
01:15:47,159 --> 01:15:50,115
숙제에 대한 연습을하게됩니다.

1437
01:15:50,115 --> 01:15:51,500
할당.

1438
01:15:51,500 --> 01:15:54,410
또한 여러 유형의 작업에 많은 작업이 있습니다.

1439
01:15:54,410 --> 01:15:57,279
조건부 GAN 및 GAN은 모든 종류의 다른

1440
01:15:57,279 --> 01:15:59,946
문제 설정 및 응용 프로그램.

1441
01:16:01,648 --> 01:16:03,507
좋아, 오늘의 정리.

1442
01:16:03,507 --> 01:16:05,807
우리는 생성 모델에 대해 이야기했습니다.

1443
01:16:05,807 --> 01:16:08,538
우리는 가장 일반적인 세대의 3
가지 유형에 대해 이야기했습니다.

1444
01:16:08,538 --> 01:16:12,329
사람들이 사용하고 있고 연구를하고있는 모델.

1445
01:16:12,329 --> 01:16:15,098
그래서 우리는 먼저 pixelRNN과
pixelCNN에 대해 이야기했습니다.

1446
01:16:15,098 --> 01:16:17,588
이것은 명시적인 밀도 모델이다.

1447
01:16:17,588 --> 01:16:20,710
정확한 확률을 최적화하고 좋은 결과를 산출합니다.

1448
01:16:20,710 --> 01:16:24,607
샘플을 사용하지만 꽤 비효율적입니다.

1449
01:16:24,607 --> 01:16:26,981
순차 생성.

1450
01:16:26,981 --> 01:16:29,902
VAE를 살펴보면,

1451
01:16:29,902 --> 01:16:32,696
가능성에 묶여 있고 이것은 또한

1452
01:16:32,696 --> 01:16:35,090
유용한 잠재 표현.

1453
01:16:35,090 --> 01:16:36,890
추론 쿼리를 할 수 있습니다.

1454
01:16:36,890 --> 01:16:40,305
그러나 예제의 품질은 여전히 최고가 아닙니다.

1455
01:16:40,305 --> 01:16:42,715
약속이 많아도 여전히 그렇습니다.

1456
01:16:42,715 --> 01:16:46,583
매우 활발한 연구 분야이며 많은 것을 가지고있다.

1457
01:16:46,583 --> 01:16:47,657
열린 문제.

1458
01:16:47,657 --> 01:16:51,654
그리고 나서 우리가 이야기 한 GAN은 게임 이론적

1459
01:16:51,654 --> 01:16:55,089
훈련을위한 접근법이며 현재 달성되는 것입니다.

1460
01:16:55,089 --> 01:16:57,375
최고의 예술적 사례.

1461
01:16:57,375 --> 01:17:00,253
그러나 훈련이 까다 롭고 불안정 할 수도 있습니다.

1462
01:17:00,253 --> 01:17:05,047
추측 쿼리에서 약간의 손실이 발생합니다.

1463
01:17:05,047 --> 01:17:08,108
그래서 여러분도 볼 수있는 것은 많은 최근 연구입니다.

1464
01:17:08,108 --> 01:17:10,239
이러한 종류의 모델의 조합.

1465
01:17:10,239 --> 01:17:12,733
그래서 예를 들어 adversarial autoencoders입니다.

1466
01:17:12,733 --> 01:17:14,865
추가로 훈련 된 VAE와 같은 것

1467
01:17:14,865 --> 01:17:18,478
샘플 품질을 향상시키는 상단의 적자 손실.

1468
01:17:18,478 --> 01:17:21,517
pixelVAE와 같은 것들도 있습니다.

1469
01:17:21,517 --> 01:17:23,848
pixelCNN과 VAE의 조합이 많아서

1470
01:17:23,848 --> 01:17:28,015
기본적으로 모든 세계를 최대한 활용하려고 노력합니다.

1471
01:17:29,808 --> 01:17:32,444
함께 모아라.

1472
01:17:32,444 --> 01:17:35,000
좋아, 오늘 우리는 생성 모델에 대해 이야기했다.

1473
01:17:35,000 --> 01:17:38,449
다음에 우리는 강화 학습에 관해 이야기 할 것입니다.

1474
01:17:38,449 --> 01:17:40,449
감사.

