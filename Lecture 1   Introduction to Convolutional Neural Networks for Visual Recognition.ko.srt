1
00:00:00,000 --> 00:00:06,000
Translated by visionNoob, KNU
https://github.com/insurgent92/CS231N_17_KOR_SUB

2
00:00:07,041 --> 00:00:09,708
 CS231n 수업에 오신 것을 환영합니다.

3
00:00:11,362 --> 00:00:15,107
이번 수업을 다시 진행하게 되어 영광입니다.

4
00:00:15,107 --> 00:00:21,523
CS231n 수업은 정말 빠르게 성장하고 있습니다.

5
00:00:21,123 --> 00:00:24,034
이번으로 세 번째 개설되었는데요

6
00:00:24,034 --> 00:00:26,066
처음에는 150명으로 시작했죠

7
00:00:26,066 --> 00:00:28,600
지난 해에는 350명이 수강하였습니다. 두 배지요.

8
00:00:28,600 --> 00:00:34,406
올해에는 또 두 배가 늘어서 오늘 아침에 확인했을 때
약 730 명의 학생이 수강신청을 해주셨습니다.

9
00:00:34,406 --> 00:00:39,694
안타깝게도 강의실 제한으로 수업에 참여하지 못하는 분들도 계십니다.

10
00:00:39,694 --> 00:00:44,531
하지만 강의 동영상이 두 시간 내로
SCPD 웹 사이트에 게시 될 것입니다.

11
00:00:44,531 --> 00:00:50,489
오늘 여기 와서 수업을 듣지 못했어도
몇 시간 후면 바로 확인 하실 수 있습니다.

12
00:00:50,489 --> 00:00:54,676
CS231n은 컴퓨터 비전에 관한 수업입니다.

13
00:00:54,676 --> 00:00:57,012
그렇다면 컴퓨터 비전(Computer Vision)이 무엇일까요?

14
00:00:57,012 --> 00:00:59,741
컴퓨터비전은 시각데이터(visual data)와
관련된 연구입니다.

15
00:00:59,741 --> 00:01:05,819
요즘은 워낙 컴퓨터비전이 유명해서 제가 굳이
이 분야의 중요성을 강조할 필요는 없겠지만

16
00:01:05,819 --> 00:01:09,632
어쨌든 전 계속 컴퓨터비전의 중요성을 강조할 것입니다.

17
00:01:09,632 --> 00:01:15,361
최근 몇 년간 엄청나게 많은 시각 데이터가
쏟아져 나오고 있습니다.

18
00:01:15,361 --> 00:01:19,998
이런 수 많은 데이터들은 전 세계 각처에 퍼져있는
무수한 센서들로 비롯됩니다.

19
00:01:19,998 --> 00:01:22,664
요즘은 스마트폰이 없는 분들을 더 찾기 힘듭니다.

20
00:01:22,664 --> 00:01:26,589
여러분의 스마트폰에는 한 두개의 카메라가 내장되어 있습니다.
많으면 세 개까지도 말이죠

21
00:01:26,589 --> 00:01:30,714
아마 카메라의 수가 전 세계 인구수보다 많을지도 모릅니다.

22
00:01:30,714 --> 00:01:38,108
이런 카메라와 같은 센서들이 전 세계 각지에서
매일매일 데이터를 쏟아내고 있는 실정입니다.

23
00:01:38,108 --> 00:01:46,625
CISCO에서 수행한 2015 ~ 2017년도 까지의 한 통계자료가
이 사실을 아주 적나라하게 보여줍니다.

24
00:01:46,719 --> 00:01:54,084
통계에 따르면 인터넷 트래픽 중 80%의 지분은 바로
비디오 데이터입니다.

25
00:01:54,084 --> 00:02:00,125
심지어 이 결과는 사진과 같은 다른 시각
데이터들을 모두 제외한 결과이죠

26
00:02:00,125 --> 00:02:07,076
이 통계는 인터넷의 대부분의 데이터가
시각 데이터라는 사실을 보여줍니다.

27
00:02:07,076 --> 00:02:12,757
그러니 시각 데이터들을 잘 활용할 수 있는
알고리즘을 잘 개발하는 것이 무엇보다 중요하겠죠

28
00:02:12,757 --> 00:02:17,413
하지만 문제 있습니다. 이런 시각데이터는
해석하기 상당히 까다롭다는 점이죠

29
00:02:17,413 --> 00:02:24,126
일부는 시각 데이터를 암흑물질(dark matter)이라고 합니다.

30
00:02:24,126 --> 00:02:27,037
물리학 수업에서 암흑물질을 들어본 분들도 계실테지만

31
00:02:27,037 --> 00:02:32,977
우주의 대부분의 질량을 차지하고
있는 물질이 바로 암흑 물질입니다.

32
00:02:32,977 --> 00:02:37,893
우리는 여러가지 간접적인 측정실험을 통해서
암흑물질의 "존재" 까지는 알 수 있었지만

33
00:02:37,893 --> 00:02:40,135
암흑물질을 직접적으로 "관측" 할 수는 없습니다.

34
00:02:40,135 --> 00:02:42,438
시각데이터 사실 그렇습니다

35
00:02:42,438 --> 00:02:55,285
시각 데이터가 대부분이지만 사실상 이들을
이해하고 해석하는 일은 상당히 어렵습니다.

36
00:02:55,285 --> 00:02:58,066
Youtube의 통계자료도 있습니다.

37
00:02:58,066 --> 00:03:07,346
 YouTube는 매 초마다 다섯 시간 분량의
비디오가 업로드된다고 합니다.

38
00:03:07,346 --> 00:03:15,196
우리가 "하나... 둘... 셋..." 세고 나면
YouTube에는 15시간 분량의 비디오가 새로 추가된 것이지요

39
00:03:16,676 --> 00:03:23,746
Google 직원이 아무리 많아도 이 모든 비디오를  직접 보고,
이해하고, 정리한다는 것은 사실상 불가능한 일입니다.

40
00:03:23,746 --> 00:03:28,961
따라서 그들이 비디오들을 잘 정리해서 유저들에게 제공하고
또 비디오에 적절한 광고를 달기 위해서는

41
00:03:28,961 --> 00:03:36,653
자동으로 시각데이터를 이해, 분석하는 알고리즘을
개발하는 것이 관건인 셈입니다.

42
00:03:38,249 --> 00:03:47,164
컴퓨터 비전이라는 분야 주변에는 상당이 많은 분야들이 혼재합니다.
따라서 다양한 과학, 공학 분야들과 맞닥뜨리게 됩니다.

43
00:03:47,164 --> 00:03:50,422
컴퓨터비전이 우주(universe)의 중심이라 할 수 있겠죠

44
00:03:50,422 --> 00:03:56,053
하지만 컴퓨터비전 뿐만 아니라
물리학을 다뤄야 할 수도 있습니다.

45
00:03:56,053 --> 00:04:01,384
 광학, 이미지 구성, 이미지의 물리학적 형성등을 이해하려면
물리학적인 현상들을 이해할 필요가 있기 때문입니다.

46
00:04:01,384 --> 00:04:03,595
생물학이나 심리학도 알아야 합니다.

47
00:04:03,595 --> 00:04:09,494
동물의 뇌가 어떤 방식으로 시각정보를
물리적으로 "보고 처리하는지" 를 이해하려면 말이죠

48
00:04:09,494 --> 00:04:13,905
물론 그 밖에 컴퓨터 과학, 수학, 그리고 공학 등도 다룹니다.

49
00:04:13,905 --> 00:04:19,239
컴퓨터비전 알고리즘을 구현할 컴퓨터시스템을
실제로 구축할 때 필요한 분야들이죠

50
00:04:19,240 --> 00:04:25,592
그럼 이제 저를 포함한 이 수업의 교수진과
운영진을 간단히 설명해 드리겠습니다.

51
00:04:25,592 --> 00:04:33,206
저와 Serena는 Fei-Fei Li 교수님의 지도 하에 있는
Stanford Vision Lab의 박사과정 (PhD) 학생 입니다.

52
00:04:33,206 --> 00:04:40,784
그리고 저희 Lab은 기계학습과 컴퓨터과학에
관련된 연구들을 진행하고 있습니다.

53
00:04:40,784 --> 00:04:42,908
저 같은 경우에는 Language와 Vision에 좀 더 집중하고 있습니다.

54
00:04:42,908 --> 00:04:44,500
저희 Lab에서는 다양한 연구를 진행하고 있습니다.

55
00:04:44,500 --> 00:04:49,375
그 밖에도 Lab에서는 신경과학과 인지과학과 관련된 분야도 연구합니다.

56
00:04:52,141 --> 00:04:57,157
아마도 여러분은 CS231n이 Stanford의 다른 수업들과
어떤 연관성이 있는지 궁금하실 것입니다.

57
00:04:57,157 --> 00:05:02,448
이 수업은 여러분이 컴퓨터비전의 기초개론을
알고 있다고 가정하고 수업을 진행합니다.

58
00:05:02,448 --> 00:05:06,526
그러니 만일 여러분이 학부생이거나
혹은 컴퓨터비전이 처음이시라면

59
00:05:06,526 --> 00:05:13,829
Fei-Fei 와 Juan Carlos Niebles의 CS131를
선수과목을 수강하셨어야 합니다.

60
00:05:13,829 --> 00:05:24,525
그리고 Chris Mannin & Richard Socher의
딥러닝 & 자연어처리 수업이 지난학기에 있었습니다.

61
00:05:24,525 --> 00:05:28,195
아마 대다수가 지난 학기에 그 수업을 수강 하셨을것 같습니다.

62
00:05:31,082 --> 00:05:33,385
CS231n은 그 수업과 일부 겹치는 부분이 있습니다.

63
00:05:33,385 --> 00:05:40,044
하지만 여기에서는 컴퓨터비전에 초점을 맞춥니다.

64
00:05:40,961 --> 00:05:46,978
또한 Silvio Savarese 교수께서 이번
학기에 CS231a를 강의하십니다.

65
00:05:46,978 --> 00:05:53,610
그리고 CS231a는 컴퓨터비전을 둘러싼
조금 더 넓은 분야들에 초점을 맞추고 있습니다.

66
00:05:53,610 --> 00:06:03,413
3D reconstruction, 로봇 비전 등
CS231n보다 광범위한 분야를 다루게 됩니다.

67
00:06:03,413 --> 00:06:13,386
여기 CS231n은 신경망(Neural Network), 특히 CNN과
관련된 세부 분야를 중점적으로 배우게 될 것입니다.

68
00:06:13,386 --> 00:06:15,828
그리고 이런 알고리즘들은 다양한 테스크에 사용됩니다.

69
00:06:15,828 --> 00:06:18,778
물론 세미나 수업도 진행할 예정입니다.

70
00:06:18,778 --> 00:06:27,467
세미나 일정이 매년 변동하므로 자세한 사항은
강의계획서와 수업시간표를 확인하시길 바랍니다.

71
00:06:27,467 --> 00:06:31,272
보통 첫 수업은 Fei-Fei Li 교수님이 진행하시지만

72
00:06:31,272 --> 00:06:33,774
안타깝게도 오늘 오실 수 없으셨습니다.

73
00:06:33,774 --> 00:06:38,063
대신 Fei Fei 교수님이 안계시므로 다른 방법을 고안했습니다.

74
00:06:38,063 --> 00:06:44,372
교수님께서 Computer Vision의 역사를 소개하는
비디오를  녹화하셨습니다.

75
00:06:44,372 --> 00:06:47,829
이 수업은 컴퓨터비전 수업이기 때문에

76
00:06:47,829 --> 00:06:57,600
오늘날의 CNN을 발전시킨 기존연구의
역사와 흐름을 이해해야만 합니다.

77
00:06:58,100 --> 00:06:59,600
가상의 Fei Fei 교수님을 소개하겠습니다.

78
00:06:59,998 --> 00:07:01,515
[웃음]

79
00:07:01,515 --> 00:07:05,100
여러분께 컴퓨터비전의 역사를 간단히 소개해 주실 것입니다.

80
00:07:08,210 --> 00:07:20,220
자 우선 오늘의 강의목표를 살펴 보겠습니다. 두 가지 주제가 있습니다.
컴퓨터비전의 역사와 우리 CS231n 수업의 개요입니다.

81
00:07:20,220 --> 00:07:35,700
그렇다면 비전(시각)과 컴퓨터비전이 언제 어디에서 비롯됬고
현재는 어디쯤에 왔는지를 알아 보겠습니다.

82
00:07:35,700 --> 00:07:44,370
비전의 역사는 아주 오래 전으로 돌아갑니다.
정확하게는 5억 4천만년 전이죠.

83
00:07:44,370 --> 00:07:50,400
그 시대의 삶은 어땠을까요?
지구의 대부분은 물이었고

84
00:07:50,520 --> 00:07:57,900
바다를 부유하는 일부 생물들만 존재했습니다.

85
00:07:57,900 --> 00:08:03,330
이들의 삶은 단조로웠습니다. 그들은 많이 움직이지 않았고
눈(eyes)같은건 존재하지 않았습니다.

86
00:08:03,330 --> 00:08:09,240
먹이가 주변에 있으면 잡아먹고 없으면
그저 둥둥 떠있는 것이 다였습니다.

87
00:08:09,240 --> 00:08:16,740
하지만 5억 4천만년 전에 아주 놀라운 사건이 벌어졌습니다.

88
00:08:16,740 --> 00:08:33,420
동물 학자들은 화석을 연구하면서 천 만년 이라는 아주 짧은 시기동안에
생물의 종이 폭발적으로 늘어났다는 것을 발견했습니다.

89
00:08:33,420 --> 00:08:41,100
얼마 없던 종의 수가 수십 만이 된 것입니다.
정말 신기한 일이었습니다. 이유가 무엇이었을까요?

90
00:08:41,100 --> 00:08:55,140
많은 가설이 있었지만 여전히 수 년간 풀지못한 숙제였습니다.
진화 생물학자들은 이를 "진화의 빅뱅" 이라고 불렀습니다.

91
00:08:55,140 --> 00:09:00,899
몇해 전 오스트레일리아의 동물학자인 앤드류 파커는
화석 연구를 통해 가장 설득력 있는 가설 제안하였습니다.

92
00:09:00,899 --> 00:09:18,910
그는 약 5억 4천만 년 전 최초의 눈(eyes)이 생겨났다는
것을 발견했습니다. 비젼(시각)의 탄생이

93
00:09:18,910 --> 00:09:26,210
폭발적인 종 분화의 시기를 촉발시킨 것입니다. 생물들은
갑자기 볼 수 있게 되었습니다. 볼 수 있다면 삶은

94
00:09:26,210 --> 00:09:32,180
훨씬 더 능동적이됩니다. 일부 포식자들은 먹이를 찾아다니고

95
00:09:32,180 --> 00:09:39,580
먹이들은 포식자로부터 달아나야만 했죠.
그래서 비전의 도래는

96
00:09:39,580 --> 00:09:46,460
진화적 군비경쟁을 촉발시켰고  생물들은
한 종으로써 살아남기 위해서 빠르게 진화해야 했습니다.

97
00:09:46,460 --> 00:09:54,470
이것이 바로 비전의 태동입니다  5억 4천만년 후(현재)

98
00:09:54,470 --> 00:10:00,980
비전은 거의 모든 동물들, 특히 지능을 가진 동물들의

99
00:10:00,980 --> 00:10:09,260
가장 큰 감각 체계로 발전했습니다.
우리 인간은 대뇌 피질의 50% 가량의 뉴런이

100
00:10:09,260 --> 00:10:15,050
시각처리를 관여합니다.
비전은 가장 큰 감각체계이며

101
00:10:15,050 --> 00:10:22,190
우리가 생존하고, 일을 하고,
움직이고, 어떤 것들을 다루고,

102
00:10:22,190 --> 00:10:29,330
의사소통하고, 오락을 즐기는 등 많은 것들을 가능하게 해줍니다.
비전은 동물들에게 중요하며

103
00:10:29,330 --> 00:10:38,530
특히 지능을 가진 동물들에게 정말 중요합니다.
지금까지는 생물학적 비전의

104
00:10:38,530 --> 00:10:47,929
짧은 줄거리였습니다만, 그렇다면 인간이 만든 공학적 비전인
카메라의 역사는 어떨까요?

105
00:10:47,929 --> 00:10:56,050
오늘날 우리가 알고있는 초창기의 카메라는

106
00:10:56,050 --> 00:11:04,010
1600년대 르네상스 시대의 카메라인 obscura입니다.

107
00:11:04,010 --> 00:11:13,330
이 카메라는 핀홀 카메라 이론을 기반으로한 카메라입니다.

108
00:11:13,330 --> 00:11:20,990
Obscura는 생물학적으로 발전한 초기의 눈과 상당히 유사합니다.
빛을 모아주는 구멍이 하나 있고

109
00:11:20,990 --> 00:11:27,620
카메라 뒷편의 평평한 면은 정보를 모으고

110
00:11:27,620 --> 00:11:36,160
이미지를 투영합니다. 카메라 기술이 발전하면서
오늘날 카메라는 어디에나 있습니다.

111
00:11:36,160 --> 00:11:40,510
카메라는 스마트폰 카메라나 다른 여러 기기에 이르기까지
사람들이 사용하는 가장 인기있는 센서중 하나가 되었습니다.

112
00:11:40,510 --> 00:11:56,110
그동안에 생물학자들은 비전의 매커니즘을 연구하기 시작했습니다.
인간과 동물의 비전에 연구에 가장 영향력있었을 뿐만 아니라

113
00:11:56,110 --> 00:12:10,450
컴퓨터비전에도 영감을  준 한 연구가 있었습니다. 1950/60년대
전기생리학을 이용한 Hubel과 Wiesel의 연구입니다.

114
00:12:10,450 --> 00:12:17,770
그들이 묻고싶었던 질문은 바로
"포유류의 시각적 처리 메커니즘은 무엇일까?" 였습니다.

115
00:12:17,770 --> 00:12:26,200
그래서 그들은 고양이의 뇌를 연구하기로 합니다.

116
00:12:26,200 --> 00:12:31,690
시각 처리 매커니즘만 보면
고양이와 인간은 비슷합니다.

117
00:12:31,690 --> 00:12:45,430
그들의 고양이 두뇌 뒷 면에 전극 몇 개를 꽂았습니다.
"일차 시각 피질"이 있는 곳이었죠

118
00:12:45,430 --> 00:12:52,570
그리고 어떤 자극을 줘야 일차 시각 피질의 뉴런들이
격렬하게 반응 하는지 관찰하였습니다.

119
00:12:52,570 --> 00:12:59,980
그들은일차 시각 피질에는 댜양한 종류의
세포가 있다는 것을 알았습니다.

120
00:12:59,980 --> 00:13:11,680
그중 가장 중요한 세포가 있었는데 그 세포들은 아주 단순했습니다.
경계(edges)가 움직이면 이에 반응하는 세포들이었습니다.

121
00:13:11,680 --> 00:13:25,660
물론 더 복잡한 세포들도 있긴 하지만, 주된 발견은
시각 처리가 처음에는 단순한 구조로 시작되며

122
00:13:25,660 --> 00:13:38,160
그 정보가 통로를 거치면서 점점 복잡해 진다는 것입니다.

123
00:13:38,160 --> 00:13:45,880
실제 세상을 제대로 인지할 수 있을 때 까지 말이죠.

124
00:13:45,880 --> 00:13:54,670
컴퓨터비전의 역사는 60년대 초반에 태동합니다.
Block World는 Larry Roberts의 연구는

125
00:13:54,670 --> 00:14:06,850
아마도 컴퓨터비전 분야에서의 최초의 박사 학위논문입니다.

126
00:14:06,850 --> 00:14:13,450
이 연구에서는 우리 눈에 보이는 사물들을
기하학적 모양으로 단순화 시켰습니다.

127
00:14:13,450 --> 00:14:23,019
이 연구의 목표는 우리 눈에 보이는 세상을 인식하고
그 모양을 재구성 하는 일이었습니다.

128
00:14:23,019 --> 00:14:31,150
1966년에는 MIT 여름 프로젝트가 하나 진행되었는데, 아주 유명하죠
바로 "The Summer Vision Project" 입니다.

129
00:14:31,150 --> 00:14:38,040
당시 프로젝트의 목표는, 제가 읽어드리겠습니다.
"시각 시스템의 전반을 구현하기 위해서

130
00:14:38,040 --> 00:14:43,840
프로젝트 참가자들을 효율적으로 이용하는 것."
이였습니다.

131
00:14:43,840 --> 00:14:47,380
다시 말해  그들은 그 여름 안에 대부분의 시각 체계를 구현해
내려는 야심찬 목표를 세우고 있었던 것입니다.

132
00:14:47,380 --> 00:14:54,190
이는 아주 야심 찬 목표였습니다.
그로부터 50년이 지났습니다.

133
00:14:54,190 --> 00:15:01,840
"컴퓨터비전"이라는 분야가 한 여름 프로젝트에서 피어나서는

134
00:15:01,840 --> 00:15:13,540
현재 전 세계 수천 명의 연구자들이 아직도 비전의
가장 근본적인 문제들을 연구를 하고 있습니다.

135
00:15:13,540 --> 00:15:20,980
컴퓨터비전은 인공지능 분야에서 가장 중요하면서도
가장 빠르게 성장하는 분야중 하나입니다.

136
00:15:20,980 --> 00:15:27,010
언급하지 않을 수 없는 인물하 한 명 더 있습니다.
그는 바로 David Marr입니다.

137
00:15:27,010 --> 00:15:34,150
David Marr은 MIT의 비전 과학자였으며
그는 70년대 후기에 아주 유명한 책을 한권 저술합니다.

138
00:15:34,150 --> 00:15:47,800
이 책은 그가 비전을 무엇이라 생각하는지, 그리고 어떤 방향으로 컴퓨터
비전이 나아가야 하느지, 그리고 컴퓨터가 비전을 인식하게 하기 위해

139
00:15:47,800 --> 00:15:56,620
어떤 방향으로 알고리즘을 개발해야 하는지를 다룬 책이었습니다.

140
00:15:56,620 --> 00:16:10,239
그는 그의 저서에서, 우리가 눈으로 받아드린 "이미지"를
 "최종적인 full3D 표현"으로 만드려면

141
00:16:10,240 --> 00:16:15,960
몇 단계의 과정을 거쳐야만 한다고 주장했습니다.
첫 단계는, 그가 부르길  "Primal Sketch" 라고 하는 단계입니다.

142
00:16:15,960 --> 00:16:22,660
이 과정은 주로 경계(edges), 막대(bars),
끝(ends), 가상의 선(virtual lines),

143
00:16:22,660 --> 00:16:28,570
커브(curves), 경계(boundaries)가 표현되는 과정입니다.
이 과정은 신경과학자들에게 영감을 받은 것들이죠.

144
00:16:28,570 --> 00:16:41,020
Hubel과 Wiesel은 시각처리의 초기 단계는 경계와 같은
단순한 구조와 아주 밀접한 관계가 있다고 했었죠

145
00:16:41,020 --> 00:16:45,460
경계와 커브 이후의 다음 단계는, 그가 부르기로는

146
00:16:45,460 --> 00:16:51,900
"2.5-D sketch"라는 단계이며 이 단계에서는
시각 장면을 구성하는 표면(surfaces) 정보,

147
00:16:51,900 --> 00:16:58,440
깊이 정보, 레이어, 불연속 점과 같은 것들을 종합합니다.

148
00:16:58,450 --> 00:17:04,530
그리고 결국에 그 모든 것을 한데 모아서
surface and volumetric primives의 형태의

149
00:17:04,530 --> 00:17:11,179
계층적으로 조직화된 최종적인 3D 모델을 만들어 냅니다.

150
00:17:11,179 --> 00:17:20,319
그리고 이런 방식은 "비전이 무엇인가" 라는 것에 대한 아주
"이상적인" 사고과정 이었습니다. 그리고 이런 방식의 사고방식은

151
00:17:20,320 --> 00:17:25,390
실제로 수십 년간 컴퓨터비전 분야를 지배했으며

152
00:17:25,390 --> 00:17:31,540
학생들이 컴퓨터비전을 처음 입문 하고나서
"어떻게 시각정보를 분석할 수 있을까"라는 질문을 던졌을 때

153
00:17:31,540 --> 00:17:37,830
직관적인 생각해 볼 수 있는 방법이었습니다.

154
00:17:38,910 --> 00:17:47,980
70년대에는 또 다른 아주 중요한 연구들이 있었습니다.

155
00:17:47,980 --> 00:17:54,760
"우리는 어떻게 해야 장난감 같은 단순한 블록 세계를 뛰어 넘어서

156
00:17:54,760 --> 00:18:02,109
실제 세계를 인식하고 표현할 수 있을까?" 라는 질문을 하기 시작했습니다.
70 년대를 생각해보면

157
00:18:02,109 --> 00:18:07,510
그 당시에는 사용할 수있는 데이터가 거의 없었습니다.
컴퓨터도 정말 느렸고

158
00:18:07,510 --> 00:18:19,770
심지어 PC가 보급되기도 전이죠. 이 상황에서 컴퓨터 과학자들은 어떻게
해야 대상을 인식하고 표현할 수 있을 지를 고민하기 시작했습니다.

159
00:18:19,770 --> 00:18:26,249
 Stanford와 SRI에서 과학자들이
서로 비슷한 아이디어를 제안했습니다.

160
00:18:26,249 --> 00:18:32,340
하나는 "commonized cylinde"이고
하나는 "pictorial structure"입니다.

161
00:18:32,340 --> 00:18:39,660
기본 개념은 "모든 객체는 단순한 기하학적 형태로 이루어진다"는 것입니다.

162
00:18:39,660 --> 00:18:45,110
가령 사람은 원통모양을 조합해서 만들 수 있습니다. (왼쪽 그림)

163
00:18:45,110 --> 00:18:55,679
혹은 사람을 "주요 부위"와  "관절" 로 표현할 수도 있을 것입니다.
(오른쪽 그림)

164
00:18:55,679 --> 00:19:10,740
두 방법 모두 단순한 모양과 기하학적인 구성을 이용해서
복잡한 객체를 단순화 시키는 방법입니다.

165
00:19:10,740 --> 00:19:18,820
이러한 연구들은 수 년간 다른 연구에 상당히 많은 영향을 미쳤습니다.

166
00:19:18,820 --> 00:19:33,299
80년대 또 다른 사례로, David Lowe는 어떻게 하면 단순한 구조로
실제 세계를 재구성/인식할 수 있을지 고민했습니다.

167
00:19:33,299 --> 00:19:43,040
David Lowe는 이 연구에서 면도기를 인식하기 위해서 면도기를

168
00:19:43,040 --> 00:19:50,460
선(lines)과 경계(edges) 그리고 직선(straight lines)
그리고 이들의 조합을 이용해서 구성했습니다.

169
00:19:50,460 --> 00:20:00,740
정리해보면 60/70/80년대에는 사람들이 컴퓨터비전으로 어떤 일을
할 수 있을까를 고민한 시대였습니다.

170
00:20:00,749 --> 00:20:10,010
하지만 객체를 인식하는 문제는 너무 어려웠습니다.

171
00:20:10,010 --> 00:20:17,580
지금까지 제가 보여드린 연구들이 모두 아주 대담했고
큰 야망을 가진 시도였지만

172
00:20:17,580 --> 00:20:23,760
그들은 단순한 수준(toy example)에 불과했습니다.

173
00:20:23,760 --> 00:20:30,419
현실세계에서 잘 동작할지를 생각해보면
많이 진보하지 못했다고 할 수 있죠

174
00:20:30,419 --> 00:20:37,619
그래서 컴퓨터비전 연구자들은

175
00:20:37,619 --> 00:20:43,309
우리가 도대체 무슨 실수를 하고 있을까 
고민하다가 한가지 질문을 떠올리게 됩니다.

176
00:20:43,309 --> 00:20:49,800
객체 인식이 너무 어렵다면 우선 객체 분할(segmentation)
이 우선이 아니었을까 라고 말이죠

177
00:20:49,800 --> 00:20:58,360
객체분할은 이미지의 각 픽셀들을 의미있는
방향으로 군집화하는 방법입니다.

178
00:20:58,360 --> 00:21:03,480
픽셀을 모아놔도 사람을 정확히 
인식할 수 없을 지도 모르지만

179
00:21:03,480 --> 00:21:09,740
적어도 배경인 픽셀과 사람이 속해 있을 지도 
모르는 픽셀을 가려낼 수는 있었습니다.

180
00:21:09,740 --> 00:21:14,939
이를 "영상분할(Image Segmentation)"이라고 합니다.
이 문제를 다룬 아주 중요한 연구가 있었는데

181
00:21:14,939 --> 00:21:21,359
 Berkeley 대학의 Jitendra Malik 교수와 
그의 제자인 Jianbo Shi의 연구였습니다.

182
00:21:21,360 --> 00:21:29,480
이 연구는 영상분할 문제를 해결하기 위해서
그래프 이론을 도입했습니다.

183
00:21:29,480 --> 00:21:39,200
그리고 컴퓨터 비전에서 유난히
발전 속도가 빨랐던 분야가 있었습니다.

184
00:21:39,210 --> 00:21:45,450
바로 "얼굴인식" 입니다. 인간에게 가장 
중요한 부위 중 하나가 바로 얼굴이죠.

185
00:21:45,450 --> 00:21:51,379
어쩌면 얼굴이 가장 중요할 수도 있겠군요. 
대략 1999/2000년대에는

186
00:21:51,379 --> 00:22:04,820
"기계학습", 특히나 "통계적 기계학습"  이라는 방법이
점차 탄력을 얻기 시작했습니다.

187
00:22:04,820 --> 00:22:08,787
가령 "Support Vector Machine", "Boosting", -

188
00:22:08,812 --> 00:22:13,312
"Graphical models", 그리고 초기 
"Neural Network" 등이 있었습니다.

189
00:22:13,420 --> 00:22:16,949
그 중 가장 큰 기여를 한 연구는 바로

190
00:22:16,949 --> 00:22:25,539
Paul Viola와 Michael Jones이 AdaBoost를
이용해 실시간 얼굴인식에 성공한 것입니다.

191
00:22:25,539 --> 00:22:31,379
이 연구는 당시 아주 대단한 성과였습니다.  
연구 당시는 2001년 이었고

192
00:22:31,379 --> 00:22:36,330
컴퓨터는 여전히 엄청 느렸습니다. 
하지만 그들의 얼굴인식 알고리즘은

193
00:22:36,330 --> 00:22:42,150
실시간과 가깝게(near-real-time) 인식할 수 
있었고 논문발표 5년이 지난 -

194
00:22:42,150 --> 00:22:58,560
2006년에 Fujifilm은 실시간 얼굴인식을 지원하는
최초의 디지털 카메라를 선보였습니다.

195
00:22:58,560 --> 00:23:05,560
이는 기초과학연구의 성과를 실제 응용제품으로
가장 빠르게 전달한 사례라고 할 수 있습니다.

196
00:23:05,560 --> 00:23:15,120
자! 이제 다시 "어떻게 객체를 잘 인식할 것인가?" 
라는 질문으로 다시한번 돌아가 봅시다.

197
00:23:15,130 --> 00:23:30,900
90년대 후반부터 2010년도 까지의 시대를 풍미했던 알고리즘은
"특징기반 객체인식 알고리즘" 이었습니다. 이 시절 나온 -

198
00:23:30,900 --> 00:23:39,270
아주 유명한 알고리즘이 바로 David Lowe의 SIFT 
feature입니다. 그의 아이디어는 전체 객체를 -

199
00:23:39,270 --> 00:23:47,460
가령, 여기 정지 표지판이 있습니다. 
이 정지 표지판들을 서로 매칭하기는 상당히 어렵습니다.

200
00:23:47,460 --> 00:23:56,810
카메라 앵글이 변할 수 있고, 겹치거나 화각이 변하고 빛도
변하고 객체 자체도 얼마든지 변할 수 있습니다.

201
00:23:57,210 --> 00:24:14,600
하지만 그들은 객체의 특징들 중 일부는 다양한 변화에 조금 더 강인하고
불변하다는 점을 발견했습니다.

202
00:24:14,610 --> 00:24:21,210
그리하여 객체 인식은 객체에서 이와 같은 
중요한 특징들을 찾아내고

203
00:24:21,210 --> 00:24:30,369
그 특징들을 다른 객체에 매칭시키는 과제가 되었습니다. 
이미지 전체를 매칭하는 일보다 훨씬 쉬운 일이었죠.

204
00:24:30,369 --> 00:24:41,660
이 그림은 그 논문에서 가져온 것입니다. 정지표지판
이미지에서 일부 SIFT 특징들을 추출하고

205
00:24:41,660 --> 00:24:49,040
또 다른 정지 표지판에서도 특징을 추출하여
이를 식별하고 매칭합니다.

206
00:24:50,730 --> 00:24:58,930
이미지에 존재하는 "특징" 을 사용하게 되면서

207
00:24:58,930 --> 00:25:06,880
컴퓨터 비전은 또 한번의 도약을 할 수 있었습니다.
그리고 장면 전체를 인식하기에 이르렀습니다.

208
00:25:07,125 --> 00:25:18,865
한 예로, Spatial Pyramid Matching이 있습니다.
기본 아이디어는 우리가 특징들을 잘 뽑아 낼 수만 있다면

209
00:25:18,865 --> 00:25:26,095
그 특징들이 일종의 "단서"를 제공해 줄 수 있다는 것이었죠
이미지가 풍경인지, 부엌인지, 또는 고속도로인지 하는 것을 말이죠.

210
00:25:26,095 --> 00:25:39,475
이 연구는 이미지 내의 여러 부분과 여러 해상도에서 추출한 특징을
하나의 특징 기술자로 표현하고

211
00:25:39,475 --> 00:25:44,525
Support Vector Algorithm을 적용합니다.

212
00:25:44,670 --> 00:25:53,820
이런 방식의 연구들은 사람 인식에도 탄력을 주었습니다.

213
00:25:53,820 --> 00:26:02,880
여러 특징들을 잘 조합해 보자는 시도들이었죠 
사람인식에 관련된 연구들도 아주 많았습니다.

214
00:26:02,880 --> 00:26:10,380
사람인식과 관련된 연구들은 어떻게 해야 사람의 몸을 
현실적으로 모델링할 수 있을지에 관련된 연구였습니다.

215
00:26:10,380 --> 00:26:15,600
그 중 하나는 "Histogram Of Gradients" 
입니다. , 또 한가지는 -

216
00:26:15,600 --> 00:26:26,660
"Deformable Part Models" 입니다. 
그 당시에는 60/70/80년대를 거치고

217
00:26:26,660 --> 00:26:34,050
2000년대를 맞이하고 있었고 
하나의 변곡점을 마주하게 됩니다.

218
00:26:34,050 --> 00:26:46,470
사진의 품질이 점점 좋아졌습니다. 인터넷과 디지털 카메라의 발전은
더더욱 좋은 실험 데이터를 만들어 낼 수 있었습니다.

219
00:26:46,470 --> 00:27:02,730
2000년대 초에 일궈낸 것 중 하나는 바로 컴퓨터 비전이 앞으로 
풀어야할 문제가 무엇인지의 정의를 어느정도 내렸다는 것입니다.

220
00:27:02,730 --> 00:27:12,210
물론 해결해야 할 다양한 문제가 있겠지만 이 또한
아주 중요한 문제였습니다. 바로 "객체인식" 입니다.

221
00:27:12,240 --> 00:27:20,070
제가 여태 말씀드린 것들이 객체인식이지만 2000년대 초 -

222
00:27:20,070 --> 00:27:29,020
우리는 Benchmark Dataset를 모으기 시작했습니다. 
객체인식 기술의 진보를 측정하기 위해서였죠

223
00:27:29,155 --> 00:27:42,600
유명한 Dataset 중 하나는  PASCAL Visual Object Challenge(VOC) 
입니다. 이 데이터 셋에는 20개의 클래스가 있고

224
00:27:42,600 --> 00:27:58,560
여기 보이는 것들과 같이: 기차, 비행기, 사람이 있고 소, 병, 고양이 
등도 있는 것으로 기억합니다. 데이터셋은 클래스 당 수 천 수 만개의

225
00:27:58,560 --> 00:28:12,870
이미지들이 있었으며, 다양한 연구 집단에서 이를 통해 알고리즘의
성능을 테스트했고,  우리는 얼마나 진보했는지를 지켜볼 수 있었습니다.

226
00:28:12,870 --> 00:28:39,000
여기 2007년부터 2012년도 까지의 표가 있습니다. 객체인식
성능은 꾸준히 증가했습니다. 많은 진보가 이루어졌죠

227
00:28:39,000 --> 00:28:54,450
그 무렵, Princeton과 Stanford에 있던 그룹에서 더 어려운 
질문을 던졌습니다. 우리는 이세상의 모든 객체들을

228
00:28:54,450 --> 00:29:01,380
인식할 준비가 되었는가? 였습니다. 
이 질문은 한 사실로부터 비롯되었습니다.

229
00:29:01,380 --> 00:29:09,090
이는 기계학습 알고리즘들로 부터 기인했습니다. 
거의 대부분의 기계학습 알고리즘에게 해당되는 질문이었습니다.

230
00:29:09,090 --> 00:29:21,190
Graphical Model,  SVM, AdaBoost 같은 기계학습 
알고리즘이 트레이닝 과정에서 Overfit을 하는것 같았습니다.

231
00:29:21,190 --> 00:29:33,820
이 문제의 원인 중 하나는 시각 데이터가 너무 복잡하기 떄문이었습니다.
모델은 복잡한 고차원 입력을 받았고 이로인해

232
00:29:33,820 --> 00:29:38,679
모델이 fit하려면 더 많은 파라미터가 요구되었죠

233
00:29:38,679 --> 00:29:45,280
학습 데이터가 부족한 상황에서는 Overfiting이 
훨씬 더 빠르게 발생했고 일반화 능력이 떨어졌습니다.

234
00:29:45,280 --> 00:29:53,560
따라서 우리는 두 가지 동기가 있었습니다. 그 중 하나는 
이 세상의 모든 것들을 인식하고 싶다는 것이었고,

235
00:29:53,560 --> 00:30:02,960
또 하나는 기계학습이 Overfilting을 한번 극복해보자는 것이였습니다.

236
00:30:03,150 --> 00:30:15,950
이 동기를 바탕으로 우리는 ImageNet 프로젝트를 시작했습니다.
구할 수 있는 모든 이미지를 가진 가장 큰 데이터셋을 만들고 싶었습니다.

237
00:30:15,950 --> 00:30:20,110
그리고 이 데이터셋으로 학습도 시킬 수 있고 
Benchmark도 할 수 있도록 말이죠

238
00:30:20,200 --> 00:30:25,540
이 프로젝트는 약 3년정도 걸렸습니다.

239
00:30:25,540 --> 00:30:39,910
어려운 일도 많았습니다, 우선 우리는 인터넷에서 수십억장의 이미지를 
다운받았고,  WordNet 이라는 Dictionary로 정리했습니다.

240
00:30:39,910 --> 00:30:43,060
WordNet에는 수 천가지의 객체 클래스가 있습니다.

241
00:30:43,060 --> 00:30:54,520
그리고 Clever Crowd Engineering trick를 도입했습니다.
이는 Amazon Mechanical Turk에서 사용하는

242
00:30:54,520 --> 00:30:58,360
이미지의 정렬, 정제, 레이블 등을 제공하는 플랫폼 입니다.

243
00:30:58,360 --> 00:31:13,120
그 결과 ImageNet은 대략 15만 장에 달하는 이미지와 22만 가지의 
클래스 카테고리를 보유하게 되었습니다.

244
00:31:13,120 --> 00:31:35,578
정말 거대했고,아마도 당시 AI분야에서 만든 가장 큰 데이터셋 이었습니다.
ImageNet 덕분에 객체인식은 다른 국면으로 접어들었습니다.

245
00:31:35,634 --> 00:31:41,075
그 당시 Image을 어떻게 Benchmark할지가 큰 문제였습니다.

246
00:31:41,075 --> 00:31:57,184
ImageNet 팀은 2009년부터 국제 규모의 대회를 주최했습니다.
ILSVRC입니다. 이 대회를 위해서

247
00:31:57,184 --> 00:32:06,065
1000개의 객체에서 140만개의 test set 이미지를 엄선했습니다.

248
00:32:06,065 --> 00:32:15,104
이 대회는 이미지 분류 문제를 푸는 알고리즘들을 테스트할 수 있었습니다.

249
00:32:15,184 --> 00:32:36,414
여기 예제 이미지가 있습니다. 알고리즘은 5개의 후보 레이블을 선택할
수 있었고, 5개 중에 정답이 있으면 성공한 것이었습니다.

250
00:32:36,439 --> 00:32:51,900
ImageNet Challenge의 Image Classification 의 결과입니다.
2010년도 부터 2015년도 까지의 결과입니다.

251
00:32:51,900 --> 00:33:00,020
 x축으로 연도를 y축으로 오류율을 볼 수 있습니다.

252
00:33:00,020 --> 00:33:05,200
좋은 소식은 오류율이 점차 감소한 다는 점입니다.

253
00:33:09,950 --> 00:33:18,499
2012 오류율이 너무 낮아서 사람이 할 수있는 것과 동등합니다.
여기에서의 사람은

254
00:33:18,499 --> 00:33:35,600
Stanford의 한 박사과정(PhD) 학생입니다
이 대회에 참여한 컴퓨터처럼 이 일로 몇 주를 보냈죠.

255
00:33:35,600 --> 00:33:46,240
앞으로 여러분이 이 수업에서 배우게 될테지만 객체 인식에 대한
모든 문제를 해결하진 못했지만, 분명 진전은 있었습니다.

256
00:33:46,240 --> 00:33:53,620
하지만 실 생활에 적용하기 역부족이었던
오류율에서 부터

257
00:33:53,620 --> 00:33:59,530
ImageNet 챌린지에서 인간과 거의 동등한 수준의
오류율로 오기까지는, 불과 몇년뿐지 걸리지 않았습니다.

258
00:33:59,530 --> 00:34:08,770
그리고 이 그래프에서 여러분이 놓쳐서는 안될
특별한 순간이 있습니다.

259
00:34:08,770 --> 00:34:18,849
바로 2012년 입니다. 처음 2년동안은 오류률이
약 25%였습니다만

260
00:34:18,849 --> 00:34:28,779
2012년에는 오류율이 16%로, 거의 10%가량 떨어졌고,

261
00:34:28,780 --> 00:34:36,099
물론 현재가 더 오류율이 낫긴 하지만
2012년도의 오류율 감소는 매우 중요합니다.

262
00:34:36,099 --> 00:34:45,699
2012년도에 우승한 알고리즘은
CNN 모델입니다.

263
00:34:45,700 --> 00:34:52,980
CNN은 그 당시 다른 모든 알고리즘을 능가하고
ImageNet Challenge에서 우승하였습니다.

264
00:34:52,980 --> 00:35:01,330
그리고 CNN이 바로 우리 강의에서 한 학기동안
주목할 바로 그것입니다.

265
00:35:01,330 --> 00:35:08,830
CNN 모델이 무엇인지를 심도싶게 다룰 것입니다.
그리고 CNN의 다른이름은

266
00:35:08,830 --> 00:35:13,500
Deep Learning 이죠,

267
00:35:13,650 --> 00:35:18,460
유명한 이름으로 CNN을 Deep leraning이라고도 불립니다.

268
00:35:18,460 --> 00:35:23,559
이 모델이 무엇인지, 어떤 법칙이 있는지, 어떤 선례가 있는지,
이 모델의 최근 행보는 어떠한지 를 살펴볼 것입니다.

269
00:35:23,559 --> 00:35:29,530
하지만 여기에 역사가 만들어진 곳이 있습니다.

270
00:35:29,530 --> 00:35:36,130
2012년의 CNN 이라는 Deep learning 모델은

271
00:35:36,130 --> 00:35:44,439
컴퓨터비전 분야의 진보를 이뤄냄으로서,
CNN의 훌륭한 역량과 능력을 보여주었습니다.

272
00:35:44,439 --> 00:35:50,500
자연어 처리나 음성 인식과 같은 다른 자매분야들과도
함께 말이죠

273
00:35:50,500 --> 00:35:55,030
소개는 이쯤 해두고,

274
00:35:55,030 --> 00:36:05,630
CS231n의 개괄에 대한 내용을 위해 이번 강의의 나머지를
Justin에게 맡기도록 하겠습니다.

275
00:36:02,890 --> 00:36:04,653
좋습니다 Fei-Fei 교수님 정말 감사합니다.

276
00:36:06,510 --> 00:36:09,668
제가 여기서 이어 받겠습니다.

277
00:36:09,699 --> 00:36:11,420
지금부터는 다른 이야기를 해야겠네요

278
00:36:11,420 --> 00:36:15,587
좀더 이 CS231n 에 대해
이야기해 보겠습니다.

279
00:36:16,946 --> 00:36:20,146
이 수업은 오로지 한가지에
중점을 둘 것입니다

280
00:36:20,146 --> 00:36:22,324
가장 중요하게 다룰 것은

281
00:36:22,324 --> 00:36:24,460
바로 이미지 분류 문제입니다

282
00:36:24,460 --> 00:36:28,547
우리가 방금 전에 ImageNet Challenge
이야기에서 조금은 들었었죠

283
00:36:28,547 --> 00:36:30,358
다시 이미지 분류로 돌아가 보자면

284
00:36:30,358 --> 00:36:32,980
기본 설정은, 여러분의 알고리즘이 한 장의 이미지를 보고는

285
00:36:32,980 --> 00:36:35,558
몇 개의 고정된 카테고리 안에서 하나는 고르는거죠

286
00:36:35,558 --> 00:36:37,953
이미지를 분류하기 위해서죠

287
00:36:37,953 --> 00:36:41,060
이것이 다소 제한적이거나

288
00:36:41,060 --> 00:36:44,016
인공적으로 보일수 있지만, 사실 매우 일반적이 것입니다.

289
00:36:44,016 --> 00:36:47,031
이 문제는 다양한 환경에 적용될 수 있습니다.

290
00:36:47,031 --> 00:36:51,140
산업현상에서든, 학술적으로든 말이죠, 많은 다양한 곳에서 가능합니다.

291
00:36:51,140 --> 00:36:54,467
예를들어 음식을 인식하거나,

292
00:36:54,467 --> 00:36:56,416
음식의 칼로리를 인식하거나,

293
00:36:56,416 --> 00:36:59,553
다양한 미술작품들을 인식하거나, 이 세상에에 존재하는 여러가지
제품을 일식하는데도 적용할 수 있습니다.

294
00:36:59,553 --> 00:37:03,086
그러니 영상 분류라는 상대적으로 기본적인 이 도구가

295
00:37:03,086 --> 00:37:05,782
독자적으로도 엄청 유용할 수 있고,

296
00:37:05,782 --> 00:37:10,013
다양한 응용을 통해 어느 곳이든 적용할 수 있을 것입니다.

297
00:37:10,013 --> 00:37:15,316
하지만 이 코스에서는 몇 가지 다른 시각 인식 문제에 대해서도
이야기 할 것입니다.

298
00:37:15,316 --> 00:37:21,170
그리고 그것들은 우리가 영상 분류를 위해 개발한
여러 도구들 기반으로 합니다.

299
00:37:21,170 --> 00:37:22,776
우리는 다른 문제들에 대해서도 다룰 것입니다.

300
00:37:22,776 --> 00:37:26,293
객체 디텍션이나
이미지 캡셔닝과 같은 것들이죠

301
00:37:26,293 --> 00:37:28,175
객체 디텍션의 설정은

302
00:37:28,175 --> 00:37:29,945
조금 다릅니다.

303
00:37:29,945 --> 00:37:32,219
전체 이미지를 분류하는 대신에 전체 이미지를

304
00:37:32,219 --> 00:37:35,237
이 이미지는 고양이다, 개다, 말이다 같이 뭐다 라고 하는 대신에

305
00:37:35,237 --> 00:37:37,361
우리는 좀 더 들어가서
경계박스를 그려야 합니다.

306
00:37:37,361 --> 00:37:39,971
그리고 개는 여기있고 고양이는 저기있다는 것을
말해야만 합니다.

307
00:37:39,971 --> 00:37:41,861
저기 뒤에 차가 있다는 것도 말이죠

308
00:37:41,861 --> 00:37:45,620
이미지 안에 객체들이 어디에 있는지를
묘사하는 박스를 그려야 합니다.

309
00:37:45,620 --> 00:37:47,832
이미지 캡션에 대해서도 이야기 할 것입니다.

310
00:37:47,832 --> 00:37:49,255
이미지가 주어지면, 시스템은

311
00:37:49,255 --> 00:37:51,621
이제 자연어 문장을 만들어내야 합니다.

312
00:37:51,621 --> 00:37:52,985
그 문장은 이미지를 설명합니다.

313
00:37:52,985 --> 00:37:55,201
정말 힘들고, 복잡하고

314
00:37:55,201 --> 00:37:57,109
서로 별 상관이 없어보일 수도 있지만, 우리는

315
00:37:57,109 --> 00:38:00,473
이미지 분류 서비스를 위해 개발한
많은 도구들을

316
00:38:00,473 --> 00:38:04,390
다른 문제에서도 똑같이 적용할 수 있습니다.

317
00:38:07,992 --> 00:38:12,755
지금까지는 ImageNet Challenge의 맥락에서 말씀드렸습니다.
 하지만,

318
00:38:12,755 --> 00:38:15,908
최근의 컴퓨터 비전 분야의 진보를 이끌어낸 것 중 하나는 바로

319
00:38:15,908 --> 00:38:21,860
Convolutional neural networks, 즉
CNN입니다. 또는 convnet으로도 불리죠

320
00:38:21,860 --> 00:38:28,337
최근 몇해 간 ImageNet Challenge의 우승을 이끈
알고리즘에 대해 살표보자면

321
00:38:28,337 --> 00:38:34,141
2011년에서 Lin et al의 알고리즘을 볼 수 있는데
여전히 계층적이죠.

322
00:38:34,141 --> 00:38:36,370
이 알고리즘은 여러 층으로 구성되어 있습니다.

323
00:38:36,370 --> 00:38:38,279
우선 몇 개의 특징을 계산하고

324
00:38:38,279 --> 00:38:40,252
그다음 몇 개의 지역 불면 특징들을 계산하고

325
00:38:40,252 --> 00:38:44,449
pooling을 하고, 몇 개의 더 레이어를 거칩니다.

326
00:38:44,449 --> 00:38:47,786
그러고 나서 생긴 기술자를 선형 SVM에 넣는 것이죠.

327
00:38:47,786 --> 00:38:50,740
여기서 주목할 점은 바로, 여전히 "계층적"이라는 것 입니다.

328
00:38:50,740 --> 00:38:52,063
우리는 여전히 edges를 감지하고,

329
00:38:52,063 --> 00:38:54,093
여전히 불변성 이라는 개념을 지니고 있죠.

330
00:38:54,093 --> 00:38:57,687
그리고 대부분의 그런 직관들은
여전히 CNN으로 까지 영향을 미칩니다.

331
00:38:57,687 --> 00:39:00,625
그러나 가장 획기적이었던 순간은 바로 2012년 이었죠

332
00:39:00,625 --> 00:39:08,576
이때 토론토의 Jeff Hinton의 연구실이 Alex Krizhevsky,
그리고 Ilya Sutskever와 함께 하던 해 였습니다.

333
00:39:08,576 --> 00:39:14,014
그 두 사람은 박사과정(PHD) 였으며, 그때 당시 7개의 레이러를 가진
Convolutional neural network를 만들었었죠.

334
00:39:14,014 --> 00:39:16,722
현재 아주 잘 알려진 AlexNet 입니다,
Supervision으로도 불렸죠

335
00:39:16,722 --> 00:39:21,161
AlexNet은 2012년의 ImageNet 대회에서 정말로 잘 해냈습니다.

336
00:39:21,161 --> 00:39:25,707
그 후로는 ImageNet의 승자는
매년 Newral Network의 몫이었습니다.

337
00:39:25,707 --> 00:39:29,606
그리고 이러한 추세는 CNN이 매년
더 깊어지게 만들었죠.

338
00:39:29,606 --> 00:39:35,102
AlexNet은 층이 7개 또는 8개인 Neural Network였습니다.
어떻게 층을 세느냐에 따라 조금 다릅니다.

339
00:39:35,102 --> 00:39:41,028
2015 년에 우리는 훨씬 더 깊은 네트워크를 가졌습니다.
Google의 GoogleNet 그리고 Oxford의 VGG가 바로 그것이죠.

340
00:39:41,028 --> 00:39:44,682
VGGnet은 약 19층의 레이어를 가지고 있었죠.

341
00:39:44,682 --> 00:39:46,481
그러고 나서 2015년에는 정말 놀라웠습니다.

342
00:39:46,481 --> 00:39:50,108
한 논문아 Microsoft Research Asis에서 나왔는데,

343
00:39:50,108 --> 00:39:53,883
Residual Networks라 불리는 이 네트워크는
그 당시 152층의 레이러를 가지고 있었습니다.

344
00:39:53,883 --> 00:40:00,015
그 이후에도, 200층 까지 쌓아 올리면 더 좋은 성능을 보일 수
있다고 했지만, 아마도 여러분의 GPU 메모리가 감당할 수 없을 것입니다.

345
00:40:00,015 --> 00:40:01,862
이 모든건 다음에 더 다루기로 하죠

346
00:40:00,415 --> 00:40:02,262


347
00:40:01,862 --> 00:40:04,606
하지만 이 강의에서 중점적으로 다루는 것은
바로 convolutional neural networks 가

348
00:40:02,262 --> 00:40:05,006


349
00:40:04,606 --> 00:40:06,334
2012년에 아주 하나의 돌파구를 만들었다는 것이고,

350
00:40:05,006 --> 00:40:06,734


351
00:40:05,219 --> 00:40:13,158


352
00:40:06,334 --> 00:40:10,293
그때 이후로, CNN이 성능을 개선하고 객체 분류를 더 잘 하도록 하기 위해서

353
00:40:06,734 --> 00:40:08,735


354
00:40:08,735 --> 00:40:10,693


355
00:40:10,293 --> 00:40:14,989
CNN을 개선하고 튜닝하려는 많은 시도를이 있었습니다.

356
00:40:10,693 --> 00:40:13,250


357
00:40:13,250 --> 00:40:15,389


358
00:40:13,633 --> 00:40:17,022


359
00:40:14,989 --> 00:40:16,989
그리고 이번 학기의 남은 시간동안은

360
00:40:15,389 --> 00:40:17,389


361
00:40:16,989 --> 00:40:18,610
우리는 더 깊이 파고 들 것입니다.

362
00:40:17,389 --> 00:40:19,010


363
00:40:18,610 --> 00:40:21,459
그리고 아마도 여러분은 어떻게 서로 다른 모델이
동작하는지 정확히 이해할 수 있을 것입니다.

364
00:40:19,010 --> 00:40:21,026


365
00:40:21,026 --> 00:40:21,859


366
00:40:24,024 --> 00:40:26,175
하지만 한가지 중요한점은

367
00:40:24,424 --> 00:40:26,575


368
00:40:26,175 --> 00:40:31,770
2012년에 CNN이 돌파구를 열었고,

369
00:40:26,575 --> 00:40:29,258


370
00:40:27,833 --> 00:40:34,568


371
00:40:29,258 --> 00:40:32,170


372
00:40:31,770 --> 00:40:38,061
ImageNet Chllenge에서 아주 좋은 성적을 낸 것은 사실이지만,
CNN이 2012년에 발명된 것은 아니라는 점입니다.

373
00:40:32,170 --> 00:40:34,304


374
00:40:34,304 --> 00:40:36,732


375
00:40:34,568 --> 00:40:45,243


376
00:40:36,732 --> 00:40:38,461


377
00:40:38,061 --> 00:40:41,820
이  CNN이란 알고리즘은 실제로
오래 전부터 존재해 왔습니다.

378
00:40:38,461 --> 00:40:40,096


379
00:40:40,096 --> 00:40:42,220


380
00:40:40,365 --> 00:40:43,475


381
00:40:41,820 --> 00:40:47,667
CNN이라는 분야의 일종의 기초연구 라고 할 수 있는 것은

382
00:40:42,220 --> 00:40:45,706


383
00:40:43,475 --> 00:40:46,975


384
00:40:45,706 --> 00:40:48,067


385
00:40:47,667 --> 00:40:55,143
90년도의 Jan LeCun과 Bell Labs와의 공동 과제 였습니다.

386
00:40:48,067 --> 00:40:52,360


387
00:40:48,585 --> 00:40:50,343


388
00:40:50,343 --> 00:40:52,557


389
00:40:52,360 --> 00:40:55,543


390
00:40:55,143 --> 00:41:00,339
1998년에 그들이 CNN이란 것을 구축했습니다.
숫자 인식을 위한 것이었죠.

391
00:40:55,543 --> 00:40:59,242


392
00:40:57,475 --> 00:41:02,142


393
00:40:59,242 --> 00:41:00,739


394
00:41:00,339 --> 00:41:08,876
그들은 이 CNN을 이용해서 자필 수표와 우체국의
우편 주소를 자동으로 인식하길 원했습니다.

395
00:41:00,739 --> 00:41:04,501


396
00:41:02,142 --> 00:41:05,864


397
00:41:04,501 --> 00:41:06,578


398
00:41:06,578 --> 00:41:09,276


399
00:41:08,876 --> 00:41:10,894
그래서 그들이 바로  CNN을 만든 것입니다.

400
00:41:09,276 --> 00:41:11,294


401
00:41:10,894 --> 00:41:13,168
CNN은 Image의 Pixel을 입력으로 받아서,

402
00:41:11,294 --> 00:41:13,568


403
00:41:13,168 --> 00:41:18,747
이 숫자가 몇이고, 이 글자가 무엇인지를 분류할 수 있었습니다.

404
00:41:13,568 --> 00:41:16,492


405
00:41:16,492 --> 00:41:19,147


406
00:41:18,747 --> 00:41:20,716
이 네트워크의 구조는

407
00:41:19,147 --> 00:41:21,116


408
00:41:20,716 --> 00:41:22,716
사실 AlexNet의 아키텍쳐와 아주 유사합니다.

409
00:41:21,116 --> 00:41:23,116


410
00:41:22,716 --> 00:41:25,128
AlexNet은 2012년도였죠

411
00:41:23,116 --> 00:41:25,528


412
00:41:25,128 --> 00:41:28,188
우리가 저 그림에서 볼 수 있듯이,
raw 픽셀을 입력으로 받아서는

413
00:41:25,528 --> 00:41:27,359


414
00:41:25,978 --> 00:41:32,086


415
00:41:28,188 --> 00:41:30,590
수많은 Convolution 레이어를 거치고,
서브 샘플링을 합니다

416
00:41:28,588 --> 00:41:30,990


417
00:41:30,590 --> 00:41:32,908
 Fully Connected Layer 라고 부르는 것으로
모아줍니다.

418
00:41:30,990 --> 00:41:33,308


419
00:41:31,561 --> 00:41:33,611


420
00:41:32,908 --> 00:41:36,224
이 모든건 다음 강의 부터 더 자세히 다루도록 하겠습니다.

421
00:41:33,308 --> 00:41:35,305


422
00:41:33,611 --> 00:41:35,493


423
00:41:36,224 --> 00:41:38,226
하지만, 여러분이 이 두 그림을 보고 있자면

424
00:41:36,624 --> 00:41:38,626


425
00:41:38,226 --> 00:41:39,907
둘이 꽤 비슷해 보일겁니다.

426
00:41:38,626 --> 00:41:40,307


427
00:41:39,907 --> 00:41:50,809
2012년의 CNN 아키텍쳐들은 서로 비슷비슷 했습니다.
90년대의 LeNet을의 아키텍처를 서로 공유했기 때문입니다.

428
00:41:40,307 --> 00:41:43,640


429
00:41:40,613 --> 00:41:42,512


430
00:41:41,627 --> 00:41:43,922


431
00:41:42,512 --> 00:41:44,588


432
00:41:44,519 --> 00:41:46,359


433
00:41:46,359 --> 00:41:51,209


434
00:41:48,798 --> 00:41:51,290


435
00:41:50,809 --> 00:41:54,887
그럼 이런 질문을 할 수 있겠군요
90년대부터 알고리즘이 었었다면

436
00:41:51,209 --> 00:41:52,726


437
00:41:52,726 --> 00:41:55,287


438
00:41:54,887 --> 00:41:58,964
왜 최근 몇년간이 되어서야 갑자기 인기있어 진 걸까요?

439
00:41:55,287 --> 00:41:57,725


440
00:41:57,725 --> 00:41:59,364


441
00:41:58,964 --> 00:42:04,787
90년대 이래로 아주 큰 혁신적인 것들이 있었습니다.

442
00:41:59,364 --> 00:42:01,213


443
00:42:01,213 --> 00:42:05,187


444
00:42:01,914 --> 00:42:03,616


445
00:42:03,198 --> 00:42:04,912


446
00:42:03,616 --> 00:42:07,957


447
00:42:04,787 --> 00:42:06,861
하나는 바로 계산능력입니다.

448
00:42:05,187 --> 00:42:07,261


449
00:42:06,861 --> 00:42:10,727
무어의 법칙 덕분에, 우리는
점점 더 빠른 컴퓨터를 쓸 수 있게 되었고

450
00:42:07,261 --> 00:42:08,931


451
00:42:08,931 --> 00:42:11,127


452
00:42:10,727 --> 00:42:12,743
그리고 완벽한 척도는 아니겠지만,

453
00:42:11,127 --> 00:42:13,143


454
00:42:11,702 --> 00:42:14,785


455
00:42:12,743 --> 00:42:20,084
칩 안의 트랜지스터의 수만 봤을때 90년대와 지금을
비교해보면 몇십배 이상 발전해 왔음을 알 수 있습니다.

456
00:42:13,143 --> 00:42:15,144


457
00:42:15,144 --> 00:42:17,039


458
00:42:17,039 --> 00:42:20,484


459
00:42:18,967 --> 00:42:21,586


460
00:42:20,084 --> 00:42:24,553
우리는 또한 graphics processing units의
진보 겪었습니다.

461
00:42:20,484 --> 00:42:24,953


462
00:42:21,586 --> 00:42:25,993


463
00:42:23,114 --> 00:42:32,496


464
00:42:24,553 --> 00:42:27,388
GPU라고도 하죠, 이는 강력한 병렬처리가 가능한데

465
00:42:24,953 --> 00:42:27,788


466
00:42:25,993 --> 00:42:28,946


467
00:42:27,388 --> 00:42:34,542
계산 집약적인 CNN 모델을 고속으로 처리하기 위한
아주 완벽한 툴로 거듭났습니다.

468
00:42:27,788 --> 00:42:30,015


469
00:42:28,946 --> 00:42:31,937


470
00:42:30,015 --> 00:42:32,776


471
00:42:32,776 --> 00:42:34,942


472
00:42:34,542 --> 00:42:41,234
그러니, 단지 좀더 많은 계산이 가능하다는 것 만으로
연구자들이 더 큰 아키텍쳐를 연구할 수 있었고,

473
00:42:34,942 --> 00:42:37,851


474
00:42:37,851 --> 00:42:41,634


475
00:42:38,422 --> 00:42:41,286


476
00:42:41,234 --> 00:42:45,636
좀 더 큰 모델을 연구할 수 있었습니다.
경우 따라서는 모델 사이즈만 키웠음에도,

477
00:42:41,634 --> 00:42:44,060


478
00:42:44,060 --> 00:42:46,036


479
00:42:45,636 --> 00:42:49,986
기존의 고전적인 방법과 알고리즘은 아무 잘 동작했습니다.

480
00:42:46,036 --> 00:42:48,748


481
00:42:48,748 --> 00:42:50,386


482
00:42:49,986 --> 00:42:57,064
그러므로 계산할 수 있는 양이 늘어났다는 것은
딥 러닝의 역사에서 아주 중요한 것입니다.

483
00:42:50,386 --> 00:42:53,325


484
00:42:51,609 --> 00:42:54,472


485
00:42:53,325 --> 00:42:57,464


486
00:42:54,472 --> 00:42:56,801


487
00:42:55,428 --> 00:43:01,914


488
00:42:57,064 --> 00:43:02,069
지금과 90년대 사이에 변화한 두번째 주요 혁신은
바로 데이터가 아닐까 생각합니다.

489
00:42:57,464 --> 00:43:00,557


490
00:43:00,557 --> 00:43:02,469


491
00:43:02,069 --> 00:43:05,768
이런 알고리즘들은 데이터가 아주 부족할 수 있습니다.

492
00:43:02,469 --> 00:43:06,168


493
00:43:02,771 --> 00:43:04,860


494
00:43:05,768 --> 00:43:10,905
CNN 알고리즘이 잘 동작하게 하기 위해서는
여러분은 아주 많은 레이블된 이미지 그리고 픽셀을 학습시켜야 합니다.

495
00:43:06,168 --> 00:43:08,229


496
00:43:08,229 --> 00:43:11,305


497
00:43:09,360 --> 00:43:10,503


498
00:43:10,905 --> 00:43:15,651
그리고 90년대에는 충분한 레이블 데이터가
존재하지 않았습니다.

499
00:43:11,305 --> 00:43:13,563


500
00:43:12,233 --> 00:43:13,618


501
00:43:13,563 --> 00:43:16,051


502
00:43:15,651 --> 00:43:21,742
그때 당시에는 Mechanical Turk이 생겨나기 전이었고
인터넷이 아주 널리 쓰이기도 전이었습니다.

503
00:43:16,051 --> 00:43:19,399


504
00:43:19,399 --> 00:43:22,142


505
00:43:19,795 --> 00:43:23,431


506
00:43:21,742 --> 00:43:25,124
아무 크고 다양한 데이터셋을 수집하기도 힘들었습니다.

507
00:43:22,142 --> 00:43:23,781


508
00:43:22,412 --> 00:43:39,643


509
00:43:23,781 --> 00:43:25,524


510
00:43:25,124 --> 00:43:35,738
하지만 지금은 PASCAL이나 ImageNet같은 데이터셋과 같이,
더 규모가 크고 고퀄의 레이블을 가진 데이터셋이 많이 있습니다.

511
00:43:25,524 --> 00:43:29,441


512
00:43:27,076 --> 00:43:29,532


513
00:43:30,493 --> 00:43:33,543


514
00:43:32,194 --> 00:43:36,361


515
00:43:33,543 --> 00:43:36,138


516
00:43:35,738 --> 00:43:40,285
이들은, 90년대에 사용가능했던 데이터셋에 비하면
수십제곱만큼이나 더 크다고 할 수 있습니다.

517
00:43:36,138 --> 00:43:38,500


518
00:43:38,500 --> 00:43:40,685


519
00:43:40,285 --> 00:43:44,663
또 이런 엄청 큰 데이터셋들은
우리가 Higher Capacity Model을 만들 수 있게 하였습니다.

520
00:43:40,685 --> 00:43:42,532


521
00:43:42,532 --> 00:43:45,063


522
00:43:44,663 --> 00:43:48,667
그런 모델을 학습하게 되면 실생활 문제에 실제로도 잘 동작합니다.

523
00:43:45,063 --> 00:43:47,171


524
00:43:47,171 --> 00:43:49,067


525
00:43:48,667 --> 00:43:50,772
하지만 여기에서 비평한만한 것이 있다면,

526
00:43:49,067 --> 00:43:51,172


527
00:43:50,772 --> 00:43:55,669
 convolution neural network가 간지나고, 새로워 보이고

528
00:43:51,172 --> 00:43:52,933


529
00:43:52,933 --> 00:43:56,069


530
00:43:53,295 --> 00:44:02,294


531
00:43:55,669 --> 00:43:59,037
지난 몇 해동안 갑자기 튀어 나온 것 처럼 보일 수도 있지만,
그건 정말 사실이 아니라는 것 입니다.

532
00:43:56,069 --> 00:43:58,027


533
00:43:58,027 --> 00:43:59,437


534
00:43:59,037 --> 00:44:05,176
CNN과 같은 부류의 알고리즘은 아주 오래 전부터 존재했습니다.

535
00:43:59,437 --> 00:44:01,493


536
00:43:59,825 --> 00:44:03,242


537
00:44:01,493 --> 00:44:05,576


538
00:44:02,294 --> 00:44:08,040


539
00:44:06,525 --> 00:44:14,265
내가 집고 넘어가고 싶은 것은, 컴퓨터 비전에서 우리가 하는 일은
"사람 처럼 볼 수 있는" 기계를 만드려는 노력 이라는 것입니다.

540
00:44:06,925 --> 00:44:09,825


541
00:44:08,040 --> 00:44:11,238


542
00:44:09,825 --> 00:44:11,634


543
00:44:11,634 --> 00:44:14,665


544
00:44:14,265 --> 00:44:18,160
그리고 실제로 사람들은 우리의 시각 체계를
이동해서 아주 많은 것을 할 수 잇습니다.

545
00:44:14,665 --> 00:44:17,167


546
00:44:18,160 --> 00:44:20,008
여러분이 이 세상을 살아가면서

547
00:44:18,560 --> 00:44:20,408


548
00:44:18,864 --> 00:44:22,649


549
00:44:20,008 --> 00:44:26,498
여러분은 고양이나 강아지에 사각형을 그리고
분류하는 것 이상의 일을 할 수 있습니다.

550
00:44:20,408 --> 00:44:22,944


551
00:44:22,944 --> 00:44:26,898


552
00:44:26,498 --> 00:44:29,221
여러분의 시각체계는 컴퓨터비전보다 훤씬 더 강력합니다.

553
00:44:26,898 --> 00:44:29,621


554
00:44:27,162 --> 00:44:29,981


555
00:44:29,221 --> 00:44:30,925
다시 이 분야로 돌아가 보자면,

556
00:44:29,621 --> 00:44:31,325


557
00:44:30,925 --> 00:44:35,557
아직도 우리가 다뤄야 할 엄청나게 많은 도전과제와
해결하지 못한 문제가 있다고 생각합니다.

558
00:44:31,325 --> 00:44:33,522


559
00:44:31,950 --> 00:44:38,183


560
00:44:33,522 --> 00:44:35,957


561
00:44:35,557 --> 00:44:41,730
그리고 우리는 더 나은 일을 하고, 더 야심찬 문제에 도전할 수 있도록
알고리즘을 계속해서 개발해 나갈 필요가 있습니다.

562
00:44:35,957 --> 00:44:38,540


563
00:44:36,936 --> 00:44:40,124


564
00:44:38,540 --> 00:44:42,130


565
00:44:40,124 --> 00:44:41,884


566
00:44:41,730 --> 00:44:45,553
몇가지 예를 들어보자면, 사실은 오래 전부터 있던 아이디어 이기는 합니다만

567
00:44:42,130 --> 00:44:44,874


568
00:44:44,090 --> 00:44:46,675


569
00:44:45,553 --> 00:44:48,433
Semantic Segmentation, 즉
 Perceptual Grouping 같은 것들이죠

570
00:44:45,953 --> 00:44:48,833


571
00:44:46,675 --> 00:44:49,088


572
00:44:48,433 --> 00:44:50,802
여기에서는 한장의 이미지 전체에
레이블링을 하는 것이 아니라

573
00:44:48,833 --> 00:44:51,202


574
00:44:49,088 --> 00:44:51,992


575
00:44:50,802 --> 00:44:53,479
이미지 내의 모든 픽셀 하나 하나를
이해하는 것입니다.

576
00:44:51,202 --> 00:44:53,879


577
00:44:51,992 --> 00:44:55,409


578
00:44:53,479 --> 00:44:55,376
뭘 하고있는지, 뭘 의미하는지를 말이죠

579
00:44:53,879 --> 00:44:55,776


580
00:44:55,376 --> 00:44:58,356
이건 좀 더 뒤에 다시 다루도록 하겠습니다.

581
00:44:55,776 --> 00:44:57,571


582
00:44:56,201 --> 00:45:00,404


583
00:44:58,356 --> 00:45:01,644
실제 세계를 재 구성하는것에 관한 3D 이해에 관한 아이디어로
거슬러 올라가 보자면,

584
00:44:58,756 --> 00:45:00,363


585
00:45:00,363 --> 00:45:02,044


586
00:45:01,644 --> 00:45:07,637
제 생각에는 여전히 풀지못한 문제입니다.

587
00:45:02,044 --> 00:45:04,287


588
00:45:04,287 --> 00:45:08,037


589
00:45:05,574 --> 00:45:11,563


590
00:45:07,299 --> 00:45:11,428


591
00:45:09,008 --> 00:45:11,688
여러분이 상상할 수 있는
엄청나게 많은 과제들이 있습니다.

592
00:45:09,408 --> 00:45:10,920


593
00:45:11,688 --> 00:45:13,327
예를들어 행동인식이 있겠네요,

594
00:45:12,088 --> 00:45:13,727


595
00:45:13,327 --> 00:45:18,235
만약 여러분에게 어떤 사람이 무언가를 하고있는 비디오가 있다고 했을때,
그 활동을 인식할 수 있는 최고의 방법이 과연 무엇일까요?

596
00:45:13,727 --> 00:45:15,348


597
00:45:15,348 --> 00:45:17,122


598
00:45:15,803 --> 00:45:18,142


599
00:45:17,122 --> 00:45:18,635


600
00:45:18,235 --> 00:45:20,979
그것은 꽤 도전적인 문제 이기도 합니다.

601
00:45:18,635 --> 00:45:21,379


602
00:45:19,858 --> 00:45:21,574


603
00:45:20,979 --> 00:45:24,784
그리고 나서 우리가 증강현실, 가상현실로 뻗어나가고

604
00:45:21,379 --> 00:45:23,196


605
00:45:23,196 --> 00:45:25,184


606
00:45:24,784 --> 00:45:29,088
새로운 종류의 센서들과 마주하게 된다면,

607
00:45:25,184 --> 00:45:27,242


608
00:45:25,556 --> 00:45:27,067


609
00:45:27,242 --> 00:45:29,488


610
00:45:29,088 --> 00:45:33,965
제 생각에, 우리는 한 분야로 다룰 수 있을만큼
새롭고 흥미롭고, 어렵고 아주 도전적인 문제들을 또 만나게 될 것입니다.

611
00:45:29,488 --> 00:45:31,865


612
00:45:31,865 --> 00:45:34,365


613
00:45:33,450 --> 00:45:36,867


614
00:45:35,426 --> 00:45:43,738
지금부터 보여드릴 예는 제가 비전연구실에서 하고있는 일중에 일부인데,
Visual Genome 이라는 데이터셋입니다.

615
00:45:35,826 --> 00:45:39,834


616
00:45:38,527 --> 00:45:42,194


617
00:45:39,834 --> 00:45:44,138


618
00:45:43,738 --> 00:45:48,984
여기에서 주된 아이디어는 바로 복잡한 실제 세상에서 일부를
포착해 내는 것입니다.

619
00:45:44,138 --> 00:45:47,336


620
00:45:45,269 --> 00:45:48,262


621
00:45:45,970 --> 00:45:54,946


622
00:45:47,336 --> 00:45:49,384


623
00:45:48,984 --> 00:45:53,818
박스만 치는 것으로는 부족하고 이미지를

624
00:45:49,384 --> 00:45:51,703


625
00:45:51,703 --> 00:45:54,218


626
00:45:53,818 --> 00:45:59,035
하나의 커다란 의미론적인 그래프로 표현하는 것입니다.
이 그래프는, 객체를 식별하는것 뿐만 아니라

627
00:45:54,218 --> 00:45:56,966


628
00:45:54,946 --> 00:45:57,081


629
00:45:56,966 --> 00:45:59,435


630
00:45:59,035 --> 00:46:04,100
그 장면에 나타난 객체의 관계, 객체의 성격, 행동 등을
나타낼 수 있습니다.

631
00:45:59,435 --> 00:46:02,361


632
00:46:01,183 --> 00:46:02,863


633
00:46:02,361 --> 00:46:04,500


634
00:46:02,863 --> 00:46:06,613


635
00:46:04,100 --> 00:46:11,037
그리고 이런 방식의 표현방법을 통해서 어쩌면 실제 세계를
일부 만이라도 포착할 수 있지 않을까 예상합니다.

636
00:46:04,500 --> 00:46:08,881


637
00:46:08,881 --> 00:46:11,437


638
00:46:09,321 --> 00:46:14,841


639
00:46:11,037 --> 00:46:14,399
그리고 그것들은 우리가 단순한 분류만 하고 있을때
활용하지 못했던 것들이죠

640
00:46:11,437 --> 00:46:13,135


641
00:46:13,135 --> 00:46:14,799


642
00:46:14,399 --> 00:46:16,780
이것이 현 시점에서 표준 접근법 이라는 말은 아니지만,

643
00:46:14,799 --> 00:46:17,180


644
00:46:16,780 --> 00:46:21,145
우리 인간의 시각 체계라는 것이 단순한 이미지 분류 알고리즘으로는
포착해 낼 수 없는

645
00:46:17,180 --> 00:46:19,240


646
00:46:19,240 --> 00:46:21,545


647
00:46:21,145 --> 00:46:26,350
훨씬 더 많은 것을 할 수 있다는 것을 여러분들이 깨달게
해 주는 것 만으로도 충분합니다.

648
00:46:21,545 --> 00:46:24,500


649
00:46:24,500 --> 00:46:26,750


650
00:46:27,498 --> 00:46:31,097


651
00:46:29,513 --> 00:46:33,102
그런 관점에서 봤을때, 정말 재밌는 연구가 하나 있는데

652
00:46:29,913 --> 00:46:31,654


653
00:46:31,654 --> 00:46:33,502


654
00:46:33,102 --> 00:46:35,655
Fei-Fei 교수님의 학부시절의 연구입니다.

655
00:46:33,502 --> 00:46:36,055


656
00:46:35,655 --> 00:46:40,462
그 당시 그녀는 지도 교수님과 Cal Tech에서 박사과정을 진행하고
있었습니다.

657
00:46:36,055 --> 00:46:38,753


658
00:46:37,396 --> 00:46:38,573


659
00:46:38,753 --> 00:46:40,862


660
00:46:40,462 --> 00:46:43,202
이 연구에서는, 사람들을 붙잡아서

661
00:46:40,862 --> 00:46:43,602


662
00:46:43,202 --> 00:46:46,114
사람들에게 이 사진을 아주 잠시 동안만 보여줬습니다.

663
00:46:43,602 --> 00:46:46,514


664
00:46:44,166 --> 00:46:46,700


665
00:46:44,694 --> 00:46:48,356


666
00:46:46,114 --> 00:46:49,406
그들에게 아무 짧은 시간만 이 이미지를 보여준 것이죠,

667
00:46:46,514 --> 00:46:48,212


668
00:46:48,212 --> 00:46:49,806


669
00:46:49,406 --> 00:46:53,618
이미지를 본 시간이 아무 짧음에도 불구하고, 사람들은

670
00:46:49,806 --> 00:46:52,079


671
00:46:50,795 --> 00:46:54,274


672
00:46:52,079 --> 00:46:54,018


673
00:46:53,618 --> 00:46:57,983
위와 같이 그 이미지에 관한 아주 긴 문장을 쓸 수 있었습니다.

674
00:46:54,018 --> 00:46:55,943


675
00:46:54,274 --> 00:46:56,724


676
00:46:55,943 --> 00:46:58,383


677
00:46:56,724 --> 00:46:59,629


678
00:46:57,983 --> 00:47:05,202
그리고 이것은 아주 주목할만한 것입니다.
이미지를 아무 잠깐만 본 후에도

679
00:46:58,383 --> 00:47:02,194


680
00:46:59,629 --> 00:47:01,690


681
00:46:59,920 --> 00:47:06,021


682
00:47:02,194 --> 00:47:05,602


683
00:47:03,976 --> 00:47:08,143


684
00:47:05,202 --> 00:47:07,070
인간은 이미지에 대해 말할 수 있었습니다.

685
00:47:05,602 --> 00:47:07,470


686
00:47:06,021 --> 00:47:13,821


687
00:47:07,070 --> 00:47:11,885
일종의 게임, 또는 싸움을 하고 있고, 두 무리의 남자기 있고, 왼쪽에
있는 남자는 뭘 던지고 있고,

688
00:47:07,470 --> 00:47:10,391


689
00:47:10,391 --> 00:47:12,285


690
00:47:11,885 --> 00:47:16,086
이곳이 밖이고, 잔디와 같은 느낌이 들어서, 등등

691
00:47:12,285 --> 00:47:15,044


692
00:47:15,044 --> 00:47:16,486


693
00:47:16,086 --> 00:47:19,127
그리고 아마 사람이 이 이미지를 좀더 오래 보게 된다면
어떨지 상상할 수 있을 것입니다.

694
00:47:16,486 --> 00:47:17,926


695
00:47:17,926 --> 00:47:19,527


696
00:47:19,127 --> 00:47:20,679
아마도, 그들이 누구이고

697
00:47:19,527 --> 00:47:21,079


698
00:47:20,679 --> 00:47:23,817
왜 그들이 저기에서 게임을 하고있는지에 대해서
소설 한편을 쓸지도 모르겠습니다.

699
00:47:21,079 --> 00:47:22,852


700
00:47:23,817 --> 00:47:25,195
아마 끝도없이 계속 할 수도 있을 것입니다.

701
00:47:25,195 --> 00:47:28,697
외부의 지식과, 선행 경험을 통해서 말이죠

702
00:47:25,595 --> 00:47:27,523


703
00:47:27,523 --> 00:47:29,097


704
00:47:28,697 --> 00:47:31,807
이는 어찌보면 컴퓨터 비전의 성배라고 할 수 있습니다.

705
00:47:29,097 --> 00:47:32,207


706
00:47:30,685 --> 00:47:33,589


707
00:47:31,807 --> 00:47:36,173
이미지의 스토리를 아주 풍부하고 깊은 방법으로
이해 한다는 면에서 말이죠

708
00:47:32,207 --> 00:47:34,569


709
00:47:34,569 --> 00:47:36,573


710
00:47:36,173 --> 00:47:41,216
그리고 제 생각에는, 지난 컴퓨터비전이라는 분야의
수년간의 큰 진보에서 불구하고

711
00:47:36,573 --> 00:47:38,842


712
00:47:38,842 --> 00:47:41,616


713
00:47:41,216 --> 00:47:45,970
성배를 얻기위한 길은 아직도 멀고도 험난합니다.

714
00:47:41,616 --> 00:47:46,370


715
00:47:43,776 --> 00:47:50,413


716
00:47:45,970 --> 00:47:51,982
이것에 대해 예를 들고싶은 이미지가 하나 더 있습니다.
Andrej Karpathy의 블로그에 있는 이미지입니다.

717
00:47:46,370 --> 00:47:48,473


718
00:47:48,473 --> 00:47:52,382


719
00:47:50,413 --> 00:47:54,370


720
00:47:51,982 --> 00:47:54,400
아주 놀라운 것이죠

721
00:47:52,382 --> 00:47:54,800


722
00:47:54,400 --> 00:47:55,901
많은 사람들이 웃었습니다.

723
00:47:54,800 --> 00:47:56,301


724
00:47:55,901 --> 00:47:57,722
제생각에 이 이미지는 상당히 재밌다고 생각합니다.

725
00:47:56,301 --> 00:47:58,122


726
00:47:57,722 --> 00:47:59,206
왜 이게 웃기죠?

727
00:47:58,122 --> 00:47:59,606


728
00:47:59,206 --> 00:48:03,117
한 남자가 체중계에 서 있습니다. 우리는 보통 사람들이 가끔씩

729
00:47:59,606 --> 00:48:01,805


730
00:48:00,444 --> 00:48:03,199


731
00:48:01,805 --> 00:48:03,517


732
00:48:03,117 --> 00:48:05,890
자신의 체중을 알아보기 위해 체중계를 사용한다는 것을 알고 있습니다.

733
00:48:03,517 --> 00:48:06,290


734
00:48:04,716 --> 00:48:09,614


735
00:48:05,890 --> 00:48:10,301
그리고 우린 뒤에서 체중계를 밟고 있는 다른 한 사람을 볼 수 있습니다.

736
00:48:06,290 --> 00:48:08,809


737
00:48:06,878 --> 00:48:10,689


738
00:48:08,809 --> 00:48:10,701


739
00:48:10,301 --> 00:48:12,410
그리고 우리는 체중계가 어떻게 동작할 지 짐작할 수 있고,

740
00:48:10,701 --> 00:48:12,810


741
00:48:12,410 --> 00:48:15,377
저 사람이 보게될 부풀려진 체중의 이유를 알고 있습니다.

742
00:48:12,810 --> 00:48:14,868


743
00:48:13,837 --> 00:48:16,914


744
00:48:15,377 --> 00:48:16,405
그러나 더 많은 것이 있습니다.

745
00:48:16,405 --> 00:48:18,329
우리는 저 사람이 평범한 사람이 아니란 것을 알고 있습니다.

746
00:48:16,805 --> 00:48:18,729


747
00:48:18,329 --> 00:48:22,415
저 사람은 당의 미국 대통령 Barack Obama 입니다.

748
00:48:18,729 --> 00:48:21,410


749
00:48:19,772 --> 00:48:20,834


750
00:48:21,410 --> 00:48:22,815


751
00:48:22,415 --> 00:48:26,251
그리고 우리는 미국 대통령은 존경받는 정치인이
되어야 한다고 알 고 있습니다.

752
00:48:22,815 --> 00:48:24,451


753
00:48:24,451 --> 00:48:26,651


754
00:48:24,707 --> 00:48:30,433


755
00:48:26,251 --> 00:48:28,555
[웃음]

756
00:48:26,651 --> 00:48:28,955


757
00:48:28,555 --> 00:48:32,814
아마도 이런식으로 동료에게 장난을 치지 않아야 하겠죠

758
00:48:28,955 --> 00:48:31,064


759
00:48:31,064 --> 00:48:33,214


760
00:48:31,707 --> 00:48:33,180


761
00:48:32,814 --> 00:48:36,074
우리는 뒤 쪽의 사람들이 웃고 있다는 것을 알 수 있습니다.

762
00:48:33,214 --> 00:48:34,623


763
00:48:34,623 --> 00:48:36,474


764
00:48:36,074 --> 00:48:39,422
우리는 뒤쪽의 사람들이 이 장면을 어떻게
이해하는지를 알 수도 있습니다.

765
00:48:36,474 --> 00:48:37,976


766
00:48:37,976 --> 00:48:39,822


767
00:48:38,414 --> 00:48:41,679


768
00:48:39,422 --> 00:48:44,376
그들도 우리처럼 오바마대통령이 존경받는 사람이라는 것을 알고 있다는
것을 이해할 수 있습니다.

769
00:48:39,822 --> 00:48:41,507


770
00:48:41,507 --> 00:48:43,485


771
00:48:44,376 --> 00:48:45,277
이건 정말 놀라운 것입니다.

772
00:48:45,277 --> 00:48:47,340
이 이미지에는 많은 것이 있습니다.

773
00:48:45,677 --> 00:48:47,740


774
00:48:47,340 --> 00:48:49,677
그리고 우리의 컴퓨터 비전 알고리즘은

775
00:48:47,740 --> 00:48:50,077


776
00:48:49,677 --> 00:48:54,512
이미지에 대한 이런 진정한 깊은 이해를 하기까지는
아직 갈 길이 멀다고 생각합니다.

777
00:48:50,077 --> 00:48:53,018


778
00:48:50,319 --> 00:48:56,517


779
00:48:53,018 --> 00:48:54,912


780
00:48:54,512 --> 00:49:00,287
저는 이 분야의 큰 진보에도 불구하고,
아직 갈이 멀다고 생각합니다.

781
00:48:54,912 --> 00:48:57,942


782
00:48:56,517 --> 00:49:03,545


783
00:48:57,942 --> 00:49:00,687


784
00:48:58,321 --> 00:49:01,141


785
00:49:00,287 --> 00:49:02,895
저에게 이것은 연구자로서 정말 흥분되는 것입니다.

786
00:49:00,687 --> 00:49:03,295


787
00:49:01,141 --> 00:49:02,742


788
00:49:02,895 --> 00:49:08,204
왜냐하면 앞으로 나가갈 수 있는 정말 흥미진진하고
재미있는 문제들이 우리에게 아직 많이 남아있기 때문입니다.

789
00:49:03,295 --> 00:49:04,540


790
00:49:04,540 --> 00:49:06,521


791
00:49:05,152 --> 00:49:09,319


792
00:49:06,521 --> 00:49:08,604


793
00:49:08,059 --> 00:49:16,096


794
00:49:09,423 --> 00:49:14,564
그래서 저는 컴퓨터비전이 정말 재미있다는 것을
여러분들에게 알리고 싶습니다.

795
00:49:09,823 --> 00:49:12,112


796
00:49:12,112 --> 00:49:14,964


797
00:49:14,564 --> 00:49:15,718
정말 재밌습니다.

798
00:49:15,718 --> 00:49:17,839
그리고 매우 유용합니다.

799
00:49:16,118 --> 00:49:18,239


800
00:49:17,839 --> 00:49:21,553
그리고 나아 가서 다양한 방법으로
이 세상을 좋은 곳으로 만들어 줄 수 있습니다.

801
00:49:18,239 --> 00:49:20,225


802
00:49:20,225 --> 00:49:21,953


803
00:49:21,553 --> 00:49:29,644
컴퓨터비전은 의학진단이나 자율주행 자동차, 로보틱스 등
어느 곳이든 적용할 수 있습니다.

804
00:49:21,953 --> 00:49:23,501


805
00:49:22,491 --> 00:49:25,658


806
00:49:23,501 --> 00:49:26,469


807
00:49:24,140 --> 00:49:28,739


808
00:49:26,469 --> 00:49:30,044


809
00:49:29,644 --> 00:49:34,630
게다가 인간의 지능을 이해하기 위한 여러가지 핵심 아이디어를
서로 묶어주는 일존의 매듭이 될 수도 있습니다.

810
00:49:30,044 --> 00:49:32,623


811
00:49:30,688 --> 00:49:32,400


812
00:49:32,623 --> 00:49:35,030


813
00:49:34,630 --> 00:49:38,651
제 생각에는 컴퓨터비전은 정말 기상천외하고 재밌는 분야입니다.

814
00:49:35,030 --> 00:49:36,759


815
00:49:36,759 --> 00:49:39,051


816
00:49:38,651 --> 00:49:41,985
그리고 여러분들과 이 수업을 통해서 오늘날 알고리즘들이
실제로 어떻게 동작하는지에 대해서

817
00:49:39,051 --> 00:49:40,685


818
00:49:40,685 --> 00:49:42,385


819
00:49:41,985 --> 00:49:47,744
여러분들과 심도깊은 이야기를 할수 있게 되어서 정말 좋습니다.

820
00:49:42,385 --> 00:49:44,247


821
00:49:44,247 --> 00:49:48,144


822
00:49:46,592 --> 00:49:48,186


823
00:49:47,744 --> 00:49:52,183
여기까지는 컴퓨터비전에 대한 개인적인 견해와
컴퓨터 비전의 역사에 대해서 였습니다.

824
00:49:48,144 --> 00:49:50,859


825
00:49:50,859 --> 00:49:52,583


826
00:49:52,183 --> 00:49:54,876
혹시 궁금한 점이 있으신가요?

827
00:49:52,583 --> 00:49:54,193


828
00:49:54,193 --> 00:49:55,276


829
00:49:57,217 --> 00:49:58,565
좋습니다.

830
00:49:58,565 --> 00:50:03,918
그러면 이제 앞으로의 수업 계획에 대해 말해보죠

831
00:49:58,965 --> 00:50:00,255


832
00:50:00,255 --> 00:50:02,318


833
00:50:02,318 --> 00:50:04,318


834
00:50:02,625 --> 00:50:09,333


835
00:50:03,918 --> 00:50:05,892
어쩌면 여러분은 우리가 누구냐고 물으실 수도 있습니다.

836
00:50:04,318 --> 00:50:06,292


837
00:50:05,892 --> 00:50:08,414
이 수업은 Fei-Fei Li 교수님께서 가르치십니다.

838
00:50:06,292 --> 00:50:08,814


839
00:50:08,414 --> 00:50:12,781
이곳 Stanford의 컴퓨터 과학 교수님이십니다.

840
00:50:08,814 --> 00:50:13,181


841
00:50:09,867 --> 00:50:12,973


842
00:50:11,033 --> 00:50:13,022


843
00:50:12,781 --> 00:50:16,026
그리고 제 지도 교수님이시기도 하고
Stanford Vision Lab의 교수님이십니다.

844
00:50:13,181 --> 00:50:16,426


845
00:50:16,026 --> 00:50:18,362
Stanford AI Lab에 계시기도 하죠

846
00:50:16,426 --> 00:50:18,762


847
00:50:18,362 --> 00:50:24,029
그리고 다른 두명, 저 Justin Tohnson과 Serena
Yeung, 여기 앞에 서있습니다.

848
00:50:18,762 --> 00:50:21,991


849
00:50:19,555 --> 00:50:21,227


850
00:50:21,991 --> 00:50:24,429


851
00:50:24,029 --> 00:50:28,889
우리 둘은 Fei-Fei 교수님의 지도 하에
다양한 컴퓨터 비전 과제를 수행하고 있는 PHD 학생입니다.

852
00:50:24,429 --> 00:50:27,129


853
00:50:25,983 --> 00:50:28,148


854
00:50:27,129 --> 00:50:29,289


855
00:50:28,889 --> 00:50:33,430
우리에게 18명의 훌륭한 조교가 있습니다.

856
00:50:29,289 --> 00:50:31,906


857
00:50:30,555 --> 00:50:32,396


858
00:50:31,906 --> 00:50:33,830


859
00:50:32,396 --> 00:50:35,050


860
00:50:33,430 --> 00:50:35,689
대부분은 여기 앞에 앉아 있습니다.

861
00:50:33,830 --> 00:50:36,089


862
00:50:35,689 --> 00:50:41,830
우리가 수업을 잘 진행하고, 모든것이 잘 돌아갈 수 있도록
도와주는 얼굴없는 영웅들 입니다.

863
00:50:36,089 --> 00:50:37,831


864
00:50:37,831 --> 00:50:40,437


865
00:50:40,437 --> 00:50:42,230


866
00:50:40,812 --> 00:50:42,253


867
00:50:41,830 --> 00:50:43,875
그러니 그들에게 잘해주세요.

868
00:50:42,230 --> 00:50:44,275


869
00:50:43,875 --> 00:50:45,706
[웃음]

870
00:50:44,275 --> 00:50:46,106


871
00:50:45,706 --> 00:50:50,726
말씀 드려야 할 점이 있다면, 이 강의는 세 번째 열리는 강의이지만

872
00:50:46,106 --> 00:50:49,063


873
00:50:49,063 --> 00:50:51,126


874
00:50:50,726 --> 00:50:54,560
Andrej Karpathy가 강의를 하지 않는 첫 번째 강의이기도 합니다.

875
00:50:51,126 --> 00:50:53,562


876
00:50:54,560 --> 00:50:57,702
그는 저와 아주 친한 친구입니다.

877
00:50:54,960 --> 00:50:58,102


878
00:50:57,702 --> 00:50:58,603
그는 아직 살아 있습니다.

879
00:50:58,603 --> 00:50:59,863
그는 괜찮습니다. 걱정하지 마세요.

880
00:50:59,863 --> 00:51:01,122
[웃음]

881
00:51:01,122 --> 00:51:04,290
그는 졸업을 했고 사실 여기에 있습니다.

882
00:51:01,522 --> 00:51:04,690


883
00:51:01,806 --> 00:51:03,314


884
00:51:04,290 --> 00:51:07,234
강당 어딘가에 있겠죠

885
00:51:04,690 --> 00:51:07,634


886
00:51:05,422 --> 00:51:09,944


887
00:51:07,234 --> 00:51:13,127
이 수업의 발전과 역사의 대부분은 수년동안 저와 함께 일해준
그의 덕분 이었습니다.

888
00:51:07,634 --> 00:51:09,572


889
00:51:08,213 --> 00:51:10,585


890
00:51:09,572 --> 00:51:11,480


891
00:51:11,480 --> 00:51:13,527


892
00:51:13,127 --> 00:51:16,908
그 사실은 여러분도 알고 계셨으면 좋겠습니다.

893
00:51:13,527 --> 00:51:17,308


894
00:51:14,514 --> 00:51:19,474


895
00:51:16,908 --> 00:51:23,719
강의에 대해 말해보자면, 조교들과 연락할 수 있는 가장
좋은 방법은 Piazza를 이용하는 것입니다.

896
00:51:17,308 --> 00:51:20,104


897
00:51:20,104 --> 00:51:22,814


898
00:51:22,382 --> 00:51:24,428


899
00:51:23,719 --> 00:51:26,722
당장 가서 가입하세요

900
00:51:24,119 --> 00:51:27,122


901
00:51:24,428 --> 00:51:26,773


902
00:51:26,722 --> 00:51:31,863
Piazza는 이 수업에 대한 의사소통을 할 수 있는
우리가 가장 선호하는 방법입니다.

903
00:51:27,122 --> 00:51:29,507


904
00:51:28,307 --> 00:51:32,529


905
00:51:29,507 --> 00:51:32,263


906
00:51:31,863 --> 00:51:35,823
만약 친구들 앞에서 질문하는 것이 꺼려진다면,

907
00:51:32,263 --> 00:51:34,531


908
00:51:32,538 --> 00:51:36,705


909
00:51:34,531 --> 00:51:36,223


910
00:51:35,823 --> 00:51:42,082
Piazza에 가서 익명으로 질문을 하세요 private
질문을 올릴수도 있습니다. 교직원에게 직접 연락하십시오.

911
00:51:36,223 --> 00:51:37,977


912
00:51:37,977 --> 00:51:40,512


913
00:51:38,680 --> 00:51:46,003


914
00:51:40,512 --> 00:51:42,482


915
00:51:42,082 --> 00:51:45,962
기본적으로 여러분이 필요한것은 그저 Piazza를 경험하는 것입니다.

916
00:51:42,482 --> 00:51:44,179


917
00:51:42,961 --> 00:51:46,128


918
00:51:44,179 --> 00:51:46,362


919
00:51:45,962 --> 00:51:49,932
조교들의 메일링 리스트가 있긴 하지만

920
00:51:46,362 --> 00:51:48,355


921
00:51:47,052 --> 00:51:51,219


922
00:51:48,355 --> 00:51:50,332


923
00:51:49,932 --> 00:51:55,027
Piazza에 올리기 껄끄러운 개인적이거나 비공개적인 것들을 위해서만 쓰고

924
00:51:50,332 --> 00:51:53,212


925
00:51:52,170 --> 00:51:55,724


926
00:51:53,212 --> 00:51:55,427


927
00:51:55,027 --> 00:52:03,635
혹시나 정말 중요한 말못할 사항이 있다면, 저나, Serena, Fei-Fei
교수님께 직접 메일을 주셔도 되겠습니다.

928
00:51:55,427 --> 00:51:57,683


929
00:51:55,724 --> 00:51:58,547


930
00:51:57,683 --> 00:52:00,275


931
00:51:58,547 --> 00:52:01,697


932
00:52:00,275 --> 00:52:04,035


933
00:52:01,697 --> 00:52:05,256


934
00:52:03,635 --> 00:52:07,606
하지만 그 외의 조교와의 커뮤니케이션은 Piazza을
통해서여만 합니다.

935
00:52:04,035 --> 00:52:05,810


936
00:52:05,810 --> 00:52:08,006


937
00:52:07,606 --> 00:52:10,170
올해는 부교재도 있습니다.

938
00:52:08,006 --> 00:52:10,570


939
00:52:10,170 --> 00:52:11,911
필수는 아닙니다.

940
00:52:10,570 --> 00:52:12,311


941
00:52:11,911 --> 00:52:14,126
이 책없이도 이 강의를 들을 수 있습니다.

942
00:52:12,311 --> 00:52:14,526


943
00:52:12,865 --> 00:52:15,282


944
00:52:14,126 --> 00:52:15,882
모든걸 스스로 챙겨야 할 것입니다.

945
00:52:14,526 --> 00:52:16,282


946
00:52:15,882 --> 00:52:21,296
정말 흥분되는 것은, 이 책이 아마 딥 러닝에 관해서 처음 출간된
교과서 라는 것 떄문입니다.

947
00:52:16,282 --> 00:52:19,680


948
00:52:16,787 --> 00:52:18,514


949
00:52:18,514 --> 00:52:21,847


950
00:52:19,680 --> 00:52:21,696


951
00:52:21,296 --> 00:52:25,588
올해 초에 출간된 E.N. Goodfellow, U
oshua Bengio, Aaron Courville이 쓴 책 입니다.

952
00:52:21,696 --> 00:52:23,799


953
00:52:23,799 --> 00:52:25,988


954
00:52:25,588 --> 00:52:28,194
슬라이드에 아마존 링크를 주가했습니다.

955
00:52:25,988 --> 00:52:28,594


956
00:52:28,194 --> 00:52:29,707
원한다면 구입하도록 하세요

957
00:52:28,594 --> 00:52:30,107


958
00:52:29,707 --> 00:52:33,317
하지만 온라인에 무료 컨텐츠도 있기 떄문에,
반드시 살 필요는 없습니다.

959
00:52:30,107 --> 00:52:31,989


960
00:52:31,989 --> 00:52:33,717


961
00:52:33,317 --> 00:52:34,453
사고 싶지 않다면 말이죠

962
00:52:34,453 --> 00:52:35,771
다시 한번 말하지만 이것은 완전히 선택 사항입니다.

963
00:52:35,771 --> 00:52:42,124
하지만 아마도 학기동안 이 책의 일부를 읽으라고 공지할 수도 있습니다.
이 책은 여러분에게 추가적인 관점을 얻는데 도움을 줄 것입니다.

964
00:52:36,171 --> 00:52:37,688


965
00:52:37,688 --> 00:52:39,524


966
00:52:39,524 --> 00:52:42,524


967
00:52:41,969 --> 00:52:44,218


968
00:52:43,207 --> 00:52:50,304
이 수업의 철학은 여러분이 딥러닝에 관한 모든 알고리즘을 정말로
이해해야 한다는 것입니다.

969
00:52:43,607 --> 00:52:45,169


970
00:52:45,169 --> 00:52:48,945


971
00:52:46,229 --> 00:52:49,741


972
00:52:48,945 --> 00:52:50,704


973
00:52:50,304 --> 00:52:52,181
아주 깊은 수준에서 이해해야 합니다.

974
00:52:50,704 --> 00:52:52,581


975
00:52:52,181 --> 00:52:54,227
이 알고리듬이 정확히 어떻게 작동하는지

976
00:52:52,581 --> 00:52:54,627


977
00:52:53,224 --> 00:52:55,358


978
00:52:54,227 --> 00:52:57,607
여러분이 뉴럴 네트워크들을 연결했을때 정확이 무슨 일이 일어나는지,

979
00:52:54,627 --> 00:52:56,205


980
00:52:56,205 --> 00:52:58,007


981
00:52:57,607 --> 00:53:03,824
그런 아키텍쳐의 선택이 어떤 영향을 미치는, 네트워크가 어떻게
학습되고 테스팅 되는지 와 같은 것들입니다.

982
00:52:58,007 --> 00:53:00,038


983
00:53:00,038 --> 00:53:02,054


984
00:53:02,054 --> 00:53:04,224


985
00:53:03,824 --> 00:53:06,721
그리고 과제를 통해 코스 전반에 걸쳐셔

986
00:53:04,224 --> 00:53:07,121


987
00:53:06,721 --> 00:53:10,267
여러분은 아마 여러분만의 CNN을 파이썬을 이용해서
밑바닥부터 구현할 것입니다.

988
00:53:07,121 --> 00:53:09,073


989
00:53:09,073 --> 00:53:10,667


990
00:53:10,267 --> 00:53:14,770
여러분은 전체 foward, backward passes을 구현할 것입니다.

991
00:53:10,667 --> 00:53:13,470


992
00:53:10,969 --> 00:53:11,909


993
00:53:11,909 --> 00:53:15,409


994
00:53:13,470 --> 00:53:15,170


995
00:53:14,770 --> 00:53:17,830
결국, 여러분은 전체 CNN을 완벽히 구현하게 될 것입니다.

996
00:53:15,170 --> 00:53:17,016


997
00:53:16,490 --> 00:53:20,323


998
00:53:17,830 --> 00:53:19,830
저는 이게 멋지다고 생각합니다.

999
00:53:18,230 --> 00:53:20,230


1000
00:53:19,830 --> 00:53:25,030
하지만 실용적인 측면에서, 아마 대부분의 사람들이
이런 것들을 밑바닥부터 하지는 않을 것이라는 것을 알고 있습니다.

1001
00:53:20,230 --> 00:53:22,479


1002
00:53:21,472 --> 00:53:24,293


1003
00:53:22,479 --> 00:53:25,430


1004
00:53:25,030 --> 00:53:32,836
떄문에, 여러분에이 실용적으로 쓸 수 있는 일부
최신의 소프트웨어 툴을 소개해 드릴 것입니다.

1005
00:53:25,430 --> 00:53:27,523


1006
00:53:27,523 --> 00:53:29,679


1007
00:53:29,679 --> 00:53:33,236


1008
00:53:32,836 --> 00:53:39,173
Tensor Flow, Torch, PyTorch 와 같은 최신 소프트웨어에
대해서도 이야기할 것입니다.

1009
00:53:33,236 --> 00:53:35,283


1010
00:53:33,700 --> 00:53:35,008


1011
00:53:35,283 --> 00:53:38,302


1012
00:53:36,115 --> 00:53:37,673


1013
00:53:37,673 --> 00:53:41,840


1014
00:53:39,173 --> 00:53:46,038
아마 그럴 툴들을 이 강의의 과제나 프로젝트를
통해서 접할 수 있을 것입니다.

1015
00:53:39,573 --> 00:53:41,800


1016
00:53:41,800 --> 00:53:44,546


1017
00:53:44,546 --> 00:53:46,438


1018
00:53:46,038 --> 00:53:49,330
또 한 가지 말씀드릴 것은, 이 강의는
매우 state-of-the-art 하다는 것입니다.

1019
00:53:46,438 --> 00:53:48,213


1020
00:53:48,213 --> 00:53:49,730


1021
00:53:49,330 --> 00:53:50,632
저는 이점이 매우 흥분됩니다.

1022
00:53:49,547 --> 00:53:52,728


1023
00:53:50,632 --> 00:53:52,225
이 분야는 매우 빠르게 변하는 분야입니다.

1024
00:53:51,032 --> 00:53:52,625


1025
00:53:52,225 --> 00:53:57,121
여러분도 ImageNet Challenge의 그래프에서 보았듯이
2012년 이래로 엄청난 변화가 있었습니다.

1026
00:53:52,625 --> 00:53:55,247


1027
00:53:55,247 --> 00:53:57,521


1028
00:53:57,121 --> 00:54:02,048
제가 대학원에 있는 동안, 이 분야는 일년 내내 변했습니다.

1029
00:53:57,521 --> 00:54:00,750


1030
00:54:00,750 --> 00:54:02,448


1031
00:54:02,048 --> 00:54:05,259
그리고, 그것은 매우 흥분되고 매우 유망하다는 것입니다.

1032
00:54:02,448 --> 00:54:05,659


1033
00:54:05,259 --> 00:54:10,642
어쨌든, 말하고 싶었던 것은 어쩌면 우리가 저번 해에 다뤘던 내용이

1034
00:54:05,659 --> 00:54:09,087


1035
00:54:09,087 --> 00:54:11,042


1036
00:54:09,370 --> 00:54:12,515


1037
00:54:10,642 --> 00:54:14,403
올해에는 없을 수도 있다는 것을 의미합니다.

1038
00:54:11,042 --> 00:54:14,803


1039
00:54:12,515 --> 00:54:14,764


1040
00:54:14,403 --> 00:54:18,139
그것은 매우 흥미로운 부분이고, 제가 이 과목을 가르칠때
가장 좋아하는 부분 중 하나입니다.

1041
00:54:14,803 --> 00:54:16,327


1042
00:54:16,327 --> 00:54:18,539


1043
00:54:18,139 --> 00:54:25,551
이 분야는 모든 과학적인 새로운 것들을 모조리 빨아드릴 수 있고
저는 여러분들에게 이것을 알려줄 수 있다는 것입니다.

1044
00:54:18,539 --> 00:54:20,736


1045
00:54:20,736 --> 00:54:22,951


1046
00:54:22,951 --> 00:54:25,951


1047
00:54:23,391 --> 00:54:25,681


1048
00:54:24,297 --> 00:54:30,367


1049
00:54:25,551 --> 00:54:27,581
재밌는 것들도 있습니다.

1050
00:54:25,951 --> 00:54:27,981


1051
00:54:27,581 --> 00:54:31,963
심각하지 않은 재미있는 주제에 관해서도 다룰 것입니다.

1052
00:54:27,981 --> 00:54:29,680


1053
00:54:29,680 --> 00:54:32,363


1054
00:54:30,367 --> 00:54:36,369


1055
00:54:31,963 --> 00:54:34,632
이미지 캡셔닝과 같은 것인데, 매우 재밌습니다.

1056
00:54:32,363 --> 00:54:35,032


1057
00:54:34,632 --> 00:54:36,859
이미지 캡셔닝은 이미지에 관해 기술하는 것입니다.

1058
00:54:35,032 --> 00:54:37,259


1059
00:54:35,558 --> 00:54:38,251


1060
00:54:36,859 --> 00:54:41,406
그리고 여기 왼쪽에 보이는 DeepDream과 같은
좀 더 예술적인 것들에 관해서는 다룰 것입니다.

1061
00:54:37,259 --> 00:54:39,087


1062
00:54:39,087 --> 00:54:41,806


1063
00:54:41,406 --> 00:54:45,787
이것은 우리가 Neural Network를 통해
이런 사이키델릭한 이미지를 만들게도 해줍니다.

1064
00:54:41,806 --> 00:54:44,171


1065
00:54:42,461 --> 00:54:46,070


1066
00:54:44,171 --> 00:54:46,187


1067
00:54:45,787 --> 00:54:48,387
그리고 코스가 끝날 쯤이면, 어떻게 동작하는지 알 수 있을 겁니다.

1068
00:54:46,187 --> 00:54:47,885


1069
00:54:47,379 --> 00:54:48,609


1070
00:54:48,387 --> 00:54:56,850
오른쪽 그림의, style tranfer라는 아이디어는 우리에게 이미지가
있을때, 이를 피카소나 반 고흐와 같은 유명화가의 풍으로 바꿔줍니다.

1071
00:54:48,787 --> 00:54:50,810


1072
00:54:49,371 --> 00:54:55,983


1073
00:54:50,810 --> 00:54:52,538


1074
00:54:52,538 --> 00:54:56,417


1075
00:54:53,564 --> 00:54:55,158


1076
00:54:55,158 --> 00:54:56,267


1077
00:54:56,850 --> 00:54:58,164
그리고 다시 이 수업을 마치면

1078
00:54:58,164 --> 00:55:01,164
여러분은 어떻게 동작하는지 알게 될 것입니다.

1079
00:54:58,564 --> 00:55:01,564


1080
00:55:01,164 --> 00:55:05,304
여러분에게 수업동안 세가지 문제를 던져줄 것입니다.

1081
00:55:01,564 --> 00:55:04,429


1082
00:55:04,197 --> 00:55:06,661


1083
00:55:05,304 --> 00:55:09,762
첫 번째 문제는 잘하면 일주일 내로 끝날 수도 있습니다.

1084
00:55:05,704 --> 00:55:08,949


1085
00:55:06,661 --> 00:55:10,161


1086
00:55:07,161 --> 00:55:13,438


1087
00:55:09,762 --> 00:55:12,216
그리고 중간고사가 있습니다.

1088
00:55:10,162 --> 00:55:12,616


1089
00:55:12,216 --> 00:55:18,917
그리고 여러분의 학점에서 가장 큰 비율을 차지하는 것이 바로
최종 코스 프로젝트인데, 3인 1조로 진행할 것이며,

1090
00:55:12,616 --> 00:55:14,421


1091
00:55:14,421 --> 00:55:16,966


1092
00:55:16,966 --> 00:55:19,317


1093
00:55:18,917 --> 00:55:22,024
여러분들은 모든 사람들의 마음을 날려버릴만큼
놀라운 프로젝트를 만들 것입니다.

1094
00:55:19,317 --> 00:55:22,424


1095
00:55:20,047 --> 00:55:25,263


1096
00:55:22,024 --> 00:55:27,890
제출기한에 대한 정책도 있습니다. 도합 7일정도는 늦을 수
있고, 여러분들의 과제 수행 중 자유롭게 분배할 수 있습니다.

1097
00:55:22,424 --> 00:55:25,781


1098
00:55:22,865 --> 00:55:25,509


1099
00:55:25,781 --> 00:55:28,290


1100
00:55:27,890 --> 00:55:35,714
몸이 조금 아프거나, 여행을 가거나, 컨퍼런스에 참가하거나 할때
쓸 수 있을 것입니다.

1101
00:55:28,290 --> 00:55:31,459


1102
00:55:28,779 --> 00:55:31,529


1103
00:55:29,042 --> 00:55:34,062


1104
00:55:31,459 --> 00:55:36,114


1105
00:55:33,372 --> 00:55:37,183


1106
00:55:34,062 --> 00:55:38,968


1107
00:55:35,714 --> 00:55:41,481
하지만, 갑자기 학기 말에 와서는
"이번에 컨퍼런스에서 발표를 해야만 해요" 라고 말한다면

1108
00:55:36,114 --> 00:55:38,098


1109
00:55:38,098 --> 00:55:40,667


1110
00:55:38,968 --> 00:55:42,540


1111
00:55:41,481 --> 00:55:42,390
아마 좋지 않을것입니다.

1112
00:55:42,390 --> 00:55:44,134
이것이 바로 late days가 의미하는 것입니다.

1113
00:55:42,790 --> 00:55:44,534


1114
00:55:44,134 --> 00:55:48,153
그렇긴 해도, 만약 여러분이 정상참작할만한
이유가 있었다면

1115
00:55:44,534 --> 00:55:46,021


1116
00:55:46,021 --> 00:55:48,553


1117
00:55:48,153 --> 00:55:51,805
언제든지 조교들에게 이메일을 보내주시길 바랍니다.
피지못할 사정이 있었다면 말이죠.

1118
00:55:48,553 --> 00:55:50,615


1119
00:55:50,615 --> 00:55:52,205


1120
00:55:51,805 --> 00:55:55,687
또 한가지 알려드릴 점은
협업 정책입니다.

1121
00:55:52,205 --> 00:55:54,314


1122
00:55:52,519 --> 00:55:57,091


1123
00:55:54,314 --> 00:55:56,087


1124
00:55:55,687 --> 00:56:05,119
Stanford 학생으로서, 여러분은 항상 규율에 대해 알고 있어야 합니다.
이것은 아주 중요합니다.

1125
00:55:56,087 --> 00:55:57,831


1126
00:55:57,831 --> 00:56:00,299


1127
00:56:00,299 --> 00:56:02,695


1128
00:56:01,467 --> 00:56:04,857


1129
00:56:02,695 --> 00:56:05,519


1130
00:56:05,119 --> 00:56:09,130
우리는 여러분이 어떻게 협력하고 있는지에 대해, 그리고 그것을

1131
00:56:05,519 --> 00:56:07,545


1132
00:56:07,545 --> 00:56:09,530


1133
00:56:09,130 --> 00:56:12,547
규율의 테두리 안에 있도록 하는 것에 대해 아주
조심스럽게 생각하는 것을 장려합니다.

1134
00:56:09,530 --> 00:56:12,947


1135
00:56:11,007 --> 00:56:16,156


1136
00:56:12,600 --> 00:56:15,628


1137
00:56:13,814 --> 00:56:19,002
Pre-requisites에 대해서라면, 가장 중요한 것은
아마도 얼마나 Python에 익숙한지 일 것입니다.

1138
00:56:14,214 --> 00:56:16,288


1139
00:56:16,288 --> 00:56:19,402


1140
00:56:19,002 --> 00:56:23,849
모든 프로그래밍 과제는 Python
으로 진행 될 것이기 때문입니다.

1141
00:56:19,402 --> 00:56:21,991


1142
00:56:21,991 --> 00:56:24,249


1143
00:56:23,849 --> 00:56:27,576
C나 C++에 익숙한 것도
어느정도는 유용할 것입니다.

1144
00:56:24,249 --> 00:56:27,976


1145
00:56:25,067 --> 00:56:26,705


1146
00:56:27,576 --> 00:56:33,215
이번 코스에서 C나 C++을 쓰진 않을 거지만,
아마 과제를 하다 보면

1147
00:56:27,976 --> 00:56:31,264


1148
00:56:29,002 --> 00:56:32,078


1149
00:56:31,264 --> 00:56:33,615


1150
00:56:32,078 --> 00:56:33,674


1151
00:56:33,215 --> 00:56:41,389
여러 소프트웨어 패키지의 코드를 살펴볼 것이고, C++ 코드는
패키지들이 어떻게 동작하는지 이해하는데 아주 도움이 될 것입니다.

1152
00:56:33,615 --> 00:56:35,586


1153
00:56:35,586 --> 00:56:37,832


1154
00:56:37,832 --> 00:56:41,789


1155
00:56:39,483 --> 00:56:41,572


1156
00:56:41,389 --> 00:56:43,949
이 코스에서는 여러분이 미분에 대해 한다고
가정하고 수업을 진행할 것입니다.

1157
00:56:41,789 --> 00:56:44,349


1158
00:56:43,949 --> 00:56:46,481
여러분이 모든 종류의 미분을 할 줄 안다고도 가정할 것입니다

1159
00:56:44,349 --> 00:56:46,881


1160
00:56:45,419 --> 00:56:47,504


1161
00:56:46,481 --> 00:56:48,043
또한 일부 선형대수도 안다고 가정할 것입니다.

1162
00:56:46,881 --> 00:56:48,443


1163
00:56:48,043 --> 00:56:49,389
매트릭스가 뭔지 알고,

1164
00:56:49,389 --> 00:56:53,582
어떻게 곱하고 하는것들을 미리 알아야 합니다.

1165
00:56:49,789 --> 00:56:53,982


1166
00:56:51,726 --> 00:56:57,124


1167
00:56:53,582 --> 00:56:57,201
우리가 도함수를 계산하는 방법같은 것을
전부 다 가르칠 순 없습니다.

1168
00:56:53,982 --> 00:56:55,570


1169
00:56:55,570 --> 00:56:57,601


1170
00:56:57,201 --> 00:57:02,748
또한 우리는 CS131 또는 231a 정도 수준의 컴퓨터 비전
지식을 어느정도 알 고 있다고 가정할 것입니다.

1171
00:56:57,601 --> 00:56:59,231


1172
00:56:59,231 --> 00:57:01,731


1173
00:57:01,731 --> 00:57:03,148


1174
00:57:03,877 --> 00:57:06,630
이 과목들을 수강한 적이 있는 분들은
괜찮을 것입니다.

1175
00:57:04,277 --> 00:57:05,833


1176
00:57:04,979 --> 00:57:08,015


1177
00:57:06,630 --> 00:57:11,363
그렇지 않다 해도, 수업을 듣는데는 지장이 없겠지만,
따라 잡으려면 좀 더 노력해야 할 것입니다.

1178
00:57:07,030 --> 00:57:09,257


1179
00:57:08,015 --> 00:57:10,227


1180
00:57:09,257 --> 00:57:11,763


1181
00:57:10,227 --> 00:57:11,530


1182
00:57:11,363 --> 00:57:13,060
그래도 아마 큰 문제는 없으이라 봅니다.

1183
00:57:11,763 --> 00:57:13,460


1184
00:57:13,060 --> 00:57:15,214
완전 완전 필수인 prerequisites은 없습니다.

1185
00:57:13,460 --> 00:57:15,614


1186
00:57:15,214 --> 00:57:22,050
우리는 또한 CS229 정도 수준의 기계학습에
어느정도의 배경지식이 있다고 가정합니다.

1187
00:57:15,614 --> 00:57:18,874


1188
00:57:18,874 --> 00:57:22,450


1189
00:57:22,050 --> 00:57:27,233
하지만, 기계학습에서 정말 중요하고
핵심적인 개념에 대해서는 아마 제가 다시 설명해 드릴 것입니다.

1190
00:57:22,450 --> 00:57:25,466


1191
00:57:25,466 --> 00:57:27,633


1192
00:57:27,233 --> 00:57:29,265
수업 중 그 개념이 나오고, 그것이 아주 중요할때 말이죠

1193
00:57:27,633 --> 00:57:29,665


1194
00:57:29,265 --> 00:57:33,926
뭐 그렇긴 해도, 미리 익숙해 지는 것이 수업 진도를
따라가는 데 더 도움일 될 것입니다.

1195
00:57:29,665 --> 00:57:31,826


1196
00:57:30,681 --> 00:57:33,025


1197
00:57:31,826 --> 00:57:34,326


1198
00:57:33,025 --> 00:57:41,720


1199
00:57:36,284 --> 00:57:37,556
우리는 강의 홈페이지를 가지고 있습니다.

1200
00:57:37,556 --> 00:57:38,460
가서 확인해 보세요

1201
00:57:38,460 --> 00:57:41,252
많은 정보나 링크, 교수과목 등 많은 것들이 있습니다.

1202
00:57:38,860 --> 00:57:40,213


1203
00:57:40,213 --> 00:57:41,652


1204
00:57:41,252 --> 00:57:45,166
그 모든 것들이 제가 이번 수업에서
정말로 다루고 싶은 것들 입니다.

1205
00:57:41,652 --> 00:57:45,566


1206
00:57:45,166 --> 00:57:50,667
그리고 이번 주 목요일에, 우리는 첫번째
학습 알고리즘부터 시작할 것이고, 세부사항을 알아 볼 것입니다.

1207
00:57:45,566 --> 00:57:48,067


1208
00:57:48,067 --> 00:57:50,643

