1
00:00:06,971 --> 00:00:10,106
Okay, so welcome to lecture two of CS231N.

2
00:00:10,106 --> 00:00:12,646
On Tuesday we, just recall, we, sort of, gave you

3
00:00:12,646 --> 00:00:15,098
the big picture view of what is computer vision,

4
00:00:15,098 --> 00:00:16,188
what is the history,

5
00:00:16,188 --> 00:00:18,101
and a little bit of the overview of the class.

6
00:00:18,101 --> 00:00:20,340
And today, we're really going to dive in, for the first time,

7
00:00:20,340 --> 00:00:21,451
into the details.

8
00:00:21,451 --> 00:00:23,339
And we'll start to see, in much more depth,

9
00:00:23,339 --> 00:00:25,752
exactly how some of these learning algorithms

10
00:00:25,752 --> 00:00:27,864
actually work in practice.

11
00:00:27,864 --> 00:00:29,089
So, the first lecture of the class

12
00:00:29,089 --> 00:00:31,927
is probably, sort of, the largest big picture vision.

13
00:00:31,927 --> 00:00:33,808
And the majority of the lectures in this class

14
00:00:33,808 --> 00:00:35,574
will be much more detail orientated,

15
00:00:35,574 --> 00:00:37,298
much more focused on the specific mechanics,

16
00:00:37,298 --> 00:00:39,617
of these different algorithms.

17
00:00:39,617 --> 00:00:41,148
So, today we'll see our first learning algorithm

18
00:00:41,148 --> 00:00:43,419
and that'll be really exciting, I think.

19
00:00:43,419 --> 00:00:44,822
But, before we get to that,

20
00:00:44,822 --> 00:00:47,535
I wanted to talk about a couple of administrative issues.

21
00:00:47,535 --> 00:00:48,785
One, is Piazza.

22
00:00:49,645 --> 00:00:51,580
So, I saw it when I checked yesterday,

23
00:00:51,580 --> 00:00:54,168
it seemed like we had maybe 500 students

24
00:00:54,168 --> 00:00:55,357
signed up on Piazza.

25
00:00:55,357 --> 00:00:56,839
Which means that there are several hundred of you

26
00:00:56,839 --> 00:00:58,493
who are not yet there.

27
00:00:58,493 --> 00:01:01,457
So, we really want Piazza to be the main source

28
00:01:01,457 --> 00:01:04,222
of communication between the students and the core staff.

29
00:01:04,222 --> 00:01:07,401
So, we've gotten a lot of questions to the staff list

30
00:01:07,401 --> 00:01:11,170
about project ideas or questions about midterm attendance

31
00:01:11,170 --> 00:01:12,841
or poster session attendance.

32
00:01:12,841 --> 00:01:14,389
And, any, sort of, questions like that

33
00:01:14,389 --> 00:01:16,138
should really go to Piazza.

34
00:01:16,138 --> 00:01:18,134
You'll probably get answers to your questions faster

35
00:01:18,134 --> 00:01:21,568
on Piazza, because all the TAs are knowing to check that.

36
00:01:21,568 --> 00:01:23,181
And it's, sort of, easy for emails to get lost

37
00:01:23,181 --> 00:01:26,234
in the shuffle if you just send to the course list.

38
00:01:26,234 --> 00:01:28,983
It's also come to my attention that some SCPD students

39
00:01:28,983 --> 00:01:33,629
are having a bit of a hard time signing up for Piazza.

40
00:01:33,629 --> 00:01:35,458
SCPD students are supposed to receive a

41
00:01:35,458 --> 00:01:37,791
@stanford.edu email address.

42
00:01:38,804 --> 00:01:40,733
So, once you get that email address,

43
00:01:40,733 --> 00:01:44,276
then you can use the Stanford email to sign into Piazza.

44
00:01:44,276 --> 00:01:45,857
Probably that doesn't affect those of you who are

45
00:01:45,857 --> 00:01:46,908
sitting in the room right now,

46
00:01:46,908 --> 00:01:50,408
but, for those students listening on SCPD.

47
00:01:52,191 --> 00:01:55,643
The next administrative issue is about assignment one.

48
00:01:55,643 --> 00:01:58,178
Assignment one will be up later today,

49
00:01:58,178 --> 00:01:59,517
probably sometime this afternoon,

50
00:01:59,517 --> 00:02:01,653
but I promise, before I go to sleep tonight,

51
00:02:01,653 --> 00:02:03,043
it'll be up.

52
00:02:03,043 --> 00:02:04,589
But, if you're getting a little bit antsy

53
00:02:04,589 --> 00:02:07,304
and really want to start working on it right now,

54
00:02:07,304 --> 00:02:09,297
then you can look at last year's version

55
00:02:09,297 --> 00:02:10,531
of assignment one.

56
00:02:10,531 --> 00:02:12,684
It'll be pretty much the same content.

57
00:02:12,684 --> 00:02:15,081
We're just reshuffling it a little bit to make it,

58
00:02:15,081 --> 00:02:17,169
like, for example, upgrading to work with Python 3,

59
00:02:17,169 --> 00:02:19,082
rather than Python 2.7.

60
00:02:19,082 --> 00:02:20,943
And some of these minor cosmetic changes,

61
00:02:20,943 --> 00:02:23,068
but the content of the assignment will still be the same

62
00:02:23,068 --> 00:02:24,742
as last year.

63
00:02:24,742 --> 00:02:27,332
So, in this assignment you'll be implementing your own

64
00:02:27,332 --> 00:02:28,665
k-nearest neighbor classifier,

65
00:02:28,665 --> 00:02:30,686
which we're going to talk about in this lecture.

66
00:02:30,686 --> 00:02:33,514
You'll also implement several different linear classifiers,

67
00:02:33,514 --> 00:02:35,694
including the SVM and Softmax,

68
00:02:35,694 --> 00:02:37,927
as well as a simple two-layer neural network.

69
00:02:37,927 --> 00:02:39,410
And we'll cover all this content

70
00:02:39,410 --> 00:02:42,160
over the next couple of lectures.

71
00:02:43,112 --> 00:02:46,168
So, all of our assignments are using Python and NumPy.

72
00:02:46,168 --> 00:02:49,229
If you aren't familiar with Python or NumPy,

73
00:02:49,229 --> 00:02:51,608
then we have written a tutorial that you can find

74
00:02:51,608 --> 00:02:54,312
on the course website to try and get you up to speed.

75
00:02:54,312 --> 00:02:56,856
But, this is, actually, pretty important.

76
00:02:56,856 --> 00:02:59,211
NumPy lets you write these very efficient vectorized

77
00:02:59,211 --> 00:03:02,236
operations that let you do quite a lot of computation

78
00:03:02,236 --> 00:03:03,856
in just a couple lines of code.

79
00:03:03,856 --> 00:03:06,081
So this is super important for pretty much

80
00:03:06,081 --> 00:03:09,087
all aspects of numerical computing and machine learning

81
00:03:09,087 --> 00:03:10,288
and everything like that,

82
00:03:10,288 --> 00:03:13,424
is efficiently implementing these vectorized operations.

83
00:03:13,424 --> 00:03:15,600
And you'll get a lot of practice with this

84
00:03:15,600 --> 00:03:16,964
on the first assignment.

85
00:03:16,964 --> 00:03:19,433
So, for those of you who don't have a lot of experience

86
00:03:19,433 --> 00:03:23,449
with Matlab or NumPy or other types of vectorized

87
00:03:23,449 --> 00:03:26,407
tensor computation, I recommend that you start looking

88
00:03:26,407 --> 00:03:27,606
at this assignment pretty early

89
00:03:27,606 --> 00:03:32,175
and also, read carefully through the tutorial.

90
00:03:32,175 --> 00:03:34,255
The other thing I wanted to talk about

91
00:03:34,255 --> 00:03:36,287
is that we're happy to announce that

92
00:03:36,287 --> 00:03:38,867
we're officially supported through Google Cloud

93
00:03:38,867 --> 00:03:40,198
for this class.

94
00:03:40,198 --> 00:03:43,630
So, Google Cloud is somewhat similar to Amazon AWS.

95
00:03:43,630 --> 00:03:46,694
You can go and start virtual machines up in the cloud.

96
00:03:46,694 --> 00:03:50,432
These virtual machines can have GPUs.

97
00:03:50,432 --> 00:03:53,197
We're working on the tutorial for exactly how to use

98
00:03:53,197 --> 00:03:55,386
Google Cloud and get it to work for the assignments.

99
00:03:55,386 --> 00:03:58,517
But our intention is that you'll be able to just download

100
00:03:58,517 --> 00:04:00,776
some image, and it'll be very seamless

101
00:04:00,776 --> 00:04:02,366
for you to work on the assignments

102
00:04:02,366 --> 00:04:04,723
on one of these instances on the cloud.

103
00:04:04,723 --> 00:04:07,086
And because Google has, very generously,

104
00:04:07,086 --> 00:04:08,437
supported this course,

105
00:04:08,437 --> 00:04:10,414
we'll be able to distribute to each of you

106
00:04:10,414 --> 00:04:14,122
coupons that let you use Google Cloud credits for free

107
00:04:14,122 --> 00:04:15,582
for the class.

108
00:04:15,582 --> 00:04:18,571
So you can feel free to use these for the assignments

109
00:04:18,571 --> 00:04:20,084
and also for the course projects

110
00:04:20,084 --> 00:04:22,607
when you want to start using GPUs and larger machines

111
00:04:22,607 --> 00:04:24,015
and whatnot.

112
00:04:24,015 --> 00:04:25,976
So, we'll post more details about that,

113
00:04:25,976 --> 00:04:28,023
probably, on Piazza later today.

114
00:04:28,023 --> 00:04:29,300
But, I just wanted to mention,

115
00:04:29,300 --> 00:04:31,241
because I know there had been a couple of questions

116
00:04:31,241 --> 00:04:33,369
about, can I use my laptop?

117
00:04:33,369 --> 00:04:34,389
Do I have to run on corn?

118
00:04:34,389 --> 00:04:35,566
Do I have to, whatever?

119
00:04:35,566 --> 00:04:37,607
And the answer is that, you'll be able to run on

120
00:04:37,607 --> 00:04:41,774
Google Cloud and we'll provide you some coupons for that.

121
00:04:43,923 --> 00:04:44,756
Yeah, so,

122
00:04:45,959 --> 00:04:47,818
those are, kind of, the major administrative issues

123
00:04:47,818 --> 00:04:49,716
I wanted to talk about today.

124
00:04:49,716 --> 00:04:53,681
And then, let's dive into the content.

125
00:04:53,681 --> 00:04:55,463
So, the last lecture we talked a little bit

126
00:04:55,463 --> 00:04:58,125
about this task of image classification,

127
00:04:58,125 --> 00:05:00,450
which is really a core task in computer vision.

128
00:05:00,450 --> 00:05:02,444
And this is something that we'll really focus on

129
00:05:02,444 --> 00:05:04,048
throughout the course of the class.

130
00:05:04,048 --> 00:05:04,964
Is, exactly,

131
00:05:04,964 --> 00:05:07,832
how do we work on this image classification task?

132
00:05:07,832 --> 00:05:09,750
So, a little bit more concretely,

133
00:05:09,750 --> 00:05:12,142
when you're doing image classification,

134
00:05:12,142 --> 00:05:14,259
your system receives some input image,

135
00:05:14,259 --> 00:05:16,457
which is this cute cat in this example,

136
00:05:16,457 --> 00:05:20,007
and the system is aware of some predetermined set

137
00:05:20,007 --> 00:05:22,455
of categories or labels.

138
00:05:22,455 --> 00:05:25,465
So, these might be, like, a dog or a cat or a truck

139
00:05:25,465 --> 00:05:29,134
or a plane, and there's some fixed set of category labels,

140
00:05:29,134 --> 00:05:31,292
and the job of the computer is to look at the picture

141
00:05:31,292 --> 00:05:34,831
and assign it one of these fixed category labels.

142
00:05:34,831 --> 00:05:36,444
This seems like a really easy problem,

143
00:05:36,444 --> 00:05:40,268
because so much of your own visual system in your brain

144
00:05:40,268 --> 00:05:42,480
is hardwired to doing these, sort of,

145
00:05:42,480 --> 00:05:44,346
visual recognition tasks.

146
00:05:44,346 --> 00:05:46,336
But this is actually a really, really hard problem

147
00:05:46,336 --> 00:05:48,232
for a machine.

148
00:05:48,232 --> 00:05:50,306
So, if you dig in and think about, actually,

149
00:05:50,306 --> 00:05:53,236
what does a computer see when it looks at this image,

150
00:05:53,236 --> 00:05:55,852
it definitely doesn't get this holistic idea of a cat

151
00:05:55,852 --> 00:05:57,428
that you see when you look at it.

152
00:05:57,428 --> 00:05:59,418
And the computer really is representing the image

153
00:05:59,418 --> 00:06:01,755
as this gigantic grid of numbers.

154
00:06:01,755 --> 00:06:05,922
So, the image might be something like 800 by 600 pixels.

155
00:06:07,371 --> 00:06:10,135
And each pixel is represented by three numbers,

156
00:06:10,135 --> 00:06:13,176
giving the red, green, and blue values for that pixel.

157
00:06:13,176 --> 00:06:14,106
So, to the computer,

158
00:06:14,106 --> 00:06:15,769
this is just a gigantic grid of numbers.

159
00:06:15,769 --> 00:06:18,569
And it's very difficult to distill the cat-ness

160
00:06:18,569 --> 00:06:22,508
out of this, like, giant array of thousands, or whatever,

161
00:06:22,508 --> 00:06:24,841
very many different numbers.

162
00:06:26,956 --> 00:06:30,186
So, we refer to this problem as the semantic gap.

163
00:06:30,186 --> 00:06:32,735
This idea of a cat, or this label of a cat,

164
00:06:32,735 --> 00:06:35,462
is a semantic label that we're assigning to this image,

165
00:06:35,462 --> 00:06:38,771
and there's this huge gap between the semantic idea of a cat

166
00:06:38,771 --> 00:06:42,897
and these pixel values that the computer is actually seeing.

167
00:06:42,897 --> 00:06:45,503
And this is a really hard problem because

168
00:06:45,503 --> 00:06:48,901
you can change the picture in very small, subtle ways

169
00:06:48,901 --> 00:06:51,916
that will cause this pixel grid to change entirely.

170
00:06:51,916 --> 00:06:54,038
So, for example, if we took this same cat,

171
00:06:54,038 --> 00:06:55,622
and if the cat happened to sit still

172
00:06:55,622 --> 00:06:57,352
and not even twitch, not move a muscle,

173
00:06:57,352 --> 00:06:58,782
which is never going to happen,

174
00:06:58,782 --> 00:07:01,077
but we moved the camera to the other side,

175
00:07:01,077 --> 00:07:04,050
then every single grid, every single pixel,

176
00:07:04,050 --> 00:07:05,620
in this giant grid of numbers

177
00:07:05,620 --> 00:07:06,921
would be completely different.

178
00:07:06,921 --> 00:07:09,431
But, somehow, it's still representing the same cat.

179
00:07:09,431 --> 00:07:12,754
And our algorithms need to be robust to this.

180
00:07:12,754 --> 00:07:15,131
But, not only viewpoint is one problem,

181
00:07:15,131 --> 00:07:16,260
another is illumination.

182
00:07:16,260 --> 00:07:18,124
There can be different lighting conditions going on

183
00:07:18,124 --> 00:07:19,298
in the scene.

184
00:07:19,298 --> 00:07:22,500
Whether the cat is appearing in this very dark, moody scene,

185
00:07:22,500 --> 00:07:25,520
or like is this very bright, sunlit scene, it's still a cat,

186
00:07:25,520 --> 00:07:28,488
and our algorithms need to be robust to that.

187
00:07:28,488 --> 00:07:30,145
Objects can also deform.

188
00:07:30,145 --> 00:07:32,355
I think cats are, maybe, among the more deformable

189
00:07:32,355 --> 00:07:34,549
of animals that you might see out there.

190
00:07:34,549 --> 00:07:37,825
And cats can really assume a lot of different, varied poses

191
00:07:37,825 --> 00:07:38,940
and positions.

192
00:07:38,940 --> 00:07:40,774
And our algorithms should be robust to these different

193
00:07:40,774 --> 00:07:42,441
kinds of transforms.

194
00:07:43,442 --> 00:07:45,823
There can also be problems of occlusion,

195
00:07:45,823 --> 00:07:49,762
where you might only see part of a cat, like, just the face,

196
00:07:49,762 --> 00:07:51,865
or in this extreme example, just a tail peeking out

197
00:07:51,865 --> 00:07:53,686
from under the couch cushion.

198
00:07:53,686 --> 00:07:56,626
But, in these cases, it's pretty easy for you, as a person,

199
00:07:56,626 --> 00:07:58,897
to realize that this is probably a cat,

200
00:07:58,897 --> 00:08:01,532
and you still recognize these images as cats.

201
00:08:01,532 --> 00:08:03,929
And this is something that our algorithms

202
00:08:03,929 --> 00:08:05,659
also must be robust to,

203
00:08:05,659 --> 00:08:08,460
which is quite difficult, I think.

204
00:08:08,460 --> 00:08:10,792
There can also be problems of background clutter,

205
00:08:10,792 --> 00:08:13,329
where maybe the foreground object of the cat,

206
00:08:13,329 --> 00:08:15,582
could actually look quite similar in appearance

207
00:08:15,582 --> 00:08:16,677
to the background.

208
00:08:16,677 --> 00:08:20,389
And this is another thing that we need to handle.

209
00:08:20,389 --> 00:08:23,637
There's also this problem of intraclass variation,

210
00:08:23,637 --> 00:08:26,776
that this one notion of cat-ness, actually spans a lot of

211
00:08:26,776 --> 00:08:28,455
different visual appearances.

212
00:08:28,455 --> 00:08:30,340
And cats can come in different shapes and sizes

213
00:08:30,340 --> 00:08:32,158
and colors and ages.

214
00:08:32,158 --> 00:08:34,154
And our algorithm, again, needs to work

215
00:08:34,154 --> 00:08:36,345
and handle all these different variations.

216
00:08:36,345 --> 00:08:40,033
So, this is actually a really, really challenging problem.

217
00:08:40,033 --> 00:08:43,402
And it's sort of easy to forget how easy this is

218
00:08:43,402 --> 00:08:46,264
because so much of your brain is specifically tuned

219
00:08:46,264 --> 00:08:47,931
for dealing with these things.

220
00:08:47,931 --> 00:08:49,604
But now if we want our computer programs

221
00:08:49,604 --> 00:08:52,590
to deal with all of these problems, all simultaneously,

222
00:08:52,590 --> 00:08:54,288
and not just for cats, by the way,

223
00:08:54,288 --> 00:08:56,832
but for just about any object category you can imagine,

224
00:08:56,832 --> 00:08:59,052
this is a fantastically challenging problem.

225
00:08:59,052 --> 00:09:00,686
And it's, actually, somewhat miraculous

226
00:09:00,686 --> 00:09:03,078
that this works at all, in my opinion.

227
00:09:03,078 --> 00:09:04,703
But, actually, not only does it work,

228
00:09:04,703 --> 00:09:07,285
but these things work very close to human accuracy

229
00:09:07,285 --> 00:09:09,278
in some limited situations.

230
00:09:09,278 --> 00:09:12,379
And take only hundreds of milliseconds to do so.

231
00:09:12,379 --> 00:09:14,921
So, this is some pretty amazing, incredible technology,

232
00:09:14,921 --> 00:09:18,418
in my opinion, and over the course of the rest of the class

233
00:09:18,418 --> 00:09:20,241
we will really see what kinds of advancements

234
00:09:20,241 --> 00:09:22,241
have made this possible.

235
00:09:23,492 --> 00:09:24,728
So now, if you, kind of, think about

236
00:09:24,728 --> 00:09:27,565
what is the API for writing an image classifier,

237
00:09:27,565 --> 00:09:30,098
you might sit down and try to write a method in Python

238
00:09:30,098 --> 00:09:31,131
like this.

239
00:09:31,131 --> 00:09:32,739
Where you want to take in an image

240
00:09:32,739 --> 00:09:34,401
and then do some crazy magic

241
00:09:34,401 --> 00:09:36,185
and then, eventually, spit out this class label

242
00:09:36,185 --> 00:09:38,180
to say cat or dog or whatnot.

243
00:09:38,180 --> 00:09:41,695
And there's really no obvious way to do this, right?

244
00:09:41,695 --> 00:09:43,476
If you're taking an algorithms class

245
00:09:43,476 --> 00:09:44,981
and your task is to sort numbers

246
00:09:44,981 --> 00:09:46,837
or compute a convex hull

247
00:09:46,837 --> 00:09:49,535
or, even, do something like RSA encryption,

248
00:09:49,535 --> 00:09:51,584
you, sort of, can write down an algorithm

249
00:09:51,584 --> 00:09:53,725
and enumerate all the steps that need to happen

250
00:09:53,725 --> 00:09:55,773
in order for this things to work.

251
00:09:55,773 --> 00:09:58,325
But, when we're trying to recognize objects,

252
00:09:58,325 --> 00:10:00,390
or recognize cats or images,

253
00:10:00,390 --> 00:10:02,838
there's no really clear, explicit algorithm

254
00:10:02,838 --> 00:10:04,810
that makes intuitive sense,

255
00:10:04,810 --> 00:10:07,909
for how you might go about recognizing these objects.

256
00:10:07,909 --> 00:10:09,874
So, this is, again, quite challenging,

257
00:10:09,874 --> 00:10:12,163
if you think about,

258
00:10:12,163 --> 00:10:13,447
if it was your first day programming

259
00:10:13,447 --> 00:10:15,464
and you had to sit down and write this function,

260
00:10:15,464 --> 00:10:18,869
I think most people would be in trouble.

261
00:10:18,869 --> 00:10:19,740
That being said,

262
00:10:19,740 --> 00:10:21,907
people have definitely made explicit attempts

263
00:10:21,907 --> 00:10:25,029
to try to write, sort of, high-end coded rules

264
00:10:25,029 --> 00:10:27,004
for recognizing different animals.

265
00:10:27,004 --> 00:10:29,193
So, we touched on this a little bit in the last lecture,

266
00:10:29,193 --> 00:10:32,095
but maybe one idea for cats is that,

267
00:10:32,095 --> 00:10:35,596
we know that cats have ears and eyes and mouths and noses.

268
00:10:35,596 --> 00:10:37,945
And we know that edges, from Hubel and Wiesel,

269
00:10:37,945 --> 00:10:39,512
we know that edges are pretty important

270
00:10:39,512 --> 00:10:41,641
when it comes to visual recognition.

271
00:10:41,641 --> 00:10:43,820
So one thing we might try to do is

272
00:10:43,820 --> 00:10:45,425
compute the edges of this image

273
00:10:45,425 --> 00:10:47,543
and then go in and try to categorize all the different

274
00:10:47,543 --> 00:10:50,983
corners and boundaries, and say that, if we have maybe

275
00:10:50,983 --> 00:10:53,146
three lines meeting this way, then it might be a corner,

276
00:10:53,146 --> 00:10:55,186
and an ear has one corner here and one corner there

277
00:10:55,186 --> 00:10:56,483
and one corner there,

278
00:10:56,483 --> 00:10:59,076
and then, kind of, write down this explicit set of rules

279
00:10:59,076 --> 00:11:01,608
for recognizing cats.

280
00:11:01,608 --> 00:11:04,391
But this turns out not to work very well.

281
00:11:04,391 --> 00:11:06,127
One, it's super brittle.

282
00:11:06,127 --> 00:11:09,013
And, two, say, if you want to start over for another

283
00:11:09,013 --> 00:11:11,876
object category, and maybe not worry about cats,

284
00:11:11,876 --> 00:11:15,005
but talk about trucks or dogs or fishes or something else,

285
00:11:15,005 --> 00:11:17,081
then you need to start all over again.

286
00:11:17,081 --> 00:11:19,853
So, this is really not a very scalable approach.

287
00:11:19,853 --> 00:11:22,579
We want to come up with some algorithm, or some method,

288
00:11:22,579 --> 00:11:25,181
for these recognition tasks

289
00:11:25,181 --> 00:11:27,360
which scales much more naturally to all the variety

290
00:11:27,360 --> 00:11:29,360
of objects in the world.

291
00:11:31,311 --> 00:11:34,766
So, the insight that, sort of, makes this all work

292
00:11:34,766 --> 00:11:38,092
is this idea of the data-driven approach.

293
00:11:38,092 --> 00:11:41,046
Rather than sitting down and writing these hand-specified

294
00:11:41,046 --> 00:11:44,340
rules to try to craft exactly what is a cat or a fish

295
00:11:44,340 --> 00:11:45,766
or what have you,

296
00:11:45,766 --> 00:11:47,845
instead, we'll go out onto the internet

297
00:11:47,845 --> 00:11:51,313
and collect a large dataset of many, many cats

298
00:11:51,313 --> 00:11:53,524
and many, many airplanes and many, many deer

299
00:11:53,524 --> 00:11:55,402
and different things like this.

300
00:11:55,402 --> 00:11:58,075
And we can actually use tools like Google Image Search,

301
00:11:58,075 --> 00:11:59,138
or something like that,

302
00:11:59,138 --> 00:12:01,546
to go out and collect a very large number of examples

303
00:12:01,546 --> 00:12:03,866
of these different categories.

304
00:12:03,866 --> 00:12:06,203
By the way, this actually takes quite a lot of effort

305
00:12:06,203 --> 00:12:08,338
to go out and actually collect these datasets

306
00:12:08,338 --> 00:12:10,873
but, luckily, there's a lot of really good, high quality

307
00:12:10,873 --> 00:12:14,105
datasets out there already for you to use.

308
00:12:14,105 --> 00:12:16,073
Then once we get this dataset,

309
00:12:16,073 --> 00:12:18,536
we train this machine learning classifier

310
00:12:18,536 --> 00:12:20,869
that is going to ingest all of the data,

311
00:12:20,869 --> 00:12:22,339
summarize it in some way,

312
00:12:22,339 --> 00:12:23,733
and then spit out a model

313
00:12:23,733 --> 00:12:26,130
that summarizes the knowledge of how to recognize

314
00:12:26,130 --> 00:12:28,446
these different object categories.

315
00:12:28,446 --> 00:12:30,134
Then finally, we'll use this training model

316
00:12:30,134 --> 00:12:31,756
and apply it on new images

317
00:12:31,756 --> 00:12:33,601
that will then be able to recognize

318
00:12:33,601 --> 00:12:35,930
cats and dogs and whatnot.

319
00:12:35,930 --> 00:12:38,428
So here our API has changed a little bit.

320
00:12:38,428 --> 00:12:39,446
Rather than a single function

321
00:12:39,446 --> 00:12:42,099
that just inputs an image and recognizes a cat,

322
00:12:42,099 --> 00:12:43,621
we have these two functions.

323
00:12:43,621 --> 00:12:48,084
One, called, train, that's going to input images and labels

324
00:12:48,084 --> 00:12:49,115
and then output a model,

325
00:12:49,115 --> 00:12:52,030
and then, separately, another function called, predict,

326
00:12:52,030 --> 00:12:54,013
which will input the model and than make predictions

327
00:12:54,013 --> 00:12:55,276
for images.

328
00:12:55,276 --> 00:12:56,780
And this is, kind of, the key insight

329
00:12:56,780 --> 00:12:59,178
that allowed all these things to start working really well

330
00:12:59,178 --> 00:13:01,928
over the last 10, 20 years or so.

331
00:13:05,784 --> 00:13:08,096
So, this class is primarily about neural networks

332
00:13:08,096 --> 00:13:09,572
and convolutional neural networks

333
00:13:09,572 --> 00:13:11,111
and deep learning and all that,

334
00:13:11,111 --> 00:13:14,446
but this idea of a data-driven approach is much more general

335
00:13:14,446 --> 00:13:15,819
than just deep learning.

336
00:13:15,819 --> 00:13:17,832
And I think it's useful to, sort of,

337
00:13:17,832 --> 00:13:19,145
step through this process

338
00:13:19,145 --> 00:13:20,924
for a very simple classifier first,

339
00:13:20,924 --> 00:13:23,058
before we get to these big, complex ones.

340
00:13:23,058 --> 00:13:26,898
So, probably, the simplest classifier you can imagine

341
00:13:26,898 --> 00:13:28,907
is something we call nearest neighbor.

342
00:13:28,907 --> 00:13:31,243
The algorithm is pretty dumb, honestly.

343
00:13:31,243 --> 00:13:34,315
So, during the training step we won't do anything,

344
00:13:34,315 --> 00:13:36,966
we'll just memorize all of the training data.

345
00:13:36,966 --> 00:13:39,108
So this is very simple.

346
00:13:39,108 --> 00:13:41,006
And now, during the prediction step,

347
00:13:41,006 --> 00:13:43,191
we're going to take some new image

348
00:13:43,191 --> 00:13:45,597
and go and try to find the most similar image

349
00:13:45,597 --> 00:13:47,964
in the training data to that new image,

350
00:13:47,964 --> 00:13:51,453
and now predict the label of that most similar image.

351
00:13:51,453 --> 00:13:53,169
A very simple algorithm.

352
00:13:53,169 --> 00:13:55,104
But it, sort of, has a lot of these nice properties

353
00:13:55,104 --> 00:13:58,771
with respect to data-drivenness and whatnot.

354
00:13:59,977 --> 00:14:01,680
So, to be a little bit more concrete,

355
00:14:01,680 --> 00:14:04,951
you might imagine working on this dataset called CIFAR-10,

356
00:14:04,951 --> 00:14:07,331
which is very commonly used in machine learning,

357
00:14:07,331 --> 00:14:09,259
as kind of a small test case.

358
00:14:09,259 --> 00:14:11,579
And you'll be working with this dataset on your homework.

359
00:14:11,579 --> 00:14:15,159
So, the CIFAR-10 dataset gives you 10 different classes,

360
00:14:15,159 --> 00:14:17,965
airplanes and automobiles and birds and cats and different

361
00:14:17,965 --> 00:14:19,920
things like that.

362
00:14:19,920 --> 00:14:22,073
And for each of those 10 categories

363
00:14:22,073 --> 00:14:24,990
it provides 50,000 training images,

364
00:14:27,173 --> 00:14:30,250
roughly evenly distributed across these 10 categories.

365
00:14:30,250 --> 00:14:33,648
And then 10,000 additional testing images

366
00:14:33,648 --> 00:14:37,565
that you're supposed to test your algorithm on.

367
00:14:38,707 --> 00:14:41,265
So here's an example of applying this simple

368
00:14:41,265 --> 00:14:44,003
nearest neighbor classifier to some of these test images

369
00:14:44,003 --> 00:14:45,741
on CIFAR-10.

370
00:14:45,741 --> 00:14:48,703
So, on this grid on the right,

371
00:14:48,703 --> 00:14:50,863
for the left most column,

372
00:14:50,863 --> 00:14:53,693
gives a test image in the CIFAR-10 dataset.

373
00:14:53,693 --> 00:14:58,375
And now on the right, we've sorted the training images

374
00:14:58,375 --> 00:15:01,328
and show the most similar training images

375
00:15:01,328 --> 00:15:03,571
to each of these test examples.

376
00:15:03,571 --> 00:15:05,878
And you can see that they look kind of visually similar

377
00:15:05,878 --> 00:15:07,938
to the training images,

378
00:15:07,938 --> 00:15:10,974
although they are not always correct, right?

379
00:15:10,974 --> 00:15:13,407
So, maybe on the second row, we see that the testing,

380
00:15:13,407 --> 00:15:14,687
this is kind of hard to see,

381
00:15:14,687 --> 00:15:17,340
because these images are 32 by 32 pixels,

382
00:15:17,340 --> 00:15:18,768
you need to really dive in there

383
00:15:18,768 --> 00:15:21,224
and try to make your best guess.

384
00:15:21,224 --> 00:15:23,850
But, this image is a dog and it's nearest neighbor is also

385
00:15:23,850 --> 00:15:28,072
a dog, but this next one, I think is actually a deer

386
00:15:28,072 --> 00:15:30,006
or a horse or something else.

387
00:15:30,006 --> 00:15:33,237
But, you can see that it looks quite visually similar,

388
00:15:33,237 --> 00:15:34,773
because there's kind of a white blob in the middle

389
00:15:34,773 --> 00:15:36,370
and whatnot.

390
00:15:36,370 --> 00:15:38,630
So, if we're applying the nearest neighbor algorithm

391
00:15:38,630 --> 00:15:39,651
to this image,

392
00:15:39,651 --> 00:15:42,707
we'll find the closest example in the training set.

393
00:15:42,707 --> 00:15:45,107
And now, the closest example, we know it's label,

394
00:15:45,107 --> 00:15:47,135
because it comes from the training set.

395
00:15:47,135 --> 00:15:49,735
And now, we'll simply say that this testing image is also

396
00:15:49,735 --> 00:15:50,875
a dog.

397
00:15:50,875 --> 00:15:53,946
You can see from these examples that is probably not

398
00:15:53,946 --> 00:15:55,851
going to work very well,

399
00:15:55,851 --> 00:16:00,018
but it's still kind of a nice example to work through.

400
00:16:00,939 --> 00:16:03,724
But then, one detail that we need to know is,

401
00:16:03,724 --> 00:16:05,013
given a pair of images,

402
00:16:05,013 --> 00:16:06,908
how can we actually compare them?

403
00:16:06,908 --> 00:16:09,152
Because, if we're going to take our test image and compare it

404
00:16:09,152 --> 00:16:10,573
to all the training images,

405
00:16:10,573 --> 00:16:12,165
we actually have many different choices

406
00:16:12,165 --> 00:16:15,640
for exactly what that comparison function should look like.

407
00:16:15,640 --> 00:16:17,687
So, in the example in the previous slide,

408
00:16:17,687 --> 00:16:20,008
we've used what's called the L1 distance,

409
00:16:20,008 --> 00:16:22,547
also sometimes called the Manhattan distance.

410
00:16:22,547 --> 00:16:25,725
So, this is a really sort of simple, easy idea

411
00:16:25,725 --> 00:16:27,448
for comparing images.

412
00:16:27,448 --> 00:16:31,691
And that's that we're going to just compare individual pixels

413
00:16:31,691 --> 00:16:32,969
in these images.

414
00:16:32,969 --> 00:16:36,519
So, supposing that our test image is maybe just a tiny

415
00:16:36,519 --> 00:16:39,346
four by four image of pixel values,

416
00:16:39,346 --> 00:16:41,802
then we're take this upper-left hand pixel

417
00:16:41,802 --> 00:16:43,172
of the test image,

418
00:16:43,172 --> 00:16:45,077
subtract off the value in the training image,

419
00:16:45,077 --> 00:16:46,242
take the absolute value,

420
00:16:46,242 --> 00:16:49,068
and get the difference in that pixel between the two images.

421
00:16:49,068 --> 00:16:50,916
And then, sum all these up across all the pixels

422
00:16:50,916 --> 00:16:51,950
in the image.

423
00:16:51,950 --> 00:16:54,213
So, this is kind of a stupid way to compare images,

424
00:16:54,213 --> 00:16:57,963
but it does some reasonable things sometimes.

425
00:16:57,963 --> 00:16:59,535
But, this gives us a very concrete way

426
00:16:59,535 --> 00:17:01,991
to measure the difference between two images.

427
00:17:01,991 --> 00:17:05,064
And in this case, we have this difference of 456

428
00:17:05,064 --> 00:17:07,147
between these two images.

429
00:17:08,447 --> 00:17:10,945
So, here's some full Python code

430
00:17:10,945 --> 00:17:13,234
for implementing this nearest neighbor classifier

431
00:17:13,234 --> 00:17:16,583
and you can see it's pretty short and pretty concise

432
00:17:16,583 --> 00:17:18,804
because we've made use of many of these vectorized

433
00:17:18,804 --> 00:17:21,349
operations offered by NumPy.

434
00:17:21,349 --> 00:17:25,079
So, here we can see that this training function,

435
00:17:25,079 --> 00:17:26,247
that we talked about earlier,

436
00:17:26,247 --> 00:17:28,946
is, again, very simple, in the case of nearest neighbor,

437
00:17:28,946 --> 00:17:30,573
you just memorize the training data,

438
00:17:30,573 --> 00:17:33,427
there's not really much to do here.

439
00:17:33,427 --> 00:17:35,869
And now, at test time, we're going to take in our image

440
00:17:35,869 --> 00:17:39,126
and then go in and compare using this L1 distance function,

441
00:17:39,126 --> 00:17:41,984
our test image to each of these training examples

442
00:17:41,984 --> 00:17:45,395
and find the most similar example in the training set.

443
00:17:45,395 --> 00:17:47,371
And you can see that, we're actually able to do this

444
00:17:47,371 --> 00:17:50,113
in just one or two lines of Python code

445
00:17:50,113 --> 00:17:53,882
by utilizing these vectorized operations in NumPy.

446
00:17:53,882 --> 00:17:55,779
So, this is something that you'll get practice with

447
00:17:55,779 --> 00:17:57,779
on the first assignment.

448
00:17:58,628 --> 00:18:02,179
So now, a couple questions about this simple classifier.

449
00:18:02,179 --> 00:18:04,910
First, if we have N examples in our training set,

450
00:18:04,910 --> 00:18:09,077
then how fast can we expect training and testing to be?

451
00:18:12,233 --> 00:18:13,998
Well, training is probably constant

452
00:18:13,998 --> 00:18:15,712
because we don't really need to do anything,

453
00:18:15,712 --> 00:18:17,878
we just need to memorize the data.

454
00:18:17,878 --> 00:18:19,241
And if you're just copying a pointer,

455
00:18:19,241 --> 00:18:20,663
that's going to be constant time

456
00:18:20,663 --> 00:18:22,703
no matter how big your dataset is.

457
00:18:22,703 --> 00:18:26,209
But now, at test time we need to do this comparison stop

458
00:18:26,209 --> 00:18:27,679
and compare our test image

459
00:18:27,679 --> 00:18:31,099
to each of the N training examples in the dataset.

460
00:18:31,099 --> 00:18:33,766
And this is actually quite slow.

461
00:18:34,991 --> 00:18:37,448
So, this is actually somewhat backwards,

462
00:18:37,448 --> 00:18:38,641
if you think about it.

463
00:18:38,641 --> 00:18:40,350
Because, in practice,

464
00:18:40,350 --> 00:18:43,489
we want our classifiers to be slow at training time

465
00:18:43,489 --> 00:18:45,326
and then fast at testing time.

466
00:18:45,326 --> 00:18:47,858
Because, you might imagine, that a classifier might go

467
00:18:47,858 --> 00:18:49,882
and be trained in a data center somewhere

468
00:18:49,882 --> 00:18:52,045
and you can afford to spend a lot of computation

469
00:18:52,045 --> 00:18:54,640
at training time to make the classifier really good.

470
00:18:54,640 --> 00:18:55,473
But then,

471
00:18:55,473 --> 00:18:57,566
when you go and deploy the classifier at test time,

472
00:18:57,566 --> 00:18:59,503
you want it to run on your mobile phone

473
00:18:59,503 --> 00:19:02,248
or in a browser or some other low power device,

474
00:19:02,248 --> 00:19:04,493
and you really want the testing time performance

475
00:19:04,493 --> 00:19:07,075
of your classifier to be quite fast.

476
00:19:07,075 --> 00:19:09,929
So, from this perspective, this nearest neighbor algorithm,

477
00:19:09,929 --> 00:19:11,826
is, actually, a little bit backwards.

478
00:19:11,826 --> 00:19:13,591
And we'll see that once we move to

479
00:19:13,591 --> 00:19:14,720
convolutional neural networks,

480
00:19:14,720 --> 00:19:16,420
and other types of parametric models,

481
00:19:16,420 --> 00:19:18,286
they'll be the reverse of this.

482
00:19:18,286 --> 00:19:20,226
Where you'll spend a lot of compute at training time,

483
00:19:20,226 --> 00:19:24,936
but then they'll be quite fast at testing time.

484
00:19:24,936 --> 00:19:25,969
So then, the question is,

485
00:19:25,969 --> 00:19:28,139
what exactly does this nearest neighbor algorithm

486
00:19:28,139 --> 00:19:30,816
look like when you apply it in practice?

487
00:19:30,816 --> 00:19:34,049
So, here we've drawn, what we call the decision regions

488
00:19:34,049 --> 00:19:36,130
of a nearest neighbor classifier.

489
00:19:36,130 --> 00:19:39,636
So, here our training set consists of these points

490
00:19:39,636 --> 00:19:42,021
in the two dimensional plane,

491
00:19:42,021 --> 00:19:45,388
where the color of the point represents the category,

492
00:19:45,388 --> 00:19:47,547
or the class label, of that point.

493
00:19:47,547 --> 00:19:49,221
So, here we see we have five classes

494
00:19:49,221 --> 00:19:51,543
and some blue ones up in the corner here,

495
00:19:51,543 --> 00:19:53,921
some purple ones in the upper-right hand corner.

496
00:19:53,921 --> 00:19:56,491
And now for each pixel in this entire plane,

497
00:19:56,491 --> 00:20:00,860
we've gone and computed what is the nearest example

498
00:20:00,860 --> 00:20:02,560
in these training data,

499
00:20:02,560 --> 00:20:04,391
and then colored the point of the background

500
00:20:04,391 --> 00:20:06,954
corresponding to what is the class label.

501
00:20:06,954 --> 00:20:09,049
So, you can see that this nearest neighbor classifier

502
00:20:09,049 --> 00:20:11,032
is just sort of carving up the space

503
00:20:11,032 --> 00:20:14,979
and coloring the space according to the nearby points.

504
00:20:14,979 --> 00:20:18,320
But this classifier is maybe not so great.

505
00:20:18,320 --> 00:20:20,002
And by looking at this picture

506
00:20:20,002 --> 00:20:22,568
we can start to see some of the problems that might come out

507
00:20:22,568 --> 00:20:24,676
with a nearest neighbor classifier.

508
00:20:24,676 --> 00:20:27,487
For one, this central region actually contains

509
00:20:27,487 --> 00:20:29,208
mostly green points,

510
00:20:29,208 --> 00:20:31,591
but one little yellow point in the middle.

511
00:20:31,591 --> 00:20:34,406
But because we're just looking at the nearest neighbor,

512
00:20:34,406 --> 00:20:36,411
this causes a little yellow island to appear

513
00:20:36,411 --> 00:20:38,552
in this middle of this green cluster.

514
00:20:38,552 --> 00:20:40,087
And that's, maybe, not so great.

515
00:20:40,087 --> 00:20:44,081
Maybe those points actually should have been green.

516
00:20:44,081 --> 00:20:47,990
And then, similarly we also see these, sort of, fingers,

517
00:20:47,990 --> 00:20:50,225
like the green region pushing into the blue region,

518
00:20:50,225 --> 00:20:52,450
again, due to the presence of one point,

519
00:20:52,450 --> 00:20:55,180
which may have been noisy or spurious.

520
00:20:55,180 --> 00:20:58,205
So, this kind of motivates a slight generalization

521
00:20:58,205 --> 00:21:01,606
of this algorithm called k-nearest neighbors.

522
00:21:01,606 --> 00:21:05,070
So rather than just looking for the single nearest neighbor,

523
00:21:05,070 --> 00:21:08,021
instead we'll do something a little bit fancier

524
00:21:08,021 --> 00:21:10,627
and find K of our nearest neighbors,

525
00:21:10,627 --> 00:21:12,240
according to our distance metric,

526
00:21:12,240 --> 00:21:15,057
and then take a vote among each of our neighbors.

527
00:21:15,057 --> 00:21:16,708
And then predict the majority vote

528
00:21:16,708 --> 00:21:18,733
among our neighbors.

529
00:21:18,733 --> 00:21:21,032
You can imagine slightly more complex ways of doing this.

530
00:21:21,032 --> 00:21:22,919
Maybe you'd vote weighted on the distance,

531
00:21:22,919 --> 00:21:24,148
or something like that,

532
00:21:24,148 --> 00:21:27,912
but the simplest thing that tends to work pretty well

533
00:21:27,912 --> 00:21:29,810
is just taking a majority vote.

534
00:21:29,810 --> 00:21:32,810
So here we've shown the exact same set of points

535
00:21:32,810 --> 00:21:35,899
using this K=1 nearest neighbor classifier,

536
00:21:35,899 --> 00:21:39,928
as well as K=3 and K=5 in the middle and on the right.

537
00:21:39,928 --> 00:21:43,792
And once we move to K=3, you can see that that spurious

538
00:21:43,792 --> 00:21:46,186
yellow point in the middle of the green cluster

539
00:21:46,186 --> 00:21:49,369
is no longer causing the points near that region

540
00:21:49,369 --> 00:21:50,966
to be classified as yellow.

541
00:21:50,966 --> 00:21:53,684
Now this entire green portion in the middle

542
00:21:53,684 --> 00:21:55,852
is all being classified as green.

543
00:21:55,852 --> 00:21:57,737
You can also see that these fingers

544
00:21:57,737 --> 00:21:59,272
of the red and blue regions

545
00:21:59,272 --> 00:22:00,823
are starting to get smoothed out

546
00:22:00,823 --> 00:22:02,454
due to this majority voting.

547
00:22:02,454 --> 00:22:05,381
And then, once we move to the K=5 case,

548
00:22:05,381 --> 00:22:06,900
then these decision boundaries

549
00:22:06,900 --> 00:22:08,437
between the blue and red regions

550
00:22:08,437 --> 00:22:12,064
have become quite smooth and quite nice.

551
00:22:12,064 --> 00:22:13,818
So, generally when you're using nearest neighbors

552
00:22:13,818 --> 00:22:14,727
classifiers,

553
00:22:14,727 --> 00:22:18,718
you almost always want to use some value of K,

554
00:22:18,718 --> 00:22:20,771
which is larger than one

555
00:22:20,771 --> 00:22:22,897
because this tends to smooth out your decision

556
00:22:22,897 --> 00:22:26,064
boundaries and lead to better results.

557
00:22:29,252 --> 00:22:30,159
Question?

558
00:22:30,159 --> 00:22:34,279
[student asking a question]

559
00:22:34,279 --> 00:22:35,208
Yes, so the question is,

560
00:22:35,208 --> 00:22:38,133
what is the deal with these white regions?

561
00:22:38,133 --> 00:22:41,025
The white regions are where there was no majority

562
00:22:41,025 --> 00:22:43,247
among the k-nearest neighbors.

563
00:22:43,247 --> 00:22:45,521
You could imagine maybe doing something slightly fancier

564
00:22:45,521 --> 00:22:48,972
and maybe taking a guess or randomly selecting among

565
00:22:48,972 --> 00:22:50,472
the majority winners,

566
00:22:50,472 --> 00:22:52,729
but for this simple example we're just coloring it white

567
00:22:52,729 --> 00:22:54,335
to indicate there was no nearest neighbor

568
00:22:54,335 --> 00:22:55,668
in those points.

569
00:23:00,005 --> 00:23:02,439
Whenever we're thinking about computer vision

570
00:23:02,439 --> 00:23:04,225
I think it's really useful to kind of flip

571
00:23:04,225 --> 00:23:06,616
back and forth between several different viewpoints.

572
00:23:06,616 --> 00:23:09,480
One, is this idea of high dimensional points in the plane,

573
00:23:09,480 --> 00:23:13,049
and then the other is actually looking at concrete images.

574
00:23:13,049 --> 00:23:15,118
Because the pixels of the image actually

575
00:23:15,118 --> 00:23:18,185
allow us to think of these images as high dimensional

576
00:23:18,185 --> 00:23:19,048
vectors.

577
00:23:19,048 --> 00:23:21,181
And it's sort of useful to ping pong back and forth

578
00:23:21,181 --> 00:23:23,395
between these two different viewpoints.

579
00:23:23,395 --> 00:23:26,193
So then, sort of taking this k-nearest neighbor

580
00:23:26,193 --> 00:23:27,876
and going back to the images

581
00:23:27,876 --> 00:23:29,443
you can see that it's actually not very good.

582
00:23:29,443 --> 00:23:31,216
Here I've colored in red and green

583
00:23:31,216 --> 00:23:33,265
which images would actually be classified correctly

584
00:23:33,265 --> 00:23:35,385
or incorrectly according to their nearest neighbor.

585
00:23:35,385 --> 00:23:38,288
And you can see that it's really not very good.

586
00:23:38,288 --> 00:23:41,459
But maybe if we used a larger value of K

587
00:23:41,459 --> 00:23:43,690
then this would involve actually voting among

588
00:23:43,690 --> 00:23:45,586
maybe the top three or the top five

589
00:23:45,586 --> 00:23:47,264
or maybe even the whole row.

590
00:23:47,264 --> 00:23:48,806
And you could imagine that that would end up being

591
00:23:48,806 --> 00:23:52,158
a lot more robust to some of this noise that we see

592
00:23:52,158 --> 00:23:55,325
when retrieving neighbors in this way.

593
00:23:57,070 --> 00:23:59,803
So another choice we have when we're working

594
00:23:59,803 --> 00:24:01,666
with the k-nearest neighbor algorithm

595
00:24:01,666 --> 00:24:04,187
is determining exactly how we should be comparing

596
00:24:04,187 --> 00:24:05,727
our different points.

597
00:24:05,727 --> 00:24:09,624
For the examples so far we've just shown

598
00:24:09,624 --> 00:24:11,666
we've talked about this L1 distance

599
00:24:11,666 --> 00:24:13,522
which takes the sum of the absolute values

600
00:24:13,522 --> 00:24:15,126
between the pixels.

601
00:24:15,126 --> 00:24:18,299
But another common choice is the L2 or Euclidean distance

602
00:24:18,299 --> 00:24:21,266
where you take the square root of the sum of the squares

603
00:24:21,266 --> 00:24:24,491
and take this as your distance.

604
00:24:24,491 --> 00:24:26,588
Choosing different distance metrics actually

605
00:24:26,588 --> 00:24:28,727
is a pretty interesting topic

606
00:24:28,727 --> 00:24:30,072
because different distance metrics

607
00:24:30,072 --> 00:24:32,266
make different assumptions about the underlying

608
00:24:32,266 --> 00:24:35,386
geometry or topology that you'd expect in the space.

609
00:24:35,386 --> 00:24:39,103
So, this L1 distance, underneath this, this is actually

610
00:24:39,103 --> 00:24:41,688
a circle according to the L1 distance

611
00:24:41,688 --> 00:24:43,487
and it forms this square shape thing

612
00:24:43,487 --> 00:24:45,020
around the origin.

613
00:24:45,020 --> 00:24:47,637
Where each of the points on this, on the square,

614
00:24:47,637 --> 00:24:51,017
is equidistant from the origin according to L1,

615
00:24:51,017 --> 00:24:53,116
whereas with the L2 or Euclidean distance

616
00:24:53,116 --> 00:24:55,290
then this circle is a familiar circle,

617
00:24:55,290 --> 00:24:57,241
it looks like what you'd expect.

618
00:24:57,241 --> 00:24:59,521
So one interesting thing to point out between these two

619
00:24:59,521 --> 00:25:00,798
metrics in particular,

620
00:25:00,798 --> 00:25:03,672
is that the L1 distance depends on your choice

621
00:25:03,672 --> 00:25:05,135
of coordinates system.

622
00:25:05,135 --> 00:25:07,306
So if you were to rotate the coordinate frame

623
00:25:07,306 --> 00:25:08,902
that would actually change the L1 distance

624
00:25:08,902 --> 00:25:10,201
between the points.

625
00:25:10,201 --> 00:25:13,287
Whereas changing the coordinate frame in the L2 distance

626
00:25:13,287 --> 00:25:15,491
doesn't matter, it's the same thing no matter what

627
00:25:15,491 --> 00:25:18,281
your coordinate frame is.

628
00:25:18,281 --> 00:25:21,721
Maybe if your input features, if the individual entries

629
00:25:21,721 --> 00:25:23,866
in your vector have some important meaning

630
00:25:23,866 --> 00:25:24,791
for your task,

631
00:25:24,791 --> 00:25:27,935
then maybe somehow L1 might be a more natural fit.

632
00:25:27,935 --> 00:25:30,533
But if it's just a generic vector in some space

633
00:25:30,533 --> 00:25:32,373
and you don't know which of the different elements,

634
00:25:32,373 --> 00:25:34,121
you don't know what they actually mean,

635
00:25:34,121 --> 00:25:37,531
then maybe L2 is slightly more natural.

636
00:25:37,531 --> 00:25:40,154
And another point here is that

637
00:25:40,154 --> 00:25:41,839
by using different distance metrics

638
00:25:41,839 --> 00:25:43,474
we can actually generalize the k-nearest neighbor

639
00:25:43,474 --> 00:25:46,343
classifier to many, many different types of data,

640
00:25:46,343 --> 00:25:48,280
not just vectors, not just images.

641
00:25:48,280 --> 00:25:51,410
So, for example, imagine you wanted to classify pieces

642
00:25:51,410 --> 00:25:54,073
of text, then the only thing you need to do

643
00:25:54,073 --> 00:25:55,366
to use k-nearest neighbors

644
00:25:55,366 --> 00:25:57,716
is to specify some distance function

645
00:25:57,716 --> 00:26:01,692
that can measure distances between maybe two paragraphs

646
00:26:01,692 --> 00:26:03,831
or two sentences or something like that.

647
00:26:03,831 --> 00:26:06,908
So, simply by specifying different distance metrics

648
00:26:06,908 --> 00:26:09,377
we can actually apply this algorithm very generally

649
00:26:09,377 --> 00:26:12,701
to basically any type of data.

650
00:26:12,701 --> 00:26:14,598
Even though it's a kind of simple algorithm,

651
00:26:14,598 --> 00:26:17,200
in general, it's a very good thing to try first

652
00:26:17,200 --> 00:26:20,283
when you're looking at a new problem.

653
00:26:21,805 --> 00:26:23,986
So then, it's also kind of interesting to think about

654
00:26:23,986 --> 00:26:25,854
what is actually happening geometrically

655
00:26:25,854 --> 00:26:28,441
if we choose different distance metrics.

656
00:26:28,441 --> 00:26:31,370
So here we see the same set of points on the left

657
00:26:31,370 --> 00:26:33,577
using the L1, or Manhattan distance,

658
00:26:33,577 --> 00:26:36,767
and then, on the right, using the familiar L2,

659
00:26:36,767 --> 00:26:38,087
or Euclidean distance.

660
00:26:38,087 --> 00:26:40,298
And you can see that the shapes of these decision

661
00:26:40,298 --> 00:26:42,476
boundaries actually change quite a bit

662
00:26:42,476 --> 00:26:44,093
between the two metrics.

663
00:26:44,093 --> 00:26:46,792
So when you're looking at L1 these decision boundaries

664
00:26:46,792 --> 00:26:49,337
tend to follow the coordinate axes.

665
00:26:49,337 --> 00:26:52,168
And this is again because the L1 depends on our choice

666
00:26:52,168 --> 00:26:53,451
of coordinate system.

667
00:26:53,451 --> 00:26:56,020
Where the L2 sort of doesn't really care about the

668
00:26:56,020 --> 00:26:57,544
coordinate axis, it just puts the boundaries

669
00:26:57,544 --> 00:27:00,294
where they should fall naturally.

670
00:27:04,161 --> 00:27:06,406
My confession is that each of these examples

671
00:27:06,406 --> 00:27:08,669
that I've shown you is actually from this interactive

672
00:27:08,669 --> 00:27:10,293
web demo that I built,

673
00:27:10,293 --> 00:27:12,918
where you can go and play with this k-nearest neighbor

674
00:27:12,918 --> 00:27:14,618
classifier on your own.

675
00:27:14,618 --> 00:27:17,938
And this is really hard to work on a projector screen.

676
00:27:17,938 --> 00:27:21,271
So maybe we'll do that on your own time.

677
00:27:26,820 --> 00:27:29,403
So, let's just go back to here.

678
00:27:32,951 --> 00:27:35,784
Man, this is kind of embarrassing.

679
00:28:07,103 --> 00:28:09,679
Okay, that was way more trouble than